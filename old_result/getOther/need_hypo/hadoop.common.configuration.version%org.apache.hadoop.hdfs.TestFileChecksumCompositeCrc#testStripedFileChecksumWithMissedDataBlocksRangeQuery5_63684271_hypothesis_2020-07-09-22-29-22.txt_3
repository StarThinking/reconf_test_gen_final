reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251584343-172.17.0.4-1594333777822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-5134e668-d573-4d8f-9971-5b8e0849e484,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-da341707-a45e-4567-be84-0a24ff5e390e,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-a45ff867-cf52-4ee3-8f22-f9c8ff62dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-938140cf-bfbe-409d-a9b7-2f1b3071f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-18639928-be6c-42a8-b4e0-b3cf4d689f61,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-85d59060-0b91-46cf-ba49-7ab18e3472fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-ec0ae7b3-b849-4a34-b998-603851503596,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-05ec9bf5-59ce-4acd-a0f9-3358a6985f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251584343-172.17.0.4-1594333777822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-5134e668-d573-4d8f-9971-5b8e0849e484,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-da341707-a45e-4567-be84-0a24ff5e390e,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-a45ff867-cf52-4ee3-8f22-f9c8ff62dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-938140cf-bfbe-409d-a9b7-2f1b3071f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-18639928-be6c-42a8-b4e0-b3cf4d689f61,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-85d59060-0b91-46cf-ba49-7ab18e3472fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-ec0ae7b3-b849-4a34-b998-603851503596,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-05ec9bf5-59ce-4acd-a0f9-3358a6985f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153521234-172.17.0.4-1594333878701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-ecf0d808-da9f-4451-9e1e-202c24f5e859,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-dce6b070-7a49-4f65-b478-7d1407a4f635,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-b9c73bea-a520-4b5c-9d30-d70b4f298847,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-978075d4-8563-40a3-a95c-ad6aa4287241,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-565e2855-5a30-43cc-80ca-3b7c2b5fddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-f8c8c2b6-4de5-4f10-8aea-b718c0bdc42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-c72b8d02-e6e0-4aad-bf5f-5dc0eec9d061,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-9afd31fd-7466-4ab1-807d-b18990a5d3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153521234-172.17.0.4-1594333878701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46226,DS-ecf0d808-da9f-4451-9e1e-202c24f5e859,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-dce6b070-7a49-4f65-b478-7d1407a4f635,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-b9c73bea-a520-4b5c-9d30-d70b4f298847,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-978075d4-8563-40a3-a95c-ad6aa4287241,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-565e2855-5a30-43cc-80ca-3b7c2b5fddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-f8c8c2b6-4de5-4f10-8aea-b718c0bdc42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-c72b8d02-e6e0-4aad-bf5f-5dc0eec9d061,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-9afd31fd-7466-4ab1-807d-b18990a5d3f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690040427-172.17.0.4-1594334174125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-e117322a-cfd8-488b-bb59-cbdf83d8983e,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-fbecc79b-71cd-41bd-9c41-57079f2c77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-a9d50ad3-42be-4411-8b44-bade7f3f85bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-67b7f4d9-738c-4923-8867-e9b8c5d0751b,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-adab3a61-e284-4a9e-a800-f2913ef0aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-f59aa416-7540-4a11-ba0d-93bb01588ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-6dea4daa-2f03-4e09-95b5-87423b3a2193,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-bbf5240e-ed15-46ec-8be5-060ed11a8a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690040427-172.17.0.4-1594334174125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-e117322a-cfd8-488b-bb59-cbdf83d8983e,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-fbecc79b-71cd-41bd-9c41-57079f2c77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-a9d50ad3-42be-4411-8b44-bade7f3f85bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-67b7f4d9-738c-4923-8867-e9b8c5d0751b,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-adab3a61-e284-4a9e-a800-f2913ef0aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-f59aa416-7540-4a11-ba0d-93bb01588ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-6dea4daa-2f03-4e09-95b5-87423b3a2193,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-bbf5240e-ed15-46ec-8be5-060ed11a8a79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379955191-172.17.0.4-1594334407557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-ebb85cd2-b33d-408c-80ee-93d41780b57e,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-4892574b-d3cf-41bb-998c-b73c65a67d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-caa63a1b-901f-4647-a423-08666a1fcd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-ac5384b6-4672-47da-8ee0-b57a7e8ae49a,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-f7a4205a-7047-411b-b96f-47c8a3c0a49c,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-ce1190c5-2c5e-4b2f-b3c0-98dc557d0874,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-0e4eb03b-778e-4fa2-bca5-20471eddbb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-f816896c-0bee-4eb7-a704-9ff911a8ea1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379955191-172.17.0.4-1594334407557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-ebb85cd2-b33d-408c-80ee-93d41780b57e,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-4892574b-d3cf-41bb-998c-b73c65a67d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-caa63a1b-901f-4647-a423-08666a1fcd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-ac5384b6-4672-47da-8ee0-b57a7e8ae49a,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-f7a4205a-7047-411b-b96f-47c8a3c0a49c,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-ce1190c5-2c5e-4b2f-b3c0-98dc557d0874,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-0e4eb03b-778e-4fa2-bca5-20471eddbb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-f816896c-0bee-4eb7-a704-9ff911a8ea1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536127712-172.17.0.4-1594334441191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-ad16634b-f811-4247-8243-7551698259af,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-1d4248b3-9e1f-4344-91cc-1612c1410627,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-5b26f7ca-abb5-4993-aacf-15712a714253,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-fa756a41-ca24-4a08-943a-e96989527a22,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-e385f5e3-feed-4dd2-ae69-0bbc8c28a5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-d73a9c16-77b2-40fc-a89a-aefaa8a1107a,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-29db8b6e-fce5-42a6-920c-a4960e966f66,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-c8d54e08-906c-4cb0-b31b-90a9d517f56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536127712-172.17.0.4-1594334441191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-ad16634b-f811-4247-8243-7551698259af,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-1d4248b3-9e1f-4344-91cc-1612c1410627,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-5b26f7ca-abb5-4993-aacf-15712a714253,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-fa756a41-ca24-4a08-943a-e96989527a22,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-e385f5e3-feed-4dd2-ae69-0bbc8c28a5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-d73a9c16-77b2-40fc-a89a-aefaa8a1107a,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-29db8b6e-fce5-42a6-920c-a4960e966f66,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-c8d54e08-906c-4cb0-b31b-90a9d517f56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244375803-172.17.0.4-1594334581326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34336,DS-7facb0db-78c8-4f40-920c-fc71589bcc61,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-387b64d9-fe57-4fc2-a191-7cf79a6a60c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-0239f0cf-d0e4-4588-9db8-c7bee82482cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-d1b494c0-daab-499b-ad4e-a398f1e08343,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-54755f30-ec01-4fd3-940b-28f833e6844d,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-8789847f-8a5c-4037-ac83-ca124c242519,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-12dbebdf-cb0d-4cc2-ab6c-9da7e1bcc013,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-825abe4d-1054-4c12-9b0e-a43e3f6ffb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244375803-172.17.0.4-1594334581326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34336,DS-7facb0db-78c8-4f40-920c-fc71589bcc61,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-387b64d9-fe57-4fc2-a191-7cf79a6a60c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-0239f0cf-d0e4-4588-9db8-c7bee82482cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-d1b494c0-daab-499b-ad4e-a398f1e08343,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-54755f30-ec01-4fd3-940b-28f833e6844d,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-8789847f-8a5c-4037-ac83-ca124c242519,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-12dbebdf-cb0d-4cc2-ab6c-9da7e1bcc013,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-825abe4d-1054-4c12-9b0e-a43e3f6ffb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128261541-172.17.0.4-1594334700070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-3105a4eb-21e2-4944-86d0-fc28b7732588,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-9b536e7c-aff7-4e39-a2ea-f9afd4a3dcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-a740d340-3894-45ab-a80c-dec57ebcf1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-4e9be631-9809-4aa8-b0f5-3530e2e7d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-90622bc2-071d-44b7-9f2a-79250dea2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-317e3489-b095-483d-9fd2-985226fb05b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-0bf9ed5a-82bf-41ec-9145-8a8ffd262d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-1ec836b5-2be4-48d8-a356-33ab9d79fad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128261541-172.17.0.4-1594334700070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46614,DS-3105a4eb-21e2-4944-86d0-fc28b7732588,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-9b536e7c-aff7-4e39-a2ea-f9afd4a3dcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-a740d340-3894-45ab-a80c-dec57ebcf1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-4e9be631-9809-4aa8-b0f5-3530e2e7d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-90622bc2-071d-44b7-9f2a-79250dea2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-317e3489-b095-483d-9fd2-985226fb05b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-0bf9ed5a-82bf-41ec-9145-8a8ffd262d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-1ec836b5-2be4-48d8-a356-33ab9d79fad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513020968-172.17.0.4-1594334733364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-eb5221f6-eb9b-4eef-8125-35c4c422e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-eed60a40-05e0-4c81-b16c-9e154f6f2cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-52cee313-d9fd-42e2-a32a-13fe87d6e53f,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-9465fc0c-14bb-4f53-ba57-e55146b8c779,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-cd754eed-5311-4629-8b7a-13ec87b0d3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-65d6d09d-0c0d-4bef-851a-1a8fc201d272,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-f6f2bccc-0447-466f-9ac6-347795f717d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-4d25470c-b385-45e2-aaa6-58ca90975761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513020968-172.17.0.4-1594334733364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-eb5221f6-eb9b-4eef-8125-35c4c422e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-eed60a40-05e0-4c81-b16c-9e154f6f2cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-52cee313-d9fd-42e2-a32a-13fe87d6e53f,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-9465fc0c-14bb-4f53-ba57-e55146b8c779,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-cd754eed-5311-4629-8b7a-13ec87b0d3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-65d6d09d-0c0d-4bef-851a-1a8fc201d272,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-f6f2bccc-0447-466f-9ac6-347795f717d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-4d25470c-b385-45e2-aaa6-58ca90975761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288077792-172.17.0.4-1594334913747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-bc71cf46-c2af-402b-a6f4-72ebec9bd29f,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-5efb740e-3101-4498-8cdb-5a8e25d47eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-4c1db727-e0b2-44e1-a5d3-e5873cdc4485,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-57ca1c10-db1f-490a-9c2a-934c3017ca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-9a16a7a4-8cdc-4e79-9b83-2ea9ece8a5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-a8f2ec56-26c7-4b8c-b772-0bc597d28d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-f62c6bfd-0950-4f17-a1ff-e33e781b1f82,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-62a925cf-02ae-43cb-87e4-6528a01a16a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288077792-172.17.0.4-1594334913747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-bc71cf46-c2af-402b-a6f4-72ebec9bd29f,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-5efb740e-3101-4498-8cdb-5a8e25d47eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-4c1db727-e0b2-44e1-a5d3-e5873cdc4485,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-57ca1c10-db1f-490a-9c2a-934c3017ca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-9a16a7a4-8cdc-4e79-9b83-2ea9ece8a5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-a8f2ec56-26c7-4b8c-b772-0bc597d28d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-f62c6bfd-0950-4f17-a1ff-e33e781b1f82,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-62a925cf-02ae-43cb-87e4-6528a01a16a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726173009-172.17.0.4-1594335278692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46125,DS-dc824dc9-4257-4c9c-852d-e490aaa59d90,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-83db031c-8d98-479e-b642-bb1af3eb333c,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-14a4eab0-48e9-4bd3-b759-4c24558b44eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-7b842738-5ffa-46ba-b591-87f4e81aaecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-b9d3b1d6-c12a-4287-85b9-4d41d117297d,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-5134d2dc-88a4-4c83-98ee-fb0ca69fae5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-1a2d727e-ab20-4dbf-9904-f7ab317958f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-586cc693-a241-42df-801e-2ba3858e87fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726173009-172.17.0.4-1594335278692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46125,DS-dc824dc9-4257-4c9c-852d-e490aaa59d90,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-83db031c-8d98-479e-b642-bb1af3eb333c,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-14a4eab0-48e9-4bd3-b759-4c24558b44eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-7b842738-5ffa-46ba-b591-87f4e81aaecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-b9d3b1d6-c12a-4287-85b9-4d41d117297d,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-5134d2dc-88a4-4c83-98ee-fb0ca69fae5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-1a2d727e-ab20-4dbf-9904-f7ab317958f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-586cc693-a241-42df-801e-2ba3858e87fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973323661-172.17.0.4-1594335387246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43449,DS-ded67c32-a3dd-4b00-8d0a-1d65ed0e2f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-0bdcd106-73e5-47e7-9eab-a3a824ceace2,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-a1192be8-0f6b-456c-aea1-8425fbdfcbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-14233c25-e679-4c55-9480-cbe643a93193,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-eab5752f-6607-4634-8a50-0209f661c983,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-b4dd2414-42e8-4ed6-9782-7b4f960d9666,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-a6667f34-4946-4039-8a1e-95f2b3f70e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-c43f7cb8-d46c-47ab-b93f-1c852517444e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973323661-172.17.0.4-1594335387246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43449,DS-ded67c32-a3dd-4b00-8d0a-1d65ed0e2f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-0bdcd106-73e5-47e7-9eab-a3a824ceace2,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-a1192be8-0f6b-456c-aea1-8425fbdfcbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-14233c25-e679-4c55-9480-cbe643a93193,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-eab5752f-6607-4634-8a50-0209f661c983,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-b4dd2414-42e8-4ed6-9782-7b4f960d9666,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-a6667f34-4946-4039-8a1e-95f2b3f70e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-c43f7cb8-d46c-47ab-b93f-1c852517444e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160104103-172.17.0.4-1594335806253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32961,DS-0022e081-a349-41aa-8e15-3a4746db126b,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-ba8a7fa6-f24a-4a4a-91a9-410cab6466ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-c6da65bf-8a93-47a6-af6c-0ce071bba915,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-16478990-df6c-4b60-8f4e-bc42d47a833b,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-45ad3c00-0317-4464-9569-fdcf490bd05e,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-05e4b1fb-2a75-4650-ad52-abb9123dbdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-6b1a7dd6-69da-4540-a0e2-8aba136e2ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-4ab6fa3f-ea98-41a8-b704-d101ef9f5c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160104103-172.17.0.4-1594335806253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32961,DS-0022e081-a349-41aa-8e15-3a4746db126b,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-ba8a7fa6-f24a-4a4a-91a9-410cab6466ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-c6da65bf-8a93-47a6-af6c-0ce071bba915,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-16478990-df6c-4b60-8f4e-bc42d47a833b,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-45ad3c00-0317-4464-9569-fdcf490bd05e,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-05e4b1fb-2a75-4650-ad52-abb9123dbdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-6b1a7dd6-69da-4540-a0e2-8aba136e2ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-4ab6fa3f-ea98-41a8-b704-d101ef9f5c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354843471-172.17.0.4-1594335865350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-dc6e582e-8a29-4006-86f4-928669389b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-034ffd00-0321-42c5-b4a6-04bf86dcfcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-2163329b-2bca-4350-bbf7-2cd7bc1fecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-095b1380-7801-4b86-91f4-69f4f2bda7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-5025abb7-60cb-4871-b2a7-0b98e2c6e218,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-f3014217-a875-4cce-bca5-6b24f64ad71a,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-f1363e7a-b475-496c-8045-12d6ed300279,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-a4192663-3af3-4145-8938-63b28d4d0ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354843471-172.17.0.4-1594335865350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-dc6e582e-8a29-4006-86f4-928669389b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-034ffd00-0321-42c5-b4a6-04bf86dcfcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-2163329b-2bca-4350-bbf7-2cd7bc1fecf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-095b1380-7801-4b86-91f4-69f4f2bda7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-5025abb7-60cb-4871-b2a7-0b98e2c6e218,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-f3014217-a875-4cce-bca5-6b24f64ad71a,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-f1363e7a-b475-496c-8045-12d6ed300279,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-a4192663-3af3-4145-8938-63b28d4d0ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937879207-172.17.0.4-1594335904881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-ee84db97-d248-43cc-9205-79e196973887,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-b956b369-488b-4f14-a7e5-51f0b17ef314,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-6c79d2f5-b3cb-40bf-9b2f-53bec63a2e69,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-62aa7f88-a4dd-4c3e-a493-d77f6515998e,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-ddf9a990-d120-4323-951a-f59502c25fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-b8f41429-a917-4bf3-996c-c726a7d72a00,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-7cff0b12-99db-4037-a293-1f3adf6781ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-8a270abc-ee67-4cc0-a0e6-7ffa0d965926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937879207-172.17.0.4-1594335904881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-ee84db97-d248-43cc-9205-79e196973887,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-b956b369-488b-4f14-a7e5-51f0b17ef314,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-6c79d2f5-b3cb-40bf-9b2f-53bec63a2e69,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-62aa7f88-a4dd-4c3e-a493-d77f6515998e,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-ddf9a990-d120-4323-951a-f59502c25fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-b8f41429-a917-4bf3-996c-c726a7d72a00,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-7cff0b12-99db-4037-a293-1f3adf6781ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-8a270abc-ee67-4cc0-a0e6-7ffa0d965926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123360345-172.17.0.4-1594336159960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-f6324f24-e323-4661-a1aa-a36a52f66a12,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-d7db3a61-2f3b-4969-a81e-9b7ccde72d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-eadfca5c-d4aa-46e3-ba6f-0f78691e69fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-c7aa47f2-b5e2-408b-b0f0-555514f46bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-9abb0d77-c770-4b4c-95e2-eae15055a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-42d46d62-b24f-4063-8172-c6564770a486,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-a63632c6-d703-4aeb-9b6d-025b1972c489,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-311355ec-39f8-4f7f-b062-0e0e9c4c9be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123360345-172.17.0.4-1594336159960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-f6324f24-e323-4661-a1aa-a36a52f66a12,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-d7db3a61-2f3b-4969-a81e-9b7ccde72d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-eadfca5c-d4aa-46e3-ba6f-0f78691e69fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-c7aa47f2-b5e2-408b-b0f0-555514f46bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-9abb0d77-c770-4b4c-95e2-eae15055a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-42d46d62-b24f-4063-8172-c6564770a486,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-a63632c6-d703-4aeb-9b6d-025b1972c489,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-311355ec-39f8-4f7f-b062-0e0e9c4c9be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234496461-172.17.0.4-1594336282561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-c2a1cc1b-f42e-47d2-8f49-f382ce943573,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-12cbb328-509c-48c7-bd61-4083694239c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-9607ea99-b068-4b7b-9be2-63dd03860bed,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-d90d6c6c-4888-4682-b033-ea74395d3473,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-ef3d006e-8080-4ecb-b602-7b28ced355b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-f7aa51a5-53cf-4e48-9695-250dd77daf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-dbdd10f9-8026-4fb7-9084-30ba150f8df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-197229f6-f99f-4a89-a27a-41ea25f7a5b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234496461-172.17.0.4-1594336282561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-c2a1cc1b-f42e-47d2-8f49-f382ce943573,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-12cbb328-509c-48c7-bd61-4083694239c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-9607ea99-b068-4b7b-9be2-63dd03860bed,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-d90d6c6c-4888-4682-b033-ea74395d3473,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-ef3d006e-8080-4ecb-b602-7b28ced355b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-f7aa51a5-53cf-4e48-9695-250dd77daf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-dbdd10f9-8026-4fb7-9084-30ba150f8df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-197229f6-f99f-4a89-a27a-41ea25f7a5b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302573513-172.17.0.4-1594336581311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43248,DS-8cc228d4-edbb-4fb3-912c-52b2a919b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-b4feeb13-bac1-4921-8a4f-f7a34517ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-9c2a7de5-f04e-43b2-a0e3-8cf1a74bdc59,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-9f1ff59b-294b-4695-ae27-9b4738e1ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-fdd552b2-6510-4a6a-a340-0d0a0129c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-a2ff5727-acc1-49a5-9ca6-e2733356ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-d1b2b21d-0cc2-4316-8928-3224b7597231,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-a645fdcc-cc7c-49da-aeee-f447243cf5f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302573513-172.17.0.4-1594336581311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43248,DS-8cc228d4-edbb-4fb3-912c-52b2a919b1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-b4feeb13-bac1-4921-8a4f-f7a34517ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-9c2a7de5-f04e-43b2-a0e3-8cf1a74bdc59,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-9f1ff59b-294b-4695-ae27-9b4738e1ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-fdd552b2-6510-4a6a-a340-0d0a0129c1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-a2ff5727-acc1-49a5-9ca6-e2733356ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-d1b2b21d-0cc2-4316-8928-3224b7597231,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-a645fdcc-cc7c-49da-aeee-f447243cf5f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282184839-172.17.0.4-1594336698307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-c8e4c6a4-bda0-4823-beea-2dcf41619f29,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-7ee8e8ae-5c14-4c0f-873f-27ae2e4fbdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-b10ab7ea-ca4e-4bb6-9255-cecbfa43e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-dfdebb00-8d5e-445c-bbe9-a38ffac8de9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-19c98465-16a6-4fd6-a663-1254dcd39814,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-4b127be3-0cf4-4c65-82d6-9b86db57b652,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-ffd887cf-86a0-4689-8da5-4779b09f4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-573dd88f-e622-4c44-af4e-793689bd70b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282184839-172.17.0.4-1594336698307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-c8e4c6a4-bda0-4823-beea-2dcf41619f29,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-7ee8e8ae-5c14-4c0f-873f-27ae2e4fbdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-b10ab7ea-ca4e-4bb6-9255-cecbfa43e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-dfdebb00-8d5e-445c-bbe9-a38ffac8de9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-19c98465-16a6-4fd6-a663-1254dcd39814,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-4b127be3-0cf4-4c65-82d6-9b86db57b652,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-ffd887cf-86a0-4689-8da5-4779b09f4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-573dd88f-e622-4c44-af4e-793689bd70b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056149313-172.17.0.4-1594337255200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-d4747428-1fac-4d81-a1d1-426fc278e6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-3011d190-2f85-440c-b7d0-43d9a0967710,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-610156d2-d5b3-44b4-bbcd-543682281799,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-5fb10fc4-aaeb-41ff-9252-6bc98dbd60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-5f6024c9-1a98-406e-b468-d40d39284abd,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-21ded294-0e78-4d01-b6ae-82a419dce48d,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-2d9afae1-be0c-4c38-8fb5-131e25cbcd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-35ca033e-5c9c-4883-9a0f-b6e5d240ff20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056149313-172.17.0.4-1594337255200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39832,DS-d4747428-1fac-4d81-a1d1-426fc278e6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-3011d190-2f85-440c-b7d0-43d9a0967710,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-610156d2-d5b3-44b4-bbcd-543682281799,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-5fb10fc4-aaeb-41ff-9252-6bc98dbd60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-5f6024c9-1a98-406e-b468-d40d39284abd,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-21ded294-0e78-4d01-b6ae-82a419dce48d,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-2d9afae1-be0c-4c38-8fb5-131e25cbcd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-35ca033e-5c9c-4883-9a0f-b6e5d240ff20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189478752-172.17.0.4-1594337293746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41411,DS-a758f2a3-ffa7-4cbb-b8aa-f42da6b4803d,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-f1174433-bb49-42dc-b542-7020a58b7e68,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-38c37ec9-f922-4fb0-a40e-f458f39a73b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-20b73d6d-9060-4661-a735-a44d591ee23a,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-1a34f4c0-0790-4dc1-a011-cb0b869b5de7,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-ccd73e43-af50-4e56-a4fe-aa13fca1b352,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-bce341e7-9ed7-4310-934e-04b6cb419a99,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-2ccb3f6e-8148-4f21-993c-2fa6e6af9943,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189478752-172.17.0.4-1594337293746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41411,DS-a758f2a3-ffa7-4cbb-b8aa-f42da6b4803d,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-f1174433-bb49-42dc-b542-7020a58b7e68,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-38c37ec9-f922-4fb0-a40e-f458f39a73b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-20b73d6d-9060-4661-a735-a44d591ee23a,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-1a34f4c0-0790-4dc1-a011-cb0b869b5de7,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-ccd73e43-af50-4e56-a4fe-aa13fca1b352,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-bce341e7-9ed7-4310-934e-04b6cb419a99,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-2ccb3f6e-8148-4f21-993c-2fa6e6af9943,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991631136-172.17.0.4-1594337332310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44207,DS-bb58825d-6b7b-4e95-b37d-3c829ddb06a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-a0292b4e-fd41-4195-9941-e0365acbf105,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-4e362c03-6007-4217-9b74-eb46cbd2c379,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-2d92d3ce-1797-4045-8807-d9f8616c60a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-934ce7e4-959f-4cf9-91c8-101380156d71,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-c780dadc-9f84-4cfb-bf72-496d978fda90,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-4782b30f-3c33-4059-9a13-3eba5cd04fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-4baafe2b-5f47-4dc1-9522-0a8046c485dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991631136-172.17.0.4-1594337332310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44207,DS-bb58825d-6b7b-4e95-b37d-3c829ddb06a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-a0292b4e-fd41-4195-9941-e0365acbf105,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-4e362c03-6007-4217-9b74-eb46cbd2c379,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-2d92d3ce-1797-4045-8807-d9f8616c60a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-934ce7e4-959f-4cf9-91c8-101380156d71,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-c780dadc-9f84-4cfb-bf72-496d978fda90,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-4782b30f-3c33-4059-9a13-3eba5cd04fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-4baafe2b-5f47-4dc1-9522-0a8046c485dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262762377-172.17.0.4-1594337634950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37016,DS-43e82508-3435-43db-a731-4c8a07f65991,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-7826a7a5-d592-4870-9319-70df2550555d,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-1d9a5225-5b74-43dd-be75-5475f17217cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-d054d23c-0061-45d8-af33-d2c0d9f46868,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-2fa7f358-7921-4517-ba10-a5b8fb5d70cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-c07106f9-4e3b-43e9-acc7-e33a1a2cc4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-d2163f81-e59a-4dde-9ed0-b2b2a7cc2a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-29ab745e-e6fb-40ce-90de-b71edf46d3a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262762377-172.17.0.4-1594337634950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37016,DS-43e82508-3435-43db-a731-4c8a07f65991,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-7826a7a5-d592-4870-9319-70df2550555d,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-1d9a5225-5b74-43dd-be75-5475f17217cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-d054d23c-0061-45d8-af33-d2c0d9f46868,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-2fa7f358-7921-4517-ba10-a5b8fb5d70cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-c07106f9-4e3b-43e9-acc7-e33a1a2cc4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-d2163f81-e59a-4dde-9ed0-b2b2a7cc2a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-29ab745e-e6fb-40ce-90de-b71edf46d3a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107767936-172.17.0.4-1594337692719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38827,DS-bb1387bb-fbae-42a1-96f2-d3072c3964a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-19a33c4f-cc85-42e8-a58e-67aca9bb6a28,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-3b29d1c5-779b-41b9-8eea-977839881bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-0846326a-20d5-4f66-a043-c2450a156e77,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-affde130-7320-468f-b861-382eb68f5957,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-8373f7ca-4f7f-4ca9-b618-c39dfbedac94,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-3c614019-7ca5-40aa-ac7a-b439f85a975e,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-ceb283e1-1202-433c-87f5-1a654c6fab24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107767936-172.17.0.4-1594337692719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38827,DS-bb1387bb-fbae-42a1-96f2-d3072c3964a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-19a33c4f-cc85-42e8-a58e-67aca9bb6a28,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-3b29d1c5-779b-41b9-8eea-977839881bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-0846326a-20d5-4f66-a043-c2450a156e77,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-affde130-7320-468f-b861-382eb68f5957,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-8373f7ca-4f7f-4ca9-b618-c39dfbedac94,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-3c614019-7ca5-40aa-ac7a-b439f85a975e,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-ceb283e1-1202-433c-87f5-1a654c6fab24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759554252-172.17.0.4-1594338224528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-077b1795-672a-4dbb-b319-fe8a08dcc4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-d86f2cb1-2ab1-4e90-85cd-9e6515098021,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-80fe310b-bd7e-430b-bdc2-8fe35a2d0fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-53ebb80d-7568-4be3-9fda-4bada3ab269b,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-8bb2366a-1f12-4380-baac-bdbfb7576e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-1ea353f4-4a13-4164-bb8e-e6dae14d8765,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-546d135f-9d77-4ad8-9e1f-a2b1d40a8bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-68507df5-ca73-48a3-90e4-3fb1d95ffa02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759554252-172.17.0.4-1594338224528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40546,DS-077b1795-672a-4dbb-b319-fe8a08dcc4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-d86f2cb1-2ab1-4e90-85cd-9e6515098021,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-80fe310b-bd7e-430b-bdc2-8fe35a2d0fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-53ebb80d-7568-4be3-9fda-4bada3ab269b,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-8bb2366a-1f12-4380-baac-bdbfb7576e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-1ea353f4-4a13-4164-bb8e-e6dae14d8765,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-546d135f-9d77-4ad8-9e1f-a2b1d40a8bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-68507df5-ca73-48a3-90e4-3fb1d95ffa02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551587151-172.17.0.4-1594338776078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34534,DS-942c39e5-ef34-4f70-9db4-5c726a024bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-219b8bce-23d8-4fb2-839d-5141541ae5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-959c9d80-032d-4fcc-9c47-47bd067fafde,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-0f444592-1e22-4705-83d7-b5ba652997b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-c0b9da48-d612-4a26-97a2-25629476ffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-f714a70e-50aa-4b87-9ec4-05aaa9659231,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-baba95d7-e549-4e21-b394-f614cccf196d,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-303f58cf-b7bd-4ea7-ad8c-8d1aeac55245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551587151-172.17.0.4-1594338776078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34534,DS-942c39e5-ef34-4f70-9db4-5c726a024bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-219b8bce-23d8-4fb2-839d-5141541ae5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-959c9d80-032d-4fcc-9c47-47bd067fafde,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-0f444592-1e22-4705-83d7-b5ba652997b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-c0b9da48-d612-4a26-97a2-25629476ffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-f714a70e-50aa-4b87-9ec4-05aaa9659231,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-baba95d7-e549-4e21-b394-f614cccf196d,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-303f58cf-b7bd-4ea7-ad8c-8d1aeac55245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203200115-172.17.0.4-1594338999086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32964,DS-dd70343c-1c74-4238-8868-44b90b570ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-169afd93-b1d9-412b-89fc-c77b4539d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-b530031d-8381-4881-ba4c-50c4d0c7a993,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-0fcc9840-e732-493c-80ca-730ef4a1011e,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-a534d762-f3b1-4013-9f52-3964f4117f99,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-f9f5e0de-0a73-438e-8234-fd843415f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-876728e4-e454-4640-a363-39d03ce3c8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-87f01f55-1322-4501-b7bf-d824b3735ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203200115-172.17.0.4-1594338999086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32964,DS-dd70343c-1c74-4238-8868-44b90b570ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-169afd93-b1d9-412b-89fc-c77b4539d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-b530031d-8381-4881-ba4c-50c4d0c7a993,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-0fcc9840-e732-493c-80ca-730ef4a1011e,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-a534d762-f3b1-4013-9f52-3964f4117f99,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-f9f5e0de-0a73-438e-8234-fd843415f4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-876728e4-e454-4640-a363-39d03ce3c8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-87f01f55-1322-4501-b7bf-d824b3735ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953937600-172.17.0.4-1594339039674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36262,DS-a08c8ae7-0f29-4bea-8c16-8d3f5cc07f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-436b46ac-7b2e-4db2-aa0b-3a32b83e2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-5ba56b4d-4f33-4bc8-84f4-2fd6f0ca2739,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-c42694a0-76aa-4e91-89f4-cfc04965d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-f67e1493-2672-49ab-bfe9-092b7811c556,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-bf889a51-3767-4a99-a16b-f28baecef563,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-b1f928af-c6d2-4639-9b88-b74c1736231a,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-5a474a3d-df15-4f68-a3ca-5ccd86ef8768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953937600-172.17.0.4-1594339039674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36262,DS-a08c8ae7-0f29-4bea-8c16-8d3f5cc07f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-436b46ac-7b2e-4db2-aa0b-3a32b83e2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-5ba56b4d-4f33-4bc8-84f4-2fd6f0ca2739,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-c42694a0-76aa-4e91-89f4-cfc04965d1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-f67e1493-2672-49ab-bfe9-092b7811c556,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-bf889a51-3767-4a99-a16b-f28baecef563,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-b1f928af-c6d2-4639-9b88-b74c1736231a,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-5a474a3d-df15-4f68-a3ca-5ccd86ef8768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: might be true error
Total execution time in seconds : 5440
