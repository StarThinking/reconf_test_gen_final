reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-9f46dcd6-912f-41d3-be56-7ad6f99cb4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-1e3fbf3e-dde6-4157-8593-93566d6d8688,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41759,DS-1e3fbf3e-dde6-4157-8593-93566d6d8688,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9f46dcd6-912f-41d3-be56-7ad6f99cb4b3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34187,DS-9f46dcd6-912f-41d3-be56-7ad6f99cb4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-1e3fbf3e-dde6-4157-8593-93566d6d8688,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41759,DS-1e3fbf3e-dde6-4157-8593-93566d6d8688,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9f46dcd6-912f-41d3-be56-7ad6f99cb4b3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-08bb7cd9-1985-408d-8021-c34247d9d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-6d381323-43b4-4e12-9dfd-b962d842843b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-08bb7cd9-1985-408d-8021-c34247d9d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-6d381323-43b4-4e12-9dfd-b962d842843b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-08bb7cd9-1985-408d-8021-c34247d9d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-6d381323-43b4-4e12-9dfd-b962d842843b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-08bb7cd9-1985-408d-8021-c34247d9d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-6d381323-43b4-4e12-9dfd-b962d842843b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36446,DS-6cd1edd9-6d96-4383-8087-f61f51d01ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-0ba5f76b-a729-421b-b052-61527303e9f3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38591,DS-0ba5f76b-a729-421b-b052-61527303e9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-6cd1edd9-6d96-4383-8087-f61f51d01ec3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36446,DS-6cd1edd9-6d96-4383-8087-f61f51d01ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-0ba5f76b-a729-421b-b052-61527303e9f3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38591,DS-0ba5f76b-a729-421b-b052-61527303e9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-6cd1edd9-6d96-4383-8087-f61f51d01ec3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34523,DS-6ae316db-6d54-48b9-b8b6-523420699273,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-3f1ee22d-5925-4b52-9c5a-2782916a5709,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34523,DS-6ae316db-6d54-48b9-b8b6-523420699273,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-3f1ee22d-5925-4b52-9c5a-2782916a5709,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34523,DS-6ae316db-6d54-48b9-b8b6-523420699273,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-3f1ee22d-5925-4b52-9c5a-2782916a5709,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34523,DS-6ae316db-6d54-48b9-b8b6-523420699273,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-3f1ee22d-5925-4b52-9c5a-2782916a5709,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-f8e50fb7-4020-4c61-947a-ff05edee24c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-4b90379c-10bf-405a-9ca9-974cbf9d44cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-f8e50fb7-4020-4c61-947a-ff05edee24c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-4b90379c-10bf-405a-9ca9-974cbf9d44cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-f8e50fb7-4020-4c61-947a-ff05edee24c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-4b90379c-10bf-405a-9ca9-974cbf9d44cd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-f8e50fb7-4020-4c61-947a-ff05edee24c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-4b90379c-10bf-405a-9ca9-974cbf9d44cd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-46922e8b-3f41-41c7-9d7b-747b1b9d3a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-9d7a50a6-c05e-42e8-a868-e24833de7c8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36085,DS-9d7a50a6-c05e-42e8-a868-e24833de7c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-46922e8b-3f41-41c7-9d7b-747b1b9d3a1b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-46922e8b-3f41-41c7-9d7b-747b1b9d3a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-9d7a50a6-c05e-42e8-a868-e24833de7c8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36085,DS-9d7a50a6-c05e-42e8-a868-e24833de7c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-46922e8b-3f41-41c7-9d7b-747b1b9d3a1b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-b00104d9-9b46-468a-9ff6-656ad8cf7a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-f180fad4-2352-4050-839d-3cd6b8d9f243,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-b00104d9-9b46-468a-9ff6-656ad8cf7a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-f180fad4-2352-4050-839d-3cd6b8d9f243,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-b00104d9-9b46-468a-9ff6-656ad8cf7a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-f180fad4-2352-4050-839d-3cd6b8d9f243,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-b00104d9-9b46-468a-9ff6-656ad8cf7a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-f180fad4-2352-4050-839d-3cd6b8d9f243,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-eefb6726-881c-45c4-8d9d-1c8b991577dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-518e8afe-6291-4a04-b178-e68020bea7c0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-eefb6726-881c-45c4-8d9d-1c8b991577dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-518e8afe-6291-4a04-b178-e68020bea7c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-eefb6726-881c-45c4-8d9d-1c8b991577dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-518e8afe-6291-4a04-b178-e68020bea7c0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-eefb6726-881c-45c4-8d9d-1c8b991577dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-518e8afe-6291-4a04-b178-e68020bea7c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-4562860e-d0d1-4f9c-9812-071ad1de33fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-48a7ff89-be3c-4ba3-bd1a-8dc6ba6b1213,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33851,DS-48a7ff89-be3c-4ba3-bd1a-8dc6ba6b1213,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-4562860e-d0d1-4f9c-9812-071ad1de33fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41260,DS-4562860e-d0d1-4f9c-9812-071ad1de33fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-48a7ff89-be3c-4ba3-bd1a-8dc6ba6b1213,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33851,DS-48a7ff89-be3c-4ba3-bd1a-8dc6ba6b1213,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-4562860e-d0d1-4f9c-9812-071ad1de33fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-c773468c-5014-4dae-989e-538dd9506bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-fb1d3ded-da8b-4981-976b-eca93989a4ed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-c773468c-5014-4dae-989e-538dd9506bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-fb1d3ded-da8b-4981-976b-eca93989a4ed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-c773468c-5014-4dae-989e-538dd9506bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-fb1d3ded-da8b-4981-976b-eca93989a4ed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-c773468c-5014-4dae-989e-538dd9506bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-fb1d3ded-da8b-4981-976b-eca93989a4ed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2049
