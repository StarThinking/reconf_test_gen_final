reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-846015d1-8c6f-43b3-8617-f6dcec27c306,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-c598fc09-bf5a-4647-be52-0521f6c8ad5e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-846015d1-8c6f-43b3-8617-f6dcec27c306,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-c598fc09-bf5a-4647-be52-0521f6c8ad5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-846015d1-8c6f-43b3-8617-f6dcec27c306,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-c598fc09-bf5a-4647-be52-0521f6c8ad5e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-846015d1-8c6f-43b3-8617-f6dcec27c306,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-c598fc09-bf5a-4647-be52-0521f6c8ad5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-ea68d25c-bfef-48bc-ba98-7a6c95b7cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-d346b646-fa1f-42a1-8548-a581613538c7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-ea68d25c-bfef-48bc-ba98-7a6c95b7cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-d346b646-fa1f-42a1-8548-a581613538c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-ea68d25c-bfef-48bc-ba98-7a6c95b7cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-d346b646-fa1f-42a1-8548-a581613538c7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-ea68d25c-bfef-48bc-ba98-7a6c95b7cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-d346b646-fa1f-42a1-8548-a581613538c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39701,DS-ac719473-2de9-4409-a236-01113fa696a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-edcaf26b-57f4-4aaf-913a-7dec07083388,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39701,DS-ac719473-2de9-4409-a236-01113fa696a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-edcaf26b-57f4-4aaf-913a-7dec07083388,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39701,DS-ac719473-2de9-4409-a236-01113fa696a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-edcaf26b-57f4-4aaf-913a-7dec07083388,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39701,DS-ac719473-2de9-4409-a236-01113fa696a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-edcaf26b-57f4-4aaf-913a-7dec07083388,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46763,DS-9b12701b-7850-419e-81ef-612fc7717c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-cbfd263a-b556-499c-9422-808bbccffb28,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-cbfd263a-b556-499c-9422-808bbccffb28,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-9b12701b-7850-419e-81ef-612fc7717c6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46763,DS-9b12701b-7850-419e-81ef-612fc7717c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-cbfd263a-b556-499c-9422-808bbccffb28,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-cbfd263a-b556-499c-9422-808bbccffb28,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-9b12701b-7850-419e-81ef-612fc7717c6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38037,DS-67a840f7-7b52-4ed3-b476-784bc5970464,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-014fc32b-ce68-4d04-a621-b79093996070,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40151,DS-014fc32b-ce68-4d04-a621-b79093996070,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-67a840f7-7b52-4ed3-b476-784bc5970464,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38037,DS-67a840f7-7b52-4ed3-b476-784bc5970464,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-014fc32b-ce68-4d04-a621-b79093996070,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40151,DS-014fc32b-ce68-4d04-a621-b79093996070,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-67a840f7-7b52-4ed3-b476-784bc5970464,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-78f413ff-9511-4bba-ab14-f0bcd71eb68f,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-1f04b661-2e66-4478-a124-5ae83ce26b99,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-78f413ff-9511-4bba-ab14-f0bcd71eb68f,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-1f04b661-2e66-4478-a124-5ae83ce26b99,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-78f413ff-9511-4bba-ab14-f0bcd71eb68f,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-1f04b661-2e66-4478-a124-5ae83ce26b99,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44942,DS-78f413ff-9511-4bba-ab14-f0bcd71eb68f,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-1f04b661-2e66-4478-a124-5ae83ce26b99,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-b5aa5087-4f42-496f-aa32-1ca294b6651d,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-a8a752ec-78f6-4eab-bf55-205364758de8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-a8a752ec-78f6-4eab-bf55-205364758de8,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-b5aa5087-4f42-496f-aa32-1ca294b6651d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-b5aa5087-4f42-496f-aa32-1ca294b6651d,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-a8a752ec-78f6-4eab-bf55-205364758de8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-a8a752ec-78f6-4eab-bf55-205364758de8,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-b5aa5087-4f42-496f-aa32-1ca294b6651d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-f642786b-6d87-4d36-a094-7100ea2c978d,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-93ebe756-ad7d-4d12-b906-d6d899dec8a0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-93ebe756-ad7d-4d12-b906-d6d899dec8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-f642786b-6d87-4d36-a094-7100ea2c978d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-f642786b-6d87-4d36-a094-7100ea2c978d,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-93ebe756-ad7d-4d12-b906-d6d899dec8a0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-93ebe756-ad7d-4d12-b906-d6d899dec8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-f642786b-6d87-4d36-a094-7100ea2c978d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: test timed out after 30000 milliseconds
stackTrace: java.lang.Exception: test timed out after 30000 milliseconds
	at java.lang.ClassLoader.findLoadedClass0(Native Method)
	at java.lang.ClassLoader.findLoadedClass(ClassLoader.java:1032)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:401)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:352)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:757)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:419)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:352)
	at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithAlignmentContext(NameNodeProxiesClient.java:378)
	at org.apache.hadoop.hdfs.NameNodeProxiesClient.createNonHAProxyWithClientProtocol(NameNodeProxiesClient.java:348)
	at org.apache.hadoop.hdfs.NameNodeProxiesClient.createProxyWithClientProtocol(NameNodeProxiesClient.java:140)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:356)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:290)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:273)
	at org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2698)
	at org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2744)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1735)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:911)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:518)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:477)
	at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testReloadOnEditReplayFailure(TestCheckpoint.java:243)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-0cbe3c3a-e108-4a26-afba-c0797cfff40c,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-f8482e7b-3933-4737-b6ef-d564627fae5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38603,DS-f8482e7b-3933-4737-b6ef-d564627fae5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-0cbe3c3a-e108-4a26-afba-c0797cfff40c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-0cbe3c3a-e108-4a26-afba-c0797cfff40c,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-f8482e7b-3933-4737-b6ef-d564627fae5b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38603,DS-f8482e7b-3933-4737-b6ef-d564627fae5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-0cbe3c3a-e108-4a26-afba-c0797cfff40c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-cf2a33b4-cb80-4064-9c1e-4bff4eb0c3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-495be63f-f902-4dda-a352-95c53e6b2969,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-495be63f-f902-4dda-a352-95c53e6b2969,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-cf2a33b4-cb80-4064-9c1e-4bff4eb0c3f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-cf2a33b4-cb80-4064-9c1e-4bff4eb0c3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-495be63f-f902-4dda-a352-95c53e6b2969,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40353,DS-495be63f-f902-4dda-a352-95c53e6b2969,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-cf2a33b4-cb80-4064-9c1e-4bff4eb0c3f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-43de6d34-13a6-40b4-8f94-58c86dcfd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-0f9abba3-d6a2-4fe0-a301-52bfa47806fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-43de6d34-13a6-40b4-8f94-58c86dcfd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-0f9abba3-d6a2-4fe0-a301-52bfa47806fa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-43de6d34-13a6-40b4-8f94-58c86dcfd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-0f9abba3-d6a2-4fe0-a301-52bfa47806fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-43de6d34-13a6-40b4-8f94-58c86dcfd7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-0f9abba3-d6a2-4fe0-a301-52bfa47806fa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43514,DS-df33e419-3589-4bed-8eb4-8844bb5efde2,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-4e065a8d-d0a6-4b8e-89b6-187f1e69c1af,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44525,DS-4e065a8d-d0a6-4b8e-89b6-187f1e69c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-df33e419-3589-4bed-8eb4-8844bb5efde2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43514,DS-df33e419-3589-4bed-8eb4-8844bb5efde2,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-4e065a8d-d0a6-4b8e-89b6-187f1e69c1af,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44525,DS-4e065a8d-d0a6-4b8e-89b6-187f1e69c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-df33e419-3589-4bed-8eb4-8844bb5efde2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38117,DS-bf8c35c0-0eed-44ca-8e78-3aad7e2f8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-2c16c16e-edbd-4d9d-96b2-71d98add4c33,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-2c16c16e-edbd-4d9d-96b2-71d98add4c33,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-bf8c35c0-0eed-44ca-8e78-3aad7e2f8fea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38117,DS-bf8c35c0-0eed-44ca-8e78-3aad7e2f8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-2c16c16e-edbd-4d9d-96b2-71d98add4c33,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40063,DS-2c16c16e-edbd-4d9d-96b2-71d98add4c33,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-bf8c35c0-0eed-44ca-8e78-3aad7e2f8fea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-b375bd3e-f753-44eb-90cb-7490908908fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-82621336-1bcd-4ba0-852a-d146f11d19d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-b375bd3e-f753-44eb-90cb-7490908908fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-82621336-1bcd-4ba0-852a-d146f11d19d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-b375bd3e-f753-44eb-90cb-7490908908fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-82621336-1bcd-4ba0-852a-d146f11d19d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-b375bd3e-f753-44eb-90cb-7490908908fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-82621336-1bcd-4ba0-852a-d146f11d19d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36654,DS-21f50ca7-0093-4cae-9334-959368fe2b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-92fa25b7-1197-4ad8-ab28-8c829ce90214,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36654,DS-21f50ca7-0093-4cae-9334-959368fe2b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-92fa25b7-1197-4ad8-ab28-8c829ce90214,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36654,DS-21f50ca7-0093-4cae-9334-959368fe2b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-92fa25b7-1197-4ad8-ab28-8c829ce90214,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36654,DS-21f50ca7-0093-4cae-9334-959368fe2b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-92fa25b7-1197-4ad8-ab28-8c829ce90214,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42039,DS-47ce519a-9c2f-465f-8c4a-49f550fdae28,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-6737f364-d6a1-4cdf-aced-c828813c6872,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42039,DS-47ce519a-9c2f-465f-8c4a-49f550fdae28,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-6737f364-d6a1-4cdf-aced-c828813c6872,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42039,DS-47ce519a-9c2f-465f-8c4a-49f550fdae28,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-6737f364-d6a1-4cdf-aced-c828813c6872,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42039,DS-47ce519a-9c2f-465f-8c4a-49f550fdae28,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-6737f364-d6a1-4cdf-aced-c828813c6872,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-66b54671-4290-45d3-a59b-b480554044e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-f7e60e69-fc47-49a2-973f-64eb84fcf17f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37287,DS-f7e60e69-fc47-49a2-973f-64eb84fcf17f,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-66b54671-4290-45d3-a59b-b480554044e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34226,DS-66b54671-4290-45d3-a59b-b480554044e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-f7e60e69-fc47-49a2-973f-64eb84fcf17f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37287,DS-f7e60e69-fc47-49a2-973f-64eb84fcf17f,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-66b54671-4290-45d3-a59b-b480554044e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46108,DS-3179cd12-8409-4a1b-84dc-522b72c33be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e9e167b8-c173-4d30-9ebc-91a842fe5c4e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46108,DS-3179cd12-8409-4a1b-84dc-522b72c33be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e9e167b8-c173-4d30-9ebc-91a842fe5c4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46108,DS-3179cd12-8409-4a1b-84dc-522b72c33be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e9e167b8-c173-4d30-9ebc-91a842fe5c4e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46108,DS-3179cd12-8409-4a1b-84dc-522b72c33be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e9e167b8-c173-4d30-9ebc-91a842fe5c4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-0f5bcb19-7af0-43ba-8e6f-463fceebb23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-047308ce-dd74-4224-b3f3-8f52d946a517,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-0f5bcb19-7af0-43ba-8e6f-463fceebb23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-047308ce-dd74-4224-b3f3-8f52d946a517,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-0f5bcb19-7af0-43ba-8e6f-463fceebb23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-047308ce-dd74-4224-b3f3-8f52d946a517,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-0f5bcb19-7af0-43ba-8e6f-463fceebb23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-047308ce-dd74-4224-b3f3-8f52d946a517,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-eb822321-aba9-47f1-80af-c940d4aefe81,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-41fe7caf-b13b-4f54-b546-1283ee22959b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-eb822321-aba9-47f1-80af-c940d4aefe81,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-41fe7caf-b13b-4f54-b546-1283ee22959b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-eb822321-aba9-47f1-80af-c940d4aefe81,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-41fe7caf-b13b-4f54-b546-1283ee22959b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-eb822321-aba9-47f1-80af-c940d4aefe81,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-41fe7caf-b13b-4f54-b546-1283ee22959b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-c683bc2d-2bb2-461c-b15d-959e044452b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-cf07e3f3-66e1-4678-8f83-cfdd239c82d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-c683bc2d-2bb2-461c-b15d-959e044452b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-cf07e3f3-66e1-4678-8f83-cfdd239c82d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-c683bc2d-2bb2-461c-b15d-959e044452b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-cf07e3f3-66e1-4678-8f83-cfdd239c82d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-c683bc2d-2bb2-461c-b15d-959e044452b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-cf07e3f3-66e1-4678-8f83-cfdd239c82d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38280,DS-e2060118-77c8-4918-943d-f174d8d246a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-f412d138-1a91-42b1-96b4-8be4915f5b20,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-f412d138-1a91-42b1-96b4-8be4915f5b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-e2060118-77c8-4918-943d-f174d8d246a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38280,DS-e2060118-77c8-4918-943d-f174d8d246a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-f412d138-1a91-42b1-96b4-8be4915f5b20,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36064,DS-f412d138-1a91-42b1-96b4-8be4915f5b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-e2060118-77c8-4918-943d-f174d8d246a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-fc2817ab-52ae-4d54-838b-fea093abbc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-83914d76-b254-403c-9bea-232946e85150,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37126,DS-83914d76-b254-403c-9bea-232946e85150,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-fc2817ab-52ae-4d54-838b-fea093abbc7a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-fc2817ab-52ae-4d54-838b-fea093abbc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-83914d76-b254-403c-9bea-232946e85150,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37126,DS-83914d76-b254-403c-9bea-232946e85150,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-fc2817ab-52ae-4d54-838b-fea093abbc7a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-e8a860da-e0cb-43db-8723-6022c2feed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-a2e2990e-ed36-4653-92e4-fead0e00cd82,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-e8a860da-e0cb-43db-8723-6022c2feed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-a2e2990e-ed36-4653-92e4-fead0e00cd82,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-e8a860da-e0cb-43db-8723-6022c2feed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-a2e2990e-ed36-4653-92e4-fead0e00cd82,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-e8a860da-e0cb-43db-8723-6022c2feed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-a2e2990e-ed36-4653-92e4-fead0e00cd82,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-3508aca7-c980-4514-94f5-715913fee736,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-d6351b5d-5ab1-4964-b6eb-af7741a77b6e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-3508aca7-c980-4514-94f5-715913fee736,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-d6351b5d-5ab1-4964-b6eb-af7741a77b6e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-3508aca7-c980-4514-94f5-715913fee736,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-d6351b5d-5ab1-4964-b6eb-af7741a77b6e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-3508aca7-c980-4514-94f5-715913fee736,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-d6351b5d-5ab1-4964-b6eb-af7741a77b6e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38850,DS-26079b93-61b1-41c2-b465-e4dbfeeb14f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-999d5b48-8b5c-44ef-9e6c-c6e98445617f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38850,DS-26079b93-61b1-41c2-b465-e4dbfeeb14f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-999d5b48-8b5c-44ef-9e6c-c6e98445617f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38850,DS-26079b93-61b1-41c2-b465-e4dbfeeb14f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-999d5b48-8b5c-44ef-9e6c-c6e98445617f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38850,DS-26079b93-61b1-41c2-b465-e4dbfeeb14f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-999d5b48-8b5c-44ef-9e6c-c6e98445617f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: test timed out after 30000 milliseconds
stackTrace: java.lang.Exception: test timed out after 30000 milliseconds
	at java.lang.Object.wait(Native Method)
	at org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:886)
	at org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync(DFSOutputStream.java:690)
	at org.apache.hadoop.hdfs.DFSOutputStream.hsync(DFSOutputStream.java:585)
	at org.apache.hadoop.fs.FSDataOutputStream.hsync(FSDataOutputStream.java:143)
	at org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testReloadOnEditReplayFailure(TestCheckpoint.java:251)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37214,DS-bb2f42c8-6a4f-4f32-931e-cfb6bea99783,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-a7ca4e44-4efc-4ff4-8c06-a2fc5103d562,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38511,DS-a7ca4e44-4efc-4ff4-8c06-a2fc5103d562,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-bb2f42c8-6a4f-4f32-931e-cfb6bea99783,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37214,DS-bb2f42c8-6a4f-4f32-931e-cfb6bea99783,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-a7ca4e44-4efc-4ff4-8c06-a2fc5103d562,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38511,DS-a7ca4e44-4efc-4ff4-8c06-a2fc5103d562,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-bb2f42c8-6a4f-4f32-931e-cfb6bea99783,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-231d710c-95d9-4a0c-98bb-98f676575f09,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-2b965cb4-2d46-4794-8fe7-542773c59760,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-231d710c-95d9-4a0c-98bb-98f676575f09,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-2b965cb4-2d46-4794-8fe7-542773c59760,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-231d710c-95d9-4a0c-98bb-98f676575f09,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-2b965cb4-2d46-4794-8fe7-542773c59760,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-231d710c-95d9-4a0c-98bb-98f676575f09,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-2b965cb4-2d46-4794-8fe7-542773c59760,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32978,DS-b55a26ef-1095-4cff-8089-2746f81d6a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-3f1f0a4c-0b35-4607-9030-f3ce7f59afb0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37062,DS-3f1f0a4c-0b35-4607-9030-f3ce7f59afb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-b55a26ef-1095-4cff-8089-2746f81d6a6c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32978,DS-b55a26ef-1095-4cff-8089-2746f81d6a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-3f1f0a4c-0b35-4607-9030-f3ce7f59afb0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37062,DS-3f1f0a4c-0b35-4607-9030-f3ce7f59afb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-b55a26ef-1095-4cff-8089-2746f81d6a6c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-ad3a6104-e89b-448a-98d0-8dae59c14496,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-413d11e5-12ae-4dce-aeb3-deeaf827cab0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-ad3a6104-e89b-448a-98d0-8dae59c14496,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-413d11e5-12ae-4dce-aeb3-deeaf827cab0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-ad3a6104-e89b-448a-98d0-8dae59c14496,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-413d11e5-12ae-4dce-aeb3-deeaf827cab0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42088,DS-ad3a6104-e89b-448a-98d0-8dae59c14496,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-413d11e5-12ae-4dce-aeb3-deeaf827cab0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42942,DS-60a0e945-a7d0-4fc9-a80b-42d4028e39e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-92262bb9-77a2-418e-9e3a-3c2c5eb9261a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42942,DS-60a0e945-a7d0-4fc9-a80b-42d4028e39e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-92262bb9-77a2-418e-9e3a-3c2c5eb9261a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42942,DS-60a0e945-a7d0-4fc9-a80b-42d4028e39e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-92262bb9-77a2-418e-9e3a-3c2c5eb9261a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42942,DS-60a0e945-a7d0-4fc9-a80b-42d4028e39e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-92262bb9-77a2-418e-9e3a-3c2c5eb9261a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-e2bcdb4d-83b1-4a63-a6fc-a5da22f0a177,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-bec576c0-c343-42cf-8119-6f98473fbe38,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-e2bcdb4d-83b1-4a63-a6fc-a5da22f0a177,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-bec576c0-c343-42cf-8119-6f98473fbe38,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-e2bcdb4d-83b1-4a63-a6fc-a5da22f0a177,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-bec576c0-c343-42cf-8119-6f98473fbe38,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34584,DS-e2bcdb4d-83b1-4a63-a6fc-a5da22f0a177,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-bec576c0-c343-42cf-8119-6f98473fbe38,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-061ff6f6-80a6-4aa0-aaa5-88b5f71b456e,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-f5e8a989-c1dc-4a32-8e7f-53c74d998dff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-061ff6f6-80a6-4aa0-aaa5-88b5f71b456e,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-f5e8a989-c1dc-4a32-8e7f-53c74d998dff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-061ff6f6-80a6-4aa0-aaa5-88b5f71b456e,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-f5e8a989-c1dc-4a32-8e7f-53c74d998dff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-061ff6f6-80a6-4aa0-aaa5-88b5f71b456e,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-f5e8a989-c1dc-4a32-8e7f-53c74d998dff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41757,DS-1d11ba93-68ab-45af-a8af-e95713e6d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-36a78e83-08c9-4983-bc56-a6dbc130879e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46708,DS-36a78e83-08c9-4983-bc56-a6dbc130879e,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-1d11ba93-68ab-45af-a8af-e95713e6d94a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41757,DS-1d11ba93-68ab-45af-a8af-e95713e6d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-36a78e83-08c9-4983-bc56-a6dbc130879e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46708,DS-36a78e83-08c9-4983-bc56-a6dbc130879e,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-1d11ba93-68ab-45af-a8af-e95713e6d94a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestCheckpoint#testReloadOnEditReplayFailure
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-b3b9807b-4f39-4a84-8e7f-eb48b2a219e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-afeea861-c53d-4f91-bc3f-a3b09463c98f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-afeea861-c53d-4f91-bc3f-a3b09463c98f,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-b3b9807b-4f39-4a84-8e7f-eb48b2a219e2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-b3b9807b-4f39-4a84-8e7f-eb48b2a219e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-afeea861-c53d-4f91-bc3f-a3b09463c98f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-afeea861-c53d-4f91-bc3f-a3b09463c98f,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-b3b9807b-4f39-4a84-8e7f-eb48b2a219e2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 35 out of 50
v1v1v2v2 failed with probability 2 out of 50
result: might be true error
Total execution time in seconds : 4405
