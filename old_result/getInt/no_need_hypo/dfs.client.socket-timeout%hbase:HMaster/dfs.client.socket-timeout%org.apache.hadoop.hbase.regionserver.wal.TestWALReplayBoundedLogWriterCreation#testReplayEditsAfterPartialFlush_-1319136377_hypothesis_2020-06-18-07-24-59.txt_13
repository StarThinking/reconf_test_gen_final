reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-4e9b7f0e-0e1d-40a0-a616-79d596615c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-ec21de7e-a525-4383-bc07-8df1bf27f919,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-4e9b7f0e-0e1d-40a0-a616-79d596615c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-ec21de7e-a525-4383-bc07-8df1bf27f919,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-4e9b7f0e-0e1d-40a0-a616-79d596615c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-ec21de7e-a525-4383-bc07-8df1bf27f919,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-4e9b7f0e-0e1d-40a0-a616-79d596615c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-ec21de7e-a525-4383-bc07-8df1bf27f919,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43679,DS-ee3b4a0a-301b-43f5-9960-f164f85ca36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-ae8fbcfd-a3f7-4070-8286-71249f8f8ff7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37906,DS-ae8fbcfd-a3f7-4070-8286-71249f8f8ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-ee3b4a0a-301b-43f5-9960-f164f85ca36c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43679,DS-ee3b4a0a-301b-43f5-9960-f164f85ca36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-ae8fbcfd-a3f7-4070-8286-71249f8f8ff7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37906,DS-ae8fbcfd-a3f7-4070-8286-71249f8f8ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-ee3b4a0a-301b-43f5-9960-f164f85ca36c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-040d7cb0-7079-4f41-be1d-c73e863c73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-3a7737b3-3a0c-4f88-b14d-88c530deb4e8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-040d7cb0-7079-4f41-be1d-c73e863c73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-3a7737b3-3a0c-4f88-b14d-88c530deb4e8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-040d7cb0-7079-4f41-be1d-c73e863c73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-3a7737b3-3a0c-4f88-b14d-88c530deb4e8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-040d7cb0-7079-4f41-be1d-c73e863c73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-3a7737b3-3a0c-4f88-b14d-88c530deb4e8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-bd063c5a-c2dc-4244-be5a-39e152b330d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-e1f0fd94-fa19-4412-8ff5-a7862ba9fd2b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-bd063c5a-c2dc-4244-be5a-39e152b330d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-e1f0fd94-fa19-4412-8ff5-a7862ba9fd2b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-bd063c5a-c2dc-4244-be5a-39e152b330d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-e1f0fd94-fa19-4412-8ff5-a7862ba9fd2b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-bd063c5a-c2dc-4244-be5a-39e152b330d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-e1f0fd94-fa19-4412-8ff5-a7862ba9fd2b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44535,DS-c0f72fe7-32c4-40e0-978c-d48caae04ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-c7b866cf-c774-4d4c-ac4f-dbf8ec2ef514,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44535,DS-c0f72fe7-32c4-40e0-978c-d48caae04ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-c7b866cf-c774-4d4c-ac4f-dbf8ec2ef514,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44535,DS-c0f72fe7-32c4-40e0-978c-d48caae04ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-c7b866cf-c774-4d4c-ac4f-dbf8ec2ef514,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44535,DS-c0f72fe7-32c4-40e0-978c-d48caae04ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-c7b866cf-c774-4d4c-ac4f-dbf8ec2ef514,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-163e0eeb-ecec-481c-9276-018084aba062,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-b1088a20-ae3a-4f89-b99a-bbe7bff56a5a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-163e0eeb-ecec-481c-9276-018084aba062,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-b1088a20-ae3a-4f89-b99a-bbe7bff56a5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-163e0eeb-ecec-481c-9276-018084aba062,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-b1088a20-ae3a-4f89-b99a-bbe7bff56a5a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43708,DS-163e0eeb-ecec-481c-9276-018084aba062,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-b1088a20-ae3a-4f89-b99a-bbe7bff56a5a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45898,DS-b38a7299-f59b-46a0-ac63-d90dd82eb076,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a2ab83d7-bc47-4710-a86f-66f13096a3ed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37913,DS-a2ab83d7-bc47-4710-a86f-66f13096a3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-b38a7299-f59b-46a0-ac63-d90dd82eb076,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45898,DS-b38a7299-f59b-46a0-ac63-d90dd82eb076,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a2ab83d7-bc47-4710-a86f-66f13096a3ed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37913,DS-a2ab83d7-bc47-4710-a86f-66f13096a3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-b38a7299-f59b-46a0-ac63-d90dd82eb076,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45512,DS-846c84cf-ae81-47d2-bf0d-58b78355cf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-116a2266-c19b-460f-a0ca-7fb46f136e7f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45512,DS-846c84cf-ae81-47d2-bf0d-58b78355cf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-116a2266-c19b-460f-a0ca-7fb46f136e7f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45512,DS-846c84cf-ae81-47d2-bf0d-58b78355cf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-116a2266-c19b-460f-a0ca-7fb46f136e7f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45512,DS-846c84cf-ae81-47d2-bf0d-58b78355cf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-116a2266-c19b-460f-a0ca-7fb46f136e7f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-a4602d72-2450-421f-a901-f82a8638fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-734e5569-c3bb-4599-90c3-f2428fabf4bb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-a4602d72-2450-421f-a901-f82a8638fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-734e5569-c3bb-4599-90c3-f2428fabf4bb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-a4602d72-2450-421f-a901-f82a8638fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-734e5569-c3bb-4599-90c3-f2428fabf4bb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37422,DS-a4602d72-2450-421f-a901-f82a8638fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-734e5569-c3bb-4599-90c3-f2428fabf4bb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testReplayEditsAfterPartialFlush
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-c654c789-6094-4698-a41d-4acdfeab9f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-815a352d-f844-424f-9eb3-3b1bc8ccf0f1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-c654c789-6094-4698-a41d-4acdfeab9f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-815a352d-f844-424f-9eb3-3b1bc8ccf0f1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-c654c789-6094-4698-a41d-4acdfeab9f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-815a352d-f844-424f-9eb3-3b1bc8ccf0f1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-c654c789-6094-4698-a41d-4acdfeab9f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-815a352d-f844-424f-9eb3-3b1bc8ccf0f1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2562
