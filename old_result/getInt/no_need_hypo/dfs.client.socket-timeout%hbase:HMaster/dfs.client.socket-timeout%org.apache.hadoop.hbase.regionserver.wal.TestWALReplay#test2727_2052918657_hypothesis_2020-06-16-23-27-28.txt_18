reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-8f606ac3-4406-433a-9e81-dbfc8132c653,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-93fb3de9-bffc-4983-afa9-ce79abc7cc3b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44287,DS-93fb3de9-bffc-4983-afa9-ce79abc7cc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-8f606ac3-4406-433a-9e81-dbfc8132c653,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-8f606ac3-4406-433a-9e81-dbfc8132c653,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-93fb3de9-bffc-4983-afa9-ce79abc7cc3b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44287,DS-93fb3de9-bffc-4983-afa9-ce79abc7cc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-8f606ac3-4406-433a-9e81-dbfc8132c653,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-40786e9d-242c-4c14-832f-e3b8d16e175e,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-00019996-f4f3-4ae7-8f90-94406738a615,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-40786e9d-242c-4c14-832f-e3b8d16e175e,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-00019996-f4f3-4ae7-8f90-94406738a615,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-40786e9d-242c-4c14-832f-e3b8d16e175e,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-00019996-f4f3-4ae7-8f90-94406738a615,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-40786e9d-242c-4c14-832f-e3b8d16e175e,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-00019996-f4f3-4ae7-8f90-94406738a615,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45371,DS-e140d24c-ce32-499e-8516-452e95348da9,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-3026130d-f978-43fd-801a-35c14d8a6fc6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41008,DS-3026130d-f978-43fd-801a-35c14d8a6fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-e140d24c-ce32-499e-8516-452e95348da9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45371,DS-e140d24c-ce32-499e-8516-452e95348da9,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-3026130d-f978-43fd-801a-35c14d8a6fc6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41008,DS-3026130d-f978-43fd-801a-35c14d8a6fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-e140d24c-ce32-499e-8516-452e95348da9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-93d41ee2-2586-4689-95bf-d94b59ed7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-cf09a2f0-7d87-4457-89f6-b80380d924ac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-93d41ee2-2586-4689-95bf-d94b59ed7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-cf09a2f0-7d87-4457-89f6-b80380d924ac,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-93d41ee2-2586-4689-95bf-d94b59ed7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-cf09a2f0-7d87-4457-89f6-b80380d924ac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34211,DS-93d41ee2-2586-4689-95bf-d94b59ed7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-cf09a2f0-7d87-4457-89f6-b80380d924ac,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-4db863c8-3e5e-4103-810b-83e75bd39af2,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a32940c6-4a11-4371-8077-0019611cf2ed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-4db863c8-3e5e-4103-810b-83e75bd39af2,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a32940c6-4a11-4371-8077-0019611cf2ed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-4db863c8-3e5e-4103-810b-83e75bd39af2,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a32940c6-4a11-4371-8077-0019611cf2ed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-4db863c8-3e5e-4103-810b-83e75bd39af2,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-a32940c6-4a11-4371-8077-0019611cf2ed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-bded1dba-5d4f-4374-a79c-1e5811ce31b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-235af5bc-e4e9-4d97-95a0-2d54470bf01a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33482,DS-235af5bc-e4e9-4d97-95a0-2d54470bf01a,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-bded1dba-5d4f-4374-a79c-1e5811ce31b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-bded1dba-5d4f-4374-a79c-1e5811ce31b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-235af5bc-e4e9-4d97-95a0-2d54470bf01a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33482,DS-235af5bc-e4e9-4d97-95a0-2d54470bf01a,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-bded1dba-5d4f-4374-a79c-1e5811ce31b7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-7ab24b1d-8591-494b-9954-465ce94cdf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-af7aaf3b-0ce9-4122-b47c-83bf39fc4820,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-7ab24b1d-8591-494b-9954-465ce94cdf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-af7aaf3b-0ce9-4122-b47c-83bf39fc4820,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-7ab24b1d-8591-494b-9954-465ce94cdf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-af7aaf3b-0ce9-4122-b47c-83bf39fc4820,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41925,DS-7ab24b1d-8591-494b-9954-465ce94cdf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-af7aaf3b-0ce9-4122-b47c-83bf39fc4820,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42436,DS-d264a4c2-797d-4a56-86da-d310637d4b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-4ba4c8e1-9f9c-4eb7-8ef1-3834405e5b8d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42436,DS-d264a4c2-797d-4a56-86da-d310637d4b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-4ba4c8e1-9f9c-4eb7-8ef1-3834405e5b8d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42436,DS-d264a4c2-797d-4a56-86da-d310637d4b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-4ba4c8e1-9f9c-4eb7-8ef1-3834405e5b8d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42436,DS-d264a4c2-797d-4a56-86da-d310637d4b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-4ba4c8e1-9f9c-4eb7-8ef1-3834405e5b8d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40558,DS-88b8dc90-262e-4851-a40e-f2832476abc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-27d322e2-f54b-4ad2-b726-997f01885863,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40558,DS-88b8dc90-262e-4851-a40e-f2832476abc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-27d322e2-f54b-4ad2-b726-997f01885863,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40558,DS-88b8dc90-262e-4851-a40e-f2832476abc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-27d322e2-f54b-4ad2-b726-997f01885863,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40558,DS-88b8dc90-262e-4851-a40e-f2832476abc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-27d322e2-f54b-4ad2-b726-997f01885863,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727 has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-5fa903a2-84ef-42fd-8847-3510dcaba37a,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-88272375-3b10-4410-88e7-9a71231f3c5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-5fa903a2-84ef-42fd-8847-3510dcaba37a,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-88272375-3b10-4410-88e7-9a71231f3c5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-5fa903a2-84ef-42fd-8847-3510dcaba37a,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-88272375-3b10-4410-88e7-9a71231f3c5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-5fa903a2-84ef-42fd-8847-3510dcaba37a,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-88272375-3b10-4410-88e7-9a71231f3c5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-4957c596-2bf4-44c4-b258-5494ccb64c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-2006102f-9223-4a75-a78b-b7847f92010c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-4957c596-2bf4-44c4-b258-5494ccb64c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-2006102f-9223-4a75-a78b-b7847f92010c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-4957c596-2bf4-44c4-b258-5494ccb64c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-2006102f-9223-4a75-a78b-b7847f92010c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35673,DS-4957c596-2bf4-44c4-b258-5494ccb64c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-2006102f-9223-4a75-a78b-b7847f92010c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42440,DS-414d889f-71b4-414c-b785-37cae6099390,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-d22c8448-ae38-4e84-85d0-31dc75f953bf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42440,DS-414d889f-71b4-414c-b785-37cae6099390,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-d22c8448-ae38-4e84-85d0-31dc75f953bf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42440,DS-414d889f-71b4-414c-b785-37cae6099390,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-d22c8448-ae38-4e84-85d0-31dc75f953bf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42440,DS-414d889f-71b4-414c-b785-37cae6099390,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-d22c8448-ae38-4e84-85d0-31dc75f953bf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-658ca601-619a-479e-8531-5033bd314751,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-78d80bd0-9e76-4add-adc2-3ab0967b71c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-658ca601-619a-479e-8531-5033bd314751,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-78d80bd0-9e76-4add-adc2-3ab0967b71c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-658ca601-619a-479e-8531-5033bd314751,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-78d80bd0-9e76-4add-adc2-3ab0967b71c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-658ca601-619a-479e-8531-5033bd314751,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-78d80bd0-9e76-4add-adc2-3ab0967b71c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-e868a7a5-2675-4f56-97c8-a0c794a9d4df,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-e868a7a5-2675-4f56-97c8-a0c794a9d4df,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-e868a7a5-2675-4f56-97c8-a0c794a9d4df,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-e868a7a5-2675-4f56-97c8-a0c794a9d4df,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43646,DS-a0ab6a84-28fc-49c1-a208-0b768ecb2bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-a010e771-5bf6-4731-b9ea-c085df309e64,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43646,DS-a0ab6a84-28fc-49c1-a208-0b768ecb2bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-a010e771-5bf6-4731-b9ea-c085df309e64,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43646,DS-a0ab6a84-28fc-49c1-a208-0b768ecb2bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-a010e771-5bf6-4731-b9ea-c085df309e64,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43646,DS-a0ab6a84-28fc-49c1-a208-0b768ecb2bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-a010e771-5bf6-4731-b9ea-c085df309e64,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-72b2bfc5-5e27-4885-bd23-ab316156bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-d04356b9-ceeb-45d0-bad5-dc410ce5518d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-72b2bfc5-5e27-4885-bd23-ab316156bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-d04356b9-ceeb-45d0-bad5-dc410ce5518d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-72b2bfc5-5e27-4885-bd23-ab316156bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-d04356b9-ceeb-45d0-bad5-dc410ce5518d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-72b2bfc5-5e27-4885-bd23-ab316156bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-d04356b9-ceeb-45d0-bad5-dc410ce5518d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-f7e7f227-a953-4813-bb0b-d966d7866628,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-245a2b07-e3bc-48ef-87fb-2c48c3b74431,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33356,DS-245a2b07-e3bc-48ef-87fb-2c48c3b74431,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-f7e7f227-a953-4813-bb0b-d966d7866628,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-f7e7f227-a953-4813-bb0b-d966d7866628,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-245a2b07-e3bc-48ef-87fb-2c48c3b74431,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33356,DS-245a2b07-e3bc-48ef-87fb-2c48c3b74431,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-f7e7f227-a953-4813-bb0b-d966d7866628,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36581,DS-d111b2e3-58bf-44df-a0da-dc11425a7726,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-7bcd189d-5183-4e44-9458-1b6c0960f197,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39296,DS-7bcd189d-5183-4e44-9458-1b6c0960f197,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-d111b2e3-58bf-44df-a0da-dc11425a7726,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36581,DS-d111b2e3-58bf-44df-a0da-dc11425a7726,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-7bcd189d-5183-4e44-9458-1b6c0960f197,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39296,DS-7bcd189d-5183-4e44-9458-1b6c0960f197,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-d111b2e3-58bf-44df-a0da-dc11425a7726,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-7c1a1eb2-cb7a-4035-b890-c90b8e411885,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-4f3a0f93-1811-4863-8b2e-6f79c9d84e05,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-7c1a1eb2-cb7a-4035-b890-c90b8e411885,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-4f3a0f93-1811-4863-8b2e-6f79c9d84e05,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-7c1a1eb2-cb7a-4035-b890-c90b8e411885,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-4f3a0f93-1811-4863-8b2e-6f79c9d84e05,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42217,DS-7c1a1eb2-cb7a-4035-b890-c90b8e411885,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-4f3a0f93-1811-4863-8b2e-6f79c9d84e05,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-7d2923ae-2368-4762-809d-ba85ef60bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-46f2fe83-e6da-4419-99bc-577db5af8cdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-7d2923ae-2368-4762-809d-ba85ef60bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-46f2fe83-e6da-4419-99bc-577db5af8cdf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-7d2923ae-2368-4762-809d-ba85ef60bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-46f2fe83-e6da-4419-99bc-577db5af8cdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-7d2923ae-2368-4762-809d-ba85ef60bd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-46f2fe83-e6da-4419-99bc-577db5af8cdf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-1f916fd7-1cb8-439e-9bc2-ff581b5d931a,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-f5983773-8edb-4ccd-97db-a268c8d3c7f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-1f916fd7-1cb8-439e-9bc2-ff581b5d931a,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-f5983773-8edb-4ccd-97db-a268c8d3c7f7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-1f916fd7-1cb8-439e-9bc2-ff581b5d931a,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-f5983773-8edb-4ccd-97db-a268c8d3c7f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-1f916fd7-1cb8-439e-9bc2-ff581b5d931a,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-f5983773-8edb-4ccd-97db-a268c8d3c7f7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-fbd5098e-2dd9-4a4b-9ec4-91893d055e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-f2eb5de7-ad34-4b09-b61d-f03d5760803b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-fbd5098e-2dd9-4a4b-9ec4-91893d055e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-f2eb5de7-ad34-4b09-b61d-f03d5760803b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-fbd5098e-2dd9-4a4b-9ec4-91893d055e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-f2eb5de7-ad34-4b09-b61d-f03d5760803b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-fbd5098e-2dd9-4a4b-9ec4-91893d055e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-f2eb5de7-ad34-4b09-b61d-f03d5760803b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34312,DS-9817ad78-f2c6-4ce5-9b81-f53769488374,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-b7353478-e75a-43eb-970f-77c1d12dde56,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34312,DS-9817ad78-f2c6-4ce5-9b81-f53769488374,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-b7353478-e75a-43eb-970f-77c1d12dde56,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34312,DS-9817ad78-f2c6-4ce5-9b81-f53769488374,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-b7353478-e75a-43eb-970f-77c1d12dde56,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34312,DS-9817ad78-f2c6-4ce5-9b81-f53769488374,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-b7353478-e75a-43eb-970f-77c1d12dde56,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-559a22be-ef97-48d4-af8a-9d4f4b6250b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-a89eab4f-4c67-41de-9588-e93eb4d52f7d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-559a22be-ef97-48d4-af8a-9d4f4b6250b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-a89eab4f-4c67-41de-9588-e93eb4d52f7d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-559a22be-ef97-48d4-af8a-9d4f4b6250b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-a89eab4f-4c67-41de-9588-e93eb4d52f7d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-559a22be-ef97-48d4-af8a-9d4f4b6250b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-a89eab4f-4c67-41de-9588-e93eb4d52f7d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36129,DS-6b295fe3-a97a-4f5d-be77-1652f1d44c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ca76a821-40c3-4f35-9a68-0a497e47309e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36129,DS-6b295fe3-a97a-4f5d-be77-1652f1d44c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ca76a821-40c3-4f35-9a68-0a497e47309e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36129,DS-6b295fe3-a97a-4f5d-be77-1652f1d44c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ca76a821-40c3-4f35-9a68-0a497e47309e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36129,DS-6b295fe3-a97a-4f5d-be77-1652f1d44c53,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ca76a821-40c3-4f35-9a68-0a497e47309e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33771,DS-ab57f4b3-7c4e-48e6-8d18-6255ce9d9aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-f1472b32-ce0e-4508-ac38-69c7f18330fb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33771,DS-ab57f4b3-7c4e-48e6-8d18-6255ce9d9aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-f1472b32-ce0e-4508-ac38-69c7f18330fb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33771,DS-ab57f4b3-7c4e-48e6-8d18-6255ce9d9aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-f1472b32-ce0e-4508-ac38-69c7f18330fb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33771,DS-ab57f4b3-7c4e-48e6-8d18-6255ce9d9aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-f1472b32-ce0e-4508-ac38-69c7f18330fb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-17c59be9-c618-458d-8a54-ec983df343d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-1426934a-65de-4f1f-88aa-3715b111ccf1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34071,DS-1426934a-65de-4f1f-88aa-3715b111ccf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-17c59be9-c618-458d-8a54-ec983df343d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-17c59be9-c618-458d-8a54-ec983df343d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-1426934a-65de-4f1f-88aa-3715b111ccf1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34071,DS-1426934a-65de-4f1f-88aa-3715b111ccf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-17c59be9-c618-458d-8a54-ec983df343d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-363af358-b706-4c53-bbd3-39697427ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-206a535e-1ec9-4d54-b333-4b03c5993c9d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-363af358-b706-4c53-bbd3-39697427ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-206a535e-1ec9-4d54-b333-4b03c5993c9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-363af358-b706-4c53-bbd3-39697427ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-206a535e-1ec9-4d54-b333-4b03c5993c9d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43463,DS-363af358-b706-4c53-bbd3-39697427ad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-206a535e-1ec9-4d54-b333-4b03c5993c9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42819,DS-af700137-90e4-42e2-945c-7de7a425447d,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-3ac48632-0620-4d42-8943-e0da4386abba,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-3ac48632-0620-4d42-8943-e0da4386abba,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-af700137-90e4-42e2-945c-7de7a425447d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42819,DS-af700137-90e4-42e2-945c-7de7a425447d,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-3ac48632-0620-4d42-8943-e0da4386abba,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-3ac48632-0620-4d42-8943-e0da4386abba,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-af700137-90e4-42e2-945c-7de7a425447d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-4d3b8470-d906-44b6-92a2-c36a13acd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-351446ae-6d66-4dcc-a0bb-9e8a1eb5d090,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-4d3b8470-d906-44b6-92a2-c36a13acd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-351446ae-6d66-4dcc-a0bb-9e8a1eb5d090,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-4d3b8470-d906-44b6-92a2-c36a13acd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-351446ae-6d66-4dcc-a0bb-9e8a1eb5d090,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41948,DS-4d3b8470-d906-44b6-92a2-c36a13acd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-351446ae-6d66-4dcc-a0bb-9e8a1eb5d090,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-a961e95a-6ef7-4246-9f82-390a9dd03716,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-3df613a4-2819-4197-92eb-66c0e2dc9d41,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-a961e95a-6ef7-4246-9f82-390a9dd03716,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-3df613a4-2819-4197-92eb-66c0e2dc9d41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-a961e95a-6ef7-4246-9f82-390a9dd03716,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-3df613a4-2819-4197-92eb-66c0e2dc9d41,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-a961e95a-6ef7-4246-9f82-390a9dd03716,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-3df613a4-2819-4197-92eb-66c0e2dc9d41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727 has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-ff68b231-0fce-4209-ba8a-b072649cc259,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-87d4d4a4-599d-47fa-8c99-26565c9247e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-ff68b231-0fce-4209-ba8a-b072649cc259,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-87d4d4a4-599d-47fa-8c99-26565c9247e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-ff68b231-0fce-4209-ba8a-b072649cc259,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-87d4d4a4-599d-47fa-8c99-26565c9247e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-ff68b231-0fce-4209-ba8a-b072649cc259,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-87d4d4a4-599d-47fa-8c99-26565c9247e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42495,DS-a80708ad-46cc-4d26-9e06-569b24259e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-75ad552e-d32f-4f40-88c7-89c6cb5d3b85,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42495,DS-a80708ad-46cc-4d26-9e06-569b24259e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-75ad552e-d32f-4f40-88c7-89c6cb5d3b85,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42495,DS-a80708ad-46cc-4d26-9e06-569b24259e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-75ad552e-d32f-4f40-88c7-89c6cb5d3b85,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42495,DS-a80708ad-46cc-4d26-9e06-569b24259e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-75ad552e-d32f-4f40-88c7-89c6cb5d3b85,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-f3fdd36e-83c6-43ec-b7aa-45b288fce458,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-32c35f85-6b5b-4500-906a-690d0b01c1e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46266,DS-32c35f85-6b5b-4500-906a-690d0b01c1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-f3fdd36e-83c6-43ec-b7aa-45b288fce458,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-f3fdd36e-83c6-43ec-b7aa-45b288fce458,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-32c35f85-6b5b-4500-906a-690d0b01c1e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46266,DS-32c35f85-6b5b-4500-906a-690d0b01c1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-f3fdd36e-83c6-43ec-b7aa-45b288fce458,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-49193482-4fd9-4dfe-9706-fd04109d2ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-30587d55-2a28-401e-8d2f-ceeda59ad786,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-49193482-4fd9-4dfe-9706-fd04109d2ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-30587d55-2a28-401e-8d2f-ceeda59ad786,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-49193482-4fd9-4dfe-9706-fd04109d2ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-30587d55-2a28-401e-8d2f-ceeda59ad786,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40980,DS-49193482-4fd9-4dfe-9706-fd04109d2ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-30587d55-2a28-401e-8d2f-ceeda59ad786,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-30e16ac7-801e-454b-bb03-6f9515bb62fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-251001e8-256a-4104-90b0-8e294c59b26b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-30e16ac7-801e-454b-bb03-6f9515bb62fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-251001e8-256a-4104-90b0-8e294c59b26b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-30e16ac7-801e-454b-bb03-6f9515bb62fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-251001e8-256a-4104-90b0-8e294c59b26b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-30e16ac7-801e-454b-bb03-6f9515bb62fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-251001e8-256a-4104-90b0-8e294c59b26b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-bf1d96d8-9259-4218-9ad1-8dac0df4e135,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-bf8596d6-5077-468c-8a51-ae63e2dacc5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-bf1d96d8-9259-4218-9ad1-8dac0df4e135,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-bf8596d6-5077-468c-8a51-ae63e2dacc5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-bf1d96d8-9259-4218-9ad1-8dac0df4e135,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-bf8596d6-5077-468c-8a51-ae63e2dacc5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-bf1d96d8-9259-4218-9ad1-8dac0df4e135,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-bf8596d6-5077-468c-8a51-ae63e2dacc5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-b92df4c2-2be2-4ec3-892c-0999580ec13d,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-c5a23622-8ab5-4eff-991b-ee2cf50e0ea6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-b92df4c2-2be2-4ec3-892c-0999580ec13d,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-c5a23622-8ab5-4eff-991b-ee2cf50e0ea6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-b92df4c2-2be2-4ec3-892c-0999580ec13d,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-c5a23622-8ab5-4eff-991b-ee2cf50e0ea6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33854,DS-b92df4c2-2be2-4ec3-892c-0999580ec13d,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-c5a23622-8ab5-4eff-991b-ee2cf50e0ea6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-638626c0-b433-4317-bdfd-3e6cd94b210a,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-fe03cd6f-7077-4c01-ae57-b101766f8414,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42888,DS-fe03cd6f-7077-4c01-ae57-b101766f8414,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-638626c0-b433-4317-bdfd-3e6cd94b210a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43179,DS-638626c0-b433-4317-bdfd-3e6cd94b210a,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-fe03cd6f-7077-4c01-ae57-b101766f8414,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42888,DS-fe03cd6f-7077-4c01-ae57-b101766f8414,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-638626c0-b433-4317-bdfd-3e6cd94b210a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-35cbf133-b17b-4496-b207-9839bfee7f17,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-5ba7a08a-e515-406c-9718-1395543b2ac7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-5ba7a08a-e515-406c-9718-1395543b2ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-35cbf133-b17b-4496-b207-9839bfee7f17,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-35cbf133-b17b-4496-b207-9839bfee7f17,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-5ba7a08a-e515-406c-9718-1395543b2ac7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-5ba7a08a-e515-406c-9718-1395543b2ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-35cbf133-b17b-4496-b207-9839bfee7f17,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42248,DS-733e2b2a-43c3-43e2-8de0-f3910a08a106,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-27ab8cd4-134a-4fc0-9247-455cd737ad30,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42248,DS-733e2b2a-43c3-43e2-8de0-f3910a08a106,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-27ab8cd4-134a-4fc0-9247-455cd737ad30,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42248,DS-733e2b2a-43c3-43e2-8de0-f3910a08a106,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-27ab8cd4-134a-4fc0-9247-455cd737ad30,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42248,DS-733e2b2a-43c3-43e2-8de0-f3910a08a106,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-27ab8cd4-134a-4fc0-9247-455cd737ad30,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33393,DS-7cb02ba8-3f07-4e5d-9e2f-c36c304a0808,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-80a63c07-05c6-498e-b5c2-7b54d8a94c27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33393,DS-7cb02ba8-3f07-4e5d-9e2f-c36c304a0808,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-80a63c07-05c6-498e-b5c2-7b54d8a94c27,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33393,DS-7cb02ba8-3f07-4e5d-9e2f-c36c304a0808,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-80a63c07-05c6-498e-b5c2-7b54d8a94c27,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33393,DS-7cb02ba8-3f07-4e5d-9e2f-c36c304a0808,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-80a63c07-05c6-498e-b5c2-7b54d8a94c27,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42400,DS-545544f6-4161-4d30-982a-874a5eb9cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-5b6f3151-bbf4-46c5-9dd3-69f3ced5c93b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42400,DS-545544f6-4161-4d30-982a-874a5eb9cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-5b6f3151-bbf4-46c5-9dd3-69f3ced5c93b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42400,DS-545544f6-4161-4d30-982a-874a5eb9cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-5b6f3151-bbf4-46c5-9dd3-69f3ced5c93b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42400,DS-545544f6-4161-4d30-982a-874a5eb9cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-5b6f3151-bbf4-46c5-9dd3-69f3ced5c93b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-ded9ebbd-7130-42c2-a9ce-9f99704ad527,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-3ab6268f-20b8-426b-96ff-ccb01fc0f365,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44132,DS-3ab6268f-20b8-426b-96ff-ccb01fc0f365,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-ded9ebbd-7130-42c2-a9ce-9f99704ad527,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-ded9ebbd-7130-42c2-a9ce-9f99704ad527,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-3ab6268f-20b8-426b-96ff-ccb01fc0f365,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44132,DS-3ab6268f-20b8-426b-96ff-ccb01fc0f365,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-ded9ebbd-7130-42c2-a9ce-9f99704ad527,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-3b3769f2-ca6d-4d98-a284-1366f07238e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-566f5df0-6fd0-4e32-86e0-ce0347f673ad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-3b3769f2-ca6d-4d98-a284-1366f07238e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-566f5df0-6fd0-4e32-86e0-ce0347f673ad,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-3b3769f2-ca6d-4d98-a284-1366f07238e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-566f5df0-6fd0-4e32-86e0-ce0347f673ad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-3b3769f2-ca6d-4d98-a284-1366f07238e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-566f5df0-6fd0-4e32-86e0-ce0347f673ad,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-dbe6e097-da27-4141-8f7e-955e2b3e670a,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-78780be8-0be1-4c41-be2e-2f8340443f5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-dbe6e097-da27-4141-8f7e-955e2b3e670a,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-78780be8-0be1-4c41-be2e-2f8340443f5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-dbe6e097-da27-4141-8f7e-955e2b3e670a,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-78780be8-0be1-4c41-be2e-2f8340443f5f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-dbe6e097-da27-4141-8f7e-955e2b3e670a,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-78780be8-0be1-4c41-be2e-2f8340443f5f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37430,DS-5baa20c1-052b-442f-840f-521f924d346b,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-1c2f31d0-5f0a-432b-b8ea-fe4f0104e60a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37965,DS-1c2f31d0-5f0a-432b-b8ea-fe4f0104e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-5baa20c1-052b-442f-840f-521f924d346b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37430,DS-5baa20c1-052b-442f-840f-521f924d346b,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-1c2f31d0-5f0a-432b-b8ea-fe4f0104e60a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37965,DS-1c2f31d0-5f0a-432b-b8ea-fe4f0104e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-5baa20c1-052b-442f-840f-521f924d346b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37373,DS-69944ce6-5e31-4b5d-8daf-b681f1dcf9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-1b3914ed-d595-42bc-b594-2df4b1c99922,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40727,DS-1b3914ed-d595-42bc-b594-2df4b1c99922,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-69944ce6-5e31-4b5d-8daf-b681f1dcf9a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37373,DS-69944ce6-5e31-4b5d-8daf-b681f1dcf9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-1b3914ed-d595-42bc-b594-2df4b1c99922,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40727,DS-1b3914ed-d595-42bc-b594-2df4b1c99922,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-69944ce6-5e31-4b5d-8daf-b681f1dcf9a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-f6ca793f-92c3-46af-8a51-4d85b0b50cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-2750db2b-9b45-4eeb-8139-86fccb7ba73e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45256,DS-2750db2b-9b45-4eeb-8139-86fccb7ba73e,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-f6ca793f-92c3-46af-8a51-4d85b0b50cff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-f6ca793f-92c3-46af-8a51-4d85b0b50cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-2750db2b-9b45-4eeb-8139-86fccb7ba73e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45256,DS-2750db2b-9b45-4eeb-8139-86fccb7ba73e,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-f6ca793f-92c3-46af-8a51-4d85b0b50cff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39885,DS-c00c811c-a63b-490e-babc-b0a187380cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-536f98e8-2925-424f-9f10-8b5f9538a01a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39885,DS-c00c811c-a63b-490e-babc-b0a187380cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-536f98e8-2925-424f-9f10-8b5f9538a01a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39885,DS-c00c811c-a63b-490e-babc-b0a187380cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-536f98e8-2925-424f-9f10-8b5f9538a01a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39885,DS-c00c811c-a63b-490e-babc-b0a187380cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-536f98e8-2925-424f-9f10-8b5f9538a01a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36013,DS-311a5228-fc5e-4a87-a8a4-189aba4305ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-6fde5b46-1cdf-408e-b1f9-e91af8fb7c05,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36013,DS-311a5228-fc5e-4a87-a8a4-189aba4305ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-6fde5b46-1cdf-408e-b1f9-e91af8fb7c05,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36013,DS-311a5228-fc5e-4a87-a8a4-189aba4305ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-6fde5b46-1cdf-408e-b1f9-e91af8fb7c05,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36013,DS-311a5228-fc5e-4a87-a8a4-189aba4305ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-6fde5b46-1cdf-408e-b1f9-e91af8fb7c05,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41938,DS-4be92a38-74fd-433c-8789-c8b19c157cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-86375e28-07ef-4723-8cd1-2ce27b1befb7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41938,DS-4be92a38-74fd-433c-8789-c8b19c157cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-86375e28-07ef-4723-8cd1-2ce27b1befb7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41938,DS-4be92a38-74fd-433c-8789-c8b19c157cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-86375e28-07ef-4723-8cd1-2ce27b1befb7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41938,DS-4be92a38-74fd-433c-8789-c8b19c157cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-86375e28-07ef-4723-8cd1-2ce27b1befb7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-263bb00a-f579-44f8-950f-8076c8e2f245,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-104f4f63-803b-4bdf-b7c5-4158a24e2f9c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-263bb00a-f579-44f8-950f-8076c8e2f245,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-104f4f63-803b-4bdf-b7c5-4158a24e2f9c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-263bb00a-f579-44f8-950f-8076c8e2f245,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-104f4f63-803b-4bdf-b7c5-4158a24e2f9c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-263bb00a-f579-44f8-950f-8076c8e2f245,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-104f4f63-803b-4bdf-b7c5-4158a24e2f9c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42755,DS-c6f523a9-dc27-42e5-95f5-6156e1fc6ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-19be337b-90ae-4df8-94a3-6ef4318bbdb7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42755,DS-c6f523a9-dc27-42e5-95f5-6156e1fc6ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-19be337b-90ae-4df8-94a3-6ef4318bbdb7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42755,DS-c6f523a9-dc27-42e5-95f5-6156e1fc6ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-19be337b-90ae-4df8-94a3-6ef4318bbdb7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42755,DS-c6f523a9-dc27-42e5-95f5-6156e1fc6ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-19be337b-90ae-4df8-94a3-6ef4318bbdb7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-dfbc989a-c5e6-4087-ac88-af8d0a85c243,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-e3f05a11-6cbc-45be-a3cc-a54dbf74b605,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-dfbc989a-c5e6-4087-ac88-af8d0a85c243,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-e3f05a11-6cbc-45be-a3cc-a54dbf74b605,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-dfbc989a-c5e6-4087-ac88-af8d0a85c243,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-e3f05a11-6cbc-45be-a3cc-a54dbf74b605,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-dfbc989a-c5e6-4087-ac88-af8d0a85c243,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-e3f05a11-6cbc-45be-a3cc-a54dbf74b605,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 11271
