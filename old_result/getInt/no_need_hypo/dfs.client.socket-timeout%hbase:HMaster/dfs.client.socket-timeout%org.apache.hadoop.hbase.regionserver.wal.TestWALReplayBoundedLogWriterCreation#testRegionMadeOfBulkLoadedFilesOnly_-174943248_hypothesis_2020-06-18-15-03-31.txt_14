reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-6dfa3fa2-259c-467f-a7ed-9a86819d5fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-41c25009-a305-44bb-8d4f-3186ed66f587,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-6dfa3fa2-259c-467f-a7ed-9a86819d5fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-41c25009-a305-44bb-8d4f-3186ed66f587,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-6dfa3fa2-259c-467f-a7ed-9a86819d5fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-41c25009-a305-44bb-8d4f-3186ed66f587,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-6dfa3fa2-259c-467f-a7ed-9a86819d5fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-41c25009-a305-44bb-8d4f-3186ed66f587,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=4, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=4, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44370,DS-54a06f3d-c8a1-42d1-84f4-af6c19c34c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-2f4f7bc5-d783-4a8b-86e6-6c2777f7779b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33085,DS-2f4f7bc5-d783-4a8b-86e6-6c2777f7779b,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-54a06f3d-c8a1-42d1-84f4-af6c19c34c1c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43924,DS-3994ae2c-550f-4415-90fd-6e96c87f7b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-b0bf37c6-0597-43a6-90bd-671ac9712869,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-b0bf37c6-0597-43a6-90bd-671ac9712869,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-3994ae2c-550f-4415-90fd-6e96c87f7b37,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43924,DS-3994ae2c-550f-4415-90fd-6e96c87f7b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-b0bf37c6-0597-43a6-90bd-671ac9712869,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-b0bf37c6-0597-43a6-90bd-671ac9712869,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-3994ae2c-550f-4415-90fd-6e96c87f7b37,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34638,DS-b9eb519e-3747-4bad-8292-79fc23ed5a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-e6c898d9-68c7-4df6-a75d-c4aab99840c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-e6c898d9-68c7-4df6-a75d-c4aab99840c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-b9eb519e-3747-4bad-8292-79fc23ed5a51,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34638,DS-b9eb519e-3747-4bad-8292-79fc23ed5a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-e6c898d9-68c7-4df6-a75d-c4aab99840c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39130,DS-e6c898d9-68c7-4df6-a75d-c4aab99840c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-b9eb519e-3747-4bad-8292-79fc23ed5a51,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-3a821504-046b-4410-b87a-ceef61887288,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-145c025b-cea3-40f6-927d-cac5dc0b7482,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-3a821504-046b-4410-b87a-ceef61887288,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-145c025b-cea3-40f6-927d-cac5dc0b7482,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-3a821504-046b-4410-b87a-ceef61887288,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-145c025b-cea3-40f6-927d-cac5dc0b7482,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-3a821504-046b-4410-b87a-ceef61887288,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-145c025b-cea3-40f6-927d-cac5dc0b7482,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=4, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=4, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44761,DS-1795b759-471d-424a-ab27-5154c7d1281d,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-bb4e6c62-bd0f-4b5c-8069-6a06deecf613,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44761,DS-1795b759-471d-424a-ab27-5154c7d1281d,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-bb4e6c62-bd0f-4b5c-8069-6a06deecf613,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-5808867e-753f-456d-b183-8e05506acc98,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-246215c3-2db9-476e-8e50-d7ce0a5f7af4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-5808867e-753f-456d-b183-8e05506acc98,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-246215c3-2db9-476e-8e50-d7ce0a5f7af4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-5808867e-753f-456d-b183-8e05506acc98,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-246215c3-2db9-476e-8e50-d7ce0a5f7af4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-5808867e-753f-456d-b183-8e05506acc98,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-246215c3-2db9-476e-8e50-d7ce0a5f7af4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42795,DS-04eea2cd-72c8-4f43-b73b-c77abf1c18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-55c62531-e460-4def-9e8d-0210892f2788,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41423,DS-55c62531-e460-4def-9e8d-0210892f2788,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-04eea2cd-72c8-4f43-b73b-c77abf1c18b8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42795,DS-04eea2cd-72c8-4f43-b73b-c77abf1c18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-55c62531-e460-4def-9e8d-0210892f2788,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41423,DS-55c62531-e460-4def-9e8d-0210892f2788,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-04eea2cd-72c8-4f43-b73b-c77abf1c18b8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-dc809e1f-cdde-4c6e-bed9-4441b2b16202,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-50abd37a-86ad-497f-9128-b8633225b872,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-50abd37a-86ad-497f-9128-b8633225b872,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-dc809e1f-cdde-4c6e-bed9-4441b2b16202,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-dc809e1f-cdde-4c6e-bed9-4441b2b16202,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-50abd37a-86ad-497f-9128-b8633225b872,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-50abd37a-86ad-497f-9128-b8633225b872,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-dc809e1f-cdde-4c6e-bed9-4441b2b16202,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-35c3bcec-94e6-457a-ab1a-f17b28d04cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-ec61ba8d-37c7-4385-af28-536049e58ee5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-35c3bcec-94e6-457a-ab1a-f17b28d04cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-ec61ba8d-37c7-4385-af28-536049e58ee5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-35c3bcec-94e6-457a-ab1a-f17b28d04cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-ec61ba8d-37c7-4385-af28-536049e58ee5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44828,DS-35c3bcec-94e6-457a-ab1a-f17b28d04cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-ec61ba8d-37c7-4385-af28-536049e58ee5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43178,DS-be1bb568-17ed-4bf3-97f6-bee8339a5203,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-b57a5184-9b00-45e3-96ea-942a5341d3f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43178,DS-be1bb568-17ed-4bf3-97f6-bee8339a5203,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-b57a5184-9b00-45e3-96ea-942a5341d3f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43178,DS-be1bb568-17ed-4bf3-97f6-bee8339a5203,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-b57a5184-9b00-45e3-96ea-942a5341d3f2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43178,DS-be1bb568-17ed-4bf3-97f6-bee8339a5203,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-b57a5184-9b00-45e3-96ea-942a5341d3f2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34926,DS-7a800c2c-38b3-4ed7-ab0d-9dedf8b0041f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-49db07ae-72b7-49e4-b4ed-9882bfa72745,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34926,DS-7a800c2c-38b3-4ed7-ab0d-9dedf8b0041f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-49db07ae-72b7-49e4-b4ed-9882bfa72745,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34926,DS-7a800c2c-38b3-4ed7-ab0d-9dedf8b0041f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-49db07ae-72b7-49e4-b4ed-9882bfa72745,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34926,DS-7a800c2c-38b3-4ed7-ab0d-9dedf8b0041f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-49db07ae-72b7-49e4-b4ed-9882bfa72745,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-d1be0095-c187-46fd-91cb-95477d8248f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-772bcdcc-c9f4-406e-bb39-e9fd432bee8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-d1be0095-c187-46fd-91cb-95477d8248f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-772bcdcc-c9f4-406e-bb39-e9fd432bee8a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-d1be0095-c187-46fd-91cb-95477d8248f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-772bcdcc-c9f4-406e-bb39-e9fd432bee8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40904,DS-d1be0095-c187-46fd-91cb-95477d8248f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-772bcdcc-c9f4-406e-bb39-e9fd432bee8a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33666,DS-07109a52-6ef3-4dc2-a948-f5c6b256c34d,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-b3a3cca9-18e6-49fc-a214-ea8376049c73,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-b3a3cca9-18e6-49fc-a214-ea8376049c73,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-07109a52-6ef3-4dc2-a948-f5c6b256c34d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33666,DS-07109a52-6ef3-4dc2-a948-f5c6b256c34d,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-b3a3cca9-18e6-49fc-a214-ea8376049c73,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39744,DS-b3a3cca9-18e6-49fc-a214-ea8376049c73,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-07109a52-6ef3-4dc2-a948-f5c6b256c34d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-0c14d721-ea53-40cf-8e6d-8fa5918cdb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-e0b10ef2-2889-46f3-bcb4-b39c4edc2857,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-0c14d721-ea53-40cf-8e6d-8fa5918cdb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-e0b10ef2-2889-46f3-bcb4-b39c4edc2857,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-0c14d721-ea53-40cf-8e6d-8fa5918cdb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-e0b10ef2-2889-46f3-bcb4-b39c4edc2857,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-0c14d721-ea53-40cf-8e6d-8fa5918cdb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-e0b10ef2-2889-46f3-bcb4-b39c4edc2857,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-b2575786-5ea1-4c8f-8ffb-001e77145540,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-00a45387-3bfd-40c5-bb93-e002fa45ae6b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-b2575786-5ea1-4c8f-8ffb-001e77145540,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-00a45387-3bfd-40c5-bb93-e002fa45ae6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-b2575786-5ea1-4c8f-8ffb-001e77145540,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-00a45387-3bfd-40c5-bb93-e002fa45ae6b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-b2575786-5ea1-4c8f-8ffb-001e77145540,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-00a45387-3bfd-40c5-bb93-e002fa45ae6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-769eadf9-f49d-48de-afc7-7778b7151472,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-58030416-9d61-415f-b7e1-174be92092ad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-769eadf9-f49d-48de-afc7-7778b7151472,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-58030416-9d61-415f-b7e1-174be92092ad,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-769eadf9-f49d-48de-afc7-7778b7151472,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-58030416-9d61-415f-b7e1-174be92092ad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-769eadf9-f49d-48de-afc7-7778b7151472,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-58030416-9d61-415f-b7e1-174be92092ad,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-7658fd43-99d4-4973-b94b-03ad784afd64,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-0fa8e857-ce75-45a5-aba7-4dd4dfca8738,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-7658fd43-99d4-4973-b94b-03ad784afd64,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-0fa8e857-ce75-45a5-aba7-4dd4dfca8738,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-7658fd43-99d4-4973-b94b-03ad784afd64,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-0fa8e857-ce75-45a5-aba7-4dd4dfca8738,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-7658fd43-99d4-4973-b94b-03ad784afd64,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-0fa8e857-ce75-45a5-aba7-4dd4dfca8738,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-53d9914f-834a-4aab-b58a-62f8f79c97a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-55b79aac-162b-40a2-9f93-0a11355022e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35597,DS-55b79aac-162b-40a2-9f93-0a11355022e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-53d9914f-834a-4aab-b58a-62f8f79c97a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-53d9914f-834a-4aab-b58a-62f8f79c97a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-55b79aac-162b-40a2-9f93-0a11355022e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35597,DS-55b79aac-162b-40a2-9f93-0a11355022e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-53d9914f-834a-4aab-b58a-62f8f79c97a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-2e70d4dc-751e-48b6-a303-252392729469,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-507bd08e-a5fb-4ce5-88b4-47132f35e671,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-2e70d4dc-751e-48b6-a303-252392729469,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-507bd08e-a5fb-4ce5-88b4-47132f35e671,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-2e70d4dc-751e-48b6-a303-252392729469,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-507bd08e-a5fb-4ce5-88b4-47132f35e671,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-2e70d4dc-751e-48b6-a303-252392729469,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-507bd08e-a5fb-4ce5-88b4-47132f35e671,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-338e3d5b-d860-47a6-9194-3a4eb8ab8332,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-bf08f890-ab65-4e38-909b-341cac9b9dba,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35692,DS-bf08f890-ab65-4e38-909b-341cac9b9dba,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-338e3d5b-d860-47a6-9194-3a4eb8ab8332,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-338e3d5b-d860-47a6-9194-3a4eb8ab8332,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-bf08f890-ab65-4e38-909b-341cac9b9dba,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35692,DS-bf08f890-ab65-4e38-909b-341cac9b9dba,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-338e3d5b-d860-47a6-9194-3a4eb8ab8332,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-e26ea275-b977-42d0-8a31-048f1a434abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-34b3f64a-9634-4a88-80e8-7197442758c7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-e26ea275-b977-42d0-8a31-048f1a434abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-34b3f64a-9634-4a88-80e8-7197442758c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-e26ea275-b977-42d0-8a31-048f1a434abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-34b3f64a-9634-4a88-80e8-7197442758c7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35805,DS-e26ea275-b977-42d0-8a31-048f1a434abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-34b3f64a-9634-4a88-80e8-7197442758c7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-31c34520-256f-4087-8b4d-fb82c7429c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-15d3d215-863c-4874-9327-195eceb76164,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-31c34520-256f-4087-8b4d-fb82c7429c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-15d3d215-863c-4874-9327-195eceb76164,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-31c34520-256f-4087-8b4d-fb82c7429c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-15d3d215-863c-4874-9327-195eceb76164,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44266,DS-31c34520-256f-4087-8b4d-fb82c7429c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-15d3d215-863c-4874-9327-195eceb76164,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35576,DS-2e032f56-6901-4437-be72-6e888adce334,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-c91bc7ff-833c-47b1-860e-3b0f328b324a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35576,DS-2e032f56-6901-4437-be72-6e888adce334,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-c91bc7ff-833c-47b1-860e-3b0f328b324a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35576,DS-2e032f56-6901-4437-be72-6e888adce334,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-c91bc7ff-833c-47b1-860e-3b0f328b324a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35576,DS-2e032f56-6901-4437-be72-6e888adce334,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-c91bc7ff-833c-47b1-860e-3b0f328b324a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-36af7035-2bd1-4b93-82ef-329d4524e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-20251318-4fbe-4d33-ba88-10e3e55d089b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-36af7035-2bd1-4b93-82ef-329d4524e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-20251318-4fbe-4d33-ba88-10e3e55d089b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-36af7035-2bd1-4b93-82ef-329d4524e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-20251318-4fbe-4d33-ba88-10e3e55d089b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-36af7035-2bd1-4b93-82ef-329d4524e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-20251318-4fbe-4d33-ba88-10e3e55d089b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-9e877acc-6189-4f76-b40e-0ef055ba93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-0f199459-1989-45a9-b8b2-a48c20792a45,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-9e877acc-6189-4f76-b40e-0ef055ba93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-0f199459-1989-45a9-b8b2-a48c20792a45,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-9e877acc-6189-4f76-b40e-0ef055ba93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-0f199459-1989-45a9-b8b2-a48c20792a45,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-9e877acc-6189-4f76-b40e-0ef055ba93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-0f199459-1989-45a9-b8b2-a48c20792a45,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40367,DS-c27045d2-d31f-4944-aa4f-c05d60fba649,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-3d148119-db8d-4528-be96-638a1906aae5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40398,DS-3d148119-db8d-4528-be96-638a1906aae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-c27045d2-d31f-4944-aa4f-c05d60fba649,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40367,DS-c27045d2-d31f-4944-aa4f-c05d60fba649,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-3d148119-db8d-4528-be96-638a1906aae5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40398,DS-3d148119-db8d-4528-be96-638a1906aae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-c27045d2-d31f-4944-aa4f-c05d60fba649,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-c6c2e8d6-31c2-4382-a9d6-668fbc9094bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-8fe1e9b5-03c8-49dc-967a-9e4c302aaf9e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-c6c2e8d6-31c2-4382-a9d6-668fbc9094bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-8fe1e9b5-03c8-49dc-967a-9e4c302aaf9e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-c6c2e8d6-31c2-4382-a9d6-668fbc9094bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-8fe1e9b5-03c8-49dc-967a-9e4c302aaf9e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-c6c2e8d6-31c2-4382-a9d6-668fbc9094bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-8fe1e9b5-03c8-49dc-967a-9e4c302aaf9e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-fa56c783-6174-4a74-ab11-cb8466f74439,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-490fa6f2-46f1-49e8-972f-f7c617565e1e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-fa56c783-6174-4a74-ab11-cb8466f74439,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-490fa6f2-46f1-49e8-972f-f7c617565e1e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-fa56c783-6174-4a74-ab11-cb8466f74439,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-490fa6f2-46f1-49e8-972f-f7c617565e1e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41241,DS-fa56c783-6174-4a74-ab11-cb8466f74439,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-490fa6f2-46f1-49e8-972f-f7c617565e1e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-1c5ecc5a-72c6-470c-a931-dc893e3fb2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-e9c7061d-df6f-4208-a77e-abf931c69927,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-1c5ecc5a-72c6-470c-a931-dc893e3fb2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-e9c7061d-df6f-4208-a77e-abf931c69927,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-1c5ecc5a-72c6-470c-a931-dc893e3fb2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-e9c7061d-df6f-4208-a77e-abf931c69927,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-1c5ecc5a-72c6-470c-a931-dc893e3fb2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-e9c7061d-df6f-4208-a77e-abf931c69927,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-99e18300-f940-4219-bb82-a13d5ebea5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-4a316256-9353-402b-a948-7c2af83ebee9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-99e18300-f940-4219-bb82-a13d5ebea5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-4a316256-9353-402b-a948-7c2af83ebee9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-99e18300-f940-4219-bb82-a13d5ebea5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-4a316256-9353-402b-a948-7c2af83ebee9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-99e18300-f940-4219-bb82-a13d5ebea5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-4a316256-9353-402b-a948-7c2af83ebee9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-7577ecff-c213-43a5-82b3-57533ce0c3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-4d781b5a-c5c2-4ecc-976a-0411716a5bb7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-4d781b5a-c5c2-4ecc-976a-0411716a5bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-7577ecff-c213-43a5-82b3-57533ce0c3a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-7577ecff-c213-43a5-82b3-57533ce0c3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-4d781b5a-c5c2-4ecc-976a-0411716a5bb7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-4d781b5a-c5c2-4ecc-976a-0411716a5bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-7577ecff-c213-43a5-82b3-57533ce0c3a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-ed61304b-3ec7-4031-9adc-45c60e7ebab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-ac811352-9052-4c18-97c4-702c2b1303cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-ac811352-9052-4c18-97c4-702c2b1303cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-ed61304b-3ec7-4031-9adc-45c60e7ebab5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-ed61304b-3ec7-4031-9adc-45c60e7ebab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-ac811352-9052-4c18-97c4-702c2b1303cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-ac811352-9052-4c18-97c4-702c2b1303cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-ed61304b-3ec7-4031-9adc-45c60e7ebab5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-7d9ea646-5df7-4039-a764-b941dd3dec04,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-8a755dfa-cd43-4d16-9070-8ddf82739e95,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-7d9ea646-5df7-4039-a764-b941dd3dec04,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-8a755dfa-cd43-4d16-9070-8ddf82739e95,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-7d9ea646-5df7-4039-a764-b941dd3dec04,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-8a755dfa-cd43-4d16-9070-8ddf82739e95,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-7d9ea646-5df7-4039-a764-b941dd3dec04,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-8a755dfa-cd43-4d16-9070-8ddf82739e95,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38078,DS-08e88738-5ab2-4969-a00e-bb0020af8f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-61f3813b-31ca-450f-9817-b43ac7ee1b43,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38078,DS-08e88738-5ab2-4969-a00e-bb0020af8f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-61f3813b-31ca-450f-9817-b43ac7ee1b43,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38078,DS-08e88738-5ab2-4969-a00e-bb0020af8f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-61f3813b-31ca-450f-9817-b43ac7ee1b43,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38078,DS-08e88738-5ab2-4969-a00e-bb0020af8f46,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-61f3813b-31ca-450f-9817-b43ac7ee1b43,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-a511e64d-bc18-4db6-8968-6f297709edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-97dfb442-8104-46b9-98e9-c3608316e3d6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-a511e64d-bc18-4db6-8968-6f297709edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-97dfb442-8104-46b9-98e9-c3608316e3d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-a511e64d-bc18-4db6-8968-6f297709edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-97dfb442-8104-46b9-98e9-c3608316e3d6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-a511e64d-bc18-4db6-8968-6f297709edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-97dfb442-8104-46b9-98e9-c3608316e3d6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33004,DS-a61b85ec-205b-4571-a3f0-7f0b7e9f70d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-91b10670-1e2c-471c-9cfe-3ce2e691f05f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33004,DS-a61b85ec-205b-4571-a3f0-7f0b7e9f70d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-91b10670-1e2c-471c-9cfe-3ce2e691f05f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33004,DS-a61b85ec-205b-4571-a3f0-7f0b7e9f70d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-91b10670-1e2c-471c-9cfe-3ce2e691f05f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33004,DS-a61b85ec-205b-4571-a3f0-7f0b7e9f70d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-91b10670-1e2c-471c-9cfe-3ce2e691f05f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-172e9a1e-a689-4fe4-8016-a419ea934a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-01f81471-84ee-4e3f-856d-8e78cdd41b73,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-01f81471-84ee-4e3f-856d-8e78cdd41b73,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-172e9a1e-a689-4fe4-8016-a419ea934a3a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-172e9a1e-a689-4fe4-8016-a419ea934a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-01f81471-84ee-4e3f-856d-8e78cdd41b73,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-01f81471-84ee-4e3f-856d-8e78cdd41b73,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-172e9a1e-a689-4fe4-8016-a419ea934a3a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39516,DS-77843b52-a254-48e3-a3db-c58b478431ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-88a8c4dd-005c-43a3-8794-5b6286ce2df6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39516,DS-77843b52-a254-48e3-a3db-c58b478431ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-88a8c4dd-005c-43a3-8794-5b6286ce2df6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39516,DS-77843b52-a254-48e3-a3db-c58b478431ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-88a8c4dd-005c-43a3-8794-5b6286ce2df6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39516,DS-77843b52-a254-48e3-a3db-c58b478431ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-88a8c4dd-005c-43a3-8794-5b6286ce2df6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-e2f7b9b6-7c8e-4279-8d8a-992d43441803,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-51e9ea5b-5df3-4d14-8d9e-4206f2fc6a14,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-e2f7b9b6-7c8e-4279-8d8a-992d43441803,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-51e9ea5b-5df3-4d14-8d9e-4206f2fc6a14,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-e2f7b9b6-7c8e-4279-8d8a-992d43441803,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-51e9ea5b-5df3-4d14-8d9e-4206f2fc6a14,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-e2f7b9b6-7c8e-4279-8d8a-992d43441803,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-51e9ea5b-5df3-4d14-8d9e-4206f2fc6a14,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-72d6068a-6bed-489f-9d4c-9efa145ce0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ff1e3959-72c8-41c8-84bf-dcd6f61bfe8f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-72d6068a-6bed-489f-9d4c-9efa145ce0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ff1e3959-72c8-41c8-84bf-dcd6f61bfe8f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-72d6068a-6bed-489f-9d4c-9efa145ce0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ff1e3959-72c8-41c8-84bf-dcd6f61bfe8f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40738,DS-72d6068a-6bed-489f-9d4c-9efa145ce0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ff1e3959-72c8-41c8-84bf-dcd6f61bfe8f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-0d50b4c4-ce4c-472b-b0c3-cc0169cb1e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-7639c6fa-bad9-4359-94f7-0275039af266,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-0d50b4c4-ce4c-472b-b0c3-cc0169cb1e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-7639c6fa-bad9-4359-94f7-0275039af266,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-0d50b4c4-ce4c-472b-b0c3-cc0169cb1e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-7639c6fa-bad9-4359-94f7-0275039af266,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-0d50b4c4-ce4c-472b-b0c3-cc0169cb1e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-7639c6fa-bad9-4359-94f7-0275039af266,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-729bcf9e-a5c0-4371-b7af-07eda4adadcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-1ceea415-488b-44e9-a346-ef7ebffd7ca4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-1ceea415-488b-44e9-a346-ef7ebffd7ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-729bcf9e-a5c0-4371-b7af-07eda4adadcf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-729bcf9e-a5c0-4371-b7af-07eda4adadcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-1ceea415-488b-44e9-a346-ef7ebffd7ca4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-1ceea415-488b-44e9-a346-ef7ebffd7ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-729bcf9e-a5c0-4371-b7af-07eda4adadcf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41845,DS-4b65f92e-3c37-4393-8575-508441f93516,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-2fc3f95c-8da3-4a8f-9f34-25e02569f0b1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41845,DS-4b65f92e-3c37-4393-8575-508441f93516,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-2fc3f95c-8da3-4a8f-9f34-25e02569f0b1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41845,DS-4b65f92e-3c37-4393-8575-508441f93516,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-2fc3f95c-8da3-4a8f-9f34-25e02569f0b1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41845,DS-4b65f92e-3c37-4393-8575-508441f93516,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-2fc3f95c-8da3-4a8f-9f34-25e02569f0b1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34714,DS-5a752585-b259-4d3c-aead-bb5d5bd1d34f,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-a36c0a03-4fdf-48a9-a543-2313e0c047ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-a36c0a03-4fdf-48a9-a543-2313e0c047ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-5a752585-b259-4d3c-aead-bb5d5bd1d34f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34714,DS-5a752585-b259-4d3c-aead-bb5d5bd1d34f,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-a36c0a03-4fdf-48a9-a543-2313e0c047ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-a36c0a03-4fdf-48a9-a543-2313e0c047ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-5a752585-b259-4d3c-aead-bb5d5bd1d34f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-e6bea518-6c4d-482d-a5e0-38ef04675b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-378dc4b3-7527-47ec-a41a-a31981c06ddc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-e6bea518-6c4d-482d-a5e0-38ef04675b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-378dc4b3-7527-47ec-a41a-a31981c06ddc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-e6bea518-6c4d-482d-a5e0-38ef04675b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-378dc4b3-7527-47ec-a41a-a31981c06ddc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42461,DS-e6bea518-6c4d-482d-a5e0-38ef04675b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-378dc4b3-7527-47ec-a41a-a31981c06ddc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-cd333816-9061-4f7a-b7b2-d7621fd10fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-fd8f14ac-6f68-420a-9f48-3478542f937c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-fd8f14ac-6f68-420a-9f48-3478542f937c,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-cd333816-9061-4f7a-b7b2-d7621fd10fdb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37766,DS-cd333816-9061-4f7a-b7b2-d7621fd10fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-fd8f14ac-6f68-420a-9f48-3478542f937c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42897,DS-fd8f14ac-6f68-420a-9f48-3478542f937c,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-cd333816-9061-4f7a-b7b2-d7621fd10fdb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36693,DS-275f61d7-d44f-4309-ba1a-396f56356832,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-8e9f8369-84f5-4afe-aa5a-1b44fce980bc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45432,DS-8e9f8369-84f5-4afe-aa5a-1b44fce980bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-275f61d7-d44f-4309-ba1a-396f56356832,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36693,DS-275f61d7-d44f-4309-ba1a-396f56356832,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-8e9f8369-84f5-4afe-aa5a-1b44fce980bc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45432,DS-8e9f8369-84f5-4afe-aa5a-1b44fce980bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-275f61d7-d44f-4309-ba1a-396f56356832,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-3cacc94a-f35c-4a4c-ab8c-896313a283a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-2a704225-9cf9-4544-9fe2-7e1e08dffe48,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-3cacc94a-f35c-4a4c-ab8c-896313a283a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-2a704225-9cf9-4544-9fe2-7e1e08dffe48,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-3cacc94a-f35c-4a4c-ab8c-896313a283a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-2a704225-9cf9-4544-9fe2-7e1e08dffe48,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-3cacc94a-f35c-4a4c-ab8c-896313a283a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-2a704225-9cf9-4544-9fe2-7e1e08dffe48,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-7990d727-5951-4899-80c3-03fa56767ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-8747a7f9-f1bc-4e6f-9b75-81ee095c8148,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-7990d727-5951-4899-80c3-03fa56767ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-8747a7f9-f1bc-4e6f-9b75-81ee095c8148,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-7990d727-5951-4899-80c3-03fa56767ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-8747a7f9-f1bc-4e6f-9b75-81ee095c8148,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-7990d727-5951-4899-80c3-03fa56767ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-8747a7f9-f1bc-4e6f-9b75-81ee095c8148,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-2b5c4ebf-66a3-4a1e-b348-1f63d126f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-9594fa61-5425-42ff-bec6-dfe2ed0597c4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-2b5c4ebf-66a3-4a1e-b348-1f63d126f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-9594fa61-5425-42ff-bec6-dfe2ed0597c4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-2b5c4ebf-66a3-4a1e-b348-1f63d126f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-9594fa61-5425-42ff-bec6-dfe2ed0597c4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-2b5c4ebf-66a3-4a1e-b348-1f63d126f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-9594fa61-5425-42ff-bec6-dfe2ed0597c4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-26abc165-8213-4b11-a5bb-7e342e4ef7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-080ec26c-435a-4f28-91a7-f74d3148fbac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-26abc165-8213-4b11-a5bb-7e342e4ef7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-080ec26c-435a-4f28-91a7-f74d3148fbac,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-26abc165-8213-4b11-a5bb-7e342e4ef7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-080ec26c-435a-4f28-91a7-f74d3148fbac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-26abc165-8213-4b11-a5bb-7e342e4ef7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-080ec26c-435a-4f28-91a7-f74d3148fbac,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-ede51ff8-ecb2-4d28-85e6-c57d3791fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b777b9c5-8075-4db3-9146-3e7d239cc336,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-ede51ff8-ecb2-4d28-85e6-c57d3791fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b777b9c5-8075-4db3-9146-3e7d239cc336,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-ede51ff8-ecb2-4d28-85e6-c57d3791fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b777b9c5-8075-4db3-9146-3e7d239cc336,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-ede51ff8-ecb2-4d28-85e6-c57d3791fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-b777b9c5-8075-4db3-9146-3e7d239cc336,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testRegionMadeOfBulkLoadedFilesOnly
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45636,DS-6a444d54-0348-450f-b87d-5e0e84222f93,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-9a4beef8-a27b-4a0a-9472-f393fabaffac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39141,DS-9a4beef8-a27b-4a0a-9472-f393fabaffac,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-6a444d54-0348-450f-b87d-5e0e84222f93,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45636,DS-6a444d54-0348-450f-b87d-5e0e84222f93,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-9a4beef8-a27b-4a0a-9472-f393fabaffac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39141,DS-9a4beef8-a27b-4a0a-9472-f393fabaffac,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-6a444d54-0348-450f-b87d-5e0e84222f93,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 12616
