reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34934,DS-02a10cf4-dd55-4ac0-b179-ddd4dac11fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-fc8e3be7-c14e-4248-a07c-513ce24caf57,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34934,DS-02a10cf4-dd55-4ac0-b179-ddd4dac11fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-fc8e3be7-c14e-4248-a07c-513ce24caf57,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34934,DS-02a10cf4-dd55-4ac0-b179-ddd4dac11fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-fc8e3be7-c14e-4248-a07c-513ce24caf57,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34934,DS-02a10cf4-dd55-4ac0-b179-ddd4dac11fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-fc8e3be7-c14e-4248-a07c-513ce24caf57,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-a0d1f113-2e0b-4547-a967-079ceb3ce228,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-0159fd0a-1974-4917-9088-5c6f845d5e8d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-0159fd0a-1974-4917-9088-5c6f845d5e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-a0d1f113-2e0b-4547-a967-079ceb3ce228,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35904,DS-a0d1f113-2e0b-4547-a967-079ceb3ce228,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-0159fd0a-1974-4917-9088-5c6f845d5e8d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-0159fd0a-1974-4917-9088-5c6f845d5e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-a0d1f113-2e0b-4547-a967-079ceb3ce228,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-ddb37fba-8394-4079-ada3-d9e6585f2419,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-8cb38f0c-bdd4-499b-b5f3-d6c57fe9653e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-ddb37fba-8394-4079-ada3-d9e6585f2419,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-8cb38f0c-bdd4-499b-b5f3-d6c57fe9653e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-ddb37fba-8394-4079-ada3-d9e6585f2419,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-8cb38f0c-bdd4-499b-b5f3-d6c57fe9653e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35870,DS-ddb37fba-8394-4079-ada3-d9e6585f2419,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-8cb38f0c-bdd4-499b-b5f3-d6c57fe9653e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-8546e55f-b151-48a5-8303-f876862bba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-2e35900e-7ac8-4c94-9606-137056b70cd2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-8546e55f-b151-48a5-8303-f876862bba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-2e35900e-7ac8-4c94-9606-137056b70cd2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-8546e55f-b151-48a5-8303-f876862bba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-2e35900e-7ac8-4c94-9606-137056b70cd2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44579,DS-8546e55f-b151-48a5-8303-f876862bba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-2e35900e-7ac8-4c94-9606-137056b70cd2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-19ca6ce5-ad6b-43e5-ba11-0a4d596ea1da,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-da0c1922-c52f-488c-9a9b-a5b005176e01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43221,DS-da0c1922-c52f-488c-9a9b-a5b005176e01,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-19ca6ce5-ad6b-43e5-ba11-0a4d596ea1da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38589,DS-19ca6ce5-ad6b-43e5-ba11-0a4d596ea1da,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-da0c1922-c52f-488c-9a9b-a5b005176e01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43221,DS-da0c1922-c52f-488c-9a9b-a5b005176e01,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-19ca6ce5-ad6b-43e5-ba11-0a4d596ea1da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-3c99e0ab-8605-4ba6-8fd5-de34d6d28ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-d1a546ad-6e49-4889-8b2c-4240e74e079e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-3c99e0ab-8605-4ba6-8fd5-de34d6d28ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-d1a546ad-6e49-4889-8b2c-4240e74e079e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-3c99e0ab-8605-4ba6-8fd5-de34d6d28ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-d1a546ad-6e49-4889-8b2c-4240e74e079e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35949,DS-3c99e0ab-8605-4ba6-8fd5-de34d6d28ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-d1a546ad-6e49-4889-8b2c-4240e74e079e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-ce4ecab4-c715-428f-ae78-0f8a13e9a298,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-629e16b0-9631-417b-93c0-49c4a064748c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-ce4ecab4-c715-428f-ae78-0f8a13e9a298,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-629e16b0-9631-417b-93c0-49c4a064748c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-ce4ecab4-c715-428f-ae78-0f8a13e9a298,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-629e16b0-9631-417b-93c0-49c4a064748c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-ce4ecab4-c715-428f-ae78-0f8a13e9a298,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-629e16b0-9631-417b-93c0-49c4a064748c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-d67b8228-5af8-47cb-ad11-640c44590e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-a4f9c191-b240-4ad6-a015-a053ac022115,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-d67b8228-5af8-47cb-ad11-640c44590e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-a4f9c191-b240-4ad6-a015-a053ac022115,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-d67b8228-5af8-47cb-ad11-640c44590e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-a4f9c191-b240-4ad6-a015-a053ac022115,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-d67b8228-5af8-47cb-ad11-640c44590e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-a4f9c191-b240-4ad6-a015-a053ac022115,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34473,DS-7f5373ed-eb20-43ef-b294-3b153c1b57dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-a1c8dbc7-da75-4915-a4b7-8be45d80acf5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36185,DS-a1c8dbc7-da75-4915-a4b7-8be45d80acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-7f5373ed-eb20-43ef-b294-3b153c1b57dc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34473,DS-7f5373ed-eb20-43ef-b294-3b153c1b57dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-a1c8dbc7-da75-4915-a4b7-8be45d80acf5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36185,DS-a1c8dbc7-da75-4915-a4b7-8be45d80acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-7f5373ed-eb20-43ef-b294-3b153c1b57dc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestSecureWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46589,DS-056eddcc-61c0-4a83-96cc-c97ac8cf09d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-376c9210-b5fb-4418-a2f5-5d3e02c252ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45116,DS-376c9210-b5fb-4418-a2f5-5d3e02c252ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-056eddcc-61c0-4a83-96cc-c97ac8cf09d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46589,DS-056eddcc-61c0-4a83-96cc-c97ac8cf09d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-376c9210-b5fb-4418-a2f5-5d3e02c252ae,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45116,DS-376c9210-b5fb-4418-a2f5-5d3e02c252ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-056eddcc-61c0-4a83-96cc-c97ac8cf09d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1882
