reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39465,DS-462ac044-b263-4f6c-891d-8342ab69b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-9aa68be7-56f8-4335-a622-abf7fd9c98a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-9aa68be7-56f8-4335-a622-abf7fd9c98a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-462ac044-b263-4f6c-891d-8342ab69b15d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39465,DS-462ac044-b263-4f6c-891d-8342ab69b15d,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-9aa68be7-56f8-4335-a622-abf7fd9c98a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-9aa68be7-56f8-4335-a622-abf7fd9c98a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-462ac044-b263-4f6c-891d-8342ab69b15d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41734,DS-8f6a71b2-9e2a-4393-8a95-35edca5f5299,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-a9eeebb9-b328-4141-b9ae-f937f6b0249b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41734,DS-8f6a71b2-9e2a-4393-8a95-35edca5f5299,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-a9eeebb9-b328-4141-b9ae-f937f6b0249b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41734,DS-8f6a71b2-9e2a-4393-8a95-35edca5f5299,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-a9eeebb9-b328-4141-b9ae-f937f6b0249b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41734,DS-8f6a71b2-9e2a-4393-8a95-35edca5f5299,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-a9eeebb9-b328-4141-b9ae-f937f6b0249b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40495,DS-c8e1a4ae-6219-4a53-af15-98d3114bd45a,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-23328122-9a4e-4f40-aec5-4dcfeaef8fda,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-23328122-9a4e-4f40-aec5-4dcfeaef8fda,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-c8e1a4ae-6219-4a53-af15-98d3114bd45a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40495,DS-c8e1a4ae-6219-4a53-af15-98d3114bd45a,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-23328122-9a4e-4f40-aec5-4dcfeaef8fda,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-23328122-9a4e-4f40-aec5-4dcfeaef8fda,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-c8e1a4ae-6219-4a53-af15-98d3114bd45a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-051f5750-b5c5-481a-b334-7def9cc3551e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-c1084a9c-52c6-4fba-9bc3-78cd81258cf9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-051f5750-b5c5-481a-b334-7def9cc3551e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-c1084a9c-52c6-4fba-9bc3-78cd81258cf9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-051f5750-b5c5-481a-b334-7def9cc3551e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-c1084a9c-52c6-4fba-9bc3-78cd81258cf9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-051f5750-b5c5-481a-b334-7def9cc3551e,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-c1084a9c-52c6-4fba-9bc3-78cd81258cf9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-c8394e24-9aa9-4bf3-9d10-b866a91ec5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-ffbd05d4-d5e2-49a8-8e4b-f71d56e4fb61,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-c8394e24-9aa9-4bf3-9d10-b866a91ec5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-ffbd05d4-d5e2-49a8-8e4b-f71d56e4fb61,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-c8394e24-9aa9-4bf3-9d10-b866a91ec5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-ffbd05d4-d5e2-49a8-8e4b-f71d56e4fb61,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-c8394e24-9aa9-4bf3-9d10-b866a91ec5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-ffbd05d4-d5e2-49a8-8e4b-f71d56e4fb61,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40910,DS-86fb3542-89d5-4cc9-bbf6-8a36742ab7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-4c404bd3-0e0e-4f6b-b985-85d88ab21de2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-4c404bd3-0e0e-4f6b-b985-85d88ab21de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-86fb3542-89d5-4cc9-bbf6-8a36742ab7ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40910,DS-86fb3542-89d5-4cc9-bbf6-8a36742ab7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-4c404bd3-0e0e-4f6b-b985-85d88ab21de2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34284,DS-4c404bd3-0e0e-4f6b-b985-85d88ab21de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-86fb3542-89d5-4cc9-bbf6-8a36742ab7ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-45985de8-4c32-4a66-84f1-d077d5c90a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-7875e471-4984-4c9c-95e4-fa5d16fc2f9b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-45985de8-4c32-4a66-84f1-d077d5c90a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-7875e471-4984-4c9c-95e4-fa5d16fc2f9b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-45985de8-4c32-4a66-84f1-d077d5c90a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-7875e471-4984-4c9c-95e4-fa5d16fc2f9b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-45985de8-4c32-4a66-84f1-d077d5c90a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-7875e471-4984-4c9c-95e4-fa5d16fc2f9b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46652,DS-b5b32150-aed4-4450-bd1a-819d0173bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-a1745d1a-5542-4e13-a35b-408a398ccafe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46652,DS-b5b32150-aed4-4450-bd1a-819d0173bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-a1745d1a-5542-4e13-a35b-408a398ccafe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46652,DS-b5b32150-aed4-4450-bd1a-819d0173bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-a1745d1a-5542-4e13-a35b-408a398ccafe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46652,DS-b5b32150-aed4-4450-bd1a-819d0173bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-a1745d1a-5542-4e13-a35b-408a398ccafe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35538,DS-76d9df64-7655-4da4-a026-0aa70cc62dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-51e0ea8d-d57a-4f44-a00e-7f746a245585,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32872,DS-51e0ea8d-d57a-4f44-a00e-7f746a245585,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-76d9df64-7655-4da4-a026-0aa70cc62dc8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35538,DS-76d9df64-7655-4da4-a026-0aa70cc62dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-51e0ea8d-d57a-4f44-a00e-7f746a245585,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32872,DS-51e0ea8d-d57a-4f44-a00e-7f746a245585,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-76d9df64-7655-4da4-a026-0aa70cc62dc8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=37, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=37, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42997,DS-ae476b87-0f08-4c70-b19c-58787be7c4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-963a9076-b862-4476-aeaf-76614ecb8bfe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42997,DS-ae476b87-0f08-4c70-b19c-58787be7c4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-963a9076-b862-4476-aeaf-76614ecb8bfe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40925,DS-2c386156-b99f-416b-8e53-0cd8bcafdcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-0b51ac9b-5b52-42cb-a734-582b7ebdb615,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45878,DS-0b51ac9b-5b52-42cb-a734-582b7ebdb615,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-2c386156-b99f-416b-8e53-0cd8bcafdcdc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40925,DS-2c386156-b99f-416b-8e53-0cd8bcafdcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-0b51ac9b-5b52-42cb-a734-582b7ebdb615,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45878,DS-0b51ac9b-5b52-42cb-a734-582b7ebdb615,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-2c386156-b99f-416b-8e53-0cd8bcafdcdc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-c07e019e-5c09-4b0d-add4-d1b9c3f0f3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-fdd36a25-afb6-4c72-8a75-74fb4f6caef2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37970,DS-fdd36a25-afb6-4c72-8a75-74fb4f6caef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-c07e019e-5c09-4b0d-add4-d1b9c3f0f3a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-c07e019e-5c09-4b0d-add4-d1b9c3f0f3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-fdd36a25-afb6-4c72-8a75-74fb4f6caef2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37970,DS-fdd36a25-afb6-4c72-8a75-74fb4f6caef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-c07e019e-5c09-4b0d-add4-d1b9c3f0f3a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-090d6f14-202b-4ad4-968e-a1969b65f873,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-4c57aabc-7531-412c-bbf0-8bacde8085c0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-090d6f14-202b-4ad4-968e-a1969b65f873,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-4c57aabc-7531-412c-bbf0-8bacde8085c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-090d6f14-202b-4ad4-968e-a1969b65f873,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-4c57aabc-7531-412c-bbf0-8bacde8085c0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-090d6f14-202b-4ad4-968e-a1969b65f873,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-4c57aabc-7531-412c-bbf0-8bacde8085c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-1f84a9d8-b219-4888-8f70-2b16c8d0bd58,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-187b9082-15ac-431c-bc39-ba91ea8edd19,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39829,DS-187b9082-15ac-431c-bc39-ba91ea8edd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-1f84a9d8-b219-4888-8f70-2b16c8d0bd58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-1f84a9d8-b219-4888-8f70-2b16c8d0bd58,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-187b9082-15ac-431c-bc39-ba91ea8edd19,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39829,DS-187b9082-15ac-431c-bc39-ba91ea8edd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-1f84a9d8-b219-4888-8f70-2b16c8d0bd58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45040,DS-a809b133-5e1b-46ad-9364-7b06f5765370,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-698da72e-15c0-4d34-9960-825066345a85,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45040,DS-a809b133-5e1b-46ad-9364-7b06f5765370,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-698da72e-15c0-4d34-9960-825066345a85,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45040,DS-a809b133-5e1b-46ad-9364-7b06f5765370,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-698da72e-15c0-4d34-9960-825066345a85,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45040,DS-a809b133-5e1b-46ad-9364-7b06f5765370,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-698da72e-15c0-4d34-9960-825066345a85,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=3, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=3, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39923,DS-06b92e6f-ca01-464e-be56-a33cf1122a69,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-91366957-75bb-4cb4-8151-ef302f276d9d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39923,DS-06b92e6f-ca01-464e-be56-a33cf1122a69,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-91366957-75bb-4cb4-8151-ef302f276d9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-716ae1c8-04ee-4aa5-b3c9-8e19783195e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-cc92170a-707f-4979-b6cc-3baf43fcd98c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-cc92170a-707f-4979-b6cc-3baf43fcd98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-716ae1c8-04ee-4aa5-b3c9-8e19783195e6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-716ae1c8-04ee-4aa5-b3c9-8e19783195e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-cc92170a-707f-4979-b6cc-3baf43fcd98c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-cc92170a-707f-4979-b6cc-3baf43fcd98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-716ae1c8-04ee-4aa5-b3c9-8e19783195e6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-c22e068f-778f-4caa-bc47-6273d9b1dabc,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-fb14d810-a5ee-4402-8f34-83574f6538a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-c22e068f-778f-4caa-bc47-6273d9b1dabc,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-fb14d810-a5ee-4402-8f34-83574f6538a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-c22e068f-778f-4caa-bc47-6273d9b1dabc,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-fb14d810-a5ee-4402-8f34-83574f6538a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-c22e068f-778f-4caa-bc47-6273d9b1dabc,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-fb14d810-a5ee-4402-8f34-83574f6538a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37190,DS-1f6bda31-aed9-4b92-9711-f641a1b99d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-ffd72acf-1f28-4b33-b1a9-cab61e924e1a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37190,DS-1f6bda31-aed9-4b92-9711-f641a1b99d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-ffd72acf-1f28-4b33-b1a9-cab61e924e1a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37190,DS-1f6bda31-aed9-4b92-9711-f641a1b99d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-ffd72acf-1f28-4b33-b1a9-cab61e924e1a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37190,DS-1f6bda31-aed9-4b92-9711-f641a1b99d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-ffd72acf-1f28-4b33-b1a9-cab61e924e1a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-5f9ba0d7-d760-401e-a2b3-6ad505dcb2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-fb7656b0-1dce-46c3-a15d-fd974282bfc1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-5f9ba0d7-d760-401e-a2b3-6ad505dcb2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-fb7656b0-1dce-46c3-a15d-fd974282bfc1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-5f9ba0d7-d760-401e-a2b3-6ad505dcb2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-fb7656b0-1dce-46c3-a15d-fd974282bfc1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-5f9ba0d7-d760-401e-a2b3-6ad505dcb2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-fb7656b0-1dce-46c3-a15d-fd974282bfc1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-9341ac3d-3369-4ca7-b195-8e7ad07278c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-22a6e0bb-7b2a-4d4a-94ac-704c272b1ae1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-9341ac3d-3369-4ca7-b195-8e7ad07278c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-22a6e0bb-7b2a-4d4a-94ac-704c272b1ae1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-9341ac3d-3369-4ca7-b195-8e7ad07278c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-22a6e0bb-7b2a-4d4a-94ac-704c272b1ae1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-9341ac3d-3369-4ca7-b195-8e7ad07278c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-22a6e0bb-7b2a-4d4a-94ac-704c272b1ae1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-fae5085a-7423-43c7-b40e-11403b26736b,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-1788ca5a-90cc-4900-a9c1-a0f0fba930e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-fae5085a-7423-43c7-b40e-11403b26736b,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-1788ca5a-90cc-4900-a9c1-a0f0fba930e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-fae5085a-7423-43c7-b40e-11403b26736b,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-1788ca5a-90cc-4900-a9c1-a0f0fba930e0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-fae5085a-7423-43c7-b40e-11403b26736b,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-1788ca5a-90cc-4900-a9c1-a0f0fba930e0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37882,DS-fdfc835d-2dfa-48f1-a66b-3e479ddf4e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-757b9902-81b9-43b5-8e67-3947c1f1ee6e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37882,DS-fdfc835d-2dfa-48f1-a66b-3e479ddf4e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-757b9902-81b9-43b5-8e67-3947c1f1ee6e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37882,DS-fdfc835d-2dfa-48f1-a66b-3e479ddf4e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-757b9902-81b9-43b5-8e67-3947c1f1ee6e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37882,DS-fdfc835d-2dfa-48f1-a66b-3e479ddf4e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-757b9902-81b9-43b5-8e67-3947c1f1ee6e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-4516cf0b-1b25-4c33-bfd5-21485f0c60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-d9a36c89-e45c-448a-a8bd-238bf728edcf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-4516cf0b-1b25-4c33-bfd5-21485f0c60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-d9a36c89-e45c-448a-a8bd-238bf728edcf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-4516cf0b-1b25-4c33-bfd5-21485f0c60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-d9a36c89-e45c-448a-a8bd-238bf728edcf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-4516cf0b-1b25-4c33-bfd5-21485f0c60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-d9a36c89-e45c-448a-a8bd-238bf728edcf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-99ddf7fc-7d9a-47e0-bdd0-ec4d30a86583,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-49c15b3c-1816-48e6-9380-45e6b0e8a2d1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44207,DS-49c15b3c-1816-48e6-9380-45e6b0e8a2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-99ddf7fc-7d9a-47e0-bdd0-ec4d30a86583,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-99ddf7fc-7d9a-47e0-bdd0-ec4d30a86583,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-49c15b3c-1816-48e6-9380-45e6b0e8a2d1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44207,DS-49c15b3c-1816-48e6-9380-45e6b0e8a2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-99ddf7fc-7d9a-47e0-bdd0-ec4d30a86583,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38283,DS-018ee67e-8816-4ad9-bce9-470dc47125a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-4ad9b8e3-7fb6-48d6-a967-694819b76c98,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-4ad9b8e3-7fb6-48d6-a967-694819b76c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-018ee67e-8816-4ad9-bce9-470dc47125a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38283,DS-018ee67e-8816-4ad9-bce9-470dc47125a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-4ad9b8e3-7fb6-48d6-a967-694819b76c98,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-4ad9b8e3-7fb6-48d6-a967-694819b76c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-018ee67e-8816-4ad9-bce9-470dc47125a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38197,DS-20ced8df-8f60-4cf2-a91a-d518bbaadd70,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-8abab8df-8a50-4b8c-b0c1-249a96de69f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38197,DS-20ced8df-8f60-4cf2-a91a-d518bbaadd70,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-8abab8df-8a50-4b8c-b0c1-249a96de69f7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38197,DS-20ced8df-8f60-4cf2-a91a-d518bbaadd70,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-8abab8df-8a50-4b8c-b0c1-249a96de69f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38197,DS-20ced8df-8f60-4cf2-a91a-d518bbaadd70,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-8abab8df-8a50-4b8c-b0c1-249a96de69f7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-73d49086-d54e-40b4-88e2-eb2325d999b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-9695616c-fa2a-4e9d-beee-a0d831b4f94c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-73d49086-d54e-40b4-88e2-eb2325d999b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-9695616c-fa2a-4e9d-beee-a0d831b4f94c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-73d49086-d54e-40b4-88e2-eb2325d999b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-9695616c-fa2a-4e9d-beee-a0d831b4f94c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40169,DS-73d49086-d54e-40b4-88e2-eb2325d999b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-9695616c-fa2a-4e9d-beee-a0d831b4f94c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-f3e9e310-06fb-41d4-8aa1-4f99c97e1d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-677dd469-3c4e-48f3-b367-65e2d2ef790b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-f3e9e310-06fb-41d4-8aa1-4f99c97e1d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-677dd469-3c4e-48f3-b367-65e2d2ef790b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-f3e9e310-06fb-41d4-8aa1-4f99c97e1d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-677dd469-3c4e-48f3-b367-65e2d2ef790b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34900,DS-f3e9e310-06fb-41d4-8aa1-4f99c97e1d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-677dd469-3c4e-48f3-b367-65e2d2ef790b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34400,DS-0d20f864-56ab-40c0-a49c-ea6740d98886,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-931c05b0-bc43-420b-ab2b-87b2a7f16d30,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34400,DS-0d20f864-56ab-40c0-a49c-ea6740d98886,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-931c05b0-bc43-420b-ab2b-87b2a7f16d30,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34400,DS-0d20f864-56ab-40c0-a49c-ea6740d98886,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-931c05b0-bc43-420b-ab2b-87b2a7f16d30,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34400,DS-0d20f864-56ab-40c0-a49c-ea6740d98886,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-931c05b0-bc43-420b-ab2b-87b2a7f16d30,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38081,DS-8fb89c20-498a-4b35-b5a1-9e7e13ebf9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-0ad3c514-1f14-4dfa-a264-6d5f0c16244d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-0ad3c514-1f14-4dfa-a264-6d5f0c16244d,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-8fb89c20-498a-4b35-b5a1-9e7e13ebf9f3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38081,DS-8fb89c20-498a-4b35-b5a1-9e7e13ebf9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-0ad3c514-1f14-4dfa-a264-6d5f0c16244d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-0ad3c514-1f14-4dfa-a264-6d5f0c16244d,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-8fb89c20-498a-4b35-b5a1-9e7e13ebf9f3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-7ae55a55-532a-47b2-a8a6-a92c01477648,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-f2433962-7b9a-42e9-8100-4564d266eee5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-7ae55a55-532a-47b2-a8a6-a92c01477648,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-f2433962-7b9a-42e9-8100-4564d266eee5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-7ae55a55-532a-47b2-a8a6-a92c01477648,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-f2433962-7b9a-42e9-8100-4564d266eee5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-7ae55a55-532a-47b2-a8a6-a92c01477648,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-f2433962-7b9a-42e9-8100-4564d266eee5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42529,DS-05661cce-ab57-41b5-8f37-49d369f8bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-63f468ba-c2a4-4320-8f1e-27c9b2a675c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35542,DS-63f468ba-c2a4-4320-8f1e-27c9b2a675c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-05661cce-ab57-41b5-8f37-49d369f8bca1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42529,DS-05661cce-ab57-41b5-8f37-49d369f8bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-63f468ba-c2a4-4320-8f1e-27c9b2a675c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35542,DS-63f468ba-c2a4-4320-8f1e-27c9b2a675c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-05661cce-ab57-41b5-8f37-49d369f8bca1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-66843027-5783-4793-9678-bf60cec3a184,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-ea562c99-8770-429d-9804-1cb247602588,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-66843027-5783-4793-9678-bf60cec3a184,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-ea562c99-8770-429d-9804-1cb247602588,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-66843027-5783-4793-9678-bf60cec3a184,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-ea562c99-8770-429d-9804-1cb247602588,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-66843027-5783-4793-9678-bf60cec3a184,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-ea562c99-8770-429d-9804-1cb247602588,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-78ee10dc-5e4d-4adf-b478-b3f3bd6dc808,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-b4a06268-fd29-45c1-b89b-fc95f1504e58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-78ee10dc-5e4d-4adf-b478-b3f3bd6dc808,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-b4a06268-fd29-45c1-b89b-fc95f1504e58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-78ee10dc-5e4d-4adf-b478-b3f3bd6dc808,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-b4a06268-fd29-45c1-b89b-fc95f1504e58,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-78ee10dc-5e4d-4adf-b478-b3f3bd6dc808,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-b4a06268-fd29-45c1-b89b-fc95f1504e58,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-fdea5de3-3406-4082-8cc1-3f4493de2838,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-89b7ecfa-a7af-4b6c-90a3-1eba898e1c01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41743,DS-89b7ecfa-a7af-4b6c-90a3-1eba898e1c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-fdea5de3-3406-4082-8cc1-3f4493de2838,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35278,DS-fdea5de3-3406-4082-8cc1-3f4493de2838,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-89b7ecfa-a7af-4b6c-90a3-1eba898e1c01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41743,DS-89b7ecfa-a7af-4b6c-90a3-1eba898e1c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-fdea5de3-3406-4082-8cc1-3f4493de2838,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-d46d9958-bd6e-440a-bf5b-83b2d3b211c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-9e8d2b3c-8851-4661-b39a-028af6029a01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-d46d9958-bd6e-440a-bf5b-83b2d3b211c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-9e8d2b3c-8851-4661-b39a-028af6029a01,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-d46d9958-bd6e-440a-bf5b-83b2d3b211c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-9e8d2b3c-8851-4661-b39a-028af6029a01,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-d46d9958-bd6e-440a-bf5b-83b2d3b211c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-9e8d2b3c-8851-4661-b39a-028af6029a01,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44810,DS-75c21e75-558c-41ab-970d-00bc76ecf9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-4b3bc9aa-fe47-4dce-8796-2d80cc39e73a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-4b3bc9aa-fe47-4dce-8796-2d80cc39e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-75c21e75-558c-41ab-970d-00bc76ecf9d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44810,DS-75c21e75-558c-41ab-970d-00bc76ecf9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-4b3bc9aa-fe47-4dce-8796-2d80cc39e73a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-4b3bc9aa-fe47-4dce-8796-2d80cc39e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-75c21e75-558c-41ab-970d-00bc76ecf9d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-d1372330-4760-4437-ab7b-cd6fcbe2f7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-066ed924-7803-41da-88ce-b1aae1b99186,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-d1372330-4760-4437-ab7b-cd6fcbe2f7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-066ed924-7803-41da-88ce-b1aae1b99186,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-d1372330-4760-4437-ab7b-cd6fcbe2f7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-066ed924-7803-41da-88ce-b1aae1b99186,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-d1372330-4760-4437-ab7b-cd6fcbe2f7df,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-066ed924-7803-41da-88ce-b1aae1b99186,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-d6c8f8e1-f75a-4855-b771-3019e1eb784e,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-a875bbc5-b921-4d13-b66c-422810fc23e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34302,DS-a875bbc5-b921-4d13-b66c-422810fc23e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-d6c8f8e1-f75a-4855-b771-3019e1eb784e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38185,DS-d6c8f8e1-f75a-4855-b771-3019e1eb784e,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-a875bbc5-b921-4d13-b66c-422810fc23e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34302,DS-a875bbc5-b921-4d13-b66c-422810fc23e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-d6c8f8e1-f75a-4855-b771-3019e1eb784e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-c53ef847-88c3-4824-a853-8b98c28ce224,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-07b94ca2-3aeb-4b21-a63f-7710448356b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-07b94ca2-3aeb-4b21-a63f-7710448356b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-c53ef847-88c3-4824-a853-8b98c28ce224,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-c53ef847-88c3-4824-a853-8b98c28ce224,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-07b94ca2-3aeb-4b21-a63f-7710448356b3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-07b94ca2-3aeb-4b21-a63f-7710448356b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-c53ef847-88c3-4824-a853-8b98c28ce224,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46823,DS-e2ea539c-0e45-4209-bd3e-07faa3b2ec96,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-43aa6e06-c9a0-41a8-a678-34230740480f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-43aa6e06-c9a0-41a8-a678-34230740480f,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-e2ea539c-0e45-4209-bd3e-07faa3b2ec96,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46823,DS-e2ea539c-0e45-4209-bd3e-07faa3b2ec96,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-43aa6e06-c9a0-41a8-a678-34230740480f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44864,DS-43aa6e06-c9a0-41a8-a678-34230740480f,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-e2ea539c-0e45-4209-bd3e-07faa3b2ec96,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42207,DS-82d09fe6-7607-42cd-9f32-cef21a47a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-c854650a-63a6-4ad6-9891-c9745309ee36,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42207,DS-82d09fe6-7607-42cd-9f32-cef21a47a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-c854650a-63a6-4ad6-9891-c9745309ee36,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42207,DS-82d09fe6-7607-42cd-9f32-cef21a47a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-c854650a-63a6-4ad6-9891-c9745309ee36,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42207,DS-82d09fe6-7607-42cd-9f32-cef21a47a7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-c854650a-63a6-4ad6-9891-c9745309ee36,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-0e6f939f-7391-4bfe-9ba7-fe320df61f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-d923d78c-f743-4f98-82f1-6333b5ffabc3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-0e6f939f-7391-4bfe-9ba7-fe320df61f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-d923d78c-f743-4f98-82f1-6333b5ffabc3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-0e6f939f-7391-4bfe-9ba7-fe320df61f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-d923d78c-f743-4f98-82f1-6333b5ffabc3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-0e6f939f-7391-4bfe-9ba7-fe320df61f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-d923d78c-f743-4f98-82f1-6333b5ffabc3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35602,DS-271ca478-2826-4ef3-80e3-eee86837a0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-4fa73490-bcce-448c-bcfd-45cd2d73cc48,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35602,DS-271ca478-2826-4ef3-80e3-eee86837a0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-4fa73490-bcce-448c-bcfd-45cd2d73cc48,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35602,DS-271ca478-2826-4ef3-80e3-eee86837a0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-4fa73490-bcce-448c-bcfd-45cd2d73cc48,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35602,DS-271ca478-2826-4ef3-80e3-eee86837a0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-4fa73490-bcce-448c-bcfd-45cd2d73cc48,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-a4bf9f6f-9290-4dbe-9633-125e749d7612,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-28207b87-dbcc-4da0-a0e1-cee4e47366ab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-28207b87-dbcc-4da0-a0e1-cee4e47366ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-a4bf9f6f-9290-4dbe-9633-125e749d7612,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35093,DS-a4bf9f6f-9290-4dbe-9633-125e749d7612,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-28207b87-dbcc-4da0-a0e1-cee4e47366ab,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-28207b87-dbcc-4da0-a0e1-cee4e47366ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-a4bf9f6f-9290-4dbe-9633-125e749d7612,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-2b25f164-d65a-436c-80f2-dd3fe83265f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-40989c5b-11d1-4b62-b65f-23b89020f4b1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-2b25f164-d65a-436c-80f2-dd3fe83265f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-40989c5b-11d1-4b62-b65f-23b89020f4b1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-2b25f164-d65a-436c-80f2-dd3fe83265f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-40989c5b-11d1-4b62-b65f-23b89020f4b1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-2b25f164-d65a-436c-80f2-dd3fe83265f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-40989c5b-11d1-4b62-b65f-23b89020f4b1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-c41709bd-bf3d-4427-b293-57d0663a96ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-f2362780-3dd8-4965-9e54-04215d51545d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-f2362780-3dd8-4965-9e54-04215d51545d,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-c41709bd-bf3d-4427-b293-57d0663a96ed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-c41709bd-bf3d-4427-b293-57d0663a96ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-f2362780-3dd8-4965-9e54-04215d51545d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-f2362780-3dd8-4965-9e54-04215d51545d,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-c41709bd-bf3d-4427-b293-57d0663a96ed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-ef56ab95-6e2e-41f0-89fe-5c02d9a33f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-8003d379-2a37-4564-b27b-9d58e2665c8c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-8003d379-2a37-4564-b27b-9d58e2665c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-ef56ab95-6e2e-41f0-89fe-5c02d9a33f9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38961,DS-ef56ab95-6e2e-41f0-89fe-5c02d9a33f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-8003d379-2a37-4564-b27b-9d58e2665c8c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-8003d379-2a37-4564-b27b-9d58e2665c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-ef56ab95-6e2e-41f0-89fe-5c02d9a33f9d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-0c3cc776-1d01-42c0-b13c-0b696da67d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-aecb81dd-cefe-4204-a8a1-0448c9615315,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-0c3cc776-1d01-42c0-b13c-0b696da67d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-aecb81dd-cefe-4204-a8a1-0448c9615315,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-0c3cc776-1d01-42c0-b13c-0b696da67d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-aecb81dd-cefe-4204-a8a1-0448c9615315,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-0c3cc776-1d01-42c0-b13c-0b696da67d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-aecb81dd-cefe-4204-a8a1-0448c9615315,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-a5dfa1a7-7357-4fc8-aa2e-6cb698e26ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-d938600e-0690-4025-b9c2-dfd5a7fbe11a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-d938600e-0690-4025-b9c2-dfd5a7fbe11a,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-a5dfa1a7-7357-4fc8-aa2e-6cb698e26ce5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-a5dfa1a7-7357-4fc8-aa2e-6cb698e26ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-d938600e-0690-4025-b9c2-dfd5a7fbe11a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-d938600e-0690-4025-b9c2-dfd5a7fbe11a,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-a5dfa1a7-7357-4fc8-aa2e-6cb698e26ce5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-20e96e40-4323-4352-a707-7ad52c6e7c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-4edc1f9e-8b38-4860-b551-ec9dc57e415d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-20e96e40-4323-4352-a707-7ad52c6e7c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-4edc1f9e-8b38-4860-b551-ec9dc57e415d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-20e96e40-4323-4352-a707-7ad52c6e7c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-4edc1f9e-8b38-4860-b551-ec9dc57e415d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-20e96e40-4323-4352-a707-7ad52c6e7c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-4edc1f9e-8b38-4860-b551-ec9dc57e415d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-800eed65-2bfc-4cb0-8148-81ba7d500d61,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-e8687c6e-eaaf-4626-b6a7-cb198718fd4e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-800eed65-2bfc-4cb0-8148-81ba7d500d61,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-e8687c6e-eaaf-4626-b6a7-cb198718fd4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-800eed65-2bfc-4cb0-8148-81ba7d500d61,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-e8687c6e-eaaf-4626-b6a7-cb198718fd4e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-800eed65-2bfc-4cb0-8148-81ba7d500d61,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-e8687c6e-eaaf-4626-b6a7-cb198718fd4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-ba723bc1-d4da-4812-8a61-fbecef6a752d,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-38f79621-edf8-41dc-8fbf-76645a8760bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-38f79621-edf8-41dc-8fbf-76645a8760bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-ba723bc1-d4da-4812-8a61-fbecef6a752d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-ba723bc1-d4da-4812-8a61-fbecef6a752d,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-38f79621-edf8-41dc-8fbf-76645a8760bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42596,DS-38f79621-edf8-41dc-8fbf-76645a8760bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-ba723bc1-d4da-4812-8a61-fbecef6a752d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-8cd295ad-b903-421a-ba2a-4c542641859c,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-3ff7dbf5-8bd8-4fc2-95ff-fe94d2eaa9fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-8cd295ad-b903-421a-ba2a-4c542641859c,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-3ff7dbf5-8bd8-4fc2-95ff-fe94d2eaa9fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-8cd295ad-b903-421a-ba2a-4c542641859c,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-3ff7dbf5-8bd8-4fc2-95ff-fe94d2eaa9fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-8cd295ad-b903-421a-ba2a-4c542641859c,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-3ff7dbf5-8bd8-4fc2-95ff-fe94d2eaa9fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 13115
