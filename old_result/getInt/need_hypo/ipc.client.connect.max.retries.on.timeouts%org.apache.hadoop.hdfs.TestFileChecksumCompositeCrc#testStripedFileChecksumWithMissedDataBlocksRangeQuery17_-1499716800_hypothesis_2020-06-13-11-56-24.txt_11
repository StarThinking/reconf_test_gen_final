reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849520027-172.17.0.20-1592049842869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-f2de5d65-5f64-45f9-a29b-4c471c9196a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-5447cba4-9e34-4645-8739-4e4d2243537a,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-18c97946-8066-489b-b88c-9be3901967b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-b5c1adad-934c-4002-b506-6a6a8af74278,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-24392155-4183-4acf-86a5-73af14836e98,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-62acb7c1-806e-4857-b48b-3051285c99e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-094ce32a-fd4e-4c0b-86ff-159c0afdbde3,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-67e2a96b-fc9f-4dbc-817b-a86d959f8ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849520027-172.17.0.20-1592049842869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-f2de5d65-5f64-45f9-a29b-4c471c9196a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-5447cba4-9e34-4645-8739-4e4d2243537a,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-18c97946-8066-489b-b88c-9be3901967b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-b5c1adad-934c-4002-b506-6a6a8af74278,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-24392155-4183-4acf-86a5-73af14836e98,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-62acb7c1-806e-4857-b48b-3051285c99e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-094ce32a-fd4e-4c0b-86ff-159c0afdbde3,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-67e2a96b-fc9f-4dbc-817b-a86d959f8ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143249189-172.17.0.20-1592049944792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44512,DS-9dfa53d0-4609-49d1-ab0b-766efaa7a9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-390af569-375f-464b-bf18-a9c88486bb01,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-65a35b9f-1cac-42f8-9b04-a8c0edee18d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-bef1016d-e53e-47a5-ba9b-54708a78e2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-a1e54111-4e18-42ba-95f4-a5ff08eb9dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-c42dbff5-5e05-434f-9ed3-def23bfac954,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-5f69176a-df74-4a4f-96b4-38d6847700fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-da06c240-8bed-4116-a436-73da02a12962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143249189-172.17.0.20-1592049944792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44512,DS-9dfa53d0-4609-49d1-ab0b-766efaa7a9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-390af569-375f-464b-bf18-a9c88486bb01,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-65a35b9f-1cac-42f8-9b04-a8c0edee18d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-bef1016d-e53e-47a5-ba9b-54708a78e2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-a1e54111-4e18-42ba-95f4-a5ff08eb9dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-c42dbff5-5e05-434f-9ed3-def23bfac954,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-5f69176a-df74-4a4f-96b4-38d6847700fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-da06c240-8bed-4116-a436-73da02a12962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051898193-172.17.0.20-1592050277392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-713e0b1c-e477-4811-ab21-ecbbd83193d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-74f1120d-1174-407d-862c-4e2db17089f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-2ed2a76b-f6d7-4f9b-930d-d638378c093d,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-e3006ca1-9681-4abd-a6b8-5cfac811b191,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-915b4c43-82ad-4f56-ab88-fb05ab414be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-ed550023-b1f0-496f-8a98-2c25c7603366,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-b1975b4d-0f85-431e-bdbc-5eafc052dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-5e5647b6-eef7-4bbb-97c7-f8f72c09e857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051898193-172.17.0.20-1592050277392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-713e0b1c-e477-4811-ab21-ecbbd83193d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-74f1120d-1174-407d-862c-4e2db17089f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-2ed2a76b-f6d7-4f9b-930d-d638378c093d,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-e3006ca1-9681-4abd-a6b8-5cfac811b191,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-915b4c43-82ad-4f56-ab88-fb05ab414be0,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-ed550023-b1f0-496f-8a98-2c25c7603366,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-b1975b4d-0f85-431e-bdbc-5eafc052dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-5e5647b6-eef7-4bbb-97c7-f8f72c09e857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490341911-172.17.0.20-1592050398754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-079adcc8-e695-4bb3-9c84-e7b5a544ccc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-87dc1296-92f8-4ac4-a976-448262d281a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-cc675b11-3bae-4cd5-a063-129d1ae3e0da,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-2d49c488-8cea-41d6-befa-2f83276143ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-befe60b6-5074-464c-9b59-105c150fadb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-e5536ba0-646e-42b1-b1c4-29673d39cc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-fa986f99-7dfb-4e94-97c4-4c5638cb952b,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-695c439d-e3bd-4f9e-b7b4-461ae0da5ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490341911-172.17.0.20-1592050398754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-079adcc8-e695-4bb3-9c84-e7b5a544ccc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-87dc1296-92f8-4ac4-a976-448262d281a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-cc675b11-3bae-4cd5-a063-129d1ae3e0da,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-2d49c488-8cea-41d6-befa-2f83276143ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-befe60b6-5074-464c-9b59-105c150fadb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-e5536ba0-646e-42b1-b1c4-29673d39cc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-fa986f99-7dfb-4e94-97c4-4c5638cb952b,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-695c439d-e3bd-4f9e-b7b4-461ae0da5ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307885116-172.17.0.20-1592050523502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35054,DS-ab49432e-6c1e-4540-81ca-5b47fd32afa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-ea0b86e0-4f19-43fb-a9cf-902dca4d065d,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-f5f41b86-bd3e-415c-91e1-a649de8effde,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-5417cf47-ba91-47c5-889d-5e4d63a79140,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-412ac2ef-8fc7-4ae7-a621-6000b9862bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-0ee8c5e1-a1fb-438f-9800-d353e94dc98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-bac9a3c8-ead8-4f2b-a66d-9c4a0e19613f,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-22d54a50-014f-4b95-ac32-ca4c9b6f7e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307885116-172.17.0.20-1592050523502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35054,DS-ab49432e-6c1e-4540-81ca-5b47fd32afa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-ea0b86e0-4f19-43fb-a9cf-902dca4d065d,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-f5f41b86-bd3e-415c-91e1-a649de8effde,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-5417cf47-ba91-47c5-889d-5e4d63a79140,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-412ac2ef-8fc7-4ae7-a621-6000b9862bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-0ee8c5e1-a1fb-438f-9800-d353e94dc98c,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-bac9a3c8-ead8-4f2b-a66d-9c4a0e19613f,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-22d54a50-014f-4b95-ac32-ca4c9b6f7e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574066669-172.17.0.20-1592051211341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-783b7b93-cf2f-418a-9c09-429aaf29b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-e89d52be-3cfd-4eac-b685-2cc285cf5ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-909d101d-a19e-485b-ab18-dd90fdda92e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-7a475cfe-5571-4fcb-b200-df33bf1d3416,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-64345b3d-e199-4683-a374-ad7fcf86f308,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-b492cbe3-440b-4133-9d25-f105bedcbb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-4028c2ef-97cc-483a-aee2-5d1a0a0d8ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-209c7b75-2f3f-416c-97a6-2fff47031d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574066669-172.17.0.20-1592051211341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-783b7b93-cf2f-418a-9c09-429aaf29b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-e89d52be-3cfd-4eac-b685-2cc285cf5ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-909d101d-a19e-485b-ab18-dd90fdda92e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-7a475cfe-5571-4fcb-b200-df33bf1d3416,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-64345b3d-e199-4683-a374-ad7fcf86f308,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-b492cbe3-440b-4133-9d25-f105bedcbb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-4028c2ef-97cc-483a-aee2-5d1a0a0d8ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-209c7b75-2f3f-416c-97a6-2fff47031d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664373106-172.17.0.20-1592052731800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43342,DS-1cdf4585-3192-4331-80a5-6aa0c783b689,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-a7e32ef0-5d2b-42a5-a624-d65b210f6c96,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-c3afec6d-8d93-4356-a9f6-a64a245c88c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-c8aee56f-2b7e-43ec-880a-a1b578381913,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-4b629aa1-a9f1-4b36-b068-56982cc24d15,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-453d59f4-0ec7-42aa-b741-a6beb9db6e15,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-338a5e97-09d3-4560-8540-cd50c4a6938e,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-4b830797-56c6-4585-a944-9a74e40fc967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664373106-172.17.0.20-1592052731800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43342,DS-1cdf4585-3192-4331-80a5-6aa0c783b689,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-a7e32ef0-5d2b-42a5-a624-d65b210f6c96,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-c3afec6d-8d93-4356-a9f6-a64a245c88c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-c8aee56f-2b7e-43ec-880a-a1b578381913,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-4b629aa1-a9f1-4b36-b068-56982cc24d15,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-453d59f4-0ec7-42aa-b741-a6beb9db6e15,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-338a5e97-09d3-4560-8540-cd50c4a6938e,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-4b830797-56c6-4585-a944-9a74e40fc967,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911476453-172.17.0.20-1592053200710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-a0567e0f-cb3c-4482-9931-3d7670775118,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-70b72a7b-ad58-4520-bd48-ad5e50700aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-201ce2aa-076f-4b4d-8bdc-c73e612d230c,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-59d1ceca-fef9-460c-9be3-8fee505ea395,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-bfd21bcb-1c18-47f7-a711-d4226898eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-1394586f-a374-4ba0-9221-1dee9144cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-38181bd6-7b6c-4c37-899d-0c60a421a778,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-39899b43-f109-40fc-ba79-32a4afdcb330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911476453-172.17.0.20-1592053200710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-a0567e0f-cb3c-4482-9931-3d7670775118,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-70b72a7b-ad58-4520-bd48-ad5e50700aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-201ce2aa-076f-4b4d-8bdc-c73e612d230c,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-59d1ceca-fef9-460c-9be3-8fee505ea395,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-bfd21bcb-1c18-47f7-a711-d4226898eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-1394586f-a374-4ba0-9221-1dee9144cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-38181bd6-7b6c-4c37-899d-0c60a421a778,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-39899b43-f109-40fc-ba79-32a4afdcb330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056901533-172.17.0.20-1592053242344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-1652ce6f-0e0a-4d49-be97-1019253dad23,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-28e601fb-9154-4577-9359-7d229749b652,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-9712ea49-c80d-412c-a311-0a34af011f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-7c1c885f-7ae4-47df-88d7-dbdf9c242d44,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-e8686e1c-957b-4604-ad8b-6ccea3b15dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-5e804a42-6239-4bd7-9dfe-ec0f44afd7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-f5106d51-b84f-4bd6-b277-010b112d4fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-0beb940c-e0dd-45f5-b198-2d3d523f6e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056901533-172.17.0.20-1592053242344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-1652ce6f-0e0a-4d49-be97-1019253dad23,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-28e601fb-9154-4577-9359-7d229749b652,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-9712ea49-c80d-412c-a311-0a34af011f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-7c1c885f-7ae4-47df-88d7-dbdf9c242d44,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-e8686e1c-957b-4604-ad8b-6ccea3b15dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-5e804a42-6239-4bd7-9dfe-ec0f44afd7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-f5106d51-b84f-4bd6-b277-010b112d4fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-0beb940c-e0dd-45f5-b198-2d3d523f6e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029551495-172.17.0.20-1592053619373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35930,DS-ee1c3e31-3357-48bc-8f62-965dad982d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-8798a907-cdd3-45e8-8313-dd0f43448e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-9da5190c-d194-4a19-a9de-001dae90d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-53391715-c0d3-42ea-8fe1-3f4bb99102a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-448927cf-59f8-4afc-bfe8-dc35d0f7c136,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-f27dfaf9-12e9-4193-975b-d41952605816,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-89b32663-f754-42f7-a0b5-c85841ff706f,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-9009e395-99dc-43d7-91b9-f336264986dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029551495-172.17.0.20-1592053619373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35930,DS-ee1c3e31-3357-48bc-8f62-965dad982d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-8798a907-cdd3-45e8-8313-dd0f43448e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-9da5190c-d194-4a19-a9de-001dae90d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-53391715-c0d3-42ea-8fe1-3f4bb99102a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-448927cf-59f8-4afc-bfe8-dc35d0f7c136,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-f27dfaf9-12e9-4193-975b-d41952605816,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-89b32663-f754-42f7-a0b5-c85841ff706f,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-9009e395-99dc-43d7-91b9-f336264986dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763739483-172.17.0.20-1592053897219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36416,DS-6769f981-e232-455d-9bc8-c19b540bcb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-30ada4fa-b12a-4792-8c2e-670da50ea145,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-3aadef33-8716-494a-8b56-a146c982849a,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-a8c7e0f1-0d29-44d8-8200-c2a60681390d,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-78c77d45-8541-4088-8667-7abcd2f8bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-06d86828-2b61-45af-8634-f7436e71d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-02956f4d-bfca-452d-9f60-9cdafc19a67f,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-88088692-e9d0-4d68-93a0-c35798e595e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763739483-172.17.0.20-1592053897219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36416,DS-6769f981-e232-455d-9bc8-c19b540bcb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-30ada4fa-b12a-4792-8c2e-670da50ea145,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-3aadef33-8716-494a-8b56-a146c982849a,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-a8c7e0f1-0d29-44d8-8200-c2a60681390d,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-78c77d45-8541-4088-8667-7abcd2f8bc66,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-06d86828-2b61-45af-8634-f7436e71d8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-02956f4d-bfca-452d-9f60-9cdafc19a67f,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-88088692-e9d0-4d68-93a0-c35798e595e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1688144136-172.17.0.20-1592053931725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32820,DS-bd5f8d8f-401d-4bca-bdd3-9d03e1b9a036,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-262c732a-b475-448f-81b9-14c47975309c,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-e584d2a8-e990-4534-a911-60f035adbff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-da2c1614-255d-477f-8a35-d754ab32b029,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-fbe7123b-d942-43fb-a2e7-44d58083c8df,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-aa12c9db-b845-4f7a-a18f-1c0f23547ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-061c2361-0a54-4eb2-89eb-65ecd17b25dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-8af35774-9ee6-4144-b2c2-a942f7e34f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1688144136-172.17.0.20-1592053931725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32820,DS-bd5f8d8f-401d-4bca-bdd3-9d03e1b9a036,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-262c732a-b475-448f-81b9-14c47975309c,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-e584d2a8-e990-4534-a911-60f035adbff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-da2c1614-255d-477f-8a35-d754ab32b029,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-fbe7123b-d942-43fb-a2e7-44d58083c8df,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-aa12c9db-b845-4f7a-a18f-1c0f23547ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-061c2361-0a54-4eb2-89eb-65ecd17b25dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-8af35774-9ee6-4144-b2c2-a942f7e34f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683743828-172.17.0.20-1592054336575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35511,DS-9129e04d-cebc-44d5-a062-0031533f24f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-6ddb1cc1-df30-43bc-a1c0-813c32ace5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-ef13484e-e6bb-43f4-8a53-339794274560,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-f5804109-64e7-42c7-87dc-ca3e24f34064,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-ef8cfd77-dcdd-42bb-a9c0-0a38db855823,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-a356c7fe-bb5b-4608-86b1-af0c3589316f,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-bcdd0f9b-f86c-4993-bd25-14bd56591c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-10a91bab-205f-4509-8146-8866fb5a4d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683743828-172.17.0.20-1592054336575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35511,DS-9129e04d-cebc-44d5-a062-0031533f24f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-6ddb1cc1-df30-43bc-a1c0-813c32ace5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-ef13484e-e6bb-43f4-8a53-339794274560,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-f5804109-64e7-42c7-87dc-ca3e24f34064,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-ef8cfd77-dcdd-42bb-a9c0-0a38db855823,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-a356c7fe-bb5b-4608-86b1-af0c3589316f,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-bcdd0f9b-f86c-4993-bd25-14bd56591c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-10a91bab-205f-4509-8146-8866fb5a4d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645368831-172.17.0.20-1592054410154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42047,DS-fd2eb13b-6b4f-419b-905f-a729d88fad3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-28164de1-4d95-42b2-92d1-c5b705106e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-a19d0830-c8a5-40c4-95cb-0b51d9925454,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-3b1c33a8-98a8-4fa4-b812-79c0cda345f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-8723a2c4-ea3f-4fdc-a84a-225ed859a319,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-5283063d-6bc7-47ad-ae33-7523325269f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-d125e6bc-5903-4333-ab14-4a683eb6e496,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-71cd5b47-221a-46d4-809f-695d6e0bb667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645368831-172.17.0.20-1592054410154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42047,DS-fd2eb13b-6b4f-419b-905f-a729d88fad3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-28164de1-4d95-42b2-92d1-c5b705106e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-a19d0830-c8a5-40c4-95cb-0b51d9925454,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-3b1c33a8-98a8-4fa4-b812-79c0cda345f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-8723a2c4-ea3f-4fdc-a84a-225ed859a319,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-5283063d-6bc7-47ad-ae33-7523325269f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-d125e6bc-5903-4333-ab14-4a683eb6e496,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-71cd5b47-221a-46d4-809f-695d6e0bb667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 45
v2: 450
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955475216-172.17.0.20-1592054685380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-6722981d-ef55-45c4-b4c7-c5c402df1580,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-7ded5649-7b6d-4972-af27-db79d1156a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-88f341d4-4423-4af2-b828-c525e68a16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-ff70e5f8-60a3-4fe8-baa4-d9e4e220ca28,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-4cda0567-e619-4a89-947c-81f7ecd5fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-744fcbb7-e111-46d2-8540-d47e5cb68831,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-68664d2c-3508-415c-9a9f-dbb1740182d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-c6641c94-8b53-4148-afe8-f5c247a57c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955475216-172.17.0.20-1592054685380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-6722981d-ef55-45c4-b4c7-c5c402df1580,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-7ded5649-7b6d-4972-af27-db79d1156a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-88f341d4-4423-4af2-b828-c525e68a16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-ff70e5f8-60a3-4fe8-baa4-d9e4e220ca28,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-4cda0567-e619-4a89-947c-81f7ecd5fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-744fcbb7-e111-46d2-8540-d47e5cb68831,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-68664d2c-3508-415c-9a9f-dbb1740182d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-c6641c94-8b53-4148-afe8-f5c247a57c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5698
