reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974089854-172.17.0.15-1592513531943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-08c72a80-974a-42d2-9871-42593bf6bd66,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-161932be-da4b-4b95-a757-0a88b324813e,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-7f9213b8-3ad5-469b-a397-e4706237cc77,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-19f35e0b-b5ee-43bb-a1d4-c8689366b914,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-74a2308d-40d1-44bf-9116-dc8a62bbf692,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-750d11e4-1381-4173-9bd7-fdd7d8ac11b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-788d8db1-c602-427a-90fc-c2538470b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-0f8a1c53-f9a1-4be2-a595-efce63fac14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974089854-172.17.0.15-1592513531943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-08c72a80-974a-42d2-9871-42593bf6bd66,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-161932be-da4b-4b95-a757-0a88b324813e,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-7f9213b8-3ad5-469b-a397-e4706237cc77,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-19f35e0b-b5ee-43bb-a1d4-c8689366b914,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-74a2308d-40d1-44bf-9116-dc8a62bbf692,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-750d11e4-1381-4173-9bd7-fdd7d8ac11b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-788d8db1-c602-427a-90fc-c2538470b23e,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-0f8a1c53-f9a1-4be2-a595-efce63fac14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-942474244-172.17.0.15-1592514549710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42602,DS-d83dde05-860e-48c9-a4b8-d5b6f41a2589,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-dcbce8b9-7b78-4f9e-8855-c6e6e625aaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-3a7dad1a-e2eb-4c7b-bf15-e865e7409865,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-740f6977-54bd-445a-95bb-9c898cf2b0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-65baab7f-4c4e-4888-9a8e-fe2f8c9052dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-192bc638-174f-4a37-86c1-cd0fe4e8b3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-cc679e94-614c-4b72-95e8-d948bb49800b,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-8adc3762-948c-4098-88ba-9f0bce2621b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-942474244-172.17.0.15-1592514549710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42602,DS-d83dde05-860e-48c9-a4b8-d5b6f41a2589,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-dcbce8b9-7b78-4f9e-8855-c6e6e625aaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-3a7dad1a-e2eb-4c7b-bf15-e865e7409865,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-740f6977-54bd-445a-95bb-9c898cf2b0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-65baab7f-4c4e-4888-9a8e-fe2f8c9052dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-192bc638-174f-4a37-86c1-cd0fe4e8b3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-cc679e94-614c-4b72-95e8-d948bb49800b,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-8adc3762-948c-4098-88ba-9f0bce2621b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404641931-172.17.0.15-1592514981352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37453,DS-ca8297c1-189e-4ce7-8d1d-dd65a1bbf854,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-5c8b8d0e-1858-4b46-be0f-260f15513a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-e91f6d59-3fc0-45b3-8201-bccbb9be06ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-e24f3ca0-c724-433b-92cb-3ff5fcafc914,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-8120322e-1695-4d7f-9f00-58ce18e775aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-190e1b84-7762-4f7a-993b-39fbfd5ec2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-b0eaa4bb-b925-4bc8-ba40-5e2f3fc1697b,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-7bffdee4-5d57-4703-82ce-d10a6f6b099e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404641931-172.17.0.15-1592514981352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37453,DS-ca8297c1-189e-4ce7-8d1d-dd65a1bbf854,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-5c8b8d0e-1858-4b46-be0f-260f15513a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-e91f6d59-3fc0-45b3-8201-bccbb9be06ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-e24f3ca0-c724-433b-92cb-3ff5fcafc914,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-8120322e-1695-4d7f-9f00-58ce18e775aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-190e1b84-7762-4f7a-993b-39fbfd5ec2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-b0eaa4bb-b925-4bc8-ba40-5e2f3fc1697b,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-7bffdee4-5d57-4703-82ce-d10a6f6b099e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955158608-172.17.0.15-1592515299943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38685,DS-c56fd86c-223f-46b8-90f1-28afad73200d,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-ca86eab6-2c4d-45c9-96b5-d7af1cc4886d,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-1aa803ed-974a-4905-854f-459fa6e72b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-3ca355f3-168c-4606-8a0b-a42bf77b7154,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-b2f425ae-c957-43a0-bff3-9904746ba3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-a552a63c-55d4-4b83-87bf-a576512f8783,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-ea28a696-bf31-45c8-97bf-e80dc5040516,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-5d054c3e-6154-4aae-9337-09aaf08f2ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955158608-172.17.0.15-1592515299943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38685,DS-c56fd86c-223f-46b8-90f1-28afad73200d,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-ca86eab6-2c4d-45c9-96b5-d7af1cc4886d,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-1aa803ed-974a-4905-854f-459fa6e72b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-3ca355f3-168c-4606-8a0b-a42bf77b7154,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-b2f425ae-c957-43a0-bff3-9904746ba3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-a552a63c-55d4-4b83-87bf-a576512f8783,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-ea28a696-bf31-45c8-97bf-e80dc5040516,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-5d054c3e-6154-4aae-9337-09aaf08f2ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488943429-172.17.0.15-1592515706822:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40770,DS-43d5ac4a-a908-4708-8198-fffb55c585c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-994e6f33-97b9-47e5-83bd-aa2a37413db0,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-eb336166-cbea-4a48-8008-dd31026d6e55,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-ab224558-69bd-4882-9b56-9923ddda4a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-d084dec8-4af0-49ad-b1bc-80e2d0b83f32,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-6cba5704-2456-47b6-b497-c8f39d96c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-52dff887-98ca-48b5-8637-5c6f336fd3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-f66f8af5-3317-455b-9168-5dab374d822f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488943429-172.17.0.15-1592515706822:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40770,DS-43d5ac4a-a908-4708-8198-fffb55c585c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-994e6f33-97b9-47e5-83bd-aa2a37413db0,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-eb336166-cbea-4a48-8008-dd31026d6e55,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-ab224558-69bd-4882-9b56-9923ddda4a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-d084dec8-4af0-49ad-b1bc-80e2d0b83f32,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-6cba5704-2456-47b6-b497-c8f39d96c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-52dff887-98ca-48b5-8637-5c6f336fd3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-f66f8af5-3317-455b-9168-5dab374d822f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284693496-172.17.0.15-1592515964663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39909,DS-16bb84bf-703d-4486-8629-0c3cb3021ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-70887afa-3fdd-42e1-80f1-6f0caf53221d,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-58dace6a-3515-4638-96fb-4942065c418d,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-fb04af6f-0d6a-430f-a03b-d02adaebb63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-9d781e72-935b-46b6-b766-d43692c0b481,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-2f8eb111-3ce8-4bec-ad89-14b809c5a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-184d1b83-64ce-40e8-97c3-a742c87458f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-65a01044-6ff0-4f9c-b1fc-0835c6233118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284693496-172.17.0.15-1592515964663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39909,DS-16bb84bf-703d-4486-8629-0c3cb3021ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-70887afa-3fdd-42e1-80f1-6f0caf53221d,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-58dace6a-3515-4638-96fb-4942065c418d,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-fb04af6f-0d6a-430f-a03b-d02adaebb63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-9d781e72-935b-46b6-b766-d43692c0b481,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-2f8eb111-3ce8-4bec-ad89-14b809c5a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-184d1b83-64ce-40e8-97c3-a742c87458f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-65a01044-6ff0-4f9c-b1fc-0835c6233118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061431935-172.17.0.15-1592516381650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44404,DS-671d460e-5038-42b8-8f1a-ba90a1a79738,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-d0101caa-77e2-4c6a-9750-4247d28d5b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-266c8f41-3da0-4b84-88fd-b7ac452daea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-45255c2f-5d83-4ae5-8984-3ce25db99d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-45586aa7-4f26-4551-9094-582adc3e9f13,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-37d0fc34-a4b0-4407-a753-7c3377e500d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-68a84db1-4308-4842-9220-645e43ecade0,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-5a6f43e6-3426-4d4d-af6a-5cc66c0255b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2061431935-172.17.0.15-1592516381650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44404,DS-671d460e-5038-42b8-8f1a-ba90a1a79738,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-d0101caa-77e2-4c6a-9750-4247d28d5b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-266c8f41-3da0-4b84-88fd-b7ac452daea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-45255c2f-5d83-4ae5-8984-3ce25db99d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-45586aa7-4f26-4551-9094-582adc3e9f13,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-37d0fc34-a4b0-4407-a753-7c3377e500d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-68a84db1-4308-4842-9220-645e43ecade0,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-5a6f43e6-3426-4d4d-af6a-5cc66c0255b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488865126-172.17.0.15-1592516786485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-bfad1ae0-8471-4086-ad3b-4df88993d265,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-be72643d-5b45-491d-876f-8050deca6f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-87bf7a7a-5a7e-42ce-bff1-193be63883ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-6363a59c-4266-4d95-bb2c-3dac643f09e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-5f9780a8-b4d3-4016-8094-76efe7eee948,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-f93b0cbc-7575-4f59-949f-a49725bc118a,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-5b507cc7-c951-4383-b8e1-61ccb86a8225,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-bf02f4a1-8cac-48cc-bf3f-d1b34e1ee921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488865126-172.17.0.15-1592516786485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-bfad1ae0-8471-4086-ad3b-4df88993d265,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-be72643d-5b45-491d-876f-8050deca6f83,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-87bf7a7a-5a7e-42ce-bff1-193be63883ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-6363a59c-4266-4d95-bb2c-3dac643f09e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-5f9780a8-b4d3-4016-8094-76efe7eee948,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-f93b0cbc-7575-4f59-949f-a49725bc118a,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-5b507cc7-c951-4383-b8e1-61ccb86a8225,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-bf02f4a1-8cac-48cc-bf3f-d1b34e1ee921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869022418-172.17.0.15-1592518084994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-c8298bd8-79cf-4a4e-a483-0bd6de80afb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-535a6bb4-9bba-48e8-80f7-1a299b135c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-1ce7fd21-962f-4ff5-b076-05ffe0174f55,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-edbd496b-30c7-48f4-987f-76dfde40635a,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-4ffcea56-6ccd-4141-9b33-329297aecead,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-d9aad0e9-cd88-499a-99d4-2324bf41b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-a29723df-14ca-4adc-8309-3d16cc65e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-bd4fdf17-dac2-4572-9162-8419365395f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869022418-172.17.0.15-1592518084994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-c8298bd8-79cf-4a4e-a483-0bd6de80afb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-535a6bb4-9bba-48e8-80f7-1a299b135c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-1ce7fd21-962f-4ff5-b076-05ffe0174f55,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-edbd496b-30c7-48f4-987f-76dfde40635a,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-4ffcea56-6ccd-4141-9b33-329297aecead,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-d9aad0e9-cd88-499a-99d4-2324bf41b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-a29723df-14ca-4adc-8309-3d16cc65e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-bd4fdf17-dac2-4572-9162-8419365395f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850120133-172.17.0.15-1592518147185:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-2099c0ba-4622-4939-969f-1fa905051875,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-c9390c73-6d41-44e4-9fbb-1295ff39bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-d579a3ae-8b01-4c31-b6bb-0752d9cff6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-8df0c405-d122-4cbe-8879-33e2b14de421,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-79f03df4-892f-491e-aae4-ed7fef5a91d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-46972362-7a36-4724-93d6-176d73fe18c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-502f2362-0d48-4a1d-8b7e-5f1ada5cfb09,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-db0abaf0-4d98-4c11-9c6c-19cbea0f3546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850120133-172.17.0.15-1592518147185:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-2099c0ba-4622-4939-969f-1fa905051875,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-c9390c73-6d41-44e4-9fbb-1295ff39bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-d579a3ae-8b01-4c31-b6bb-0752d9cff6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-8df0c405-d122-4cbe-8879-33e2b14de421,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-79f03df4-892f-491e-aae4-ed7fef5a91d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-46972362-7a36-4724-93d6-176d73fe18c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-502f2362-0d48-4a1d-8b7e-5f1ada5cfb09,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-db0abaf0-4d98-4c11-9c6c-19cbea0f3546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298262827-172.17.0.15-1592518383390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-3cede221-63c5-4584-94c0-48cfc97be7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-441f9892-372a-4911-b448-0a6560c9300a,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-5b2ae968-76f3-43cf-b470-dd59a2537c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-718e445f-cb27-420b-9c71-de84ecbdc58c,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-ad2aadd0-08fc-4dda-81d1-0aa218d4cf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-29867ab6-0c4f-46e0-8131-08d15e7c1edc,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-9055937d-4399-4346-a52f-fc4cda5fa327,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-b6259d07-b735-4fb2-a5c8-4381c4fcf528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298262827-172.17.0.15-1592518383390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46106,DS-3cede221-63c5-4584-94c0-48cfc97be7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-441f9892-372a-4911-b448-0a6560c9300a,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-5b2ae968-76f3-43cf-b470-dd59a2537c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-718e445f-cb27-420b-9c71-de84ecbdc58c,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-ad2aadd0-08fc-4dda-81d1-0aa218d4cf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-29867ab6-0c4f-46e0-8131-08d15e7c1edc,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-9055937d-4399-4346-a52f-fc4cda5fa327,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-b6259d07-b735-4fb2-a5c8-4381c4fcf528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774036771-172.17.0.15-1592518416865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41379,DS-6cfb332a-03e4-4440-8642-23ff63f3a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-1edb3784-1ab6-4a56-aaf1-8f6541ab64df,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-12cd7cb7-04f7-4d45-8aca-49959989e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-69127572-33d7-477b-a153-69d56d82bc96,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-5773b7d8-9b3d-45ee-9128-aa6d7b898862,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-36f1df84-8ac6-4923-a414-7edcd72acf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-23846f25-62f7-4e7d-8151-358bbf5135e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-5ab1d6af-17de-4968-ad8f-a25f3d76fc23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774036771-172.17.0.15-1592518416865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41379,DS-6cfb332a-03e4-4440-8642-23ff63f3a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-1edb3784-1ab6-4a56-aaf1-8f6541ab64df,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-12cd7cb7-04f7-4d45-8aca-49959989e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-69127572-33d7-477b-a153-69d56d82bc96,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-5773b7d8-9b3d-45ee-9128-aa6d7b898862,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-36f1df84-8ac6-4923-a414-7edcd72acf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-23846f25-62f7-4e7d-8151-358bbf5135e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-5ab1d6af-17de-4968-ad8f-a25f3d76fc23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249888213-172.17.0.15-1592518446694:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35429,DS-7d96e901-afe5-4ffe-a203-e97f10da4ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-a9462923-0ad1-4958-8ff1-268f5e23d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-0151421a-db7c-47ec-a18e-f635cde98dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-bf5dc227-31af-4f09-a3b1-0caa376a1365,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-ac889cd2-6c14-4c9b-a0f0-fce8ec29acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-08df7d49-2cb9-4a5d-9daa-26e1ceb12f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-a74ddcc4-ca22-4549-9847-7fcf3fb81800,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-f1afc9a5-61cb-44df-afca-00d59c5b44d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249888213-172.17.0.15-1592518446694:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35429,DS-7d96e901-afe5-4ffe-a203-e97f10da4ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-a9462923-0ad1-4958-8ff1-268f5e23d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-0151421a-db7c-47ec-a18e-f635cde98dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-bf5dc227-31af-4f09-a3b1-0caa376a1365,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-ac889cd2-6c14-4c9b-a0f0-fce8ec29acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-08df7d49-2cb9-4a5d-9daa-26e1ceb12f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-a74ddcc4-ca22-4549-9847-7fcf3fb81800,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-f1afc9a5-61cb-44df-afca-00d59c5b44d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 5144
