reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300783269-172.17.0.23-1591791749608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45824,DS-633bf86f-c33f-4dc4-9d59-3140b9e7f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-a51a4fb1-5d13-4ddc-bdd2-5b3cd78702b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-2d1338d5-225d-4046-b050-342e7d60f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-e97da5b8-39c8-474d-a9f3-28e5b3a7986a,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-f0764806-0be9-428a-8404-ddf8318dd9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-d43a67a2-a5fc-4325-8772-67194eae933e,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-6e48202d-44ea-4617-b907-85c172f7b1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-ee0ede1a-0105-4fa0-a0b1-8a0bf9e9273e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300783269-172.17.0.23-1591791749608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45824,DS-633bf86f-c33f-4dc4-9d59-3140b9e7f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-a51a4fb1-5d13-4ddc-bdd2-5b3cd78702b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-2d1338d5-225d-4046-b050-342e7d60f37c,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-e97da5b8-39c8-474d-a9f3-28e5b3a7986a,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-f0764806-0be9-428a-8404-ddf8318dd9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-d43a67a2-a5fc-4325-8772-67194eae933e,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-6e48202d-44ea-4617-b907-85c172f7b1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-ee0ede1a-0105-4fa0-a0b1-8a0bf9e9273e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169300038-172.17.0.23-1591792152526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-7072185c-2eae-40af-975d-a309b604fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-995444e7-66c6-4778-b506-1e383fdc903b,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-40ff01cc-d67b-4e52-a3f3-f8aaae8da41f,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-10db04e6-dae4-42c0-ae10-f6e12b6fde79,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-25d74404-b836-4f0b-9279-b44a065410e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-45a666af-68cf-4753-83e1-236625288e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-b5cb81b7-1cd7-43cd-81c8-c0975cd3b769,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-63446897-d45d-402f-88d1-4358fe645690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169300038-172.17.0.23-1591792152526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-7072185c-2eae-40af-975d-a309b604fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-995444e7-66c6-4778-b506-1e383fdc903b,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-40ff01cc-d67b-4e52-a3f3-f8aaae8da41f,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-10db04e6-dae4-42c0-ae10-f6e12b6fde79,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-25d74404-b836-4f0b-9279-b44a065410e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-45a666af-68cf-4753-83e1-236625288e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-b5cb81b7-1cd7-43cd-81c8-c0975cd3b769,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-63446897-d45d-402f-88d1-4358fe645690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76137184-172.17.0.23-1591792360720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-1b00b190-e30a-4c85-b4ed-5e40abea1efd,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-193f338c-d9d5-46a6-8f1a-cc656f48e6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-c3c2f177-3625-44be-a096-10a3b2348a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-c58eb6a9-f5fd-47da-be97-dcf669aa7511,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-a758188d-b92f-44d2-8461-469c63e360d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-563b7930-5de8-47a6-a358-a0b8ace57ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-84323a2d-2491-4a41-a4eb-eab215c70edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-11ef4e36-b6e4-41e8-8f4d-0fd4fada5603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76137184-172.17.0.23-1591792360720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-1b00b190-e30a-4c85-b4ed-5e40abea1efd,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-193f338c-d9d5-46a6-8f1a-cc656f48e6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-c3c2f177-3625-44be-a096-10a3b2348a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-c58eb6a9-f5fd-47da-be97-dcf669aa7511,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-a758188d-b92f-44d2-8461-469c63e360d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-563b7930-5de8-47a6-a358-a0b8ace57ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-84323a2d-2491-4a41-a4eb-eab215c70edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-11ef4e36-b6e4-41e8-8f4d-0fd4fada5603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041862760-172.17.0.23-1591792391640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40162,DS-97122d1f-7247-4a9c-99ae-5e1228062f13,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-47d3674f-dc63-42ce-93d7-aa7bb61e8759,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-e4ba607c-85e8-45cb-85fa-ad478a695ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-20a5faf9-be38-4112-aa89-05f23901d8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-8bfcd3ac-7d0e-45e3-aded-12cb90db5629,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-0f81449a-2cae-4dbf-b86b-c4eda7e0ca21,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-ba906d15-f3ff-4b57-b8e4-a3715f8f6122,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-3c8b2ba6-b5c8-4396-a2cd-e6210444054c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041862760-172.17.0.23-1591792391640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40162,DS-97122d1f-7247-4a9c-99ae-5e1228062f13,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-47d3674f-dc63-42ce-93d7-aa7bb61e8759,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-e4ba607c-85e8-45cb-85fa-ad478a695ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-20a5faf9-be38-4112-aa89-05f23901d8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-8bfcd3ac-7d0e-45e3-aded-12cb90db5629,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-0f81449a-2cae-4dbf-b86b-c4eda7e0ca21,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-ba906d15-f3ff-4b57-b8e4-a3715f8f6122,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-3c8b2ba6-b5c8-4396-a2cd-e6210444054c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008033450-172.17.0.23-1591792532630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-ddb94177-00b7-4242-a082-aa01c99e50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-4b33a54f-76ec-485b-8bbd-34f0c7465d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-e34c6a93-7b3d-4d08-aabb-0ff3df3ca660,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-9c0f2efa-bf4b-47fb-9001-2360884f19b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-78b848cc-7c2f-4d1e-b88e-98b9c28dcef5,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-4f4c118e-fd30-4132-a1e1-a09de95e499b,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-c8c33041-1186-4f96-8c9e-27290bc1a5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-b5255839-7859-48ca-931f-5571317f439d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008033450-172.17.0.23-1591792532630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-ddb94177-00b7-4242-a082-aa01c99e50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-4b33a54f-76ec-485b-8bbd-34f0c7465d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-e34c6a93-7b3d-4d08-aabb-0ff3df3ca660,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-9c0f2efa-bf4b-47fb-9001-2360884f19b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-78b848cc-7c2f-4d1e-b88e-98b9c28dcef5,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-4f4c118e-fd30-4132-a1e1-a09de95e499b,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-c8c33041-1186-4f96-8c9e-27290bc1a5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-b5255839-7859-48ca-931f-5571317f439d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388271561-172.17.0.23-1591792567950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-dee9a873-189d-40c9-bd14-ba43ad6ce46d,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-3e41fafa-bdf7-406f-9b92-a97924b45331,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-ff2c9344-07f8-4dd9-bb5a-14f1510acfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-31c78b0a-0350-4cb9-82a2-c5fc1cb21a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-7380d840-908c-4576-a4c1-63ad9db44b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b868a271-1244-40f9-8027-300ed7bd0411,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-671ec35c-721c-4be2-96e8-678653c3985c,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-c1255620-dc3f-4c53-b3d2-43ca19a1bb6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388271561-172.17.0.23-1591792567950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-dee9a873-189d-40c9-bd14-ba43ad6ce46d,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-3e41fafa-bdf7-406f-9b92-a97924b45331,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-ff2c9344-07f8-4dd9-bb5a-14f1510acfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-31c78b0a-0350-4cb9-82a2-c5fc1cb21a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-7380d840-908c-4576-a4c1-63ad9db44b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b868a271-1244-40f9-8027-300ed7bd0411,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-671ec35c-721c-4be2-96e8-678653c3985c,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-c1255620-dc3f-4c53-b3d2-43ca19a1bb6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991712999-172.17.0.23-1591793401952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38063,DS-d3eed642-da9a-42ba-8489-75e515921280,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-8d6f8b40-5578-428d-8c8a-853309e8a327,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-e6ab7aa0-3500-4ab4-b452-f2eacff05fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-1ac38054-dfdb-421f-973a-2912c53dd1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-22817b76-1949-457e-b463-772022e30f53,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-feddb6f8-1e6d-479b-97fb-428125152ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-bf672c86-25e9-4a20-9068-5e76ed521287,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-912b3f02-f2ce-4af1-956b-c8b65e09a438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991712999-172.17.0.23-1591793401952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38063,DS-d3eed642-da9a-42ba-8489-75e515921280,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-8d6f8b40-5578-428d-8c8a-853309e8a327,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-e6ab7aa0-3500-4ab4-b452-f2eacff05fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-1ac38054-dfdb-421f-973a-2912c53dd1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-22817b76-1949-457e-b463-772022e30f53,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-feddb6f8-1e6d-479b-97fb-428125152ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-bf672c86-25e9-4a20-9068-5e76ed521287,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-912b3f02-f2ce-4af1-956b-c8b65e09a438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239387562-172.17.0.23-1591793433190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40095,DS-141d2331-b6a0-484e-bd94-bb3765a7818e,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-6574f517-86ab-40e5-8c97-a5150b5ef0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-89143cac-fea7-4ccc-9ea5-dfc99f92e67d,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-17146a7e-4e0c-4f1a-a8a3-a0bacec57f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-057ec99f-5a1a-44f4-897d-c007fb548ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-6bb6199b-95cd-49da-a644-d82e4ad6563a,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-74baff8b-d191-4d55-9aae-80a4740fd252,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-21ba258b-6a55-4f7a-ade5-bb374018b332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239387562-172.17.0.23-1591793433190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40095,DS-141d2331-b6a0-484e-bd94-bb3765a7818e,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-6574f517-86ab-40e5-8c97-a5150b5ef0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-89143cac-fea7-4ccc-9ea5-dfc99f92e67d,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-17146a7e-4e0c-4f1a-a8a3-a0bacec57f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-057ec99f-5a1a-44f4-897d-c007fb548ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-6bb6199b-95cd-49da-a644-d82e4ad6563a,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-74baff8b-d191-4d55-9aae-80a4740fd252,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-21ba258b-6a55-4f7a-ade5-bb374018b332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649924657-172.17.0.23-1591794711673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-449f8627-df97-450e-bd11-81666443f751,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-89654140-365f-4a39-8f94-4159be3d09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-21f2a4bc-9324-46b0-ba0f-97fb41b6547d,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-1ab080b3-5e50-4839-b6db-54ba6abf9bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-a77f0622-fc8c-4743-86b7-895428db1b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-e76f1d43-922b-4885-9824-7d0a1b58418a,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-cbafa8e9-3a94-45b8-a930-0b1baeed6b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-7a3661de-08be-4494-b64a-920f67c3b888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649924657-172.17.0.23-1591794711673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-449f8627-df97-450e-bd11-81666443f751,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-89654140-365f-4a39-8f94-4159be3d09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-21f2a4bc-9324-46b0-ba0f-97fb41b6547d,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-1ab080b3-5e50-4839-b6db-54ba6abf9bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-a77f0622-fc8c-4743-86b7-895428db1b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-e76f1d43-922b-4885-9824-7d0a1b58418a,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-cbafa8e9-3a94-45b8-a930-0b1baeed6b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-7a3661de-08be-4494-b64a-920f67c3b888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301369831-172.17.0.23-1591795064630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46676,DS-0198dda1-c46d-4444-973c-135a69089c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-3e62acba-fa94-47a5-ab0f-9b3194218ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-98e6c6d5-fb8d-4123-afd2-876ee3ff9571,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-89949ecc-8a42-468b-a3e4-4a1401fddd38,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-ed285d4a-7848-4794-9b08-c44f3c62b255,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-3c1207a4-0423-4607-8f87-917d51a8d566,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-a1bb377f-ebf2-418c-8b90-170031714351,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-4ec4b666-98bb-4c1c-b230-87d0bdc520cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301369831-172.17.0.23-1591795064630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46676,DS-0198dda1-c46d-4444-973c-135a69089c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-3e62acba-fa94-47a5-ab0f-9b3194218ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-98e6c6d5-fb8d-4123-afd2-876ee3ff9571,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-89949ecc-8a42-468b-a3e4-4a1401fddd38,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-ed285d4a-7848-4794-9b08-c44f3c62b255,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-3c1207a4-0423-4607-8f87-917d51a8d566,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-a1bb377f-ebf2-418c-8b90-170031714351,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-4ec4b666-98bb-4c1c-b230-87d0bdc520cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908497589-172.17.0.23-1591795184101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42007,DS-8db75c5d-5607-41d6-ae8a-534cd77df981,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-265d9b60-37ba-43f9-907a-75a275e596aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-83ac4146-4e84-4a4b-bb20-f8d30e303f68,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-0581fe51-f5c2-4d72-8148-bbfd7be993bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-5171a418-07ab-4254-b76d-823877fefbce,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-77edbbf6-1c3c-4189-88fc-2d43d8abe2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-0d287e2d-13bf-4df5-a08a-6527f13b5cea,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-e9de8b6f-f744-4a7c-a7bf-56b777c88dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908497589-172.17.0.23-1591795184101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42007,DS-8db75c5d-5607-41d6-ae8a-534cd77df981,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-265d9b60-37ba-43f9-907a-75a275e596aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-83ac4146-4e84-4a4b-bb20-f8d30e303f68,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-0581fe51-f5c2-4d72-8148-bbfd7be993bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-5171a418-07ab-4254-b76d-823877fefbce,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-77edbbf6-1c3c-4189-88fc-2d43d8abe2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-0d287e2d-13bf-4df5-a08a-6527f13b5cea,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-e9de8b6f-f744-4a7c-a7bf-56b777c88dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990337509-172.17.0.23-1591795286952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-accf7356-5321-41b8-9316-07f0b79f7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-8bb8e004-8350-4f67-920a-b972037d2230,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-91c3314f-b26f-453d-9270-9bd6d353d81e,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-38ded642-890b-4379-9904-32920450b539,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-bd881dfc-4575-40f2-96ac-924b82ddd6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-c65c9cf7-60e8-4673-aa18-53e08b6764ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-65bda00b-4995-4f95-a001-83612beef28d,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-add0848c-0fc0-4b98-ad4b-24f201b10775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990337509-172.17.0.23-1591795286952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-accf7356-5321-41b8-9316-07f0b79f7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-8bb8e004-8350-4f67-920a-b972037d2230,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-91c3314f-b26f-453d-9270-9bd6d353d81e,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-38ded642-890b-4379-9904-32920450b539,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-bd881dfc-4575-40f2-96ac-924b82ddd6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-c65c9cf7-60e8-4673-aa18-53e08b6764ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-65bda00b-4995-4f95-a001-83612beef28d,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-add0848c-0fc0-4b98-ad4b-24f201b10775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104038010-172.17.0.23-1591795363251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-e8c4b854-53df-4fa4-a08e-a0038d7bae63,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-0c278902-a07d-48cd-aeb6-1acfe76cc223,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-70d1e53b-f995-4ab1-86bd-f26820a673d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-c58082b4-32b2-4070-9b1d-052c0282c446,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-9e05f3cb-26dc-4afb-a591-2e9432e164f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-a0d16db0-3f10-4e07-8df4-9756ae7dc731,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-6d022c61-642d-4d94-be0a-5a058ce01c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-5368886e-73fb-417a-8138-48aa16d165ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104038010-172.17.0.23-1591795363251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-e8c4b854-53df-4fa4-a08e-a0038d7bae63,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-0c278902-a07d-48cd-aeb6-1acfe76cc223,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-70d1e53b-f995-4ab1-86bd-f26820a673d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-c58082b4-32b2-4070-9b1d-052c0282c446,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-9e05f3cb-26dc-4afb-a591-2e9432e164f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-a0d16db0-3f10-4e07-8df4-9756ae7dc731,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-6d022c61-642d-4d94-be0a-5a058ce01c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-5368886e-73fb-417a-8138-48aa16d165ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67476867-172.17.0.23-1591795541093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-2f620f9b-1ea7-4b57-9f0e-0afc57666416,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-c11c05ca-a7fc-4b20-826d-7f4e03b9d305,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-bbe2968e-82f3-4a42-bb00-a17a3a093e48,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-7907209b-1fc4-423c-9e25-56efc0709442,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-f2f3535b-1263-4a34-8983-1abd5c3607fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-73784fb2-d4b8-4801-b9b6-7650c519e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a7799492-549e-45de-96ad-26526d7d3b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-58444f3d-a84f-4396-bce1-a636e2fc385f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67476867-172.17.0.23-1591795541093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-2f620f9b-1ea7-4b57-9f0e-0afc57666416,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-c11c05ca-a7fc-4b20-826d-7f4e03b9d305,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-bbe2968e-82f3-4a42-bb00-a17a3a093e48,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-7907209b-1fc4-423c-9e25-56efc0709442,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-f2f3535b-1263-4a34-8983-1abd5c3607fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-73784fb2-d4b8-4801-b9b6-7650c519e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a7799492-549e-45de-96ad-26526d7d3b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-58444f3d-a84f-4396-bce1-a636e2fc385f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943304084-172.17.0.23-1591796042032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-95dde422-79f5-43ed-add8-53cb6dcbef7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-d70237ea-c5e0-46aa-ac57-ec53e259fd87,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-e7766fe9-5d70-4736-b365-2cda6cd3aa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-7e9c6eb5-f75c-4a47-b39b-f23b52059e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-c1533b24-5e89-42b5-bbd1-27733645f371,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-5b9dabfb-6ba6-4cb9-ba7e-1d8b93041803,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-496fe4f1-bb9b-44e6-8763-2c1ebbf7a00e,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-7ac3d63a-431e-4409-9853-ecfa565eaf69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943304084-172.17.0.23-1591796042032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-95dde422-79f5-43ed-add8-53cb6dcbef7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-d70237ea-c5e0-46aa-ac57-ec53e259fd87,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-e7766fe9-5d70-4736-b365-2cda6cd3aa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-7e9c6eb5-f75c-4a47-b39b-f23b52059e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-c1533b24-5e89-42b5-bbd1-27733645f371,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-5b9dabfb-6ba6-4cb9-ba7e-1d8b93041803,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-496fe4f1-bb9b-44e6-8763-2c1ebbf7a00e,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-7ac3d63a-431e-4409-9853-ecfa565eaf69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82965793-172.17.0.23-1591796160934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-6680c5ab-8880-4945-8f49-faadb5830ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-c274367d-6955-462f-9a8f-3394664e2146,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-3ba4bd88-cb69-45a6-844a-83122e486f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-d8ab61e5-9edf-4114-82c1-7a0ae18f9d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-29a9ef95-19fe-402a-a39e-f2a40dadd141,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-6f5c1398-a351-4b67-b992-0e2793299679,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-203014d9-e518-4214-ab9f-01aac3ae8c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-3700df46-0466-4d64-bb62-c4e97e88ca0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82965793-172.17.0.23-1591796160934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-6680c5ab-8880-4945-8f49-faadb5830ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-c274367d-6955-462f-9a8f-3394664e2146,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-3ba4bd88-cb69-45a6-844a-83122e486f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-d8ab61e5-9edf-4114-82c1-7a0ae18f9d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-29a9ef95-19fe-402a-a39e-f2a40dadd141,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-6f5c1398-a351-4b67-b992-0e2793299679,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-203014d9-e518-4214-ab9f-01aac3ae8c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-3700df46-0466-4d64-bb62-c4e97e88ca0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020183819-172.17.0.23-1591796411302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-ebd9998a-2e55-46a8-8a05-bc758b9bb1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-074d0259-e399-45e5-920a-87ca4961b862,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-a46ff5de-4be5-476b-9db2-6a6b3adeb7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-7dc37706-a8d8-4d9b-8c6d-9279407484ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-784cf51b-6ab8-42f0-8e48-7b5f4ff897ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-a2e1f2f4-6f05-4fb0-a322-9ed5b7de8df2,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-882e4f31-3016-4994-8d96-ed0e9ff86f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-8a454fa1-5ccb-4ea5-bb02-3e2402e44e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020183819-172.17.0.23-1591796411302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-ebd9998a-2e55-46a8-8a05-bc758b9bb1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-074d0259-e399-45e5-920a-87ca4961b862,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-a46ff5de-4be5-476b-9db2-6a6b3adeb7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-7dc37706-a8d8-4d9b-8c6d-9279407484ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-784cf51b-6ab8-42f0-8e48-7b5f4ff897ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-a2e1f2f4-6f05-4fb0-a322-9ed5b7de8df2,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-882e4f31-3016-4994-8d96-ed0e9ff86f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-8a454fa1-5ccb-4ea5-bb02-3e2402e44e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909193444-172.17.0.23-1591796444052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-3579ef76-33d8-41bc-863d-6a1c32e4be40,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-8f8c5a2b-4b4b-44ac-8265-199a5a14f5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-a515ce1c-f1f9-45cb-827d-e7ac814e19d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-2e86d981-17a2-4d2a-8614-e265e003751c,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-5280fc8d-0f33-4284-b416-ee0b2495d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-3869b448-dc13-4868-892f-f35f9a56cd24,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-9f3a770c-2c6c-4c33-bd02-b1999b702b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-481efb59-e465-4d40-ae24-ce920ff50a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909193444-172.17.0.23-1591796444052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-3579ef76-33d8-41bc-863d-6a1c32e4be40,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-8f8c5a2b-4b4b-44ac-8265-199a5a14f5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-a515ce1c-f1f9-45cb-827d-e7ac814e19d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-2e86d981-17a2-4d2a-8614-e265e003751c,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-5280fc8d-0f33-4284-b416-ee0b2495d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-3869b448-dc13-4868-892f-f35f9a56cd24,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-9f3a770c-2c6c-4c33-bd02-b1999b702b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-481efb59-e465-4d40-ae24-ce920ff50a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5366
