reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485982210-172.17.0.11-1591744391284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35306,DS-d80fa3a9-24e7-4804-a71a-8a25081188a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-ed796951-f1ca-4c40-bc1d-099c5694efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-d2f41b4e-cb9a-48fe-8c98-a5fd18bd900d,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-b3ee97c8-b4ef-40f6-a79d-911a23c94fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-b6f98624-ee57-4db2-bcea-dc23889fa9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-2d7b26dc-f6d1-404e-8194-ccd28a4ba400,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-238cd214-775d-4947-abcd-83ac82d398e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-30706a95-2d74-4ec4-b909-5086d3bca0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485982210-172.17.0.11-1591744391284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35306,DS-d80fa3a9-24e7-4804-a71a-8a25081188a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-ed796951-f1ca-4c40-bc1d-099c5694efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-d2f41b4e-cb9a-48fe-8c98-a5fd18bd900d,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-b3ee97c8-b4ef-40f6-a79d-911a23c94fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-b6f98624-ee57-4db2-bcea-dc23889fa9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-2d7b26dc-f6d1-404e-8194-ccd28a4ba400,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-238cd214-775d-4947-abcd-83ac82d398e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-30706a95-2d74-4ec4-b909-5086d3bca0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944357586-172.17.0.11-1591745683952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33062,DS-97fcf85f-a6a5-4ba8-bcd4-842c29390647,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-9bba3252-4933-47d9-9d53-a77f155df69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-bb01a72b-3229-427f-863c-2c110636ca45,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-d2f10546-e3df-4b67-b5fe-bd3638a3a766,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-d091eed1-787b-4f45-8630-e1e88411e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-6cf2cdcf-3bec-4d9f-933b-fa6346b26780,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-9e83ea4e-c822-4197-a1a5-e0c23ba53224,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-476bbc99-edaa-4243-8eb6-552ac115b0a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944357586-172.17.0.11-1591745683952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33062,DS-97fcf85f-a6a5-4ba8-bcd4-842c29390647,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-9bba3252-4933-47d9-9d53-a77f155df69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-bb01a72b-3229-427f-863c-2c110636ca45,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-d2f10546-e3df-4b67-b5fe-bd3638a3a766,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-d091eed1-787b-4f45-8630-e1e88411e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-6cf2cdcf-3bec-4d9f-933b-fa6346b26780,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-9e83ea4e-c822-4197-a1a5-e0c23ba53224,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-476bbc99-edaa-4243-8eb6-552ac115b0a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212005288-172.17.0.11-1591745792536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33259,DS-33624eac-a108-4dba-bbff-b30e3d2cb92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-71f31ef1-fb8e-4ae5-ae76-cf27766818b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-26a998bf-4eaf-4d1c-9271-ec241032a785,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-3210492f-f208-44c1-9739-088e145a690d,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-ef6f8601-64d0-421d-9979-f03732879201,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-7376af33-036d-400e-906d-ba9f2eb2a8da,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-8ec2dc9a-13a3-43b1-8079-41ae4b43aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-bb6c9413-49ed-4f64-97fd-72b1995d8517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212005288-172.17.0.11-1591745792536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33259,DS-33624eac-a108-4dba-bbff-b30e3d2cb92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-71f31ef1-fb8e-4ae5-ae76-cf27766818b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-26a998bf-4eaf-4d1c-9271-ec241032a785,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-3210492f-f208-44c1-9739-088e145a690d,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-ef6f8601-64d0-421d-9979-f03732879201,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-7376af33-036d-400e-906d-ba9f2eb2a8da,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-8ec2dc9a-13a3-43b1-8079-41ae4b43aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-bb6c9413-49ed-4f64-97fd-72b1995d8517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243636620-172.17.0.11-1591746119588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-36cb9c7c-b86e-4a5d-a124-065554eb6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-5a21a789-3109-4ebf-8950-27e8a4e31a43,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-ec0f622e-c626-4004-bedf-af6196ee94bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-7b1cf91b-a85a-42c7-8607-e3ce604313de,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-7e058d36-3ca2-4b93-a157-5921be139226,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-d57a2d58-f344-4480-8744-e6b3bf9638f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-48fd44bd-bda3-4c8c-8671-995cd0878d24,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-59cad3a8-eb22-44e5-9f62-039399ca3790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243636620-172.17.0.11-1591746119588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-36cb9c7c-b86e-4a5d-a124-065554eb6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-5a21a789-3109-4ebf-8950-27e8a4e31a43,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-ec0f622e-c626-4004-bedf-af6196ee94bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-7b1cf91b-a85a-42c7-8607-e3ce604313de,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-7e058d36-3ca2-4b93-a157-5921be139226,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-d57a2d58-f344-4480-8744-e6b3bf9638f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-48fd44bd-bda3-4c8c-8671-995cd0878d24,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-59cad3a8-eb22-44e5-9f62-039399ca3790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102125316-172.17.0.11-1591746344601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40854,DS-49cbca67-51b2-4844-b160-633d123b1eae,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-a69f3606-63c8-47b1-a27c-9177ae0bd426,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-644f0776-0de0-4097-bd8c-07aa693db843,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-b16a192f-9e4c-4167-85ae-670d696600c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-42a084e4-f16d-4ec4-992d-0b18a3e4db23,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-1281f420-0825-4787-ad88-a8ce7941f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-0dbb8425-45ff-49c4-b32f-58111a35de76,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-bf0bde09-848f-4b4f-af16-95fda35c9ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102125316-172.17.0.11-1591746344601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40854,DS-49cbca67-51b2-4844-b160-633d123b1eae,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-a69f3606-63c8-47b1-a27c-9177ae0bd426,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-644f0776-0de0-4097-bd8c-07aa693db843,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-b16a192f-9e4c-4167-85ae-670d696600c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-42a084e4-f16d-4ec4-992d-0b18a3e4db23,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-1281f420-0825-4787-ad88-a8ce7941f05e,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-0dbb8425-45ff-49c4-b32f-58111a35de76,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-bf0bde09-848f-4b4f-af16-95fda35c9ab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408287345-172.17.0.11-1591747135209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-1375c45a-3758-4f51-a125-4aa0463a3c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-adda797a-4a88-4be3-9184-c5ac2ef1b88c,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-d29ba624-372a-4baf-a478-cbc471b3fbad,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-273dfd14-7a44-4e15-8829-91e77aab7d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-32703ee9-6bbf-4c99-b5e1-0dc1f1f95e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-62d466af-bf80-4142-b2b3-8d4d037da9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-0d9599ba-7c2e-4fb1-9db2-7dc4ccd7499d,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-dda62baf-a053-49b3-9a52-cdfd88dc2a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408287345-172.17.0.11-1591747135209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-1375c45a-3758-4f51-a125-4aa0463a3c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-adda797a-4a88-4be3-9184-c5ac2ef1b88c,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-d29ba624-372a-4baf-a478-cbc471b3fbad,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-273dfd14-7a44-4e15-8829-91e77aab7d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-32703ee9-6bbf-4c99-b5e1-0dc1f1f95e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-62d466af-bf80-4142-b2b3-8d4d037da9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-0d9599ba-7c2e-4fb1-9db2-7dc4ccd7499d,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-dda62baf-a053-49b3-9a52-cdfd88dc2a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569947975-172.17.0.11-1591747314752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38792,DS-be46e730-63b0-4b76-bf35-1466be44c917,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-50cd0c04-e6df-4d93-b1fe-26d836eb577a,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-5234ed94-e451-467d-bf84-7e1dd9993cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-54efb331-07ee-4e4d-a297-0e8faf884b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-e830d142-c784-43dc-a879-e4efcdddcf56,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-20259d03-595c-4a30-ba8b-f0af4381ccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-cc958179-66a7-46eb-8a05-8432fc9f2ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-add9ba1e-0dd1-4850-a0fa-a56c13135178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569947975-172.17.0.11-1591747314752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38792,DS-be46e730-63b0-4b76-bf35-1466be44c917,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-50cd0c04-e6df-4d93-b1fe-26d836eb577a,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-5234ed94-e451-467d-bf84-7e1dd9993cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-54efb331-07ee-4e4d-a297-0e8faf884b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-e830d142-c784-43dc-a879-e4efcdddcf56,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-20259d03-595c-4a30-ba8b-f0af4381ccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-cc958179-66a7-46eb-8a05-8432fc9f2ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-add9ba1e-0dd1-4850-a0fa-a56c13135178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863960722-172.17.0.11-1591748879723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-875c984f-b0d5-46c5-bac0-589510a9a1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-0632a696-897a-4ed7-bf94-e711b5385f41,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-f9e4fb3e-c9af-4ee4-bfb8-ad22a1a3b342,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-49d42e7c-a531-42f1-a824-e1a25bb5dba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-58156c65-6cc0-4981-8678-70066aa2ec23,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-8f28be20-eedc-42a5-8a88-22ea132bdb90,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-26a3437a-b82e-4110-852a-6a8cb85ac414,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-1314e7b2-d72e-455b-b3ee-95673be46b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863960722-172.17.0.11-1591748879723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-875c984f-b0d5-46c5-bac0-589510a9a1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-0632a696-897a-4ed7-bf94-e711b5385f41,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-f9e4fb3e-c9af-4ee4-bfb8-ad22a1a3b342,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-49d42e7c-a531-42f1-a824-e1a25bb5dba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-58156c65-6cc0-4981-8678-70066aa2ec23,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-8f28be20-eedc-42a5-8a88-22ea132bdb90,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-26a3437a-b82e-4110-852a-6a8cb85ac414,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-1314e7b2-d72e-455b-b3ee-95673be46b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178846996-172.17.0.11-1591749214238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40525,DS-760644cd-a982-4704-b20c-d2f1b429edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-6e7b80f6-bc83-4f40-82c5-427ca978ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-55a2b610-7059-457f-bb5b-59ef77eb795b,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-e96ac3b6-740c-41cc-9e1d-eb688e0e39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-ee0bd6d3-189a-4f4f-a8f8-a85dac2dd822,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-c1849070-896f-4f54-ade5-0b405125ae47,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-4552fe0d-720f-4ba1-96df-8165c923e59e,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-b83f2305-f2cd-48f1-aaec-f27281bcac15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178846996-172.17.0.11-1591749214238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40525,DS-760644cd-a982-4704-b20c-d2f1b429edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-6e7b80f6-bc83-4f40-82c5-427ca978ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-55a2b610-7059-457f-bb5b-59ef77eb795b,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-e96ac3b6-740c-41cc-9e1d-eb688e0e39f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-ee0bd6d3-189a-4f4f-a8f8-a85dac2dd822,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-c1849070-896f-4f54-ade5-0b405125ae47,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-4552fe0d-720f-4ba1-96df-8165c923e59e,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-b83f2305-f2cd-48f1-aaec-f27281bcac15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38806309-172.17.0.11-1591749255229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-9ee92e0d-e7c3-41fc-bb86-7011c557a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-986ac07c-662b-4ae5-8743-d1b3bc123bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-07661dd1-3360-46a5-a97a-f3e8dba7b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-41686a43-b251-4a5b-9d8d-174a595daae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-6d680e8f-dd55-4cf7-9755-f2bd10c6b854,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-35c827f6-ab20-45b4-a78e-e0ec24a51111,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-567713de-8a47-4a8f-84de-7a77589f5ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-2625ba02-36f1-434d-be6a-591dee0c7b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-38806309-172.17.0.11-1591749255229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39436,DS-9ee92e0d-e7c3-41fc-bb86-7011c557a0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-986ac07c-662b-4ae5-8743-d1b3bc123bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-07661dd1-3360-46a5-a97a-f3e8dba7b60f,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-41686a43-b251-4a5b-9d8d-174a595daae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-6d680e8f-dd55-4cf7-9755-f2bd10c6b854,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-35c827f6-ab20-45b4-a78e-e0ec24a51111,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-567713de-8a47-4a8f-84de-7a77589f5ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-2625ba02-36f1-434d-be6a-591dee0c7b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777949274-172.17.0.11-1591749327195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-a09bbc69-2ab9-45ae-b901-e5739edafe69,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-c9eecf75-05cd-4e11-8ec7-b90664be6736,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-bb3f41a7-63ea-4f11-9f2f-96abe3eefd97,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-ed5f0d91-3b92-4284-9a87-15508f498489,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-98c9fbbf-a9ff-4819-b1af-fda2098bc54d,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-11c5d9fb-1892-4544-9ceb-4045dd3c2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-fa9d66cb-e093-457c-8d80-42e1082fd1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-9dbcdaba-0471-4df7-8c67-a72118c2e30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777949274-172.17.0.11-1591749327195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-a09bbc69-2ab9-45ae-b901-e5739edafe69,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-c9eecf75-05cd-4e11-8ec7-b90664be6736,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-bb3f41a7-63ea-4f11-9f2f-96abe3eefd97,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-ed5f0d91-3b92-4284-9a87-15508f498489,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-98c9fbbf-a9ff-4819-b1af-fda2098bc54d,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-11c5d9fb-1892-4544-9ceb-4045dd3c2abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-fa9d66cb-e093-457c-8d80-42e1082fd1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-9dbcdaba-0471-4df7-8c67-a72118c2e30d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 5506
