reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-1346051723-172.17.0.2-1591784403663:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-838a3aaf-ce7a-4cad-8d30-5d5906ec1e24,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-1346051723-172.17.0.2-1591784403663:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-838a3aaf-ce7a-4cad-8d30-5d5906ec1e24,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-1578407208-172.17.0.2-1591784553663:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33316,DS-c9827ac7-c4f8-469d-a11c-86f4e2c82fc4,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-1578407208-172.17.0.2-1591784553663:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33316,DS-c9827ac7-c4f8-469d-a11c-86f4e2c82fc4,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-1982612553-172.17.0.2-1591784692076:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39161,DS-6b9d860a-cae7-4538-b451-82cf6f675971,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-1982612553-172.17.0.2-1591784692076:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39161,DS-6b9d860a-cae7-4538-b451-82cf6f675971,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-1885474239-172.17.0.2-1591784832367:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41671,DS-f3f3d823-04a7-4d99-872c-f4e9532b1284,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-1885474239-172.17.0.2-1591784832367:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41671,DS-f3f3d823-04a7-4d99-872c-f4e9532b1284,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-259833457-172.17.0.2-1591784974870:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-92d58ee5-e99f-4c51-b9c2-3ca95f8dcdf2,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-259833457-172.17.0.2-1591784974870:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-92d58ee5-e99f-4c51-b9c2-3ca95f8dcdf2,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-1178591741-172.17.0.2-1591785116206:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42347,DS-e42fc6f2-0395-458c-bd5b-437452f9faea,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-1178591741-172.17.0.2-1591785116206:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42347,DS-e42fc6f2-0395-458c-bd5b-437452f9faea,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-915844327-172.17.0.2-1591785255237:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42367,DS-afdef720-1aa1-4d64-a78e-63d662c4a3d9,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-915844327-172.17.0.2-1591785255237:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42367,DS-afdef720-1aa1-4d64-a78e-63d662c4a3d9,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-1569151172-172.17.0.2-1591785404700:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-80fc07e9-697c-4b8d-8d1a-2d148bef40ec,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-1569151172-172.17.0.2-1591785404700:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-80fc07e9-697c-4b8d-8d1a-2d148bef40ec,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-1890635598-172.17.0.2-1591785549655:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-21ecf992-bef2-43ed-9fc3-e594995da8a7,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-1890635598-172.17.0.2-1591785549655:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41619,DS-21ecf992-bef2-43ed-9fc3-e594995da8a7,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication#testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF
reconfPoint: -1
result: -1
failureMessage: Cannot obtain block length for LocatedBlock{BP-1950782445-172.17.0.2-1591785711058:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43958,DS-b1b98600-7998-40e8-b93f-97505c8d669a,DISK]]}
stackTrace: org.apache.hadoop.hdfs.CannotObtainBlockLengthException: Cannot obtain block length for LocatedBlock{BP-1950782445-172.17.0.2-1591785711058:blk_1073741827_1003; getBlockSize()=1; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43958,DS-b1b98600-7998-40e8-b93f-97505c8d669a,DISK]]}
	at org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(DFSInputStream.java:363)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:201)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:185)
	at org.apache.hadoop.hdfs.DFSClient.openInternal(DFSClient.java:1048)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1011)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:319)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:315)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:327)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:899)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.verifyFileContent(TestReplaceDatanodeFailureReplication.java:227)
	at org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication.testLessNumberOfLiveDatanodesThanWriteReplaceDatanodeOnFailureRF(TestReplaceDatanodeFailureReplication.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1458
