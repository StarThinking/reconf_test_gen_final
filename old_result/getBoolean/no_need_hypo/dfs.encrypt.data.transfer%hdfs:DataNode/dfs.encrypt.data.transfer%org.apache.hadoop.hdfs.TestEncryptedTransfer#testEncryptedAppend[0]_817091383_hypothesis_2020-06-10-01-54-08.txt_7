reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36694,DS-93c1d3f8-600a-4f3c-9d55-ab2c74576b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-b35f5b87-65c9-4ac0-adf3-94a83e86d95f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36694,DS-93c1d3f8-600a-4f3c-9d55-ab2c74576b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-b35f5b87-65c9-4ac0-adf3-94a83e86d95f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36694,DS-93c1d3f8-600a-4f3c-9d55-ab2c74576b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-b35f5b87-65c9-4ac0-adf3-94a83e86d95f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36694,DS-93c1d3f8-600a-4f3c-9d55-ab2c74576b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-b35f5b87-65c9-4ac0-adf3-94a83e86d95f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39885,DS-cbbbfbff-0803-42b5-a8ec-12e9e02f5fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-669360ee-3a33-40f6-b777-90bb9b307e78,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39885,DS-cbbbfbff-0803-42b5-a8ec-12e9e02f5fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-669360ee-3a33-40f6-b777-90bb9b307e78,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39885,DS-cbbbfbff-0803-42b5-a8ec-12e9e02f5fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-669360ee-3a33-40f6-b777-90bb9b307e78,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39885,DS-cbbbfbff-0803-42b5-a8ec-12e9e02f5fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-669360ee-3a33-40f6-b777-90bb9b307e78,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-ee47682d-366f-4c19-9128-a957aa1f564a,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-e7cea843-e4ad-4e66-a1f4-fed7c40216b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-ee47682d-366f-4c19-9128-a957aa1f564a,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-e7cea843-e4ad-4e66-a1f4-fed7c40216b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-ee47682d-366f-4c19-9128-a957aa1f564a,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-e7cea843-e4ad-4e66-a1f4-fed7c40216b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-ee47682d-366f-4c19-9128-a957aa1f564a,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-e7cea843-e4ad-4e66-a1f4-fed7c40216b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39551,DS-3dd00954-7cf4-4258-9f9b-1766362d5b99,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-01530b60-a7eb-4e25-887e-f7ec251bcec0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39551,DS-3dd00954-7cf4-4258-9f9b-1766362d5b99,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-01530b60-a7eb-4e25-887e-f7ec251bcec0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39551,DS-3dd00954-7cf4-4258-9f9b-1766362d5b99,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-01530b60-a7eb-4e25-887e-f7ec251bcec0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39551,DS-3dd00954-7cf4-4258-9f9b-1766362d5b99,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-01530b60-a7eb-4e25-887e-f7ec251bcec0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-747a4f61-eaaf-41c2-873a-f47305f9add5,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-8b68aaed-b04b-4247-a9a5-20108188c07d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-747a4f61-eaaf-41c2-873a-f47305f9add5,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-8b68aaed-b04b-4247-a9a5-20108188c07d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-747a4f61-eaaf-41c2-873a-f47305f9add5,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-8b68aaed-b04b-4247-a9a5-20108188c07d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-747a4f61-eaaf-41c2-873a-f47305f9add5,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-8b68aaed-b04b-4247-a9a5-20108188c07d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-412cca99-cd4e-4581-a594-866d6150a490,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-35930324-6185-4982-9970-851a4444b7d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-412cca99-cd4e-4581-a594-866d6150a490,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-35930324-6185-4982-9970-851a4444b7d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-412cca99-cd4e-4581-a594-866d6150a490,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-35930324-6185-4982-9970-851a4444b7d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-412cca99-cd4e-4581-a594-866d6150a490,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-35930324-6185-4982-9970-851a4444b7d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33628,DS-161e2c31-ff00-4401-a81f-c2239b2a05eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-7449424e-2e85-432d-98ac-4329f459c62d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33628,DS-161e2c31-ff00-4401-a81f-c2239b2a05eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-7449424e-2e85-432d-98ac-4329f459c62d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33628,DS-161e2c31-ff00-4401-a81f-c2239b2a05eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-7449424e-2e85-432d-98ac-4329f459c62d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33628,DS-161e2c31-ff00-4401-a81f-c2239b2a05eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-7449424e-2e85-432d-98ac-4329f459c62d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45865,DS-2d73a574-f656-478a-9687-217ff830df47,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-f13fd185-142c-48bd-9fd1-55efb3269953,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45865,DS-2d73a574-f656-478a-9687-217ff830df47,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-f13fd185-142c-48bd-9fd1-55efb3269953,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45865,DS-2d73a574-f656-478a-9687-217ff830df47,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-f13fd185-142c-48bd-9fd1-55efb3269953,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45865,DS-2d73a574-f656-478a-9687-217ff830df47,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-f13fd185-142c-48bd-9fd1-55efb3269953,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-e38eeeeb-a727-42f8-9a68-584e7a70b215,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-4ee8638b-de85-4701-b1d0-8d443ed33e98,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-4ee8638b-de85-4701-b1d0-8d443ed33e98,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-e38eeeeb-a727-42f8-9a68-584e7a70b215,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-e38eeeeb-a727-42f8-9a68-584e7a70b215,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-4ee8638b-de85-4701-b1d0-8d443ed33e98,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-4ee8638b-de85-4701-b1d0-8d443ed33e98,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-e38eeeeb-a727-42f8-9a68-584e7a70b215,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.transfer
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestEncryptedTransfer#testEncryptedAppend[0]
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-e65dda40-af61-48e9-be9f-429637a2d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-1eb92a83-79ad-4a8a-aa3c-e589961d16a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-e65dda40-af61-48e9-be9f-429637a2d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-1eb92a83-79ad-4a8a-aa3c-e589961d16a1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-e65dda40-af61-48e9-be9f-429637a2d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-1eb92a83-79ad-4a8a-aa3c-e589961d16a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-e65dda40-af61-48e9-be9f-429637a2d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-1eb92a83-79ad-4a8a-aa3c-e589961d16a1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 696
