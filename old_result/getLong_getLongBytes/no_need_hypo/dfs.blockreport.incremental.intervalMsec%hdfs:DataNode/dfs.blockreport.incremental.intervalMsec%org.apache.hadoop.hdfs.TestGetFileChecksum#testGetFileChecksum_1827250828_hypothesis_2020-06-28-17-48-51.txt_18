reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-28bc8539-843c-40d1-bec3-2093a69cfd70,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-e2b87418-4ab1-480d-ac0c-b4c5e4296466,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-e2b87418-4ab1-480d-ac0c-b4c5e4296466,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-28bc8539-843c-40d1-bec3-2093a69cfd70,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-28bc8539-843c-40d1-bec3-2093a69cfd70,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-e2b87418-4ab1-480d-ac0c-b4c5e4296466,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-e2b87418-4ab1-480d-ac0c-b4c5e4296466,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-28bc8539-843c-40d1-bec3-2093a69cfd70,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-ab3af4a5-8a91-41e7-879d-2ccb98eed1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-238070e2-c75e-43c8-a7c7-849a6db04815,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-ab3af4a5-8a91-41e7-879d-2ccb98eed1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-238070e2-c75e-43c8-a7c7-849a6db04815,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-ab3af4a5-8a91-41e7-879d-2ccb98eed1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-238070e2-c75e-43c8-a7c7-849a6db04815,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-ab3af4a5-8a91-41e7-879d-2ccb98eed1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-238070e2-c75e-43c8-a7c7-849a6db04815,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46607,DS-a559436f-fa97-4fab-87ca-0a7e0b649db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-95123adc-a8b6-4ce9-92f5-bda9ab83b247,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-95123adc-a8b6-4ce9-92f5-bda9ab83b247,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-a559436f-fa97-4fab-87ca-0a7e0b649db9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46607,DS-a559436f-fa97-4fab-87ca-0a7e0b649db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-95123adc-a8b6-4ce9-92f5-bda9ab83b247,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-95123adc-a8b6-4ce9-92f5-bda9ab83b247,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-a559436f-fa97-4fab-87ca-0a7e0b649db9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44463,DS-76ecc80e-3016-413e-ad0a-7d3540812a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-297a3918-3236-4b59-a6e4-6d21232bcb7c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-297a3918-3236-4b59-a6e4-6d21232bcb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-76ecc80e-3016-413e-ad0a-7d3540812a8d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44463,DS-76ecc80e-3016-413e-ad0a-7d3540812a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-297a3918-3236-4b59-a6e4-6d21232bcb7c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-297a3918-3236-4b59-a6e4-6d21232bcb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-76ecc80e-3016-413e-ad0a-7d3540812a8d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-a0acf096-aae3-4ac6-a3fc-5e20e8971576,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-997e76bb-5e2e-49ad-9aa7-931871800584,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39459,DS-997e76bb-5e2e-49ad-9aa7-931871800584,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-a0acf096-aae3-4ac6-a3fc-5e20e8971576,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-a0acf096-aae3-4ac6-a3fc-5e20e8971576,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-997e76bb-5e2e-49ad-9aa7-931871800584,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39459,DS-997e76bb-5e2e-49ad-9aa7-931871800584,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-a0acf096-aae3-4ac6-a3fc-5e20e8971576,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-b716f9c4-e8ca-46bb-9166-4db521b6a172,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-4de5b5b1-078b-49a2-acbc-a6666c44338a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37916,DS-4de5b5b1-078b-49a2-acbc-a6666c44338a,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-b716f9c4-e8ca-46bb-9166-4db521b6a172,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-b716f9c4-e8ca-46bb-9166-4db521b6a172,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-4de5b5b1-078b-49a2-acbc-a6666c44338a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37916,DS-4de5b5b1-078b-49a2-acbc-a6666c44338a,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-b716f9c4-e8ca-46bb-9166-4db521b6a172,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41524,DS-6eb30856-5142-4241-91dd-fc783ad40e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-08a83e53-d251-42cc-9cc5-90f8e0d4f6d1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41524,DS-6eb30856-5142-4241-91dd-fc783ad40e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-08a83e53-d251-42cc-9cc5-90f8e0d4f6d1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41524,DS-6eb30856-5142-4241-91dd-fc783ad40e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-08a83e53-d251-42cc-9cc5-90f8e0d4f6d1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41524,DS-6eb30856-5142-4241-91dd-fc783ad40e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-08a83e53-d251-42cc-9cc5-90f8e0d4f6d1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-70cd5f08-aadc-4b03-985e-2f21aa64fd46,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-962a08d4-6e4f-421d-b8cd-b1ca908a4161,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-70cd5f08-aadc-4b03-985e-2f21aa64fd46,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-962a08d4-6e4f-421d-b8cd-b1ca908a4161,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-70cd5f08-aadc-4b03-985e-2f21aa64fd46,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-962a08d4-6e4f-421d-b8cd-b1ca908a4161,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-70cd5f08-aadc-4b03-985e-2f21aa64fd46,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-962a08d4-6e4f-421d-b8cd-b1ca908a4161,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32790,DS-bceaf5ca-975f-4ec0-8cb5-8eca5ac23aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-55046ea2-4b61-4a71-bae2-14e4b5332c81,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32790,DS-bceaf5ca-975f-4ec0-8cb5-8eca5ac23aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-55046ea2-4b61-4a71-bae2-14e4b5332c81,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32790,DS-bceaf5ca-975f-4ec0-8cb5-8eca5ac23aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-55046ea2-4b61-4a71-bae2-14e4b5332c81,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32790,DS-bceaf5ca-975f-4ec0-8cb5-8eca5ac23aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-55046ea2-4b61-4a71-bae2-14e4b5332c81,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-d93b9a8f-cd2d-4086-96a8-bbd8800bab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-8f46536a-fd12-432f-a434-fe8d59818f47,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37927,DS-8f46536a-fd12-432f-a434-fe8d59818f47,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-d93b9a8f-cd2d-4086-96a8-bbd8800bab4c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-d93b9a8f-cd2d-4086-96a8-bbd8800bab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-8f46536a-fd12-432f-a434-fe8d59818f47,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37927,DS-8f46536a-fd12-432f-a434-fe8d59818f47,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-d93b9a8f-cd2d-4086-96a8-bbd8800bab4c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34221,DS-d17d235a-dd41-4c70-b902-a4d952b7b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-d5315f40-b9e5-4552-9b68-9b322208cbb6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34221,DS-d17d235a-dd41-4c70-b902-a4d952b7b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-d5315f40-b9e5-4552-9b68-9b322208cbb6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34221,DS-d17d235a-dd41-4c70-b902-a4d952b7b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-d5315f40-b9e5-4552-9b68-9b322208cbb6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34221,DS-d17d235a-dd41-4c70-b902-a4d952b7b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-d5315f40-b9e5-4552-9b68-9b322208cbb6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-815c187d-dd93-4a57-a137-a38454dfdc28,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-fb3cb6a3-3c6b-46ce-bda4-ffbce1cf7e6d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-815c187d-dd93-4a57-a137-a38454dfdc28,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-fb3cb6a3-3c6b-46ce-bda4-ffbce1cf7e6d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-815c187d-dd93-4a57-a137-a38454dfdc28,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-fb3cb6a3-3c6b-46ce-bda4-ffbce1cf7e6d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34917,DS-815c187d-dd93-4a57-a137-a38454dfdc28,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-fb3cb6a3-3c6b-46ce-bda4-ffbce1cf7e6d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43680,DS-b7fbdfb7-8edf-48d3-b102-ad7acb005fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-fcd60654-2eb5-461e-b707-2289e39556a6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43680,DS-b7fbdfb7-8edf-48d3-b102-ad7acb005fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-fcd60654-2eb5-461e-b707-2289e39556a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43680,DS-b7fbdfb7-8edf-48d3-b102-ad7acb005fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-fcd60654-2eb5-461e-b707-2289e39556a6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43680,DS-b7fbdfb7-8edf-48d3-b102-ad7acb005fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-fcd60654-2eb5-461e-b707-2289e39556a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41051,DS-a58ebac3-f82a-4044-9b46-5f85983990b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-42880870-a7bb-4c92-a299-71e5782053ac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-42880870-a7bb-4c92-a299-71e5782053ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-a58ebac3-f82a-4044-9b46-5f85983990b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41051,DS-a58ebac3-f82a-4044-9b46-5f85983990b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-42880870-a7bb-4c92-a299-71e5782053ac,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-42880870-a7bb-4c92-a299-71e5782053ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-a58ebac3-f82a-4044-9b46-5f85983990b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-3e4386df-da43-474b-8306-834ceff56bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-ca351e84-f985-4a76-8b19-66a13e392300,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40525,DS-ca351e84-f985-4a76-8b19-66a13e392300,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-3e4386df-da43-474b-8306-834ceff56bc6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-3e4386df-da43-474b-8306-834ceff56bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-ca351e84-f985-4a76-8b19-66a13e392300,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40525,DS-ca351e84-f985-4a76-8b19-66a13e392300,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-3e4386df-da43-474b-8306-834ceff56bc6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-b899e7fe-b361-44b9-9aa6-f3683e909b71,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-0e8053e3-7061-416d-96d9-bed967267e47,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32857,DS-0e8053e3-7061-416d-96d9-bed967267e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-b899e7fe-b361-44b9-9aa6-f3683e909b71,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-b899e7fe-b361-44b9-9aa6-f3683e909b71,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-0e8053e3-7061-416d-96d9-bed967267e47,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32857,DS-0e8053e3-7061-416d-96d9-bed967267e47,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-b899e7fe-b361-44b9-9aa6-f3683e909b71,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-f5451f0f-7c50-4890-8676-563520be7a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-d41d8d83-33a2-4d25-95dc-8f212765a28d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-f5451f0f-7c50-4890-8676-563520be7a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-d41d8d83-33a2-4d25-95dc-8f212765a28d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-f5451f0f-7c50-4890-8676-563520be7a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-d41d8d83-33a2-4d25-95dc-8f212765a28d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-f5451f0f-7c50-4890-8676-563520be7a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-d41d8d83-33a2-4d25-95dc-8f212765a28d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-161e4f76-42de-40ef-bcf0-530021825ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-126f4d8d-eb48-4e88-855b-8d00f923e90e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-126f4d8d-eb48-4e88-855b-8d00f923e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-161e4f76-42de-40ef-bcf0-530021825ce0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-161e4f76-42de-40ef-bcf0-530021825ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-126f4d8d-eb48-4e88-855b-8d00f923e90e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-126f4d8d-eb48-4e88-855b-8d00f923e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-161e4f76-42de-40ef-bcf0-530021825ce0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-4eff83c6-d5d4-4a10-a577-c5df12eb8d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-5e592f96-3817-4b8e-ad41-979b357b14e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-4eff83c6-d5d4-4a10-a577-c5df12eb8d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-5e592f96-3817-4b8e-ad41-979b357b14e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-4eff83c6-d5d4-4a10-a577-c5df12eb8d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-5e592f96-3817-4b8e-ad41-979b357b14e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-4eff83c6-d5d4-4a10-a577-c5df12eb8d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-5e592f96-3817-4b8e-ad41-979b357b14e5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35083,DS-cb3723bb-658f-486d-97e0-81cb48e10685,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-83c48403-6fc7-4fcc-bb29-43a1f4bf79ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-83c48403-6fc7-4fcc-bb29-43a1f4bf79ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-cb3723bb-658f-486d-97e0-81cb48e10685,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35083,DS-cb3723bb-658f-486d-97e0-81cb48e10685,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-83c48403-6fc7-4fcc-bb29-43a1f4bf79ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-83c48403-6fc7-4fcc-bb29-43a1f4bf79ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-cb3723bb-658f-486d-97e0-81cb48e10685,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41783,DS-4dca3a68-7d75-4909-a599-a50be6e31001,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-ea1fc31c-5325-45ef-ac28-402289eb940c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41783,DS-4dca3a68-7d75-4909-a599-a50be6e31001,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-ea1fc31c-5325-45ef-ac28-402289eb940c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41783,DS-4dca3a68-7d75-4909-a599-a50be6e31001,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-ea1fc31c-5325-45ef-ac28-402289eb940c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41783,DS-4dca3a68-7d75-4909-a599-a50be6e31001,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-ea1fc31c-5325-45ef-ac28-402289eb940c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-d4b83a15-931b-4bbb-a69a-3c6099ab93c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-a8e607bf-9e95-4b9e-8b5f-2ecff1f347fb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-d4b83a15-931b-4bbb-a69a-3c6099ab93c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-a8e607bf-9e95-4b9e-8b5f-2ecff1f347fb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-d4b83a15-931b-4bbb-a69a-3c6099ab93c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-a8e607bf-9e95-4b9e-8b5f-2ecff1f347fb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-d4b83a15-931b-4bbb-a69a-3c6099ab93c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-a8e607bf-9e95-4b9e-8b5f-2ecff1f347fb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-dee7651a-f223-4a8b-bf10-cb876a11d4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-9fde3ac0-4260-4a4d-a9d5-5dad0e3ee435,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-dee7651a-f223-4a8b-bf10-cb876a11d4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-9fde3ac0-4260-4a4d-a9d5-5dad0e3ee435,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-dee7651a-f223-4a8b-bf10-cb876a11d4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-9fde3ac0-4260-4a4d-a9d5-5dad0e3ee435,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-dee7651a-f223-4a8b-bf10-cb876a11d4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-9fde3ac0-4260-4a4d-a9d5-5dad0e3ee435,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-6b6f890a-f83b-4910-976d-1ceca1afc836,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b9ce0bcc-f9cf-4438-9d95-e421b8cf335e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-6b6f890a-f83b-4910-976d-1ceca1afc836,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b9ce0bcc-f9cf-4438-9d95-e421b8cf335e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-6b6f890a-f83b-4910-976d-1ceca1afc836,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b9ce0bcc-f9cf-4438-9d95-e421b8cf335e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-6b6f890a-f83b-4910-976d-1ceca1afc836,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b9ce0bcc-f9cf-4438-9d95-e421b8cf335e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-4f1ef802-18de-4dbb-b7a1-c95bb1885da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-55343b8a-8b0c-4554-81fc-1f2f72ef8830,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42838,DS-55343b8a-8b0c-4554-81fc-1f2f72ef8830,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-4f1ef802-18de-4dbb-b7a1-c95bb1885da8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-4f1ef802-18de-4dbb-b7a1-c95bb1885da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-55343b8a-8b0c-4554-81fc-1f2f72ef8830,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42838,DS-55343b8a-8b0c-4554-81fc-1f2f72ef8830,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-4f1ef802-18de-4dbb-b7a1-c95bb1885da8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45679,DS-4aff68dc-3c4c-4555-a41c-d0cb16131a25,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-6ba7bb6b-3de5-44fc-ae9c-ed2efc8b3075,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45679,DS-4aff68dc-3c4c-4555-a41c-d0cb16131a25,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-6ba7bb6b-3de5-44fc-ae9c-ed2efc8b3075,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45679,DS-4aff68dc-3c4c-4555-a41c-d0cb16131a25,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-6ba7bb6b-3de5-44fc-ae9c-ed2efc8b3075,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45679,DS-4aff68dc-3c4c-4555-a41c-d0cb16131a25,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-6ba7bb6b-3de5-44fc-ae9c-ed2efc8b3075,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38902,DS-85ee38b8-9903-459a-91b7-fd48a560d0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-bea06b9d-1aeb-40b5-87df-d08fcf978acb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-bea06b9d-1aeb-40b5-87df-d08fcf978acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-85ee38b8-9903-459a-91b7-fd48a560d0a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38902,DS-85ee38b8-9903-459a-91b7-fd48a560d0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-bea06b9d-1aeb-40b5-87df-d08fcf978acb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-bea06b9d-1aeb-40b5-87df-d08fcf978acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-85ee38b8-9903-459a-91b7-fd48a560d0a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-24b43be4-3757-4f5f-8cee-ccc117642ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-51d82e88-6c84-45b2-b13c-dfd660a04fe4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-24b43be4-3757-4f5f-8cee-ccc117642ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-51d82e88-6c84-45b2-b13c-dfd660a04fe4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-24b43be4-3757-4f5f-8cee-ccc117642ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-51d82e88-6c84-45b2-b13c-dfd660a04fe4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42182,DS-24b43be4-3757-4f5f-8cee-ccc117642ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-51d82e88-6c84-45b2-b13c-dfd660a04fe4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41972,DS-739a95be-7c1e-4e90-bd05-4370d7479cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-f24a9047-37e1-415b-81a0-c1fdbe8b1fec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41558,DS-f24a9047-37e1-415b-81a0-c1fdbe8b1fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-739a95be-7c1e-4e90-bd05-4370d7479cfc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41972,DS-739a95be-7c1e-4e90-bd05-4370d7479cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-f24a9047-37e1-415b-81a0-c1fdbe8b1fec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41558,DS-f24a9047-37e1-415b-81a0-c1fdbe8b1fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-739a95be-7c1e-4e90-bd05-4370d7479cfc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-21b369cd-6d9a-4ac1-bbc9-ada6bd526641,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-47d41860-d890-4842-8176-47ed9da83718,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-21b369cd-6d9a-4ac1-bbc9-ada6bd526641,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-47d41860-d890-4842-8176-47ed9da83718,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-21b369cd-6d9a-4ac1-bbc9-ada6bd526641,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-47d41860-d890-4842-8176-47ed9da83718,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-21b369cd-6d9a-4ac1-bbc9-ada6bd526641,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-47d41860-d890-4842-8176-47ed9da83718,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestGetFileChecksum#testGetFileChecksum
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35727,DS-c308fe7b-2022-4ada-8bcd-deccc2f77f82,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-72d59a7f-2ebb-43fe-ad56-69386079bb83,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-72d59a7f-2ebb-43fe-ad56-69386079bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-c308fe7b-2022-4ada-8bcd-deccc2f77f82,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35727,DS-c308fe7b-2022-4ada-8bcd-deccc2f77f82,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-72d59a7f-2ebb-43fe-ad56-69386079bb83,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-72d59a7f-2ebb-43fe-ad56-69386079bb83,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-c308fe7b-2022-4ada-8bcd-deccc2f77f82,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:720)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 27 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 6172
