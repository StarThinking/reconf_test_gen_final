reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639879136-172.17.0.4-1593861609587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-c0a39805-459e-4ea5-bf7e-aa7c539650bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-a057014a-ecba-4e75-9af1-2e53779fbedc,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-bc78b705-9ead-4acf-a869-3d97823ef47c,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-bb1c223c-87e1-42c9-84f8-e91c62a6d5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-04ebd995-21fd-4d0f-a8af-5e0ce483513a,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-1201cf4f-ea59-402e-95f1-1ac4c69d417f,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-3b80a103-f157-4f4b-b405-7bc5f3dc9cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-305de9ea-aaad-47dc-ab03-1405d8585342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1639879136-172.17.0.4-1593861609587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-c0a39805-459e-4ea5-bf7e-aa7c539650bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-a057014a-ecba-4e75-9af1-2e53779fbedc,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-bc78b705-9ead-4acf-a869-3d97823ef47c,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-bb1c223c-87e1-42c9-84f8-e91c62a6d5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-04ebd995-21fd-4d0f-a8af-5e0ce483513a,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-1201cf4f-ea59-402e-95f1-1ac4c69d417f,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-3b80a103-f157-4f4b-b405-7bc5f3dc9cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-305de9ea-aaad-47dc-ab03-1405d8585342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202352870-172.17.0.4-1593861733380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36604,DS-5915b5db-dd18-4906-8ec8-355d314e90eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-c96571c0-1660-4a5e-b6a4-194c2f19059e,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-87a5038e-f9c5-41f0-a19d-3b412e39258f,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-fd18cfba-03cf-47f9-a321-f0ca15c38881,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-745a40fc-1a58-4565-828c-8d602ed12f39,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-bb47777e-0d35-4416-b749-bbd82f1c2292,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-6f0e72f9-3fbf-4708-90fd-30c09303d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-9027f38c-e2b9-43c3-963e-b96e44c3f0bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202352870-172.17.0.4-1593861733380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36604,DS-5915b5db-dd18-4906-8ec8-355d314e90eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-c96571c0-1660-4a5e-b6a4-194c2f19059e,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-87a5038e-f9c5-41f0-a19d-3b412e39258f,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-fd18cfba-03cf-47f9-a321-f0ca15c38881,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-745a40fc-1a58-4565-828c-8d602ed12f39,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-bb47777e-0d35-4416-b749-bbd82f1c2292,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-6f0e72f9-3fbf-4708-90fd-30c09303d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-9027f38c-e2b9-43c3-963e-b96e44c3f0bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383979442-172.17.0.4-1593861805401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37995,DS-08e81b47-6fae-4ce9-9570-5e30c353027f,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-d5e253c6-fa50-46a5-ab65-a04f829072c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-2ad9b7c0-8ab0-4b62-aacc-f2bfc4708975,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-75d9d995-99a3-406d-a6b6-a4890497c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-340d8f52-532d-441f-b824-a2b3c993b63d,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-d484eb9f-29c8-4537-816b-86b6b18b4e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-4b6a88ac-25a8-461f-987f-8deddce1251e,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-37f37424-9458-4532-8e9b-c2111a1bb4d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383979442-172.17.0.4-1593861805401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37995,DS-08e81b47-6fae-4ce9-9570-5e30c353027f,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-d5e253c6-fa50-46a5-ab65-a04f829072c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-2ad9b7c0-8ab0-4b62-aacc-f2bfc4708975,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-75d9d995-99a3-406d-a6b6-a4890497c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-340d8f52-532d-441f-b824-a2b3c993b63d,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-d484eb9f-29c8-4537-816b-86b6b18b4e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-4b6a88ac-25a8-461f-987f-8deddce1251e,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-37f37424-9458-4532-8e9b-c2111a1bb4d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878739289-172.17.0.4-1593861995693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-85e68267-cae0-41b8-bb33-dbd9e38be48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-11573895-d522-4e4a-9807-f8c9ab577e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fbf20e86-dbbc-40b2-a059-0dcbcdad0597,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-dd050699-2f86-4663-88a6-5093580715a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-82ae1e11-a604-4751-bed2-3477dc82f6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-baf3d374-c2ec-4a72-b7d1-ce15708901a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-883c448a-9dec-401e-8e70-935d68d9ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-72458380-75c0-4f6d-ba45-43b4c5f2471e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878739289-172.17.0.4-1593861995693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-85e68267-cae0-41b8-bb33-dbd9e38be48a,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-11573895-d522-4e4a-9807-f8c9ab577e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fbf20e86-dbbc-40b2-a059-0dcbcdad0597,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-dd050699-2f86-4663-88a6-5093580715a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-82ae1e11-a604-4751-bed2-3477dc82f6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-baf3d374-c2ec-4a72-b7d1-ce15708901a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-883c448a-9dec-401e-8e70-935d68d9ea75,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-72458380-75c0-4f6d-ba45-43b4c5f2471e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070288051-172.17.0.4-1593862289880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43868,DS-26c73554-db60-47d9-9c22-eec0aa618070,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-af11a784-c874-44ae-afef-6aa13e378eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-c5655a21-d905-47a9-886a-b368d8abb94e,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-e166773f-2e98-4db7-bf93-df6c8d0cfc18,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-6fcd1fa9-9ef2-4643-99b9-8dad4575f140,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-eaf40323-5047-47a5-b2b8-8d2213e805c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-768c7dee-2cd7-4160-b864-3ffa8faac702,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-540a6555-1908-4caf-86cd-b89d3cfc18ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070288051-172.17.0.4-1593862289880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43868,DS-26c73554-db60-47d9-9c22-eec0aa618070,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-af11a784-c874-44ae-afef-6aa13e378eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-c5655a21-d905-47a9-886a-b368d8abb94e,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-e166773f-2e98-4db7-bf93-df6c8d0cfc18,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-6fcd1fa9-9ef2-4643-99b9-8dad4575f140,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-eaf40323-5047-47a5-b2b8-8d2213e805c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-768c7dee-2cd7-4160-b864-3ffa8faac702,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-540a6555-1908-4caf-86cd-b89d3cfc18ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006972234-172.17.0.4-1593862363331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34031,DS-336946a6-2042-40cc-a9a9-89380bac5faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-c568ea53-a694-4401-9823-d62edcd80881,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-7357b40e-bf1a-49d6-be71-dee9aee12afd,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-f8dcb456-e6e9-4f15-a691-ce2c3777a880,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-8b51738b-9fb3-453b-b81e-1b6865b9f43c,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-e8edd2c8-42fb-4045-a15d-5d91c33f5c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-e37b2dad-b2ce-4241-9f2e-8cd3c5267bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-5bf6a1e1-4eb9-4037-9120-727246d5b5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006972234-172.17.0.4-1593862363331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34031,DS-336946a6-2042-40cc-a9a9-89380bac5faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-c568ea53-a694-4401-9823-d62edcd80881,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-7357b40e-bf1a-49d6-be71-dee9aee12afd,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-f8dcb456-e6e9-4f15-a691-ce2c3777a880,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-8b51738b-9fb3-453b-b81e-1b6865b9f43c,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-e8edd2c8-42fb-4045-a15d-5d91c33f5c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-e37b2dad-b2ce-4241-9f2e-8cd3c5267bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-5bf6a1e1-4eb9-4037-9120-727246d5b5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551530799-172.17.0.4-1593862578869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-a3836ef7-392f-404e-a2d4-a4a33ccbabb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-5beb6f89-43b2-4df9-9749-63811545e997,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-7af0832d-0a94-4b4a-ad01-5873b38e6b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-36a6c2fd-067f-4546-858f-01a467516c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-87f401f0-262c-45a4-8a22-42d3e57a2c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-ede174e5-5376-4605-b68e-c2b0f62d1e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-0fb6843e-6344-414b-a6fb-bcdd4dc2e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-c0731457-7ddc-4cae-b005-0d3040f78b66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551530799-172.17.0.4-1593862578869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-a3836ef7-392f-404e-a2d4-a4a33ccbabb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-5beb6f89-43b2-4df9-9749-63811545e997,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-7af0832d-0a94-4b4a-ad01-5873b38e6b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-36a6c2fd-067f-4546-858f-01a467516c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-87f401f0-262c-45a4-8a22-42d3e57a2c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-ede174e5-5376-4605-b68e-c2b0f62d1e80,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-0fb6843e-6344-414b-a6fb-bcdd4dc2e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-c0731457-7ddc-4cae-b005-0d3040f78b66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897724829-172.17.0.4-1593862614628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43727,DS-2243d700-a676-4423-b84d-ad2f4c83b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-b9903ae5-28b1-4218-b26c-39eed1f43314,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-be2ee142-2078-4285-b5f9-fc1989679f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-d8833f6e-b415-42cd-8340-b3633a178233,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-80f734c1-79c0-4761-aa43-8d73e68e8749,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-618b327b-a6fe-4567-90c9-598df47cb982,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-f0b1ed51-4bef-4cca-a295-18feb884e009,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-1f26273c-1735-455e-8f6f-6b71418e4f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897724829-172.17.0.4-1593862614628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43727,DS-2243d700-a676-4423-b84d-ad2f4c83b7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-b9903ae5-28b1-4218-b26c-39eed1f43314,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-be2ee142-2078-4285-b5f9-fc1989679f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-d8833f6e-b415-42cd-8340-b3633a178233,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-80f734c1-79c0-4761-aa43-8d73e68e8749,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-618b327b-a6fe-4567-90c9-598df47cb982,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-f0b1ed51-4bef-4cca-a295-18feb884e009,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-1f26273c-1735-455e-8f6f-6b71418e4f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581161277-172.17.0.4-1593863052401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43401,DS-385cd8cc-3049-439b-9813-9a18db3e3325,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-8336a4df-fc1b-43ca-b1d6-441784e49fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-573d63d0-1c2f-49eb-8fe2-e19e537f2fec,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-9663e80d-ec5d-46af-bcbf-2eca51545126,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-180e73fe-cb77-4c26-9420-ca1e0892af72,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-c4cabc0b-24df-4b1e-ade1-f7dc6f3ac837,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-3aecd7ec-176e-4ca5-b2b2-c93e2d9737f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-4ee40f27-a4f6-4914-a3ed-3ac571884478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581161277-172.17.0.4-1593863052401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43401,DS-385cd8cc-3049-439b-9813-9a18db3e3325,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-8336a4df-fc1b-43ca-b1d6-441784e49fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-573d63d0-1c2f-49eb-8fe2-e19e537f2fec,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-9663e80d-ec5d-46af-bcbf-2eca51545126,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-180e73fe-cb77-4c26-9420-ca1e0892af72,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-c4cabc0b-24df-4b1e-ade1-f7dc6f3ac837,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-3aecd7ec-176e-4ca5-b2b2-c93e2d9737f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-4ee40f27-a4f6-4914-a3ed-3ac571884478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378951708-172.17.0.4-1593863343403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37139,DS-2cabfd95-d138-4ea4-acbd-8abbf47a7440,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-bf341df5-100a-4681-b24f-0c3c5fe87f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-0a50180e-30c0-43e2-92a7-4816b6e1cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-29de0935-e8a3-4ef9-a252-af504efcc670,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-78ed69ba-6f57-4acf-914b-2473e332fdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-33dbf38b-005e-4e63-9923-e86ca20b0bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-36de1b63-aae4-4377-bbd4-6f15d7af7a77,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-9c89e481-5de5-48d7-b97c-2a5ec1fb29dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378951708-172.17.0.4-1593863343403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37139,DS-2cabfd95-d138-4ea4-acbd-8abbf47a7440,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-bf341df5-100a-4681-b24f-0c3c5fe87f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-0a50180e-30c0-43e2-92a7-4816b6e1cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-29de0935-e8a3-4ef9-a252-af504efcc670,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-78ed69ba-6f57-4acf-914b-2473e332fdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-33dbf38b-005e-4e63-9923-e86ca20b0bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-36de1b63-aae4-4377-bbd4-6f15d7af7a77,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-9c89e481-5de5-48d7-b97c-2a5ec1fb29dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766313772-172.17.0.4-1593863537188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44737,DS-f113e7f1-487d-4b91-b11c-ca12e1bbfc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-ff223da0-84af-43ae-9320-b4b431b5e860,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-d0316b07-66a3-4a39-90ac-c00604f22137,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-5433a751-5205-4bc3-82be-bd747e15b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-d94cd323-17e8-4f2e-82ee-09aac96bf265,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-964b3aa5-1658-46bb-a4d5-e86bba3a7f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-9549416b-6da1-433c-8252-ec5bd180a230,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-07395f1a-647f-4d5b-943e-5502ad78ad54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766313772-172.17.0.4-1593863537188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44737,DS-f113e7f1-487d-4b91-b11c-ca12e1bbfc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-ff223da0-84af-43ae-9320-b4b431b5e860,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-d0316b07-66a3-4a39-90ac-c00604f22137,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-5433a751-5205-4bc3-82be-bd747e15b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-d94cd323-17e8-4f2e-82ee-09aac96bf265,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-964b3aa5-1658-46bb-a4d5-e86bba3a7f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-9549416b-6da1-433c-8252-ec5bd180a230,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-07395f1a-647f-4d5b-943e-5502ad78ad54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212401524-172.17.0.4-1593863720164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34969,DS-9363c144-27f8-491c-ad2e-6ade538c1c36,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-05f9cc5b-6167-45fa-b4c7-171570ac1ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-381fd181-2a83-41df-820f-6d0b7a77be11,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-0fb09fb1-9bfa-4358-a085-202188d89499,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-93a930ad-8be2-40c4-9c15-b3d6544fb17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-429c8928-cfa7-419f-bf62-40a94e1f7feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-9456b76e-7eaa-415c-9e68-2d7240799200,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-aa17826c-98ca-47ff-851c-9888913f7049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-212401524-172.17.0.4-1593863720164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34969,DS-9363c144-27f8-491c-ad2e-6ade538c1c36,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-05f9cc5b-6167-45fa-b4c7-171570ac1ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-381fd181-2a83-41df-820f-6d0b7a77be11,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-0fb09fb1-9bfa-4358-a085-202188d89499,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-93a930ad-8be2-40c4-9c15-b3d6544fb17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-429c8928-cfa7-419f-bf62-40a94e1f7feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-9456b76e-7eaa-415c-9e68-2d7240799200,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-aa17826c-98ca-47ff-851c-9888913f7049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524343820-172.17.0.4-1593864952239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-21ae4ea6-b002-479f-9db7-9600e36af822,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-88834906-81c9-4c27-81fb-4f54ecd31ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-9a82ce85-e379-46b9-a5b6-80d55fccc953,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-24706f1e-08e2-44aa-a3d6-3eab2d45d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-571bb482-31a4-4fa9-a671-a2c818ae4ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-9b03f941-2bb8-45a3-a8f8-d9e5c5cdf8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-22f7fb0b-bf1d-42fa-8a9b-4da704eeaad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-7d47fa1d-53e1-44af-883a-468ee8f224aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524343820-172.17.0.4-1593864952239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33593,DS-21ae4ea6-b002-479f-9db7-9600e36af822,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-88834906-81c9-4c27-81fb-4f54ecd31ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-9a82ce85-e379-46b9-a5b6-80d55fccc953,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-24706f1e-08e2-44aa-a3d6-3eab2d45d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-571bb482-31a4-4fa9-a671-a2c818ae4ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-9b03f941-2bb8-45a3-a8f8-d9e5c5cdf8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-22f7fb0b-bf1d-42fa-8a9b-4da704eeaad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-7d47fa1d-53e1-44af-883a-468ee8f224aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182147956-172.17.0.4-1593865183049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33756,DS-76e17ae8-38f7-4b5a-8cdd-9baf477aac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-e41edfaf-1eb7-466b-a5e7-3fc86bcae6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-4074be60-a5f7-4a96-8305-405babfd7b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-3ade455b-d622-4608-a6f9-c86bf195caa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-c5ea8b63-f1ee-44ea-90e1-e7ab53811071,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-eef33b16-62a2-4711-8e3d-029737cc718a,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-d39f6812-db66-4a81-bd01-d89458445c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-40e95799-9e24-4ffa-aa23-899dcd93818e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182147956-172.17.0.4-1593865183049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33756,DS-76e17ae8-38f7-4b5a-8cdd-9baf477aac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-e41edfaf-1eb7-466b-a5e7-3fc86bcae6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-4074be60-a5f7-4a96-8305-405babfd7b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-3ade455b-d622-4608-a6f9-c86bf195caa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-c5ea8b63-f1ee-44ea-90e1-e7ab53811071,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-eef33b16-62a2-4711-8e3d-029737cc718a,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-d39f6812-db66-4a81-bd01-d89458445c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-40e95799-9e24-4ffa-aa23-899dcd93818e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062212358-172.17.0.4-1593865292792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35147,DS-1e012f26-3dfe-4f71-95a6-ece0307fae96,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-8da9e677-6b71-45ba-9fc4-c9b1062566b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-a163670c-6872-4334-95c6-459017578aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-9856a89b-c421-4df9-a583-9e9548bbe333,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-179ad8f8-248b-4d01-a318-0862d43c3cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-c636481f-ddb7-44bb-acbf-6460e8b21675,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-ffa38db2-0ee0-43d5-b5a8-c0dc3ffd4abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-1a35ddce-481f-44f5-ad1a-45d3328de1dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062212358-172.17.0.4-1593865292792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35147,DS-1e012f26-3dfe-4f71-95a6-ece0307fae96,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-8da9e677-6b71-45ba-9fc4-c9b1062566b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-a163670c-6872-4334-95c6-459017578aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-9856a89b-c421-4df9-a583-9e9548bbe333,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-179ad8f8-248b-4d01-a318-0862d43c3cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-c636481f-ddb7-44bb-acbf-6460e8b21675,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-ffa38db2-0ee0-43d5-b5a8-c0dc3ffd4abe,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-1a35ddce-481f-44f5-ad1a-45d3328de1dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119260876-172.17.0.4-1593865323631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-d5951e9e-690b-45da-8665-7d2560c3158c,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-0e01934f-f4f9-46cf-9099-90edf9dc863f,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-0efb636a-0b02-4b3c-9b0f-bbe88e134f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-f88cae08-84e8-497c-9187-2e47809c8546,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-3577122d-ad17-4cb7-8a85-459e5e06e323,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-dc79a2bb-f015-460e-b9e8-82f3c2e077d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-a08bc23e-1151-492f-8d4e-4510d54e3a56,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-8df35feb-67d8-407c-a5b7-49691e4b45b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119260876-172.17.0.4-1593865323631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41325,DS-d5951e9e-690b-45da-8665-7d2560c3158c,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-0e01934f-f4f9-46cf-9099-90edf9dc863f,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-0efb636a-0b02-4b3c-9b0f-bbe88e134f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-f88cae08-84e8-497c-9187-2e47809c8546,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-3577122d-ad17-4cb7-8a85-459e5e06e323,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-dc79a2bb-f015-460e-b9e8-82f3c2e077d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-a08bc23e-1151-492f-8d4e-4510d54e3a56,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-8df35feb-67d8-407c-a5b7-49691e4b45b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601385077-172.17.0.4-1593865397853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34749,DS-dcbcb37e-59d1-48af-9b3d-0e9447f2e383,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-98d02057-be9b-41c2-bea1-22feeb435dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-93c5265b-60c1-4d04-859a-2bed9ab6317e,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-bbc656e3-45f3-4a86-a12d-965d53691b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-b2bb0c27-fc1e-4858-b5cd-d83e0f253c59,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-0cb9536b-2bdf-4d21-8828-637bae95a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-736f7852-6615-41ba-8556-8b865d16128d,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-6d231e4a-c245-4191-b0db-38b27f37015a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601385077-172.17.0.4-1593865397853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34749,DS-dcbcb37e-59d1-48af-9b3d-0e9447f2e383,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-98d02057-be9b-41c2-bea1-22feeb435dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-93c5265b-60c1-4d04-859a-2bed9ab6317e,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-bbc656e3-45f3-4a86-a12d-965d53691b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-b2bb0c27-fc1e-4858-b5cd-d83e0f253c59,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-0cb9536b-2bdf-4d21-8828-637bae95a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-736f7852-6615-41ba-8556-8b865d16128d,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-6d231e4a-c245-4191-b0db-38b27f37015a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549165469-172.17.0.4-1593865511765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37713,DS-1440fee4-375b-45cb-9547-a9665201e0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-854f5c7b-1804-4fd4-bdca-fc8fa5089363,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-8dab5285-1a90-48ed-85a4-05dd8b042d40,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-14f303a4-c0a5-42eb-9f08-76de14e8d5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-8b35e8d7-3f07-4397-98ac-226de86dc3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-b944038e-ce6e-4e09-b4a4-92ca42a6fa75,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-a18929fc-910a-4b69-9b6e-2e816258cafb,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-fdfdd1bc-7910-4174-9631-9e102fcb323d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549165469-172.17.0.4-1593865511765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37713,DS-1440fee4-375b-45cb-9547-a9665201e0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-854f5c7b-1804-4fd4-bdca-fc8fa5089363,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-8dab5285-1a90-48ed-85a4-05dd8b042d40,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-14f303a4-c0a5-42eb-9f08-76de14e8d5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-8b35e8d7-3f07-4397-98ac-226de86dc3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-b944038e-ce6e-4e09-b4a4-92ca42a6fa75,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-a18929fc-910a-4b69-9b6e-2e816258cafb,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-fdfdd1bc-7910-4174-9631-9e102fcb323d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446844540-172.17.0.4-1593867007369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43702,DS-daf0460e-f9ee-417b-ae0b-ed2a55c21e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-9318c65b-378f-4ad8-81a6-1eba614b63cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-bb58d621-365e-42e5-95a1-d6fd56d21de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-4442d813-e0e9-4d72-9028-2b6d508de587,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-70c69bb0-9f93-46ee-9c1d-3782ba2925fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-9a36d351-efcc-4766-9da7-51802226828b,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-57d28f1d-43a7-4877-9747-a2d413e9fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-ace9169d-74fa-435c-abff-3c6c3d758e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446844540-172.17.0.4-1593867007369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43702,DS-daf0460e-f9ee-417b-ae0b-ed2a55c21e47,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-9318c65b-378f-4ad8-81a6-1eba614b63cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-bb58d621-365e-42e5-95a1-d6fd56d21de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-4442d813-e0e9-4d72-9028-2b6d508de587,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-70c69bb0-9f93-46ee-9c1d-3782ba2925fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-9a36d351-efcc-4766-9da7-51802226828b,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-57d28f1d-43a7-4877-9747-a2d413e9fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-ace9169d-74fa-435c-abff-3c6c3d758e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5618
