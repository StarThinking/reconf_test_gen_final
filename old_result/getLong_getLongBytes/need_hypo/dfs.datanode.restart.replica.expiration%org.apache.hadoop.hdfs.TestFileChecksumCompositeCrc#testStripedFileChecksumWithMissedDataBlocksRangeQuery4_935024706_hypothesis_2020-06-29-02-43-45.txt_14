reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845814060-172.17.0.2-1593398748403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-71b9d1ed-3144-4817-b1d3-8e4694f89b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-4ad8358c-525d-4aa2-8e99-cd1ef73e9698,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-1becb133-18fc-4f13-9250-b667d7740d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-4de9417e-f478-4ce5-891d-41160cb469e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-80a4e296-0453-4446-843e-ef4a8ace4805,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-7caaa1f9-9696-43b6-bd75-0cda4c22d358,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-a36bdeb7-be5c-4745-bc07-4565a04ad700,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-f2d9f1ea-18ad-443f-ba38-2b6c3d636cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845814060-172.17.0.2-1593398748403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-71b9d1ed-3144-4817-b1d3-8e4694f89b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-4ad8358c-525d-4aa2-8e99-cd1ef73e9698,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-1becb133-18fc-4f13-9250-b667d7740d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-4de9417e-f478-4ce5-891d-41160cb469e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-80a4e296-0453-4446-843e-ef4a8ace4805,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-7caaa1f9-9696-43b6-bd75-0cda4c22d358,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-a36bdeb7-be5c-4745-bc07-4565a04ad700,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-f2d9f1ea-18ad-443f-ba38-2b6c3d636cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428584316-172.17.0.2-1593398786865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-37c8d0f8-c3ea-4443-8c84-2f5794118085,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-30eba9f3-142d-438e-b06b-36abe935689a,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-32eb31b5-f1b5-4de8-bbd7-c3c729d0c542,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-b0235be3-76c7-4488-8ee8-1b3724ee886f,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-b9efe105-ff81-473a-aff1-29c55b6d34ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-ede28024-69e3-487b-922c-3403a4cdf8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-e4b6086e-93da-4a8a-8b91-c2db2ebe470e,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-0d28068c-4941-47e2-95d2-79afcb52c484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428584316-172.17.0.2-1593398786865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-37c8d0f8-c3ea-4443-8c84-2f5794118085,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-30eba9f3-142d-438e-b06b-36abe935689a,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-32eb31b5-f1b5-4de8-bbd7-c3c729d0c542,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-b0235be3-76c7-4488-8ee8-1b3724ee886f,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-b9efe105-ff81-473a-aff1-29c55b6d34ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-ede28024-69e3-487b-922c-3403a4cdf8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-e4b6086e-93da-4a8a-8b91-c2db2ebe470e,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-0d28068c-4941-47e2-95d2-79afcb52c484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90758075-172.17.0.2-1593398967786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35140,DS-0b997253-a462-4286-af5a-d30c1ac7ff4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-eb01caa6-2129-4342-8117-f7bd9b1555b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-8d90965f-6fcd-48b0-a9fe-a092ce984383,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-de355e7e-0c1f-4a47-af4d-3b184e978ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-766c6e24-923f-448b-ac33-f734b249c8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-873b934b-33df-46ca-80fd-6120feb6879e,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-352a5fd1-b90e-472e-bdcd-df0d6d1a4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-fc3f9d03-2fa4-439e-9093-3cb8738cd08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90758075-172.17.0.2-1593398967786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35140,DS-0b997253-a462-4286-af5a-d30c1ac7ff4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-eb01caa6-2129-4342-8117-f7bd9b1555b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-8d90965f-6fcd-48b0-a9fe-a092ce984383,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-de355e7e-0c1f-4a47-af4d-3b184e978ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-766c6e24-923f-448b-ac33-f734b249c8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-873b934b-33df-46ca-80fd-6120feb6879e,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-352a5fd1-b90e-472e-bdcd-df0d6d1a4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-fc3f9d03-2fa4-439e-9093-3cb8738cd08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775732304-172.17.0.2-1593399518404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46854,DS-19561bc9-e7ea-43b6-b9ae-d0200c19ccbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-ad9243da-36bc-43c0-befd-15756fd44449,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-72a6cbbf-ceee-40a1-bd3b-4573aef644f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-b4859be0-c59c-4281-a45c-fffd48b4808e,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-978f4316-7403-4dee-97fd-137ecd40193e,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-5f2696eb-b109-4a40-97c3-b684dc9fbf99,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-a27b34b1-b117-4d0e-8daa-99209d10a295,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-817d4244-264d-4a35-93c5-cf1182ffcfe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775732304-172.17.0.2-1593399518404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46854,DS-19561bc9-e7ea-43b6-b9ae-d0200c19ccbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-ad9243da-36bc-43c0-befd-15756fd44449,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-72a6cbbf-ceee-40a1-bd3b-4573aef644f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-b4859be0-c59c-4281-a45c-fffd48b4808e,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-978f4316-7403-4dee-97fd-137ecd40193e,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-5f2696eb-b109-4a40-97c3-b684dc9fbf99,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-a27b34b1-b117-4d0e-8daa-99209d10a295,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-817d4244-264d-4a35-93c5-cf1182ffcfe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223714228-172.17.0.2-1593399748498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-db17b56e-57b7-48d8-aad5-cafdc53b09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-a4e59a53-eec8-4b61-917b-cc0c86118488,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-3eb3ade1-9212-43ce-a162-bc01e11d5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-3e006205-56ab-42fb-a56b-7272327627cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-a7860a52-ea0d-4d7b-bef7-6a50d7d3ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-b6f36f2e-c9ae-49ff-ab5c-5775a58f420d,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-007a999b-b442-4778-9ba6-81d3bfad3e43,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-919ae852-b89f-4a4d-9649-f4d64911e620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223714228-172.17.0.2-1593399748498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45305,DS-db17b56e-57b7-48d8-aad5-cafdc53b09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-a4e59a53-eec8-4b61-917b-cc0c86118488,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-3eb3ade1-9212-43ce-a162-bc01e11d5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-3e006205-56ab-42fb-a56b-7272327627cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-a7860a52-ea0d-4d7b-bef7-6a50d7d3ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-b6f36f2e-c9ae-49ff-ab5c-5775a58f420d,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-007a999b-b442-4778-9ba6-81d3bfad3e43,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-919ae852-b89f-4a4d-9649-f4d64911e620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542014656-172.17.0.2-1593400236010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-28e324e7-2339-4b66-bac8-36fecd354875,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-7539b2b3-eb32-4c21-93ce-d1633913adb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-93d9db11-0f7b-4c68-9b2f-8d9c70bb0d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-4d7f68cd-59bd-493e-80f1-94d38c147b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-1be2f2c7-58b8-42f7-9c36-75a8d7e4b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-5173f1c7-9983-49fd-afe0-a6267c989336,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-79aee9a6-a220-4b0f-bef1-0991a051eae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-cc6a74d7-1ea8-4af2-be8c-83f129f14ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542014656-172.17.0.2-1593400236010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45573,DS-28e324e7-2339-4b66-bac8-36fecd354875,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-7539b2b3-eb32-4c21-93ce-d1633913adb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-93d9db11-0f7b-4c68-9b2f-8d9c70bb0d79,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-4d7f68cd-59bd-493e-80f1-94d38c147b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-1be2f2c7-58b8-42f7-9c36-75a8d7e4b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-5173f1c7-9983-49fd-afe0-a6267c989336,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-79aee9a6-a220-4b0f-bef1-0991a051eae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-cc6a74d7-1ea8-4af2-be8c-83f129f14ccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609624623-172.17.0.2-1593400379009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-0cbb8fe8-a918-424f-9be1-fd875a096d74,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-2b8f5519-c655-4061-9495-15aca797e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-0dc4aa04-5cd3-4223-a9f3-762b22fc878d,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-116d4e1b-eb4d-4136-aa90-804580d68c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-10294e0d-2a49-4525-8ac2-c5da7e80fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-28ee92d7-1574-431a-9624-3cac738999af,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-560c8a14-c0c8-4153-80f5-265b631920a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-bfe87ad8-539e-4055-a31c-dc3a0d1bfbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609624623-172.17.0.2-1593400379009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-0cbb8fe8-a918-424f-9be1-fd875a096d74,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-2b8f5519-c655-4061-9495-15aca797e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-0dc4aa04-5cd3-4223-a9f3-762b22fc878d,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-116d4e1b-eb4d-4136-aa90-804580d68c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-10294e0d-2a49-4525-8ac2-c5da7e80fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-28ee92d7-1574-431a-9624-3cac738999af,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-560c8a14-c0c8-4153-80f5-265b631920a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-bfe87ad8-539e-4055-a31c-dc3a0d1bfbb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510479754-172.17.0.2-1593400413148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44189,DS-d826d5b9-c78f-4ad0-a79d-1a9dfb06afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-777a2d00-e868-471b-b994-d2222617c1de,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-1394fcd8-fe32-4fab-bf80-f7168abdcf35,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-fa7ed48a-88f9-46d7-a990-7c8f1daef4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-b845d7c3-19b8-4646-8be9-1ff19f4a981d,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-b849f962-ab6d-4b49-82a6-70a49bbd98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-f3e972e5-0bdc-4734-8fa5-2b6c23941680,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-6b5ce0f8-0b48-48cb-9746-593c1b3726d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510479754-172.17.0.2-1593400413148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44189,DS-d826d5b9-c78f-4ad0-a79d-1a9dfb06afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-777a2d00-e868-471b-b994-d2222617c1de,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-1394fcd8-fe32-4fab-bf80-f7168abdcf35,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-fa7ed48a-88f9-46d7-a990-7c8f1daef4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-b845d7c3-19b8-4646-8be9-1ff19f4a981d,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-b849f962-ab6d-4b49-82a6-70a49bbd98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-f3e972e5-0bdc-4734-8fa5-2b6c23941680,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-6b5ce0f8-0b48-48cb-9746-593c1b3726d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408512382-172.17.0.2-1593400988615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-0a1061d0-1998-4717-9206-dda769d6ab99,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-4541906b-231c-4cff-854d-c20ef4ce18bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-bf5849af-5630-47f5-967c-67f8fe342833,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-e194b629-52da-4030-b05e-6f58a2669345,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-3327f7da-7635-4301-840e-813c3b4cd9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-97bfb941-e637-4078-89ca-187ec5f1ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-4e9d0453-8a1a-4aa5-a1dc-b4f95d0ec3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-9245dd70-684f-4efd-bb52-4c3f9d669566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408512382-172.17.0.2-1593400988615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-0a1061d0-1998-4717-9206-dda769d6ab99,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-4541906b-231c-4cff-854d-c20ef4ce18bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-bf5849af-5630-47f5-967c-67f8fe342833,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-e194b629-52da-4030-b05e-6f58a2669345,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-3327f7da-7635-4301-840e-813c3b4cd9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-97bfb941-e637-4078-89ca-187ec5f1ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-4e9d0453-8a1a-4aa5-a1dc-b4f95d0ec3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-9245dd70-684f-4efd-bb52-4c3f9d669566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174036341-172.17.0.2-1593401566379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35447,DS-e242caf1-3683-411c-bccf-59dd30453dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-734d4f4f-41c6-4a3d-ae2d-c617f0fb033f,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-a191a245-305b-4d5c-8dd6-4e2151b8e7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-ffb338bc-233d-4372-aa90-72403a7f9b08,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-4624abcf-0026-4421-915d-c3d5042a2a88,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-b61cf7c4-60bd-42c6-987d-02154a97f421,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-8d287eac-4ff2-4ccd-9362-ebe73e0423ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-8211e862-d901-4a55-8248-bedf70031d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174036341-172.17.0.2-1593401566379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35447,DS-e242caf1-3683-411c-bccf-59dd30453dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-734d4f4f-41c6-4a3d-ae2d-c617f0fb033f,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-a191a245-305b-4d5c-8dd6-4e2151b8e7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-ffb338bc-233d-4372-aa90-72403a7f9b08,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-4624abcf-0026-4421-915d-c3d5042a2a88,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-b61cf7c4-60bd-42c6-987d-02154a97f421,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-8d287eac-4ff2-4ccd-9362-ebe73e0423ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-8211e862-d901-4a55-8248-bedf70031d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771963392-172.17.0.2-1593402021957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45170,DS-e940170f-4e04-4345-b802-2216d37d94b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-9f8870c0-99fb-4bbf-a90a-48ecbe63a9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-b0c8bb39-62dd-4476-865f-7eb9871d456a,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-fa00e37b-f3b6-4a83-83cd-8ec6a4005508,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-99df02b9-099a-4548-929a-d536ec391572,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-2d39d184-0f39-4184-8f13-8d653b1b8644,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-9ae9bf76-8fb6-49e6-96ba-0904ccbf9832,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-1c375a31-c70c-4df0-86bc-b8ce08aed244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771963392-172.17.0.2-1593402021957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45170,DS-e940170f-4e04-4345-b802-2216d37d94b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-9f8870c0-99fb-4bbf-a90a-48ecbe63a9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-b0c8bb39-62dd-4476-865f-7eb9871d456a,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-fa00e37b-f3b6-4a83-83cd-8ec6a4005508,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-99df02b9-099a-4548-929a-d536ec391572,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-2d39d184-0f39-4184-8f13-8d653b1b8644,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-9ae9bf76-8fb6-49e6-96ba-0904ccbf9832,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-1c375a31-c70c-4df0-86bc-b8ce08aed244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290560227-172.17.0.2-1593402175056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36342,DS-a546d9e9-aaf7-48b7-a1cd-fbf0a82c1fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-868b6792-1519-4bcd-875a-8e8429d8268b,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-d4fdc536-7852-45a8-87a7-99f7ae1e6db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-1e06ce7b-cedb-48ed-880b-88ace018149d,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-22f1042f-1315-4b00-bdc1-805528700f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-2e675fdb-f006-46d6-8e52-49c6b98d4a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-e08fc41f-59b0-4f94-b105-f4df43e00dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-0ebea680-bcef-4194-93b1-6ef0c9c49520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290560227-172.17.0.2-1593402175056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36342,DS-a546d9e9-aaf7-48b7-a1cd-fbf0a82c1fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-868b6792-1519-4bcd-875a-8e8429d8268b,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-d4fdc536-7852-45a8-87a7-99f7ae1e6db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-1e06ce7b-cedb-48ed-880b-88ace018149d,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-22f1042f-1315-4b00-bdc1-805528700f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-2e675fdb-f006-46d6-8e52-49c6b98d4a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-e08fc41f-59b0-4f94-b105-f4df43e00dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-0ebea680-bcef-4194-93b1-6ef0c9c49520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811306001-172.17.0.2-1593402287480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-0d21649c-4312-4558-a736-2b57fa5cf103,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-f44db93a-2fe5-4234-ae8e-2eccd284f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-2a24d45f-741b-421e-95d8-aaa7f20a7c32,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-43ace76b-4e51-484c-9047-88347c5216f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-1c13286e-d55e-4ecd-a562-b2f1d65af20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-e0e43d62-deaa-4d57-af64-cb150486010c,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-780ff0a3-b467-45fb-9a30-c090bf429eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-8cc89ed3-1278-4f87-ae1e-e93f31e1063e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811306001-172.17.0.2-1593402287480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-0d21649c-4312-4558-a736-2b57fa5cf103,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-f44db93a-2fe5-4234-ae8e-2eccd284f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-2a24d45f-741b-421e-95d8-aaa7f20a7c32,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-43ace76b-4e51-484c-9047-88347c5216f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-1c13286e-d55e-4ecd-a562-b2f1d65af20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-e0e43d62-deaa-4d57-af64-cb150486010c,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-780ff0a3-b467-45fb-9a30-c090bf429eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-8cc89ed3-1278-4f87-ae1e-e93f31e1063e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030569393-172.17.0.2-1593402364830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-f4fb249c-3c5a-470d-925e-7e3d8e5f2b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-72d948ba-9cb3-4078-aa1b-1a4473c8aaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-a9586359-81ce-488a-b020-74920b253b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-bc402046-79e4-4d01-bbaa-380fb0ea4c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-b146df9b-060f-4591-a50a-73a5d24cba78,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-9f248136-1513-4ad3-a843-b610d0a3732d,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-2068f840-47e0-483d-962c-22cf0c6a5bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-3de2a798-1ef1-48d4-85e8-586237734982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030569393-172.17.0.2-1593402364830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-f4fb249c-3c5a-470d-925e-7e3d8e5f2b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-72d948ba-9cb3-4078-aa1b-1a4473c8aaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-a9586359-81ce-488a-b020-74920b253b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-bc402046-79e4-4d01-bbaa-380fb0ea4c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-b146df9b-060f-4591-a50a-73a5d24cba78,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-9f248136-1513-4ad3-a843-b610d0a3732d,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-2068f840-47e0-483d-962c-22cf0c6a5bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-3de2a798-1ef1-48d4-85e8-586237734982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067285645-172.17.0.2-1593402714628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-f9749cad-0f0e-4135-9210-1dfd9d240652,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-342639ca-342c-4a0f-8592-d520f0c4b7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-2b155f33-a741-46b0-b7fb-83ce2db5fc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-098b2da5-70e6-4e06-b035-1686c1fd496d,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-56fa25c3-bfa7-4840-ac02-63bf23e9d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-ed2d5e89-8cb7-4d20-b348-d764b3d3a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-0db6099b-2e29-45eb-bda0-6c581274a646,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-1dcfe246-5106-4cd5-b8aa-8827ace045dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067285645-172.17.0.2-1593402714628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41385,DS-f9749cad-0f0e-4135-9210-1dfd9d240652,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-342639ca-342c-4a0f-8592-d520f0c4b7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-2b155f33-a741-46b0-b7fb-83ce2db5fc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-098b2da5-70e6-4e06-b035-1686c1fd496d,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-56fa25c3-bfa7-4840-ac02-63bf23e9d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-ed2d5e89-8cb7-4d20-b348-d764b3d3a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-0db6099b-2e29-45eb-bda0-6c581274a646,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-1dcfe246-5106-4cd5-b8aa-8827ace045dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309250988-172.17.0.2-1593402963159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42630,DS-0570cd15-4382-452d-b7b3-5c1d56fdde67,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-ab591f43-12dd-412d-a27f-947b6631a541,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-a93ba189-1af7-4cf5-8a1b-57f24e0cd9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-13dce694-6763-425a-8d8c-166dfdd51993,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-e87c8730-d1a7-4754-b686-05ee7a703de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-756f126a-c467-412f-b8ac-f805f368ed71,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-bc9a3915-f3b1-415b-a0ce-888e5f31245b,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-0f1c49ae-4467-4fcb-ba37-1776c2fea96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309250988-172.17.0.2-1593402963159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42630,DS-0570cd15-4382-452d-b7b3-5c1d56fdde67,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-ab591f43-12dd-412d-a27f-947b6631a541,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-a93ba189-1af7-4cf5-8a1b-57f24e0cd9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-13dce694-6763-425a-8d8c-166dfdd51993,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-e87c8730-d1a7-4754-b686-05ee7a703de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-756f126a-c467-412f-b8ac-f805f368ed71,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-bc9a3915-f3b1-415b-a0ce-888e5f31245b,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-0f1c49ae-4467-4fcb-ba37-1776c2fea96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908839580-172.17.0.2-1593402999787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44461,DS-9617afee-8312-49c9-918f-4d2f71264f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-efaa562d-a3e6-4088-b91a-901f0930186b,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-b86957c0-cf30-4535-9990-7cb067d97364,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-de5efb48-6b47-427f-8db3-9f02d3dd02f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-807877bd-0ad5-473e-a8e4-ff7fd3cb9fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-e2abb054-c3b6-4815-b063-e78d8c610df2,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-987429b6-7e6f-405a-9958-8e4749fd7764,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-218d91dd-f1d2-4f70-86b2-5f9d1dffd002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908839580-172.17.0.2-1593402999787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44461,DS-9617afee-8312-49c9-918f-4d2f71264f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-efaa562d-a3e6-4088-b91a-901f0930186b,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-b86957c0-cf30-4535-9990-7cb067d97364,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-de5efb48-6b47-427f-8db3-9f02d3dd02f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-807877bd-0ad5-473e-a8e4-ff7fd3cb9fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-e2abb054-c3b6-4815-b063-e78d8c610df2,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-987429b6-7e6f-405a-9958-8e4749fd7764,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-218d91dd-f1d2-4f70-86b2-5f9d1dffd002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031946055-172.17.0.2-1593403035561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-d0fe45ca-ed01-4fac-8269-758ade37bc85,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-44d5e5ff-ea40-4aef-b064-daf4fc647957,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-570e0cf7-246e-490d-b0d1-f091f208dcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-0333ee72-3a7b-4b74-bc7f-9d082f4b0485,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-eb2a9d60-fa02-4fe4-829d-c095d590fc72,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-a8ee5c4c-c425-48e3-8b4d-c13cc39e670a,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-3d35ca95-fe35-4893-91b2-c8c2ca4b3b43,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-51725caa-19e5-41f0-92b3-69dd9d303ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031946055-172.17.0.2-1593403035561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-d0fe45ca-ed01-4fac-8269-758ade37bc85,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-44d5e5ff-ea40-4aef-b064-daf4fc647957,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-570e0cf7-246e-490d-b0d1-f091f208dcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-0333ee72-3a7b-4b74-bc7f-9d082f4b0485,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-eb2a9d60-fa02-4fe4-829d-c095d590fc72,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-a8ee5c4c-c425-48e3-8b4d-c13cc39e670a,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-3d35ca95-fe35-4893-91b2-c8c2ca4b3b43,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-51725caa-19e5-41f0-92b3-69dd9d303ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5605
