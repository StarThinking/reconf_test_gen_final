reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493621082-172.17.0.5-1590351844187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36757,DS-c4856bbc-dc0f-4d2b-a670-92a31808cb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-0f7e9979-8aa2-4b9e-bf30-05e5ca6db221,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-39be0955-3f5d-4296-b864-1f8bb67a255f,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-b392098b-8a84-4f09-988c-8eda11e2eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-303a28c7-bd22-49b4-a18e-577078917cab,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-a4a23dba-5e46-49e2-82c2-79a075c41942,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-791ea65d-440f-4461-8876-e2188ed25a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-e953aa9e-aca7-4635-b9ee-4eaa05a14dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493621082-172.17.0.5-1590351844187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36757,DS-c4856bbc-dc0f-4d2b-a670-92a31808cb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-0f7e9979-8aa2-4b9e-bf30-05e5ca6db221,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-39be0955-3f5d-4296-b864-1f8bb67a255f,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-b392098b-8a84-4f09-988c-8eda11e2eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-303a28c7-bd22-49b4-a18e-577078917cab,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-a4a23dba-5e46-49e2-82c2-79a075c41942,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-791ea65d-440f-4461-8876-e2188ed25a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-e953aa9e-aca7-4635-b9ee-4eaa05a14dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536878173-172.17.0.5-1590351885303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34482,DS-7f4ae235-9e34-45e2-bea1-4cb35e26434c,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-2e4ce132-5987-4927-9eb0-555b58c96da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-86cc3fb3-3711-4d7b-80d6-b01347e862e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-3acc1cb0-6a11-4dcd-bf4b-715cee4f8643,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-f298841e-fd98-4ab3-b277-cb3d615bbed4,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-2734ac22-2291-49e5-8d47-4b79dbc04e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-5f937074-e46e-439e-8e12-0ad8b3700106,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-916c91f2-0b31-4f90-8fb7-8950a4107adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536878173-172.17.0.5-1590351885303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34482,DS-7f4ae235-9e34-45e2-bea1-4cb35e26434c,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-2e4ce132-5987-4927-9eb0-555b58c96da6,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-86cc3fb3-3711-4d7b-80d6-b01347e862e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-3acc1cb0-6a11-4dcd-bf4b-715cee4f8643,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-f298841e-fd98-4ab3-b277-cb3d615bbed4,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-2734ac22-2291-49e5-8d47-4b79dbc04e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-5f937074-e46e-439e-8e12-0ad8b3700106,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-916c91f2-0b31-4f90-8fb7-8950a4107adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958933503-172.17.0.5-1590352200258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40786,DS-f391f3a0-9711-48b0-8959-e501637ce8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-2332348a-192e-4bd6-9c1a-52e6ab847ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-ac673f00-808a-4969-8863-5c544f9a9941,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-5fd319ed-7852-42b5-ad9f-49177db1b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-27f3c88d-9c55-42b2-9481-492d2b892c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-baaed8f3-8412-4471-976e-6f3dbcfee199,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-1b9eaef6-0fe9-4439-a6aa-64435d48dc48,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-eafde488-3d99-4df3-a0b8-4e2d2a1e2886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958933503-172.17.0.5-1590352200258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40786,DS-f391f3a0-9711-48b0-8959-e501637ce8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-2332348a-192e-4bd6-9c1a-52e6ab847ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-ac673f00-808a-4969-8863-5c544f9a9941,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-5fd319ed-7852-42b5-ad9f-49177db1b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-27f3c88d-9c55-42b2-9481-492d2b892c04,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-baaed8f3-8412-4471-976e-6f3dbcfee199,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-1b9eaef6-0fe9-4439-a6aa-64435d48dc48,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-eafde488-3d99-4df3-a0b8-4e2d2a1e2886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785815515-172.17.0.5-1590352907630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45698,DS-52e5eeb9-4211-4f01-855d-fcb0a347014e,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-194c985a-8756-4a8e-838a-b35fa0e60f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-56342ee9-0ab7-499b-836b-8945b65ebdee,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-fdbc0131-5609-4b29-a4c8-5cc9550b0a36,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-f20c4f8e-6c69-4348-ad12-feddf4ccbab9,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-c88323b1-c923-44d5-a985-5d12f7176198,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-581662ed-d3a1-4eed-b817-81d4bbfc239c,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-39d45cea-11dc-4564-9d08-62b45ca3cf66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785815515-172.17.0.5-1590352907630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45698,DS-52e5eeb9-4211-4f01-855d-fcb0a347014e,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-194c985a-8756-4a8e-838a-b35fa0e60f93,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-56342ee9-0ab7-499b-836b-8945b65ebdee,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-fdbc0131-5609-4b29-a4c8-5cc9550b0a36,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-f20c4f8e-6c69-4348-ad12-feddf4ccbab9,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-c88323b1-c923-44d5-a985-5d12f7176198,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-581662ed-d3a1-4eed-b817-81d4bbfc239c,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-39d45cea-11dc-4564-9d08-62b45ca3cf66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645090052-172.17.0.5-1590353139731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39630,DS-d82d018b-bbbf-46d6-a689-84129e200559,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-19dc5f47-a9da-4522-9125-1b5e354430c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-d25913ea-1a81-4148-9ca4-30f0a878275c,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-5963b26a-c01b-4a90-8830-e10d09a89a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-814c1bf8-08f4-4f83-a343-a7e0d7220b99,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-d4f23320-471c-4860-90ea-7c8b730588d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-c8958263-9f1e-4a1c-973b-a3a91dba844e,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-a1cd5323-244a-4dfd-ad68-5b8fe2229d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645090052-172.17.0.5-1590353139731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39630,DS-d82d018b-bbbf-46d6-a689-84129e200559,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-19dc5f47-a9da-4522-9125-1b5e354430c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-d25913ea-1a81-4148-9ca4-30f0a878275c,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-5963b26a-c01b-4a90-8830-e10d09a89a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-814c1bf8-08f4-4f83-a343-a7e0d7220b99,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-d4f23320-471c-4860-90ea-7c8b730588d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-c8958263-9f1e-4a1c-973b-a3a91dba844e,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-a1cd5323-244a-4dfd-ad68-5b8fe2229d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305240586-172.17.0.5-1590353212562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42318,DS-82f6502f-60f3-4746-a11e-ee7d4f1e57c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-7275176c-025e-4118-9847-23f1628cdec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-df513a8f-cc65-4c86-9834-ead136b1c144,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-a87e7619-edb4-4bc2-85fb-bcfed4686454,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-216c1054-40f0-469c-931e-164406d96853,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-60642dd1-a364-4759-8978-5fb4eed59689,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-02783ca0-ac64-423e-95de-ef40e3b3c811,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-0236683b-bd8d-4865-9b13-a3fee4979cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305240586-172.17.0.5-1590353212562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42318,DS-82f6502f-60f3-4746-a11e-ee7d4f1e57c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-7275176c-025e-4118-9847-23f1628cdec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-df513a8f-cc65-4c86-9834-ead136b1c144,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-a87e7619-edb4-4bc2-85fb-bcfed4686454,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-216c1054-40f0-469c-931e-164406d96853,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-60642dd1-a364-4759-8978-5fb4eed59689,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-02783ca0-ac64-423e-95de-ef40e3b3c811,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-0236683b-bd8d-4865-9b13-a3fee4979cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915612123-172.17.0.5-1590353280170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44653,DS-b0c78ea4-9df5-49bd-8e46-8f1ccff7a60e,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-9e6d1191-5c2f-478d-8f61-8b2d875c6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-0854b537-13e3-4633-91c7-d09d965f70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-7513c0ee-6ce8-496a-b059-fbfd8f942390,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-3b7160df-df0f-49f5-8b34-7b37d80f2d71,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-4be254e2-3fdb-48c3-9665-9460bb853432,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-3d47c37e-954f-4eac-b35b-9da8c069ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-0b85fa44-2ed9-4c82-b634-847845bf1759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915612123-172.17.0.5-1590353280170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44653,DS-b0c78ea4-9df5-49bd-8e46-8f1ccff7a60e,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-9e6d1191-5c2f-478d-8f61-8b2d875c6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-0854b537-13e3-4633-91c7-d09d965f70e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-7513c0ee-6ce8-496a-b059-fbfd8f942390,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-3b7160df-df0f-49f5-8b34-7b37d80f2d71,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-4be254e2-3fdb-48c3-9665-9460bb853432,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-3d47c37e-954f-4eac-b35b-9da8c069ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-0b85fa44-2ed9-4c82-b634-847845bf1759,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609503982-172.17.0.5-1590353742260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-b6caab8c-78b8-4ee0-a3c5-ad1dfdc9fc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-b029fd20-c927-4fed-92a4-077b1b4ebc65,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-c8487be5-db46-4d0c-8638-d2d41ad7dd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-e46adad0-edfc-4216-b14d-f415489368b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-d2430f45-93e1-46e7-a24f-0399265d74f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-4d3daa89-58e0-4c51-869b-ac9a514e14f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-d807464e-faa8-4d2a-9631-0f9ba78796ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-1020e7d1-6857-476b-bf36-1fb86309cf65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609503982-172.17.0.5-1590353742260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-b6caab8c-78b8-4ee0-a3c5-ad1dfdc9fc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-b029fd20-c927-4fed-92a4-077b1b4ebc65,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-c8487be5-db46-4d0c-8638-d2d41ad7dd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-e46adad0-edfc-4216-b14d-f415489368b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-d2430f45-93e1-46e7-a24f-0399265d74f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-4d3daa89-58e0-4c51-869b-ac9a514e14f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-d807464e-faa8-4d2a-9631-0f9ba78796ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-1020e7d1-6857-476b-bf36-1fb86309cf65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845267287-172.17.0.5-1590353853342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45174,DS-aed392b3-81ea-4cc3-95c2-224249e8461e,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-a6a606a7-7151-4576-ad9b-26a4b1896aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-ddb5324a-85af-4a28-9cd2-b9c71d547282,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-4977b346-cd4a-40b5-8065-825dc28d0249,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-74b9927b-9735-4f91-8ad6-1e999fcf36b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-c3b5c472-fb58-4711-98ab-03c1c09b354b,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-090f674a-df24-4f0a-b2b8-748cacda2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-a86aa4d9-0460-4719-b22a-bad5566d9044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845267287-172.17.0.5-1590353853342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45174,DS-aed392b3-81ea-4cc3-95c2-224249e8461e,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-a6a606a7-7151-4576-ad9b-26a4b1896aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-ddb5324a-85af-4a28-9cd2-b9c71d547282,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-4977b346-cd4a-40b5-8065-825dc28d0249,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-74b9927b-9735-4f91-8ad6-1e999fcf36b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-c3b5c472-fb58-4711-98ab-03c1c09b354b,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-090f674a-df24-4f0a-b2b8-748cacda2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-a86aa4d9-0460-4719-b22a-bad5566d9044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194263328-172.17.0.5-1590355164012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-f489a728-7edb-4d27-b7c5-1fa29c6db7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-1a3110c8-47fb-4f56-b9d0-169999b181fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-1637cef0-5d6a-4ee3-93a2-5a5ea4864e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-48e67299-b6a3-4f00-be68-3ca81c550e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-1cdfa431-e1b7-471b-9bd2-743b0ade5d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-a0cde0ed-306f-4c69-96bb-465e350017d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-027f91fc-3b50-4298-8433-e210ea26c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-d98d9460-727d-45d3-9095-077ad550a42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194263328-172.17.0.5-1590355164012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-f489a728-7edb-4d27-b7c5-1fa29c6db7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-1a3110c8-47fb-4f56-b9d0-169999b181fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-1637cef0-5d6a-4ee3-93a2-5a5ea4864e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-48e67299-b6a3-4f00-be68-3ca81c550e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-1cdfa431-e1b7-471b-9bd2-743b0ade5d28,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-a0cde0ed-306f-4c69-96bb-465e350017d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-027f91fc-3b50-4298-8433-e210ea26c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-d98d9460-727d-45d3-9095-077ad550a42c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358680295-172.17.0.5-1590356535044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44629,DS-9a40247b-7b43-43ec-8e0d-86db07cde5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-09716799-b19c-4638-ab81-5d871ae8e1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-c32d6af9-cf8f-4edc-bcd3-41c8385aebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-c31d2b38-9ff8-4262-918b-1b6fecc10c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-9402c327-6c48-4584-9b12-bcd040fcc48c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-99781181-42a4-4dd2-89a2-40b134088e44,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-a5d0559f-9dc4-4692-b9a0-f285ab5b7146,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-f7bc9662-73b2-4c6a-a40a-87da7fdc1ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358680295-172.17.0.5-1590356535044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44629,DS-9a40247b-7b43-43ec-8e0d-86db07cde5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-09716799-b19c-4638-ab81-5d871ae8e1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-c32d6af9-cf8f-4edc-bcd3-41c8385aebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-c31d2b38-9ff8-4262-918b-1b6fecc10c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-9402c327-6c48-4584-9b12-bcd040fcc48c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-99781181-42a4-4dd2-89a2-40b134088e44,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-a5d0559f-9dc4-4692-b9a0-f285ab5b7146,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-f7bc9662-73b2-4c6a-a40a-87da7fdc1ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.lifetime
component: NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361624286-172.17.0.5-1590356850622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43423,DS-8a3ce7e5-ed59-4766-a017-384eb25cc8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-9a29630f-57d1-4f9f-b228-12982e0a00e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-c95b9fac-e6a6-4776-89bf-6f7069e0a0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-5e0df240-f714-446c-9729-b6241835ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-6bd0cd9b-af6b-4525-9ade-97b96744305d,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-a0895e69-de15-4fca-97f1-cee394fd179c,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-ebb58cc9-10b2-4400-886c-ec7ea918c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-745557e1-9823-4b98-ac6c-051cf2883257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1361624286-172.17.0.5-1590356850622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43423,DS-8a3ce7e5-ed59-4766-a017-384eb25cc8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-9a29630f-57d1-4f9f-b228-12982e0a00e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-c95b9fac-e6a6-4776-89bf-6f7069e0a0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-5e0df240-f714-446c-9729-b6241835ba8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-6bd0cd9b-af6b-4525-9ade-97b96744305d,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-a0895e69-de15-4fca-97f1-cee394fd179c,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-ebb58cc9-10b2-4400-886c-ec7ea918c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-745557e1-9823-4b98-ac6c-051cf2883257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5797
