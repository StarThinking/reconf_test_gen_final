reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561469122-172.17.0.15-1590355628044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-6fcc16f5-3821-443c-98bf-f85808966bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-e450d2da-9d3a-4756-af4b-95adf686a975,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-3b85f7ba-a0d3-4784-885f-ba7b6f7fa886,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-a1f34de9-bbd1-46d9-83ec-6a0828dc7ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-418b8de1-3eb1-4ba2-8311-d339b6f25001,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-b1e332b2-2660-4c69-a665-fa70061fc207,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-67b1fdf6-57da-4ee2-8ddc-64fa970d60ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-85f21a76-3cab-42c0-92be-5a679f44e496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561469122-172.17.0.15-1590355628044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-6fcc16f5-3821-443c-98bf-f85808966bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-e450d2da-9d3a-4756-af4b-95adf686a975,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-3b85f7ba-a0d3-4784-885f-ba7b6f7fa886,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-a1f34de9-bbd1-46d9-83ec-6a0828dc7ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-418b8de1-3eb1-4ba2-8311-d339b6f25001,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-b1e332b2-2660-4c69-a665-fa70061fc207,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-67b1fdf6-57da-4ee2-8ddc-64fa970d60ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-85f21a76-3cab-42c0-92be-5a679f44e496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939395867-172.17.0.15-1590355740692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34664,DS-8f7d97f5-54d0-40df-afac-4a643f5be270,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-81abb4e5-2e74-4fec-a277-19b85d431fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-21ecf049-35ed-417c-a601-729560753b92,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-7a6b5e69-9f86-4ee5-a1f4-73bb5ae4275e,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-5bd0ce23-12ce-499b-a7e8-54e6dcc33d00,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-b6032fc0-8ffe-41cf-aa95-c47f3807dce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-8af57695-12aa-4dfd-a6e9-72d9e97a0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-c6aa43a1-91ba-4a3e-ba18-87146299541c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939395867-172.17.0.15-1590355740692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34664,DS-8f7d97f5-54d0-40df-afac-4a643f5be270,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-81abb4e5-2e74-4fec-a277-19b85d431fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-21ecf049-35ed-417c-a601-729560753b92,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-7a6b5e69-9f86-4ee5-a1f4-73bb5ae4275e,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-5bd0ce23-12ce-499b-a7e8-54e6dcc33d00,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-b6032fc0-8ffe-41cf-aa95-c47f3807dce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-8af57695-12aa-4dfd-a6e9-72d9e97a0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-c6aa43a1-91ba-4a3e-ba18-87146299541c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918729440-172.17.0.15-1590356129871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45157,DS-3e290d25-54ec-4d39-8623-e652a457b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-db99f8e6-aa81-40b3-8351-208e265eedbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-6d5d0fca-d016-46b8-bb3f-69993bf6460d,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-4edc1b1d-4a49-4304-958f-c35905f6df72,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-0d430eff-eb00-4834-afe6-320fc863efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-711e5e40-1f69-4677-adca-97835c0a7a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-c28e0845-b5b2-477c-b9a7-6af1816e4145,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-560b427e-b957-4fd7-8f33-62460ce6dfab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918729440-172.17.0.15-1590356129871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45157,DS-3e290d25-54ec-4d39-8623-e652a457b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-db99f8e6-aa81-40b3-8351-208e265eedbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-6d5d0fca-d016-46b8-bb3f-69993bf6460d,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-4edc1b1d-4a49-4304-958f-c35905f6df72,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-0d430eff-eb00-4834-afe6-320fc863efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-711e5e40-1f69-4677-adca-97835c0a7a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-c28e0845-b5b2-477c-b9a7-6af1816e4145,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-560b427e-b957-4fd7-8f33-62460ce6dfab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185944888-172.17.0.15-1590356391500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39793,DS-c4376424-1f4a-45d7-badc-3519fb3b5a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-7d9ebf5b-f75e-40c7-a502-d41fe28c3082,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-1364ee80-193d-46a3-9945-682edd071859,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-199d6a41-ac8a-448b-9eff-c2f6de3b2722,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-40c4fb06-ea32-4578-8067-657d24b76de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-f2107c83-68ff-4f37-9035-93a77445b829,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-60c35e3a-9c07-4036-aef9-223f420cbc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-4661a8f7-bd3f-4be6-bd10-468cb942e88f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185944888-172.17.0.15-1590356391500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39793,DS-c4376424-1f4a-45d7-badc-3519fb3b5a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-7d9ebf5b-f75e-40c7-a502-d41fe28c3082,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-1364ee80-193d-46a3-9945-682edd071859,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-199d6a41-ac8a-448b-9eff-c2f6de3b2722,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-40c4fb06-ea32-4578-8067-657d24b76de5,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-f2107c83-68ff-4f37-9035-93a77445b829,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-60c35e3a-9c07-4036-aef9-223f420cbc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-4661a8f7-bd3f-4be6-bd10-468cb942e88f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337072080-172.17.0.15-1590356470624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39197,DS-216ed0d0-1c64-4c66-8afa-e8cd262e0b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-3ae005fa-2c84-4ca3-886c-55b1f8058b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-b807b821-bc5f-447c-a337-228334ec0822,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-84a657b0-ca6b-4cfb-a94b-ec37ab3d7faf,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-7be2cf3e-9208-4fa3-bd15-223335f11b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-c96536a7-abf8-46ff-8cd6-055cb1cf1046,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-575d05ca-d9e1-44bb-93b3-13ae17367fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-9ac3182d-01bf-4412-bff3-f89f3b706672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337072080-172.17.0.15-1590356470624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39197,DS-216ed0d0-1c64-4c66-8afa-e8cd262e0b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-3ae005fa-2c84-4ca3-886c-55b1f8058b99,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-b807b821-bc5f-447c-a337-228334ec0822,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-84a657b0-ca6b-4cfb-a94b-ec37ab3d7faf,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-7be2cf3e-9208-4fa3-bd15-223335f11b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-c96536a7-abf8-46ff-8cd6-055cb1cf1046,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-575d05ca-d9e1-44bb-93b3-13ae17367fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-9ac3182d-01bf-4412-bff3-f89f3b706672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359750950-172.17.0.15-1590356657797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-71181a1d-f106-47e9-af13-131eebdfe0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-accfe9f1-a893-4bd4-801a-02ead377a4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-a670552c-2c27-4054-a275-93e0d6f3cb83,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-0312cd4d-9d10-4228-bb05-3d416e9bd72f,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-940d0629-a5b1-46a3-b944-450400f4473a,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-a2a18d81-f69b-47b9-b8ba-5c9a547d4659,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-52d13276-74af-4d15-9a4b-70d086070d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-d508cb33-90f6-4120-8abe-fe4d0711b4cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359750950-172.17.0.15-1590356657797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-71181a1d-f106-47e9-af13-131eebdfe0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-accfe9f1-a893-4bd4-801a-02ead377a4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-a670552c-2c27-4054-a275-93e0d6f3cb83,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-0312cd4d-9d10-4228-bb05-3d416e9bd72f,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-940d0629-a5b1-46a3-b944-450400f4473a,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-a2a18d81-f69b-47b9-b8ba-5c9a547d4659,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-52d13276-74af-4d15-9a4b-70d086070d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-d508cb33-90f6-4120-8abe-fe4d0711b4cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678862046-172.17.0.15-1590356853169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-5d32748d-044d-4e39-a28e-69a65609068d,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-b196355a-f1b8-410c-8f67-a044024df17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-d2f66088-8687-48cb-8110-7e6ebae8e697,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-b34fbb58-4498-4b63-b0d8-94753e6cad59,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-45190cc5-e3e5-4453-9ac2-494824a0bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-aff3ff22-b7a8-41ca-92de-dacf6737d090,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-2ba051fb-1559-4a9f-b327-717931df2c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-ebdbc32a-d9ac-49af-be0b-22152d5ff529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678862046-172.17.0.15-1590356853169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-5d32748d-044d-4e39-a28e-69a65609068d,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-b196355a-f1b8-410c-8f67-a044024df17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-d2f66088-8687-48cb-8110-7e6ebae8e697,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-b34fbb58-4498-4b63-b0d8-94753e6cad59,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-45190cc5-e3e5-4453-9ac2-494824a0bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-aff3ff22-b7a8-41ca-92de-dacf6737d090,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-2ba051fb-1559-4a9f-b327-717931df2c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-ebdbc32a-d9ac-49af-be0b-22152d5ff529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778995770-172.17.0.15-1590356966006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-2d68377b-4195-49dc-a62a-31d0e9d13428,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-9e75157b-f86d-478a-aa48-457e2eded828,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-af022516-25e8-4100-afa3-d2c5f6b67394,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-76e21129-e6af-4d34-bea1-2c4970d2a47b,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-0c6af3cd-8485-4d5c-80df-5d5415eaad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-48b82e2c-7a1f-41c2-bfa9-8281631edbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-762dc366-943a-4204-91d1-44a853614971,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-1251ed10-9b71-453c-8a9f-12f5525e41ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778995770-172.17.0.15-1590356966006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-2d68377b-4195-49dc-a62a-31d0e9d13428,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-9e75157b-f86d-478a-aa48-457e2eded828,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-af022516-25e8-4100-afa3-d2c5f6b67394,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-76e21129-e6af-4d34-bea1-2c4970d2a47b,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-0c6af3cd-8485-4d5c-80df-5d5415eaad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-48b82e2c-7a1f-41c2-bfa9-8281631edbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-762dc366-943a-4204-91d1-44a853614971,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-1251ed10-9b71-453c-8a9f-12f5525e41ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425588171-172.17.0.15-1590357038703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33861,DS-5430ea9b-948f-4b0f-8381-c9a27874d71a,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-3ac6c9d0-068d-4c73-b36b-15d27088c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-1fb8c6ba-1de4-42a5-b1a4-9d231202e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-b9b41d34-9c4d-4d6e-a3e5-f196a2cd13b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-9194e33f-2e1e-4e59-92d9-c614c3aae058,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-ab3fb731-7bf5-4147-9422-d784595dd0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-70d8472f-1e94-4be1-b2fd-7448d8d79ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-62d474e5-ffd5-4938-8c07-e6dedd97808c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425588171-172.17.0.15-1590357038703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33861,DS-5430ea9b-948f-4b0f-8381-c9a27874d71a,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-3ac6c9d0-068d-4c73-b36b-15d27088c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-1fb8c6ba-1de4-42a5-b1a4-9d231202e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-b9b41d34-9c4d-4d6e-a3e5-f196a2cd13b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-9194e33f-2e1e-4e59-92d9-c614c3aae058,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-ab3fb731-7bf5-4147-9422-d784595dd0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-70d8472f-1e94-4be1-b2fd-7448d8d79ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-62d474e5-ffd5-4938-8c07-e6dedd97808c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161995954-172.17.0.15-1590357649384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-64ecce9d-1dc6-4c67-aea4-f53dfc2d59ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-1cab5c96-317c-4c27-91f3-736773e07af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-1f74383a-9476-4692-81d9-38ab1a89cf59,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-2c9b8622-a23f-4a1a-bfc4-ab5a49ee1730,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-c9ec58fe-3b4c-4add-a188-c0928dea7954,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-7656197d-56c5-4c78-b91f-18749308e9db,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-7c8071d2-3382-48d2-887d-e17d8e0c449a,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-806617cd-b442-448c-9341-9356cd835086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161995954-172.17.0.15-1590357649384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-64ecce9d-1dc6-4c67-aea4-f53dfc2d59ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-1cab5c96-317c-4c27-91f3-736773e07af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-1f74383a-9476-4692-81d9-38ab1a89cf59,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-2c9b8622-a23f-4a1a-bfc4-ab5a49ee1730,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-c9ec58fe-3b4c-4add-a188-c0928dea7954,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-7656197d-56c5-4c78-b91f-18749308e9db,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-7c8071d2-3382-48d2-887d-e17d8e0c449a,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-806617cd-b442-448c-9341-9356cd835086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416525790-172.17.0.15-1590357926500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-b99a5538-0a88-4fca-81cf-7f765bcabf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-5f6554a6-132a-46ca-8258-12bd2e43bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-59419700-da8e-4e48-af9d-d55424fa4f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-ce5b443f-ca45-4fe0-a61b-bc088347e298,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-c089723f-15e4-4da2-9911-d91fdf06b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-5b9c00e0-4d8d-43fe-b561-8719e0685b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-7a6f41f4-c7b2-40e8-a410-09a8493d8d09,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-a18f71c0-0808-4671-a95f-5d2fe84cc107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416525790-172.17.0.15-1590357926500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43367,DS-b99a5538-0a88-4fca-81cf-7f765bcabf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-5f6554a6-132a-46ca-8258-12bd2e43bce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-59419700-da8e-4e48-af9d-d55424fa4f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-ce5b443f-ca45-4fe0-a61b-bc088347e298,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-c089723f-15e4-4da2-9911-d91fdf06b5df,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-5b9c00e0-4d8d-43fe-b561-8719e0685b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-7a6f41f4-c7b2-40e8-a410-09a8493d8d09,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-a18f71c0-0808-4671-a95f-5d2fe84cc107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305255667-172.17.0.15-1590358070863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37383,DS-80b2b9e6-8283-4d12-83fd-93580c2253d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-af8190d1-b22d-45b4-84d2-c65bb28fd155,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-7bf72e76-734e-4ba3-a407-95c2d763fab6,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-b00fb14e-a1f3-4910-8dcb-fd85f31a73fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-8e7b6c66-07eb-43f4-839c-35a834769a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-c25a555c-e6d9-4fbb-bb10-ce9cc1dc483e,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d5dd94c6-9e56-479c-bb90-36971fc86f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-9db0e899-5024-4d1a-80a8-5be18d045527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305255667-172.17.0.15-1590358070863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37383,DS-80b2b9e6-8283-4d12-83fd-93580c2253d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-af8190d1-b22d-45b4-84d2-c65bb28fd155,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-7bf72e76-734e-4ba3-a407-95c2d763fab6,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-b00fb14e-a1f3-4910-8dcb-fd85f31a73fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-8e7b6c66-07eb-43f4-839c-35a834769a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-c25a555c-e6d9-4fbb-bb10-ce9cc1dc483e,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-d5dd94c6-9e56-479c-bb90-36971fc86f95,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-9db0e899-5024-4d1a-80a8-5be18d045527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079691358-172.17.0.15-1590359534341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41942,DS-07cad0bf-9525-40e7-a580-78442d0a64a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-e836d38f-74a7-4275-9281-a550566b392b,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-b622bc23-a94f-4fd6-9cbe-6862a61d8331,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-a804121f-eefd-41c2-a0bd-1de2c620bc58,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-46b60a3c-74fa-4e94-9ca8-da48a6914646,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-da6957e6-537d-4264-92ce-575dee1c73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-f2cd9fb4-4ba8-4f0a-b5fe-d51234e345af,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-6928959f-8a93-4cc9-b318-d145b3e3a007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079691358-172.17.0.15-1590359534341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41942,DS-07cad0bf-9525-40e7-a580-78442d0a64a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-e836d38f-74a7-4275-9281-a550566b392b,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-b622bc23-a94f-4fd6-9cbe-6862a61d8331,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-a804121f-eefd-41c2-a0bd-1de2c620bc58,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-46b60a3c-74fa-4e94-9ca8-da48a6914646,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-da6957e6-537d-4264-92ce-575dee1c73d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-f2cd9fb4-4ba8-4f0a-b5fe-d51234e345af,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-6928959f-8a93-4cc9-b318-d145b3e3a007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387517288-172.17.0.15-1590359743412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38093,DS-b9e56182-06e4-46ac-b70d-db24cc4ec3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-4ca30431-ae85-408d-8d6a-a8fa3b4dfb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-63081a33-37dd-449c-b3fd-46cb3617ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-07ec1fb3-3789-4eea-8b62-b83fb6112d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-2948bb81-1dbe-4791-8c3c-9ae76ae5ce98,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-d40a3984-a20a-463e-bb4c-3f31832e9426,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-ab1fdbd0-d340-4f2a-86ab-8380953e9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-6446f161-b771-4dc5-a38a-fb125731959e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387517288-172.17.0.15-1590359743412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38093,DS-b9e56182-06e4-46ac-b70d-db24cc4ec3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-4ca30431-ae85-408d-8d6a-a8fa3b4dfb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-63081a33-37dd-449c-b3fd-46cb3617ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-07ec1fb3-3789-4eea-8b62-b83fb6112d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-2948bb81-1dbe-4791-8c3c-9ae76ae5ce98,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-d40a3984-a20a-463e-bb4c-3f31832e9426,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-ab1fdbd0-d340-4f2a-86ab-8380953e9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-6446f161-b771-4dc5-a38a-fb125731959e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: NameNode
v1: 3000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966572810-172.17.0.15-1590360579571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46385,DS-d34c86de-1520-4333-94db-f0461227c644,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-5d769c59-97c9-42ea-99f5-4ff16a98c6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-fb01433d-7853-415c-968e-3e37a8ef7a56,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-c95f3661-a395-4c81-8c8a-d0c2ee370c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-2f4bf4b3-8583-48a1-86e0-2989995b7d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-f0b8f109-168e-42c5-afee-7ce019fbe6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-654fecdf-bba5-4af2-9fb1-284218d48433,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-5118ed11-0644-4fbc-8765-84c2b0172006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966572810-172.17.0.15-1590360579571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46385,DS-d34c86de-1520-4333-94db-f0461227c644,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-5d769c59-97c9-42ea-99f5-4ff16a98c6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-fb01433d-7853-415c-968e-3e37a8ef7a56,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-c95f3661-a395-4c81-8c8a-d0c2ee370c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-2f4bf4b3-8583-48a1-86e0-2989995b7d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-f0b8f109-168e-42c5-afee-7ce019fbe6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-654fecdf-bba5-4af2-9fb1-284218d48433,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-5118ed11-0644-4fbc-8765-84c2b0172006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5477
