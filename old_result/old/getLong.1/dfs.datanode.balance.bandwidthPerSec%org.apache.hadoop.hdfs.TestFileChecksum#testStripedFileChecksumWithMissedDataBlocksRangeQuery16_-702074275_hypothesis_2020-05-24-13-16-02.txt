reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132004330-172.17.0.16-1590326256547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40160,DS-2fa83334-5c59-4763-8c41-8e4f3ff0a052,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-e917e922-cf45-455f-88f7-2c17d2dfeb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-78a27bf4-9c91-4104-9951-46b8bab6fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-632165a3-6bdc-4d18-9c4d-06d8a7c4bf39,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-1dcbb79d-6925-45f2-b879-e6c51450a5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-fbf16cde-1ae5-434f-bd0e-9b28af407382,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-f0e9e79c-d967-414c-a527-3eb5a0958982,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-dfa0fa13-af65-4b1d-bed9-e5f62a370906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132004330-172.17.0.16-1590326256547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40160,DS-2fa83334-5c59-4763-8c41-8e4f3ff0a052,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-e917e922-cf45-455f-88f7-2c17d2dfeb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-78a27bf4-9c91-4104-9951-46b8bab6fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-632165a3-6bdc-4d18-9c4d-06d8a7c4bf39,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-1dcbb79d-6925-45f2-b879-e6c51450a5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-fbf16cde-1ae5-434f-bd0e-9b28af407382,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-f0e9e79c-d967-414c-a527-3eb5a0958982,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-dfa0fa13-af65-4b1d-bed9-e5f62a370906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544412718-172.17.0.16-1590326661100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45158,DS-9625f402-1394-4488-a462-d09d85cf39d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-628f793b-c83f-47db-b992-ecedc0cba56f,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-73108fae-eb0b-4273-a3c4-2964fa651a48,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-c41c108d-0d7c-4156-a0f0-6eea066e1202,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-2851d640-8d6d-4fd7-9d56-2acf4416212b,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-a3bc990d-3bf8-495e-b670-e2aa5ee6b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-c8361717-7301-46de-83ca-8196843d6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-4aafa2fe-21bc-4150-a636-98cb31675709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544412718-172.17.0.16-1590326661100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45158,DS-9625f402-1394-4488-a462-d09d85cf39d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-628f793b-c83f-47db-b992-ecedc0cba56f,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-73108fae-eb0b-4273-a3c4-2964fa651a48,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-c41c108d-0d7c-4156-a0f0-6eea066e1202,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-2851d640-8d6d-4fd7-9d56-2acf4416212b,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-a3bc990d-3bf8-495e-b670-e2aa5ee6b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-c8361717-7301-46de-83ca-8196843d6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-4aafa2fe-21bc-4150-a636-98cb31675709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1314300605-172.17.0.16-1590326884908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34820,DS-5d5036ad-88e6-440d-904a-3120d3806bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-65cf1bef-16d9-4da3-b869-b6606ae15c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-53aa228f-1238-416f-a43f-faf0bff9920e,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-33f90ef3-f674-404f-b913-38bd12562d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-06cb5d95-40f9-498f-b133-f97bbcda0f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-7e91dc55-7eb7-45e9-83ae-72d9297a6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8753214a-cbad-4563-b355-84fdfb4bb7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-103fb3ae-c6a7-4b06-a6f0-193c7a064831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1314300605-172.17.0.16-1590326884908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34820,DS-5d5036ad-88e6-440d-904a-3120d3806bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-65cf1bef-16d9-4da3-b869-b6606ae15c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-53aa228f-1238-416f-a43f-faf0bff9920e,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-33f90ef3-f674-404f-b913-38bd12562d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-06cb5d95-40f9-498f-b133-f97bbcda0f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-7e91dc55-7eb7-45e9-83ae-72d9297a6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8753214a-cbad-4563-b355-84fdfb4bb7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-103fb3ae-c6a7-4b06-a6f0-193c7a064831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699027014-172.17.0.16-1590326918031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-ec6b4f6e-cdf8-4d31-9a73-50c06db897de,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-08b54640-aea2-45b9-bd55-a03efabe4b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-bbcfed0b-e972-43d8-86cf-7f6c25d13400,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-238d3cdb-f698-4a02-a1aa-4107f33a6b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-f68896b1-5a62-45f1-b428-24b6795f6ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-4d8c051b-f71c-433e-9e13-7f350d2c77a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-32163911-47eb-4a2f-9d59-723943615894,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-ce41205e-bb49-4936-95e8-5d850982c552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699027014-172.17.0.16-1590326918031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39982,DS-ec6b4f6e-cdf8-4d31-9a73-50c06db897de,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-08b54640-aea2-45b9-bd55-a03efabe4b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-bbcfed0b-e972-43d8-86cf-7f6c25d13400,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-238d3cdb-f698-4a02-a1aa-4107f33a6b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-f68896b1-5a62-45f1-b428-24b6795f6ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-4d8c051b-f71c-433e-9e13-7f350d2c77a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-32163911-47eb-4a2f-9d59-723943615894,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-ce41205e-bb49-4936-95e8-5d850982c552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884277159-172.17.0.16-1590326960842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44453,DS-fdc370d6-b5de-4402-a839-23c68ec5d415,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-8c46f7de-5086-41b1-b7a0-5fe447af9a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-32438512-ed07-4434-afe2-1262c63a4b58,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-eaa8ec85-fbd7-4ae3-ab7c-67f65151238c,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-ee68ca98-b75b-4d9a-97d7-c4efe53bd398,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-e707ebae-b6fd-487d-873f-73a57dbe38f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-e23556a8-8ae1-4fe4-86ed-994a3b56ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-a5aa8e52-fca2-4a42-8e42-79c4197e82c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-884277159-172.17.0.16-1590326960842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44453,DS-fdc370d6-b5de-4402-a839-23c68ec5d415,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-8c46f7de-5086-41b1-b7a0-5fe447af9a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-32438512-ed07-4434-afe2-1262c63a4b58,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-eaa8ec85-fbd7-4ae3-ab7c-67f65151238c,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-ee68ca98-b75b-4d9a-97d7-c4efe53bd398,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-e707ebae-b6fd-487d-873f-73a57dbe38f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-e23556a8-8ae1-4fe4-86ed-994a3b56ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-a5aa8e52-fca2-4a42-8e42-79c4197e82c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833693738-172.17.0.16-1590327183054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-aa5df86d-2cd0-473a-b164-32e82084603a,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-9a5d8139-c0b5-4bc9-8a9b-9ca1b8585c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-c00a3c4d-dbeb-47c0-a1a5-4d9e6894ab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-91315f99-0d64-42c5-b794-c33722e43a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-93f4fd49-b538-4899-bae6-a727a299ac10,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-7c4475c8-3346-491d-a3d5-615079f709a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-e2410670-8b37-4f33-a2eb-abda7392cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-9418c238-effd-430d-9216-9c0f74699f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833693738-172.17.0.16-1590327183054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-aa5df86d-2cd0-473a-b164-32e82084603a,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-9a5d8139-c0b5-4bc9-8a9b-9ca1b8585c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-c00a3c4d-dbeb-47c0-a1a5-4d9e6894ab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-91315f99-0d64-42c5-b794-c33722e43a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-93f4fd49-b538-4899-bae6-a727a299ac10,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-7c4475c8-3346-491d-a3d5-615079f709a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-e2410670-8b37-4f33-a2eb-abda7392cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-9418c238-effd-430d-9216-9c0f74699f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869305250-172.17.0.16-1590327216539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36652,DS-c691ff83-d1b7-4cf7-af3e-63e7ae2a9aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-26b9974f-fd7c-4203-9265-8ec7aecc8ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-dd195b8c-7c2f-4252-9252-8907a6a4505f,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-1a39e996-8e38-4d8b-b4dd-d4c8359276e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-c06a7c6a-c363-42d5-b41d-cb0c82272f40,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-42d5a264-6037-43e3-b071-fb34f3e29d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-2ad6cfc4-4c37-478b-8408-95c1fd2ce9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-bcbde23d-d1ad-4cb0-8a63-2597aeb804a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869305250-172.17.0.16-1590327216539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36652,DS-c691ff83-d1b7-4cf7-af3e-63e7ae2a9aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-26b9974f-fd7c-4203-9265-8ec7aecc8ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-dd195b8c-7c2f-4252-9252-8907a6a4505f,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-1a39e996-8e38-4d8b-b4dd-d4c8359276e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-c06a7c6a-c363-42d5-b41d-cb0c82272f40,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-42d5a264-6037-43e3-b071-fb34f3e29d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-2ad6cfc4-4c37-478b-8408-95c1fd2ce9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-bcbde23d-d1ad-4cb0-8a63-2597aeb804a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178118604-172.17.0.16-1590327377382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-346ffe0a-f7a6-4625-94e8-a2f6356d2a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-54ffe440-8af4-430e-881f-efefc36816c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-34f88038-77b7-4275-a85d-7ad210a94fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-8302d578-83ec-4c4a-a86f-3a8f595bdbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-6d48c22b-9e11-454e-af5f-673cacda54a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-01693121-4305-45bf-96dc-e972f82f9b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-b8b239d5-4468-468f-8eeb-1449301db69d,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-bba53323-e222-4e99-8ae4-eeb3326fef35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-178118604-172.17.0.16-1590327377382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-346ffe0a-f7a6-4625-94e8-a2f6356d2a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-54ffe440-8af4-430e-881f-efefc36816c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-34f88038-77b7-4275-a85d-7ad210a94fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-8302d578-83ec-4c4a-a86f-3a8f595bdbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-6d48c22b-9e11-454e-af5f-673cacda54a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-01693121-4305-45bf-96dc-e972f82f9b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-b8b239d5-4468-468f-8eeb-1449301db69d,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-bba53323-e222-4e99-8ae4-eeb3326fef35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940474554-172.17.0.16-1590327592408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39802,DS-a18e9e59-7e88-45cf-bd8f-008e67a24e06,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-06a6549e-4aa7-4f86-85b9-89921aff85fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-169ba205-56d4-47a1-997d-418a8c3910a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-8c0a43c5-19f3-4c3a-9a7e-afb4afcba529,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-38c833bd-5882-4d52-8f77-ba6fda7b6e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-c8caa950-322c-42d4-abda-ff90acaba5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-11bc79bc-2979-4efd-bf2d-472032d643d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-fde61d53-6813-46cc-be75-7f8ad96ea58c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940474554-172.17.0.16-1590327592408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39802,DS-a18e9e59-7e88-45cf-bd8f-008e67a24e06,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-06a6549e-4aa7-4f86-85b9-89921aff85fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-169ba205-56d4-47a1-997d-418a8c3910a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-8c0a43c5-19f3-4c3a-9a7e-afb4afcba529,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-38c833bd-5882-4d52-8f77-ba6fda7b6e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-c8caa950-322c-42d4-abda-ff90acaba5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-11bc79bc-2979-4efd-bf2d-472032d643d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-fde61d53-6813-46cc-be75-7f8ad96ea58c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156439577-172.17.0.16-1590327815283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35076,DS-3c005f06-5f78-45d0-9c94-4dafacb0d258,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-d19b5135-3aa5-4be9-92bf-782d051b8efc,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-7f87660c-1117-465b-b56b-e18f14361947,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-14f169ae-8264-41a6-87f6-af27268cba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-12b5ebd7-9efa-4e79-839b-dccb5c472067,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-d9583a73-93d9-4c37-9cb3-b8de44cba804,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-c7f773bf-1ae9-406e-bad6-fe732d3b5216,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-9b658c80-73fb-4e4e-80b9-c57ccec4b9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156439577-172.17.0.16-1590327815283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35076,DS-3c005f06-5f78-45d0-9c94-4dafacb0d258,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-d19b5135-3aa5-4be9-92bf-782d051b8efc,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-7f87660c-1117-465b-b56b-e18f14361947,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-14f169ae-8264-41a6-87f6-af27268cba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-12b5ebd7-9efa-4e79-839b-dccb5c472067,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-d9583a73-93d9-4c37-9cb3-b8de44cba804,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-c7f773bf-1ae9-406e-bad6-fe732d3b5216,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-9b658c80-73fb-4e4e-80b9-c57ccec4b9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817076323-172.17.0.16-1590328380272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-82e163a9-b473-4cc2-8e94-03b94f28b9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-00730d33-054d-4963-9005-c5e5fd7a3446,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-13b63603-8a7d-4a3e-9a53-2ff298f8fdee,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-88403568-414e-42f2-bfb2-79df802968ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-bd2b22a0-8755-4a9e-ba12-dc352018d065,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-14e44730-3824-44c7-9426-bcef22ac504c,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-543d9bfd-75d0-4d25-8b3d-aa8aa6415b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-73f9b100-1d71-438d-a588-d62960e79f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817076323-172.17.0.16-1590328380272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-82e163a9-b473-4cc2-8e94-03b94f28b9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-00730d33-054d-4963-9005-c5e5fd7a3446,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-13b63603-8a7d-4a3e-9a53-2ff298f8fdee,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-88403568-414e-42f2-bfb2-79df802968ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-bd2b22a0-8755-4a9e-ba12-dc352018d065,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-14e44730-3824-44c7-9426-bcef22ac504c,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-543d9bfd-75d0-4d25-8b3d-aa8aa6415b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-73f9b100-1d71-438d-a588-d62960e79f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532627681-172.17.0.16-1590328636024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35152,DS-f6232cd8-2dc4-4b23-b81f-dd24e5a5716d,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-daeab060-2f51-4411-8cae-ad5b5ee610e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-4953dd32-85ef-49e4-9cc7-406d3f7dad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-c0af65b6-c71c-479c-a23c-6e1a331ab386,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-bf315a04-c6e7-4371-b1f8-d63b6dd21522,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-d3364052-e822-454a-9d33-84c09ed5f131,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-a5bd8534-42bf-4a87-a715-0052aa2baff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-7789830c-38b5-47fb-96a7-576c09600283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-532627681-172.17.0.16-1590328636024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35152,DS-f6232cd8-2dc4-4b23-b81f-dd24e5a5716d,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-daeab060-2f51-4411-8cae-ad5b5ee610e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-4953dd32-85ef-49e4-9cc7-406d3f7dad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-c0af65b6-c71c-479c-a23c-6e1a331ab386,DISK], DatanodeInfoWithStorage[127.0.0.1:46560,DS-bf315a04-c6e7-4371-b1f8-d63b6dd21522,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-d3364052-e822-454a-9d33-84c09ed5f131,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-a5bd8534-42bf-4a87-a715-0052aa2baff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-7789830c-38b5-47fb-96a7-576c09600283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439447349-172.17.0.16-1590329422692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43753,DS-d5d8232d-0661-4467-82bb-aced4b6db9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-031da13b-a009-4c96-b08d-e7cee1ea5f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-d5ad1770-aaff-4beb-a6ef-82980ac4c388,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-24588dc0-244f-4814-944a-51b3956b376b,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-7caf99b0-cbd3-4c9d-bd25-336cabf4cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-b26a3896-26c6-40f5-8eb5-f8fcd978f4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-5f4cae49-9bf0-453a-9d04-11f6d7f6ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-88be6e91-226f-4a7c-a680-021ecfb5e173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439447349-172.17.0.16-1590329422692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43753,DS-d5d8232d-0661-4467-82bb-aced4b6db9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-031da13b-a009-4c96-b08d-e7cee1ea5f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-d5ad1770-aaff-4beb-a6ef-82980ac4c388,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-24588dc0-244f-4814-944a-51b3956b376b,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-7caf99b0-cbd3-4c9d-bd25-336cabf4cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-b26a3896-26c6-40f5-8eb5-f8fcd978f4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-5f4cae49-9bf0-453a-9d04-11f6d7f6ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-88be6e91-226f-4a7c-a680-021ecfb5e173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241102688-172.17.0.16-1590330725547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42096,DS-887c1efa-0393-46e3-90cd-51a559eb01ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-8dbaf217-5d59-433a-a4b8-57d1f40f633a,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-725b8303-a847-403c-a6d0-205f3d78f8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-c8f938e3-2a8d-4c3f-99da-98754dfcc160,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-49ec58a6-defb-4e5a-9176-13b85a3ed3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-0bbaa2da-c681-4731-a2de-b518702f9664,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-05ee5334-bfbd-4123-b12d-2e2be118e572,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-5c5669b3-4d3c-43c7-86ae-46b2cc1d6849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-241102688-172.17.0.16-1590330725547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42096,DS-887c1efa-0393-46e3-90cd-51a559eb01ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-8dbaf217-5d59-433a-a4b8-57d1f40f633a,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-725b8303-a847-403c-a6d0-205f3d78f8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-c8f938e3-2a8d-4c3f-99da-98754dfcc160,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-49ec58a6-defb-4e5a-9176-13b85a3ed3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-0bbaa2da-c681-4731-a2de-b518702f9664,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-05ee5334-bfbd-4123-b12d-2e2be118e572,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-5c5669b3-4d3c-43c7-86ae-46b2cc1d6849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088262175-172.17.0.16-1590330864309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39781,DS-951b7471-1e22-47d9-aa2d-2a55560953d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-dac1cf6a-8fa3-4871-81b8-1748b4d1eedf,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-dbb2e6ff-4a84-4d9c-be18-d276a8dd9996,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-6d7f6f49-fd01-4c3e-9032-834794d824a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-465967bf-dc1f-4f65-bf05-69a2eff06bca,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-7fea9ee8-3898-40e6-a357-2ac19a935f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-cc9eb7dd-f1c1-467a-87d5-8131b9c09397,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-139fa6cf-d39e-4851-8d4d-3ebb628153c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088262175-172.17.0.16-1590330864309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39781,DS-951b7471-1e22-47d9-aa2d-2a55560953d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-dac1cf6a-8fa3-4871-81b8-1748b4d1eedf,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-dbb2e6ff-4a84-4d9c-be18-d276a8dd9996,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-6d7f6f49-fd01-4c3e-9032-834794d824a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-465967bf-dc1f-4f65-bf05-69a2eff06bca,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-7fea9ee8-3898-40e6-a357-2ac19a935f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-cc9eb7dd-f1c1-467a-87d5-8131b9c09397,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-139fa6cf-d39e-4851-8d4d-3ebb628153c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: DataNode
v1: 1k
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1986270845-172.17.0.16-1590331044338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45631,DS-d39e7f79-fa02-4a9e-83d9-fc3af6185aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-6808c1cb-8079-4a9e-8977-6dc8949d1ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-985ca903-fb93-4aac-bb14-3f2b51723baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-2d0d72be-7739-4095-a806-a2344a287e56,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-071c5fc5-a2cd-45cf-a85f-10c08f56c56d,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-5670102c-97ce-4b37-8c2d-7bb952d4af53,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-74e09eb5-abec-4927-9c45-16d391e00041,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-6679aa4b-fe93-44ef-8d71-41c911ca4895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1986270845-172.17.0.16-1590331044338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45631,DS-d39e7f79-fa02-4a9e-83d9-fc3af6185aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-6808c1cb-8079-4a9e-8977-6dc8949d1ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-985ca903-fb93-4aac-bb14-3f2b51723baa,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-2d0d72be-7739-4095-a806-a2344a287e56,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-071c5fc5-a2cd-45cf-a85f-10c08f56c56d,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-5670102c-97ce-4b37-8c2d-7bb952d4af53,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-74e09eb5-abec-4927-9c45-16d391e00041,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-6679aa4b-fe93-44ef-8d71-41c911ca4895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5448
