reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
fail. do 5 v1v1 v2v2 tests to filter false alarm
failed v1v2 test: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5 v1 3.0.0 v2 1.0.0

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v1 and v2v2 succeed for 5 times, it is issue
---------------------------------------full report---------------------------------------------
reconf_parameter: hadoop.common.configuration.version
component: hdfs:DataNode
v1: 3.0.0
v2: 1.0.0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450098730-172.17.0.4-1594333379224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33422,DS-4ead4eb1-8e55-4291-8142-5144bbc7ed42,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-0c22f2a4-bac3-46e6-bef6-40c3289aa7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-25967d2a-8630-4c15-829c-24dc101a8c37,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-583f37ce-cdec-416c-a95f-10df23fab844,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-9b8b5624-1b9c-48ab-8366-ea51f93d9420,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-82af987d-d345-431b-8fda-227138cc2d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-ce1bd28a-fa94-4291-944a-0058ab4ed65a,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-2f71a009-995e-4295-b0e5-e6ce91a63dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450098730-172.17.0.4-1594333379224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33422,DS-4ead4eb1-8e55-4291-8142-5144bbc7ed42,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-0c22f2a4-bac3-46e6-bef6-40c3289aa7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-25967d2a-8630-4c15-829c-24dc101a8c37,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-583f37ce-cdec-416c-a95f-10df23fab844,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-9b8b5624-1b9c-48ab-8366-ea51f93d9420,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-82af987d-d345-431b-8fda-227138cc2d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-ce1bd28a-fa94-4291-944a-0058ab4ed65a,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-2f71a009-995e-4295-b0e5-e6ce91a63dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


Total execution time in seconds : 394
1
