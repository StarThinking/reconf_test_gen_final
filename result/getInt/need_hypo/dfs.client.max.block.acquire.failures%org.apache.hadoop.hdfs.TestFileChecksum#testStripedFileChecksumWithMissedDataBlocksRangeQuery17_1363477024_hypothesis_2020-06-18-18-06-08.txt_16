reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721788929-172.17.0.27-1592504017183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34755,DS-ffc95612-359d-4933-a852-2495b0bf2aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-0fe442c6-323f-4528-8c8e-7b355e1c9a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-8c212a4b-be79-413c-90bc-b4c9f83ab485,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-36c1ee20-aad2-40d6-b660-ef6b69198868,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-9eb94a19-c61e-467c-93e2-5bcb8c6c84a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-bc294674-f26a-40d9-9fd9-9bf5f5afaf83,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-5d70673a-05be-460b-9140-297f482745ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-bc07f184-c843-4fd1-90a0-be92d5becca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721788929-172.17.0.27-1592504017183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34755,DS-ffc95612-359d-4933-a852-2495b0bf2aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-0fe442c6-323f-4528-8c8e-7b355e1c9a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-8c212a4b-be79-413c-90bc-b4c9f83ab485,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-36c1ee20-aad2-40d6-b660-ef6b69198868,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-9eb94a19-c61e-467c-93e2-5bcb8c6c84a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-bc294674-f26a-40d9-9fd9-9bf5f5afaf83,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-5d70673a-05be-460b-9140-297f482745ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-bc07f184-c843-4fd1-90a0-be92d5becca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254466892-172.17.0.27-1592504332003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-0e2045fa-797e-4d7c-a1d0-9b6b062d3419,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-a034821a-73c1-48da-8bf6-9ccc05f605a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-2e6595d2-f7ff-4916-9605-16374a91592f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-2cbca8db-822b-48eb-af40-3f00d06e81d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-ef2555a9-48f5-42f6-a6a7-10659badd043,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-6a06df8f-9e6d-4900-bfa9-d2eb8d2ff508,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-ccf56e60-0cd3-4a27-b4ce-1fb868e7f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-c7da10a9-cc75-4cb7-be4a-4897b8332875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-254466892-172.17.0.27-1592504332003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-0e2045fa-797e-4d7c-a1d0-9b6b062d3419,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-a034821a-73c1-48da-8bf6-9ccc05f605a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-2e6595d2-f7ff-4916-9605-16374a91592f,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-2cbca8db-822b-48eb-af40-3f00d06e81d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-ef2555a9-48f5-42f6-a6a7-10659badd043,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-6a06df8f-9e6d-4900-bfa9-d2eb8d2ff508,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-ccf56e60-0cd3-4a27-b4ce-1fb868e7f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-c7da10a9-cc75-4cb7-be4a-4897b8332875,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587250166-172.17.0.27-1592504465845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33381,DS-25625869-cc1c-43c7-8fec-fefa8621a336,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-8df76a84-5c22-4d7f-b282-2563b2caded9,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-65592529-4daa-4ee7-990b-690cd112404d,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-9612c035-8f84-47de-bc73-3ee9f326f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-c0429708-3093-4dfd-93e8-f185f672d0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-f43de9d6-1715-498b-be83-f5637adbbe04,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-48b1642d-1b1a-4a9d-b5d8-bd5f84b2ce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-83aa09f3-45ec-4a20-b0e5-b48d1f4c4e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587250166-172.17.0.27-1592504465845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33381,DS-25625869-cc1c-43c7-8fec-fefa8621a336,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-8df76a84-5c22-4d7f-b282-2563b2caded9,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-65592529-4daa-4ee7-990b-690cd112404d,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-9612c035-8f84-47de-bc73-3ee9f326f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-c0429708-3093-4dfd-93e8-f185f672d0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-f43de9d6-1715-498b-be83-f5637adbbe04,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-48b1642d-1b1a-4a9d-b5d8-bd5f84b2ce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-83aa09f3-45ec-4a20-b0e5-b48d1f4c4e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152365823-172.17.0.27-1592504762653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38216,DS-efdc78cc-1fee-460a-97fe-7567eaf57586,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-3b0cbe9e-5ac3-464a-a35d-ba1e7c8da8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-af93d7af-0d20-4a9f-9d4a-7da67c07b454,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-fc828054-3173-43d6-973d-8380a41c277b,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-47b1c5f2-af7f-4e03-9dda-b6d981c7497b,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-2e835887-4f72-430c-a7ac-592a4b7bbc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-71a3dd95-2679-4e86-8a76-37a347aa80d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-c60e26b4-109f-4a71-9163-7437254c72d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152365823-172.17.0.27-1592504762653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38216,DS-efdc78cc-1fee-460a-97fe-7567eaf57586,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-3b0cbe9e-5ac3-464a-a35d-ba1e7c8da8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-af93d7af-0d20-4a9f-9d4a-7da67c07b454,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-fc828054-3173-43d6-973d-8380a41c277b,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-47b1c5f2-af7f-4e03-9dda-b6d981c7497b,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-2e835887-4f72-430c-a7ac-592a4b7bbc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-71a3dd95-2679-4e86-8a76-37a347aa80d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-c60e26b4-109f-4a71-9163-7437254c72d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515126234-172.17.0.27-1592505654991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33232,DS-ab90f19a-ce6f-4cbe-a01a-d46f26c8d8af,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-ecad6932-d91a-4809-8b42-015c2a3dc936,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-064d1149-8b3f-4590-9c51-7c90e5bb6bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-b4e65f17-2c8b-463b-9594-3a7bcf17c100,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-869bbe8a-85fc-4731-a55c-ba98505905ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-5cd6d628-7af1-431b-ab33-f20510edda31,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-bb135e43-8b0c-428b-90c8-891c0da854c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-813c183e-b61e-4ac8-8640-58c904919b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515126234-172.17.0.27-1592505654991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33232,DS-ab90f19a-ce6f-4cbe-a01a-d46f26c8d8af,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-ecad6932-d91a-4809-8b42-015c2a3dc936,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-064d1149-8b3f-4590-9c51-7c90e5bb6bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-b4e65f17-2c8b-463b-9594-3a7bcf17c100,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-869bbe8a-85fc-4731-a55c-ba98505905ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-5cd6d628-7af1-431b-ab33-f20510edda31,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-bb135e43-8b0c-428b-90c8-891c0da854c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-813c183e-b61e-4ac8-8640-58c904919b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862614835-172.17.0.27-1592506354221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-d7c86e51-f2c9-4cf9-906b-533480c4446d,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-a523c1d3-2b4b-4f78-8504-3a50dc0f1094,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-8002819c-b95b-4c92-9101-9dc2eb67dd11,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-6399c3c2-3265-4cb3-856b-52302c82726c,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-cf9c2297-5754-4af3-8e17-067e653baad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-9c9fea28-8455-4788-8d4c-2b807f4e4939,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-5edf8b1a-154c-4e14-8619-6ce0365388e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-68696357-eb3e-4009-8c7f-cb8740ff3f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862614835-172.17.0.27-1592506354221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-d7c86e51-f2c9-4cf9-906b-533480c4446d,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-a523c1d3-2b4b-4f78-8504-3a50dc0f1094,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-8002819c-b95b-4c92-9101-9dc2eb67dd11,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-6399c3c2-3265-4cb3-856b-52302c82726c,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-cf9c2297-5754-4af3-8e17-067e653baad5,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-9c9fea28-8455-4788-8d4c-2b807f4e4939,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-5edf8b1a-154c-4e14-8619-6ce0365388e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-68696357-eb3e-4009-8c7f-cb8740ff3f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480617494-172.17.0.27-1592506642961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-9f988766-eb52-4be0-946a-e28981664546,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-5d796e35-d851-4370-92ef-fd0db1edd368,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-d624ec1f-d9af-47e4-9139-ba5bb56920e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-c3988b0f-401d-4372-b8c2-f3d02a430fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-96a3f60d-3960-4502-a21f-3a527fa2cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-f41f117c-0bbb-41a8-a380-41f6926438d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-15ee880e-0397-4de1-b86c-52936a8ad48d,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-4175acc2-5216-4530-88fa-de8afff41d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480617494-172.17.0.27-1592506642961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37051,DS-9f988766-eb52-4be0-946a-e28981664546,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-5d796e35-d851-4370-92ef-fd0db1edd368,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-d624ec1f-d9af-47e4-9139-ba5bb56920e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-c3988b0f-401d-4372-b8c2-f3d02a430fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-96a3f60d-3960-4502-a21f-3a527fa2cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-f41f117c-0bbb-41a8-a380-41f6926438d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-15ee880e-0397-4de1-b86c-52936a8ad48d,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-4175acc2-5216-4530-88fa-de8afff41d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886027423-172.17.0.27-1592507267960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33731,DS-e8fa1fc4-f45f-4825-a4c2-52f044f0434b,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-e9d6a8a8-ac16-41cf-83fc-ef12be8abb39,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-dd3d9753-088f-429e-8c46-e057a0b8eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-5521a31d-9569-4610-9276-ebaf31ac733d,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-cc24e911-8329-499d-8c25-95a7bd3d2406,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-ec55faaf-c397-471b-bb24-c2d5321ed437,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-fcb13329-6786-4926-ab64-d1240dfeae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-3c8d760d-5bca-42f2-8d94-e20184eae7bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886027423-172.17.0.27-1592507267960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33731,DS-e8fa1fc4-f45f-4825-a4c2-52f044f0434b,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-e9d6a8a8-ac16-41cf-83fc-ef12be8abb39,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-dd3d9753-088f-429e-8c46-e057a0b8eb54,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-5521a31d-9569-4610-9276-ebaf31ac733d,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-cc24e911-8329-499d-8c25-95a7bd3d2406,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-ec55faaf-c397-471b-bb24-c2d5321ed437,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-fcb13329-6786-4926-ab64-d1240dfeae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-3c8d760d-5bca-42f2-8d94-e20184eae7bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765086535-172.17.0.27-1592507424783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-1cfcef89-5965-4f37-a2e1-c0afea9d7e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-56ef5da7-51c0-41f3-87eb-a802c2859a45,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-6446b020-98b6-4887-95af-e60e3daf5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-d42b66be-8b9a-4059-b615-a9c0171777a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-d85ebc78-4f43-4bcc-b36a-225d291b1459,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-8e2f057f-12aa-4b6b-b117-071480388b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-0433debc-6c74-4a68-b1ac-a59e14ca8828,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-cf3e53b4-e386-46f2-a330-98a53a2b62e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-765086535-172.17.0.27-1592507424783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-1cfcef89-5965-4f37-a2e1-c0afea9d7e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-56ef5da7-51c0-41f3-87eb-a802c2859a45,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-6446b020-98b6-4887-95af-e60e3daf5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-d42b66be-8b9a-4059-b615-a9c0171777a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-d85ebc78-4f43-4bcc-b36a-225d291b1459,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-8e2f057f-12aa-4b6b-b117-071480388b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-0433debc-6c74-4a68-b1ac-a59e14ca8828,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-cf3e53b4-e386-46f2-a330-98a53a2b62e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503596175-172.17.0.27-1592508195123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39964,DS-9a8f5b0a-f714-49b6-9f16-ecfc00438f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-7429943f-7f78-4132-a4e0-516363c6e060,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-23db3f3a-1f85-4145-beff-63ddafd80860,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-a6381614-e16d-49f5-b716-7984bd43ceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-2ca76e90-c447-4d94-97f8-de9b36c88403,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-fbf1b74c-a7c9-4422-823d-cf6e5e458f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-b5d21a39-7f37-4cc5-92f1-70358eeadc41,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-37e8367b-9d3c-4c53-bb4e-8f3bb7058840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503596175-172.17.0.27-1592508195123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39964,DS-9a8f5b0a-f714-49b6-9f16-ecfc00438f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-7429943f-7f78-4132-a4e0-516363c6e060,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-23db3f3a-1f85-4145-beff-63ddafd80860,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-a6381614-e16d-49f5-b716-7984bd43ceeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-2ca76e90-c447-4d94-97f8-de9b36c88403,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-fbf1b74c-a7c9-4422-823d-cf6e5e458f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-b5d21a39-7f37-4cc5-92f1-70358eeadc41,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-37e8367b-9d3c-4c53-bb4e-8f3bb7058840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139205516-172.17.0.27-1592508302990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-2a8d89b7-be79-4e9b-aa8a-7ce7e4b57f94,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-66b86c5d-f98a-441b-8ed1-3544764b8adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-d290fd7e-56e0-4ac4-99b0-29e685bbb4df,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-6d61ac8e-17e4-4a92-8dc9-caebf0ff8b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-8ed466d0-49ea-49f2-8483-16d3f84ef09e,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-43768157-51c2-4c35-b1ad-886732271fae,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-8b286853-7fa7-4955-8743-dfdab5e593af,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-6133339d-1d47-44ed-8f38-ce0a0fe2fbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139205516-172.17.0.27-1592508302990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44241,DS-2a8d89b7-be79-4e9b-aa8a-7ce7e4b57f94,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-66b86c5d-f98a-441b-8ed1-3544764b8adc,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-d290fd7e-56e0-4ac4-99b0-29e685bbb4df,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-6d61ac8e-17e4-4a92-8dc9-caebf0ff8b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-8ed466d0-49ea-49f2-8483-16d3f84ef09e,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-43768157-51c2-4c35-b1ad-886732271fae,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-8b286853-7fa7-4955-8743-dfdab5e593af,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-6133339d-1d47-44ed-8f38-ce0a0fe2fbc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 4922
