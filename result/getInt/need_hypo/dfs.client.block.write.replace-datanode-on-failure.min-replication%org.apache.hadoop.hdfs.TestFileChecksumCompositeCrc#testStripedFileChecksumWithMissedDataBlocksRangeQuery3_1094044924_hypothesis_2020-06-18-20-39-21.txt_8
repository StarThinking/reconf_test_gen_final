reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021246788-172.17.0.13-1592513212728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-1365134a-dd25-4d4d-ac0c-6c2e87b70fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-74bc3787-44b8-4835-ba40-23cc3da3ab82,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-24ab9673-8667-42a4-8ae1-71801e8ae8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-a2516fce-96f6-48c2-9dc6-1566d901c538,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-bc5ec791-ce4c-4287-9257-4664ea04b41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-3b31e5dc-ff6e-4b15-b498-8ba8a9781f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-90842110-f134-43f1-b352-50c62d871f69,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-5e4714a7-93a1-46cb-bd03-8bc66e7137e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021246788-172.17.0.13-1592513212728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-1365134a-dd25-4d4d-ac0c-6c2e87b70fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-74bc3787-44b8-4835-ba40-23cc3da3ab82,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-24ab9673-8667-42a4-8ae1-71801e8ae8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-a2516fce-96f6-48c2-9dc6-1566d901c538,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-bc5ec791-ce4c-4287-9257-4664ea04b41c,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-3b31e5dc-ff6e-4b15-b498-8ba8a9781f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-90842110-f134-43f1-b352-50c62d871f69,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-5e4714a7-93a1-46cb-bd03-8bc66e7137e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117858192-172.17.0.13-1592513423885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34735,DS-f2baae68-adae-463d-933b-ebc6709ccf15,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-41a87dfb-ca90-43e4-b7c3-8a9259c9bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-f05351e7-ce86-46e4-ac31-e55cd7728141,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-7df86683-727f-4674-8ad4-4487fe7999cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-c594ac55-ee08-4f88-b66e-97efc453a06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-0830f9aa-7dd8-4709-9dc1-1d47e1ade0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-7d953e51-803c-411f-964c-2aa1f6f09824,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-6c880c9b-e730-4f51-ac54-6f28906fcb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117858192-172.17.0.13-1592513423885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34735,DS-f2baae68-adae-463d-933b-ebc6709ccf15,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-41a87dfb-ca90-43e4-b7c3-8a9259c9bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-f05351e7-ce86-46e4-ac31-e55cd7728141,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-7df86683-727f-4674-8ad4-4487fe7999cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-c594ac55-ee08-4f88-b66e-97efc453a06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-0830f9aa-7dd8-4709-9dc1-1d47e1ade0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-7d953e51-803c-411f-964c-2aa1f6f09824,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-6c880c9b-e730-4f51-ac54-6f28906fcb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791224131-172.17.0.13-1592514217865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40577,DS-539e8ce4-cbf0-48d1-8d49-17435631e39b,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-f29e7e35-1ed1-4535-9535-6ad3ceead966,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-7c7389b0-ca90-461e-9166-5eb2e7b70d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-afe6f493-b002-4b7a-8955-8b8eadb8ac05,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-97c37807-332d-465c-b182-234dd5c879a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-63f88c8a-01e0-4126-a7d7-d314b82c21fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-6dc7e49c-4dfe-4fb0-8dc2-e14753bc1b54,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-ac677d28-cbb0-4961-befe-7a4c5a84d82f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791224131-172.17.0.13-1592514217865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40577,DS-539e8ce4-cbf0-48d1-8d49-17435631e39b,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-f29e7e35-1ed1-4535-9535-6ad3ceead966,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-7c7389b0-ca90-461e-9166-5eb2e7b70d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-afe6f493-b002-4b7a-8955-8b8eadb8ac05,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-97c37807-332d-465c-b182-234dd5c879a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-63f88c8a-01e0-4126-a7d7-d314b82c21fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-6dc7e49c-4dfe-4fb0-8dc2-e14753bc1b54,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-ac677d28-cbb0-4961-befe-7a4c5a84d82f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598116865-172.17.0.13-1592514286343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43117,DS-ec71118b-5802-4ee8-855a-9a2a92131154,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-67d727a6-79d3-4643-a2ff-b923b2701a04,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-4612e42c-0ed8-405c-97be-48c6372f5ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-ad0b6a46-5997-46d3-aa77-9856a945d8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-ec2956ad-40a5-4022-b157-b724e0dd1326,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-954e6142-67ec-4eb1-b977-8e298eb0d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-972f6410-3c25-46e3-96b3-9d2ec64fed9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-a73f70df-0f58-409d-b8b5-72e1fc675cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598116865-172.17.0.13-1592514286343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43117,DS-ec71118b-5802-4ee8-855a-9a2a92131154,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-67d727a6-79d3-4643-a2ff-b923b2701a04,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-4612e42c-0ed8-405c-97be-48c6372f5ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-ad0b6a46-5997-46d3-aa77-9856a945d8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-ec2956ad-40a5-4022-b157-b724e0dd1326,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-954e6142-67ec-4eb1-b977-8e298eb0d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-972f6410-3c25-46e3-96b3-9d2ec64fed9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-a73f70df-0f58-409d-b8b5-72e1fc675cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864604256-172.17.0.13-1592514334323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-c0e3b6d5-e896-4c17-8336-bb76d7de5f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-8e30c0df-d018-4895-b705-960053115ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-e8ec933d-3224-4575-9f1c-d2ab89138cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-641b5621-9c9a-45d8-9c50-699078f595a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-117fff09-2731-4308-8238-348638591046,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-f59a6115-659b-4fe1-9fa0-ab33d507a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-f0690772-f48d-41ee-a526-89ab88962e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-5d11a941-5c48-4351-bb61-6740bb54026f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864604256-172.17.0.13-1592514334323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-c0e3b6d5-e896-4c17-8336-bb76d7de5f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-8e30c0df-d018-4895-b705-960053115ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-e8ec933d-3224-4575-9f1c-d2ab89138cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-641b5621-9c9a-45d8-9c50-699078f595a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-117fff09-2731-4308-8238-348638591046,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-f59a6115-659b-4fe1-9fa0-ab33d507a0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-f0690772-f48d-41ee-a526-89ab88962e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-5d11a941-5c48-4351-bb61-6740bb54026f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571229873-172.17.0.13-1592514652803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41097,DS-341b3fe3-c7c6-4539-bf10-a897372069c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-e33d8b74-14c1-4f7d-b7e0-79c62fbe3fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-cb9136ca-7e55-43dc-bce8-99cc9a9c91f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-0ec86519-4e10-458c-884f-721d6a94b798,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-0c37de5d-e87f-4975-a86c-73a7a35e374b,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-de412dc7-07d7-4ac4-8dec-283047c540f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-5655de18-0a5e-4298-9500-6546a90151af,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-812ea7e4-5946-4699-af6b-54fe6657149a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571229873-172.17.0.13-1592514652803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41097,DS-341b3fe3-c7c6-4539-bf10-a897372069c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-e33d8b74-14c1-4f7d-b7e0-79c62fbe3fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-cb9136ca-7e55-43dc-bce8-99cc9a9c91f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-0ec86519-4e10-458c-884f-721d6a94b798,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-0c37de5d-e87f-4975-a86c-73a7a35e374b,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-de412dc7-07d7-4ac4-8dec-283047c540f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-5655de18-0a5e-4298-9500-6546a90151af,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-812ea7e4-5946-4699-af6b-54fe6657149a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348759347-172.17.0.13-1592514810184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34008,DS-66979b56-088c-4c37-b891-6fba84450617,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-49a0bff1-096f-4888-9f99-9db2c0f058c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-d10902c3-102a-4bf3-8ffd-c4eb570496ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-8c723b0d-51d6-4fd6-977c-d45001df0bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-c98220ea-88fb-42e3-b2ba-5d51fcf68549,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-c2752a62-3e1c-4f8d-bedc-09e6bd6c36ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-bd3d79d8-73e4-41ac-b0bf-2d283d54bd67,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-7ef44ced-39fd-461e-b787-e730870dc42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348759347-172.17.0.13-1592514810184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34008,DS-66979b56-088c-4c37-b891-6fba84450617,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-49a0bff1-096f-4888-9f99-9db2c0f058c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-d10902c3-102a-4bf3-8ffd-c4eb570496ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-8c723b0d-51d6-4fd6-977c-d45001df0bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-c98220ea-88fb-42e3-b2ba-5d51fcf68549,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-c2752a62-3e1c-4f8d-bedc-09e6bd6c36ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-bd3d79d8-73e4-41ac-b0bf-2d283d54bd67,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-7ef44ced-39fd-461e-b787-e730870dc42e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178052566-172.17.0.13-1592514950747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36007,DS-38eba96f-5859-406f-a9ea-05dcd75755ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-1251e62c-7293-469c-abf9-4e70f7ff17df,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-a55ab9d4-c475-41ea-a45a-4995cae8aa03,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-3e9f0fb6-6c25-41f1-a6cc-7085fb41f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-9628ee75-e562-4515-970e-7d1fae78b263,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-45bf9125-39ce-434c-a583-46a682255890,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-87b5fdb3-f5db-4128-95f8-ce66b4bea94b,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-0b805260-83b9-418b-b21b-c953294ed6d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178052566-172.17.0.13-1592514950747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36007,DS-38eba96f-5859-406f-a9ea-05dcd75755ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-1251e62c-7293-469c-abf9-4e70f7ff17df,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-a55ab9d4-c475-41ea-a45a-4995cae8aa03,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-3e9f0fb6-6c25-41f1-a6cc-7085fb41f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-9628ee75-e562-4515-970e-7d1fae78b263,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-45bf9125-39ce-434c-a583-46a682255890,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-87b5fdb3-f5db-4128-95f8-ce66b4bea94b,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-0b805260-83b9-418b-b21b-c953294ed6d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476227742-172.17.0.13-1592515279660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44147,DS-2ce2b49b-4c33-42b5-bac7-1c488f23a72d,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-e304cb31-ed66-46b0-afac-303fbb48a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-a8e3b3a0-4ec6-4de5-85e6-405c0f9f06b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-ea7202ab-5e6e-4d32-8640-9088d97cd73b,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-65fa532e-c608-4fd6-8cd3-b6a8881a52fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-aaed08a3-6569-4533-a076-0daf081413bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-45765b89-37c4-40a3-9d12-6e88b0ba6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-39c0849b-66f8-4d21-9312-b2dde3d66e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476227742-172.17.0.13-1592515279660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44147,DS-2ce2b49b-4c33-42b5-bac7-1c488f23a72d,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-e304cb31-ed66-46b0-afac-303fbb48a71f,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-a8e3b3a0-4ec6-4de5-85e6-405c0f9f06b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-ea7202ab-5e6e-4d32-8640-9088d97cd73b,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-65fa532e-c608-4fd6-8cd3-b6a8881a52fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-aaed08a3-6569-4533-a076-0daf081413bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-45765b89-37c4-40a3-9d12-6e88b0ba6d96,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-39c0849b-66f8-4d21-9312-b2dde3d66e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607913638-172.17.0.13-1592515655482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-57eec0bf-a1ce-471a-85fd-be220ee3820d,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-8d8119c4-6698-48c2-8e12-7972ad708a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-70bf489c-d47d-4ebe-8696-4e165c9bc838,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-25e957f3-08d8-49c0-995d-f2727dd4fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-073102a5-2f79-498f-9aab-b8bcbb717b56,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-dd365207-bd0b-4047-b04c-da8ca779484b,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-27317469-4b7d-40a5-afd1-6c8ea8e7fe52,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-509b1fb4-ec14-407c-be7b-8ad4be7897d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607913638-172.17.0.13-1592515655482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39595,DS-57eec0bf-a1ce-471a-85fd-be220ee3820d,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-8d8119c4-6698-48c2-8e12-7972ad708a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-70bf489c-d47d-4ebe-8696-4e165c9bc838,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-25e957f3-08d8-49c0-995d-f2727dd4fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-073102a5-2f79-498f-9aab-b8bcbb717b56,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-dd365207-bd0b-4047-b04c-da8ca779484b,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-27317469-4b7d-40a5-afd1-6c8ea8e7fe52,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-509b1fb4-ec14-407c-be7b-8ad4be7897d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346253476-172.17.0.13-1592515691456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34252,DS-359e6ba1-3715-45cf-b6cb-a4ab02d7a959,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-39ca34ae-69cb-4aed-a350-6726d0f21fce,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-39f4ad4f-73c3-4d5b-90eb-c36a4407acfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-0958faad-135a-434d-9b3c-558cc194b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-77fc7027-32d9-41d5-8209-ba09731d1b76,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-4dfafbb2-0561-4e7b-9fd8-897f64e254f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-8130dcbe-b534-4a5a-90c4-1b23c2386c68,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-106f407e-9bd1-4f11-853c-6e65d28a91f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346253476-172.17.0.13-1592515691456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34252,DS-359e6ba1-3715-45cf-b6cb-a4ab02d7a959,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-39ca34ae-69cb-4aed-a350-6726d0f21fce,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-39f4ad4f-73c3-4d5b-90eb-c36a4407acfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-0958faad-135a-434d-9b3c-558cc194b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-77fc7027-32d9-41d5-8209-ba09731d1b76,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-4dfafbb2-0561-4e7b-9fd8-897f64e254f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-8130dcbe-b534-4a5a-90c4-1b23c2386c68,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-106f407e-9bd1-4f11-853c-6e65d28a91f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770179045-172.17.0.13-1592516175495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46287,DS-1f6fac3f-09e2-4de9-af20-57c5cb17a8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-f3230b6c-22d3-4f5a-b89e-d7ceda45aba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-ae8b7107-c2ae-4315-9a05-5768a147baf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-921aa688-06ec-405d-989f-2f2da8532ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-12907000-ff62-403b-8f68-571dfb9ce879,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-7af6f599-ecf1-4bd2-9ae5-e4b6f0c9c377,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-d64f83d3-4729-4b61-9ed6-09e934d7a7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-98525869-a4fe-4b97-8e53-384258e6f906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770179045-172.17.0.13-1592516175495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46287,DS-1f6fac3f-09e2-4de9-af20-57c5cb17a8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-f3230b6c-22d3-4f5a-b89e-d7ceda45aba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-ae8b7107-c2ae-4315-9a05-5768a147baf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-921aa688-06ec-405d-989f-2f2da8532ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-12907000-ff62-403b-8f68-571dfb9ce879,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-7af6f599-ecf1-4bd2-9ae5-e4b6f0c9c377,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-d64f83d3-4729-4b61-9ed6-09e934d7a7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-98525869-a4fe-4b97-8e53-384258e6f906,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101170312-172.17.0.13-1592516744277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37400,DS-b380c4a0-9210-4b73-a7fa-93547baa5890,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-e14268a7-063f-4ba8-b753-9f615403b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-bd3e64f2-94f6-4642-a29f-e4f89c0be83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-7beb064a-f5a0-420c-a0d4-6f0cdd1a8d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-be097db9-4ab1-42d2-ad62-8adc68c1975d,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-082d5ee5-8090-4d20-87aa-09737235f759,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-5ac2cfcd-3c90-4bcb-8a9b-3d8b9e54b342,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-c871eb3b-b1bb-4a82-b6d5-e78b386e5b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101170312-172.17.0.13-1592516744277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37400,DS-b380c4a0-9210-4b73-a7fa-93547baa5890,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-e14268a7-063f-4ba8-b753-9f615403b5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-bd3e64f2-94f6-4642-a29f-e4f89c0be83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-7beb064a-f5a0-420c-a0d4-6f0cdd1a8d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-be097db9-4ab1-42d2-ad62-8adc68c1975d,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-082d5ee5-8090-4d20-87aa-09737235f759,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-5ac2cfcd-3c90-4bcb-8a9b-3d8b9e54b342,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-c871eb3b-b1bb-4a82-b6d5-e78b386e5b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895766422-172.17.0.13-1592516793436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-722c7bbc-2348-4e74-a2ec-fd257f028c37,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-0f9251d3-076a-4ea8-8b0f-68e6b088ba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-caf69ba3-fca1-47b6-b1cb-83e412c95d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-b3cdc356-da44-4cb4-94b3-06c812356bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-047303b1-0135-4760-b759-6d8625c13a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-c6382328-3a9d-4ec1-a346-602b104f2e08,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-f2267764-b3d0-4113-8448-37de9dc1eaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-62b86cc3-2bef-4461-a8b1-d179c0b3c310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895766422-172.17.0.13-1592516793436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-722c7bbc-2348-4e74-a2ec-fd257f028c37,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-0f9251d3-076a-4ea8-8b0f-68e6b088ba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-caf69ba3-fca1-47b6-b1cb-83e412c95d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-b3cdc356-da44-4cb4-94b3-06c812356bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-047303b1-0135-4760-b759-6d8625c13a06,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-c6382328-3a9d-4ec1-a346-602b104f2e08,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-f2267764-b3d0-4113-8448-37de9dc1eaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-62b86cc3-2bef-4461-a8b1-d179c0b3c310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046354487-172.17.0.13-1592517643658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-222aa951-9bfe-4558-b29e-638740fa69f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-c7fee2de-6f17-49c8-9803-29714e3792a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-c7d713ad-9b73-44ea-b7b4-e18aeda1c15e,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-7565cae6-19da-4b5b-8c7e-e529d5d0e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-8fb59639-affb-4eea-9444-c0d10d76d62e,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-267af56d-666e-4c8d-824d-843ead9ad544,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-e0c1479a-00eb-4648-b54f-8f0e7bc758db,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-ddd893b0-65fe-49de-831c-9ed940cdaea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2046354487-172.17.0.13-1592517643658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-222aa951-9bfe-4558-b29e-638740fa69f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-c7fee2de-6f17-49c8-9803-29714e3792a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-c7d713ad-9b73-44ea-b7b4-e18aeda1c15e,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-7565cae6-19da-4b5b-8c7e-e529d5d0e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-8fb59639-affb-4eea-9444-c0d10d76d62e,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-267af56d-666e-4c8d-824d-843ead9ad544,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-e0c1479a-00eb-4648-b54f-8f0e7bc758db,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-ddd893b0-65fe-49de-831c-9ed940cdaea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037653724-172.17.0.13-1592517955674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43499,DS-dc7986d4-bdc2-46c0-8827-d05fbe48d3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-ff7bde4d-6f03-4ab2-9cec-624aa5dbb7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-c9940351-6a7c-4a21-84cc-6ca6ff6556a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-db0deaae-5b8f-428e-b77a-e2d917762f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-0ca14fee-8f0e-4acd-82be-fa419e861f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-971b1828-ec31-4dc5-b34f-b3aad08a037a,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-63fd5cd9-9a0f-484c-b9c5-02030603d96b,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-1ac03e51-bdc3-49dc-aeb9-89298fc9b3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037653724-172.17.0.13-1592517955674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43499,DS-dc7986d4-bdc2-46c0-8827-d05fbe48d3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-ff7bde4d-6f03-4ab2-9cec-624aa5dbb7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-c9940351-6a7c-4a21-84cc-6ca6ff6556a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-db0deaae-5b8f-428e-b77a-e2d917762f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-0ca14fee-8f0e-4acd-82be-fa419e861f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-971b1828-ec31-4dc5-b34f-b3aad08a037a,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-63fd5cd9-9a0f-484c-b9c5-02030603d96b,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-1ac03e51-bdc3-49dc-aeb9-89298fc9b3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5398
