reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-96198a45-1565-406a-9f9c-14b501446ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-8376ec8d-5867-46fe-af2e-642c8efccc2f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-96198a45-1565-406a-9f9c-14b501446ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-8376ec8d-5867-46fe-af2e-642c8efccc2f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-96198a45-1565-406a-9f9c-14b501446ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-8376ec8d-5867-46fe-af2e-642c8efccc2f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-96198a45-1565-406a-9f9c-14b501446ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-8376ec8d-5867-46fe-af2e-642c8efccc2f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=55, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=55, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36811,DS-b27ab62d-675c-4ce2-aaa6-36f645783786,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-40d66ea4-16f8-4537-928a-fac4b14a4686,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-40d66ea4-16f8-4537-928a-fac4b14a4686,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-b27ab62d-675c-4ce2-aaa6-36f645783786,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-47163d7c-9052-4f4e-9212-17e0934da200,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-78e838d0-2767-4d11-9186-4456c1987377,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-47163d7c-9052-4f4e-9212-17e0934da200,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-78e838d0-2767-4d11-9186-4456c1987377,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-47163d7c-9052-4f4e-9212-17e0934da200,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-78e838d0-2767-4d11-9186-4456c1987377,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-47163d7c-9052-4f4e-9212-17e0934da200,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-78e838d0-2767-4d11-9186-4456c1987377,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-2ca0b1fa-65c8-4ed4-8f6e-76829ec22742,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-5aac14ca-89cc-4ec5-89e8-6b881a1881b1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-2ca0b1fa-65c8-4ed4-8f6e-76829ec22742,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-5aac14ca-89cc-4ec5-89e8-6b881a1881b1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-2ca0b1fa-65c8-4ed4-8f6e-76829ec22742,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-5aac14ca-89cc-4ec5-89e8-6b881a1881b1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-2ca0b1fa-65c8-4ed4-8f6e-76829ec22742,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-5aac14ca-89cc-4ec5-89e8-6b881a1881b1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-221d5abb-6e20-4294-a60c-f8890e8d7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-cd647dc6-c950-4e5d-87ea-7ff03aa2b46a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-221d5abb-6e20-4294-a60c-f8890e8d7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-cd647dc6-c950-4e5d-87ea-7ff03aa2b46a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-221d5abb-6e20-4294-a60c-f8890e8d7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-cd647dc6-c950-4e5d-87ea-7ff03aa2b46a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-221d5abb-6e20-4294-a60c-f8890e8d7c79,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-cd647dc6-c950-4e5d-87ea-7ff03aa2b46a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-8cd006aa-6bbb-4367-9158-4c8c90fa5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-b2b7d77e-6c83-4040-b0cf-46f67d18d09d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-8cd006aa-6bbb-4367-9158-4c8c90fa5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-b2b7d77e-6c83-4040-b0cf-46f67d18d09d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-8cd006aa-6bbb-4367-9158-4c8c90fa5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-b2b7d77e-6c83-4040-b0cf-46f67d18d09d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-8cd006aa-6bbb-4367-9158-4c8c90fa5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-b2b7d77e-6c83-4040-b0cf-46f67d18d09d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46874,DS-dafe70f7-d2a5-49ec-8ffb-fa67dec4880f,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-2e444508-8b4f-4f35-89c2-813a375c14e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-2e444508-8b4f-4f35-89c2-813a375c14e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-dafe70f7-d2a5-49ec-8ffb-fa67dec4880f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46874,DS-dafe70f7-d2a5-49ec-8ffb-fa67dec4880f,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-2e444508-8b4f-4f35-89c2-813a375c14e5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-2e444508-8b4f-4f35-89c2-813a375c14e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-dafe70f7-d2a5-49ec-8ffb-fa67dec4880f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33095,DS-5468f5c5-31e8-4ee8-bede-eb318ae91f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-092582df-c492-4335-8490-99d8628d054e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33095,DS-5468f5c5-31e8-4ee8-bede-eb318ae91f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-092582df-c492-4335-8490-99d8628d054e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33095,DS-5468f5c5-31e8-4ee8-bede-eb318ae91f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-092582df-c492-4335-8490-99d8628d054e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33095,DS-5468f5c5-31e8-4ee8-bede-eb318ae91f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-092582df-c492-4335-8490-99d8628d054e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44269,DS-a02c767f-b173-40af-aa85-0ade505fb550,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-e9a17b41-f191-43aa-aefe-4c59bf06ccdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44269,DS-a02c767f-b173-40af-aa85-0ade505fb550,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-e9a17b41-f191-43aa-aefe-4c59bf06ccdf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44269,DS-a02c767f-b173-40af-aa85-0ade505fb550,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-e9a17b41-f191-43aa-aefe-4c59bf06ccdf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44269,DS-a02c767f-b173-40af-aa85-0ade505fb550,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-e9a17b41-f191-43aa-aefe-4c59bf06ccdf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-c0463d06-02d0-4348-81a7-fc1c7ada57b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-9f417301-c1fb-467a-b14d-8ada8a69699f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-9f417301-c1fb-467a-b14d-8ada8a69699f,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-c0463d06-02d0-4348-81a7-fc1c7ada57b3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-c0463d06-02d0-4348-81a7-fc1c7ada57b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-9f417301-c1fb-467a-b14d-8ada8a69699f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-9f417301-c1fb-467a-b14d-8ada8a69699f,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-c0463d06-02d0-4348-81a7-fc1c7ada57b3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-adfbdf81-0010-4d83-b5c3-865f1677b754,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-4d231a32-4b78-4184-96c3-1c462f1a1341,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-adfbdf81-0010-4d83-b5c3-865f1677b754,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-4d231a32-4b78-4184-96c3-1c462f1a1341,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-adfbdf81-0010-4d83-b5c3-865f1677b754,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-4d231a32-4b78-4184-96c3-1c462f1a1341,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-adfbdf81-0010-4d83-b5c3-865f1677b754,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-4d231a32-4b78-4184-96c3-1c462f1a1341,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-d1d8791a-a994-4072-b3ea-0a6d4580ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-be59e7d9-30fe-452c-b47a-e28dc445a8bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-d1d8791a-a994-4072-b3ea-0a6d4580ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-be59e7d9-30fe-452c-b47a-e28dc445a8bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-d1d8791a-a994-4072-b3ea-0a6d4580ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-be59e7d9-30fe-452c-b47a-e28dc445a8bd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-d1d8791a-a994-4072-b3ea-0a6d4580ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-be59e7d9-30fe-452c-b47a-e28dc445a8bd,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34325,DS-27d8cc45-5e19-4a22-965c-6943c9bf2d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-5885fb7c-afe6-4c25-9b07-389847e130ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-5885fb7c-afe6-4c25-9b07-389847e130ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-27d8cc45-5e19-4a22-965c-6943c9bf2d1d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34325,DS-27d8cc45-5e19-4a22-965c-6943c9bf2d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-5885fb7c-afe6-4c25-9b07-389847e130ce,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-5885fb7c-afe6-4c25-9b07-389847e130ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-27d8cc45-5e19-4a22-965c-6943c9bf2d1d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-9d0af43c-ed09-43b5-8e53-8e8834349872,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-77fd3ddf-a3a2-47af-b83d-044ce66ed2d2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-9d0af43c-ed09-43b5-8e53-8e8834349872,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-77fd3ddf-a3a2-47af-b83d-044ce66ed2d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-9d0af43c-ed09-43b5-8e53-8e8834349872,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-77fd3ddf-a3a2-47af-b83d-044ce66ed2d2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-9d0af43c-ed09-43b5-8e53-8e8834349872,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-77fd3ddf-a3a2-47af-b83d-044ce66ed2d2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-65828894-c05c-4f02-8483-e0dcdd223eb6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-65828894-c05c-4f02-8483-e0dcdd223eb6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-65828894-c05c-4f02-8483-e0dcdd223eb6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-65828894-c05c-4f02-8483-e0dcdd223eb6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-03cefdc5-acd7-4119-91c4-bee656f79807,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-b0ba352b-7e47-4f0d-a896-6090d92cd382,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37674,DS-b0ba352b-7e47-4f0d-a896-6090d92cd382,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-03cefdc5-acd7-4119-91c4-bee656f79807,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-03cefdc5-acd7-4119-91c4-bee656f79807,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-b0ba352b-7e47-4f0d-a896-6090d92cd382,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37674,DS-b0ba352b-7e47-4f0d-a896-6090d92cd382,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-03cefdc5-acd7-4119-91c4-bee656f79807,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-4b075549-a474-41ee-a6cf-7e4f0c52a283,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-4b075549-a474-41ee-a6cf-7e4f0c52a283,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-4b075549-a474-41ee-a6cf-7e4f0c52a283,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-4b075549-a474-41ee-a6cf-7e4f0c52a283,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-c8a29246-a8d0-47ee-a779-68713ab8c625,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-5d3e25c0-c305-4938-8e37-da52b918261b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-c8a29246-a8d0-47ee-a779-68713ab8c625,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-5d3e25c0-c305-4938-8e37-da52b918261b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-c8a29246-a8d0-47ee-a779-68713ab8c625,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-5d3e25c0-c305-4938-8e37-da52b918261b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-c8a29246-a8d0-47ee-a779-68713ab8c625,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-5d3e25c0-c305-4938-8e37-da52b918261b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-c10d8dba-bd1d-4b4c-8bea-6914a8804f8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-c10d8dba-bd1d-4b4c-8bea-6914a8804f8a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-c10d8dba-bd1d-4b4c-8bea-6914a8804f8a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-c10d8dba-bd1d-4b4c-8bea-6914a8804f8a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-fa1a1237-bc9a-4dbf-a986-3f08688aa224,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-ef51ffb3-8cc5-44d1-8030-087b3cc7266a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-fa1a1237-bc9a-4dbf-a986-3f08688aa224,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-ef51ffb3-8cc5-44d1-8030-087b3cc7266a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-fa1a1237-bc9a-4dbf-a986-3f08688aa224,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-ef51ffb3-8cc5-44d1-8030-087b3cc7266a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-fa1a1237-bc9a-4dbf-a986-3f08688aa224,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-ef51ffb3-8cc5-44d1-8030-087b3cc7266a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-22e59022-0aed-4027-a361-e6c6645b6394,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-78414d79-0536-47df-82d7-fc57bb4466ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-22e59022-0aed-4027-a361-e6c6645b6394,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-78414d79-0536-47df-82d7-fc57bb4466ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-22e59022-0aed-4027-a361-e6c6645b6394,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-78414d79-0536-47df-82d7-fc57bb4466ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-22e59022-0aed-4027-a361-e6c6645b6394,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-78414d79-0536-47df-82d7-fc57bb4466ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32998,DS-5f60fc63-3302-4b44-bd99-99d1863471a7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32998,DS-5f60fc63-3302-4b44-bd99-99d1863471a7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32998,DS-5f60fc63-3302-4b44-bd99-99d1863471a7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32998,DS-5f60fc63-3302-4b44-bd99-99d1863471a7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-f49b50a7-86fa-4669-a9a1-0c6a79494c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f5d03ee5-0752-4a01-a9c8-16eab9c47801,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-f49b50a7-86fa-4669-a9a1-0c6a79494c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f5d03ee5-0752-4a01-a9c8-16eab9c47801,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-f49b50a7-86fa-4669-a9a1-0c6a79494c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f5d03ee5-0752-4a01-a9c8-16eab9c47801,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-f49b50a7-86fa-4669-a9a1-0c6a79494c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f5d03ee5-0752-4a01-a9c8-16eab9c47801,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45793,DS-3e26f8a9-a1d4-47a2-b010-67accde0a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-f47586f5-8a0e-4245-9900-cce374b18221,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39525,DS-f47586f5-8a0e-4245-9900-cce374b18221,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-3e26f8a9-a1d4-47a2-b010-67accde0a16d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45793,DS-3e26f8a9-a1d4-47a2-b010-67accde0a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-f47586f5-8a0e-4245-9900-cce374b18221,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39525,DS-f47586f5-8a0e-4245-9900-cce374b18221,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-3e26f8a9-a1d4-47a2-b010-67accde0a16d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-f696fcc1-e97c-4ed6-9317-c93862b0449f,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-1429cd8f-966d-4d37-8a02-c6279dffdde7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-f696fcc1-e97c-4ed6-9317-c93862b0449f,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-1429cd8f-966d-4d37-8a02-c6279dffdde7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-f696fcc1-e97c-4ed6-9317-c93862b0449f,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-1429cd8f-966d-4d37-8a02-c6279dffdde7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-f696fcc1-e97c-4ed6-9317-c93862b0449f,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-1429cd8f-966d-4d37-8a02-c6279dffdde7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-84fd6439-0997-4f27-a26b-f1673d1a3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-f834103f-1c68-45b8-b6f2-060f3e6793aa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-84fd6439-0997-4f27-a26b-f1673d1a3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-f834103f-1c68-45b8-b6f2-060f3e6793aa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-84fd6439-0997-4f27-a26b-f1673d1a3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-f834103f-1c68-45b8-b6f2-060f3e6793aa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-84fd6439-0997-4f27-a26b-f1673d1a3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-f834103f-1c68-45b8-b6f2-060f3e6793aa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-d0e581ce-0401-497d-b0c3-f92258211f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-d95c3a72-3139-4791-8aec-22ef6b72e8d1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-d0e581ce-0401-497d-b0c3-f92258211f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-d95c3a72-3139-4791-8aec-22ef6b72e8d1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-d0e581ce-0401-497d-b0c3-f92258211f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-d95c3a72-3139-4791-8aec-22ef6b72e8d1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-d0e581ce-0401-497d-b0c3-f92258211f49,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-d95c3a72-3139-4791-8aec-22ef6b72e8d1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-215b282c-010e-454d-b18a-b81f9a526722,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-aac19e9a-7523-4fbb-aa95-f8d246af6ae5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-215b282c-010e-454d-b18a-b81f9a526722,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-aac19e9a-7523-4fbb-aa95-f8d246af6ae5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-215b282c-010e-454d-b18a-b81f9a526722,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-aac19e9a-7523-4fbb-aa95-f8d246af6ae5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-215b282c-010e-454d-b18a-b81f9a526722,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-aac19e9a-7523-4fbb-aa95-f8d246af6ae5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-d1d1c423-5db8-4a46-9e3f-cc3a4c5fd691,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-247166c6-8677-4db0-94ac-0b27aa1a966f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-247166c6-8677-4db0-94ac-0b27aa1a966f,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-d1d1c423-5db8-4a46-9e3f-cc3a4c5fd691,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-d1d1c423-5db8-4a46-9e3f-cc3a4c5fd691,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-247166c6-8677-4db0-94ac-0b27aa1a966f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-247166c6-8677-4db0-94ac-0b27aa1a966f,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-d1d1c423-5db8-4a46-9e3f-cc3a4c5fd691,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-80608558-f3c0-40da-a9d7-438c1ee50337,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-80608558-f3c0-40da-a9d7-438c1ee50337,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-80608558-f3c0-40da-a9d7-438c1ee50337,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-80608558-f3c0-40da-a9d7-438c1ee50337,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-64ee1afc-c8e2-4074-8606-f152c8d86da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-a7acda63-9b65-4258-be04-c78039385c4c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-64ee1afc-c8e2-4074-8606-f152c8d86da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-a7acda63-9b65-4258-be04-c78039385c4c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-64ee1afc-c8e2-4074-8606-f152c8d86da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-a7acda63-9b65-4258-be04-c78039385c4c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38758,DS-64ee1afc-c8e2-4074-8606-f152c8d86da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-a7acda63-9b65-4258-be04-c78039385c4c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=831, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=831, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46703,DS-dad1d609-9a5a-411b-92c3-743dd0af8c12,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-b6159913-1441-47b8-ba70-9501c26763ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46703,DS-dad1d609-9a5a-411b-92c3-743dd0af8c12,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-b6159913-1441-47b8-ba70-9501c26763ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46049,DS-4bf1b8b2-96e1-4837-b6db-f79020654f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-43141b06-1d90-4331-832a-b8ba80579008,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33979,DS-43141b06-1d90-4331-832a-b8ba80579008,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-4bf1b8b2-96e1-4837-b6db-f79020654f3b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46049,DS-4bf1b8b2-96e1-4837-b6db-f79020654f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-43141b06-1d90-4331-832a-b8ba80579008,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33979,DS-43141b06-1d90-4331-832a-b8ba80579008,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-4bf1b8b2-96e1-4837-b6db-f79020654f3b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-eb1dfeac-6390-4d88-85ae-265f31a1bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-7efacffb-bc6e-4af7-8b68-ea685cad18d8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-eb1dfeac-6390-4d88-85ae-265f31a1bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-7efacffb-bc6e-4af7-8b68-ea685cad18d8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-eb1dfeac-6390-4d88-85ae-265f31a1bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-7efacffb-bc6e-4af7-8b68-ea685cad18d8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40218,DS-eb1dfeac-6390-4d88-85ae-265f31a1bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-7efacffb-bc6e-4af7-8b68-ea685cad18d8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-653841ee-06e9-4c74-a36c-3009f271e079,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-00b4efee-98f2-42a6-8960-f3d95467e100,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-653841ee-06e9-4c74-a36c-3009f271e079,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-00b4efee-98f2-42a6-8960-f3d95467e100,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-653841ee-06e9-4c74-a36c-3009f271e079,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-00b4efee-98f2-42a6-8960-f3d95467e100,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-653841ee-06e9-4c74-a36c-3009f271e079,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-00b4efee-98f2-42a6-8960-f3d95467e100,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-87347197-b740-440e-a79b-deac62e4f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-8eb6dccc-b51a-4b43-956a-824993040500,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-87347197-b740-440e-a79b-deac62e4f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-8eb6dccc-b51a-4b43-956a-824993040500,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-87347197-b740-440e-a79b-deac62e4f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-8eb6dccc-b51a-4b43-956a-824993040500,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45233,DS-87347197-b740-440e-a79b-deac62e4f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-8eb6dccc-b51a-4b43-956a-824993040500,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-9d7dbb81-f113-44ec-b51c-179816299740,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-2ad504c9-40f7-440b-9837-55cb237a13fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-9d7dbb81-f113-44ec-b51c-179816299740,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-2ad504c9-40f7-440b-9837-55cb237a13fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-9d7dbb81-f113-44ec-b51c-179816299740,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-2ad504c9-40f7-440b-9837-55cb237a13fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-9d7dbb81-f113-44ec-b51c-179816299740,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-2ad504c9-40f7-440b-9837-55cb237a13fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34994,DS-e74f562c-2f02-47b5-a0fe-72f5a85f3f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-95141a78-9438-42bb-96fb-006d2983dac6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40579,DS-95141a78-9438-42bb-96fb-006d2983dac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-e74f562c-2f02-47b5-a0fe-72f5a85f3f92,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34994,DS-e74f562c-2f02-47b5-a0fe-72f5a85f3f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-95141a78-9438-42bb-96fb-006d2983dac6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40579,DS-95141a78-9438-42bb-96fb-006d2983dac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-e74f562c-2f02-47b5-a0fe-72f5a85f3f92,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Append sequenceId=8, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=8, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-f45889be-4ad3-4c53-83d7-0c3738b8ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-1946aff0-970e-4837-b4f4-7454d260b3f5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39260,DS-f45889be-4ad3-4c53-83d7-0c3738b8ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37234,DS-1946aff0-970e-4837-b4f4-7454d260b3f5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37625,DS-efe7bbf7-268e-4dd2-83fe-ba0a0daf1291,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-8dd3564d-00e9-46f9-ad8b-cb4cf6d0178d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37625,DS-efe7bbf7-268e-4dd2-83fe-ba0a0daf1291,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-8dd3564d-00e9-46f9-ad8b-cb4cf6d0178d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37625,DS-efe7bbf7-268e-4dd2-83fe-ba0a0daf1291,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-8dd3564d-00e9-46f9-ad8b-cb4cf6d0178d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37625,DS-efe7bbf7-268e-4dd2-83fe-ba0a0daf1291,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-8dd3564d-00e9-46f9-ad8b-cb4cf6d0178d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45744,DS-e5c4bc30-7cd7-46d4-a7d9-3200df7b9439,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-86ec5745-c014-44f9-a426-98bc09fed1f4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35221,DS-86ec5745-c014-44f9-a426-98bc09fed1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-e5c4bc30-7cd7-46d4-a7d9-3200df7b9439,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45744,DS-e5c4bc30-7cd7-46d4-a7d9-3200df7b9439,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-86ec5745-c014-44f9-a426-98bc09fed1f4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35221,DS-86ec5745-c014-44f9-a426-98bc09fed1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-e5c4bc30-7cd7-46d4-a7d9-3200df7b9439,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-d4cc4464-7176-47bc-aaf0-544b050b1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-0d155905-8746-409e-9fff-7f2b6a2ab8cf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-d4cc4464-7176-47bc-aaf0-544b050b1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-0d155905-8746-409e-9fff-7f2b6a2ab8cf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-d4cc4464-7176-47bc-aaf0-544b050b1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-0d155905-8746-409e-9fff-7f2b6a2ab8cf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45444,DS-d4cc4464-7176-47bc-aaf0-544b050b1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-0d155905-8746-409e-9fff-7f2b6a2ab8cf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33533,DS-f5ab7f2c-acc4-44cc-ba18-cbe2f633b39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-7fd7c9d5-432f-46c6-80c5-b90d382bfaa8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-7fd7c9d5-432f-46c6-80c5-b90d382bfaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-f5ab7f2c-acc4-44cc-ba18-cbe2f633b39a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33533,DS-f5ab7f2c-acc4-44cc-ba18-cbe2f633b39a,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-7fd7c9d5-432f-46c6-80c5-b90d382bfaa8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-7fd7c9d5-432f-46c6-80c5-b90d382bfaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-f5ab7f2c-acc4-44cc-ba18-cbe2f633b39a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-4853dcb8-f15e-4968-995b-4a03e97b1393,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-4853dcb8-f15e-4968-995b-4a03e97b1393,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-4853dcb8-f15e-4968-995b-4a03e97b1393,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45421,DS-4853dcb8-f15e-4968-995b-4a03e97b1393,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-6f5f86b2-7dcd-4cdb-8dd3-aaae8f8164f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-e5955cb6-5a6a-48e4-8bf2-c8ea641c2f45,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-e5955cb6-5a6a-48e4-8bf2-c8ea641c2f45,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-6f5f86b2-7dcd-4cdb-8dd3-aaae8f8164f5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-6f5f86b2-7dcd-4cdb-8dd3-aaae8f8164f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-e5955cb6-5a6a-48e4-8bf2-c8ea641c2f45,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-e5955cb6-5a6a-48e4-8bf2-c8ea641c2f45,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-6f5f86b2-7dcd-4cdb-8dd3-aaae8f8164f5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HRegionServer
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testReplayEditsWrittenIntoWAL
reconfPoint: -2
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-86eb6d74-93da-4cec-9994-0bcd182c5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-b5c98cbd-a0e7-41de-8aa4-27f621d68836,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40900,DS-b5c98cbd-a0e7-41de-8aa4-27f621d68836,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-86eb6d74-93da-4cec-9994-0bcd182c5c22,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36076,DS-86eb6d74-93da-4cec-9994-0bcd182c5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-b5c98cbd-a0e7-41de-8aa4-27f621d68836,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40900,DS-b5c98cbd-a0e7-41de-8aa4-27f621d68836,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-86eb6d74-93da-4cec-9994-0bcd182c5c22,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)


v1v2 failed with probability 28 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: might be true error
Total execution time in seconds : 11052
