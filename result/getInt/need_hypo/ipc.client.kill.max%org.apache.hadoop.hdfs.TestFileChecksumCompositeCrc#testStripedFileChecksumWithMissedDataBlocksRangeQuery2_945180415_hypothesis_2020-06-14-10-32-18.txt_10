reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691565831-172.17.0.9-1592131352138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-399ae57c-9a9c-425d-ab9b-25c1d2ff9c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-19ddff17-7cfe-4f7c-812f-fb9dabb86232,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-9be7a50e-b228-4a6d-b795-79bc8c24b17d,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-908dd1c8-7f07-480c-a0fb-70def6947de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-2e8b791e-5ded-4d5f-ac98-36758cccc229,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-7b55ceed-b1b8-4063-9377-0c1673a12f74,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-0a082dbb-2231-44d5-a884-a80d46508482,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-b22100f7-e194-4d91-8d9f-0dae23585cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691565831-172.17.0.9-1592131352138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-399ae57c-9a9c-425d-ab9b-25c1d2ff9c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-19ddff17-7cfe-4f7c-812f-fb9dabb86232,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-9be7a50e-b228-4a6d-b795-79bc8c24b17d,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-908dd1c8-7f07-480c-a0fb-70def6947de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-2e8b791e-5ded-4d5f-ac98-36758cccc229,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-7b55ceed-b1b8-4063-9377-0c1673a12f74,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-0a082dbb-2231-44d5-a884-a80d46508482,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-b22100f7-e194-4d91-8d9f-0dae23585cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412065231-172.17.0.9-1592131547282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37813,DS-bcd5dc63-df6d-45e6-94f4-1ddeec3c6697,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-f7a88446-bc01-4eac-885b-7d99bf91dcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-8b8134f9-f474-4e45-bebd-0e0cfb6508c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-85bec76b-3a1b-43a0-ab08-91136d366157,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-e1827247-e828-4257-93dc-d5805a6f3cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-f9a215d4-2b12-4cbe-b30a-27b8da773ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-4075c212-4da4-4cee-950e-05a6f2524ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-38488c6a-1f88-4aea-a80e-d3a014045674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412065231-172.17.0.9-1592131547282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37813,DS-bcd5dc63-df6d-45e6-94f4-1ddeec3c6697,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-f7a88446-bc01-4eac-885b-7d99bf91dcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-8b8134f9-f474-4e45-bebd-0e0cfb6508c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-85bec76b-3a1b-43a0-ab08-91136d366157,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-e1827247-e828-4257-93dc-d5805a6f3cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-f9a215d4-2b12-4cbe-b30a-27b8da773ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-4075c212-4da4-4cee-950e-05a6f2524ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-38488c6a-1f88-4aea-a80e-d3a014045674,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292296939-172.17.0.9-1592132877011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34421,DS-826a0b48-2072-450d-b730-c953e32e0643,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-254ba66a-0745-4d69-9a3a-d2f3e2a72149,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-7ce6d462-f660-40d5-a4e4-4666c81fb2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-c1cf41dc-3c28-4c1c-aa8b-bf3b51174997,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-d26de3d4-25d2-4e4d-8441-419378c0a251,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-ee6723d8-e1c1-47f3-a2ec-f2e3c62e9cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9ab1c004-9688-4c3a-88bc-eb7fdea2f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-d6ec042b-04ed-42b0-82ef-932e62f61b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292296939-172.17.0.9-1592132877011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34421,DS-826a0b48-2072-450d-b730-c953e32e0643,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-254ba66a-0745-4d69-9a3a-d2f3e2a72149,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-7ce6d462-f660-40d5-a4e4-4666c81fb2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-c1cf41dc-3c28-4c1c-aa8b-bf3b51174997,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-d26de3d4-25d2-4e4d-8441-419378c0a251,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-ee6723d8-e1c1-47f3-a2ec-f2e3c62e9cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-9ab1c004-9688-4c3a-88bc-eb7fdea2f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-d6ec042b-04ed-42b0-82ef-932e62f61b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567556056-172.17.0.9-1592133169516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-8695c906-87d9-4d5c-85fe-3cbfe4c13ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-a2712291-a19a-413f-8e48-a6e71a7234b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-e6768372-9ced-423e-9d89-82af4a70c613,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-7d03c891-4a0e-4bb9-9b30-2f3042f03fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-640cc180-3c15-46c0-9ffa-8f145656183a,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-ea197efd-12d6-47c0-a2fc-c4610aae299b,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-72d7bf69-90f7-4f40-a646-6b53249d8eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-9515f735-39dc-4487-8a4f-c6b94ace4a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567556056-172.17.0.9-1592133169516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-8695c906-87d9-4d5c-85fe-3cbfe4c13ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-a2712291-a19a-413f-8e48-a6e71a7234b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-e6768372-9ced-423e-9d89-82af4a70c613,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-7d03c891-4a0e-4bb9-9b30-2f3042f03fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-640cc180-3c15-46c0-9ffa-8f145656183a,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-ea197efd-12d6-47c0-a2fc-c4610aae299b,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-72d7bf69-90f7-4f40-a646-6b53249d8eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-9515f735-39dc-4487-8a4f-c6b94ace4a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257457313-172.17.0.9-1592133661027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-a629e64f-d326-4a57-b896-5714f6058459,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-f482751a-7f44-4c9f-b9ce-4311f84c25e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-6098a244-3c50-46b6-9a2b-58cc319b8133,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-fa753bce-ce11-4af2-a7d4-9222ed851185,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-c859cd5c-e48e-45d4-8ab5-8109b02f799f,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-e17357be-2f02-4f7a-9d28-1b88d35a23bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-5cf2b236-42b6-4cdc-b3c8-33daa6e676f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-98b35be7-766c-4023-854d-e40a17fa702b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257457313-172.17.0.9-1592133661027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36053,DS-a629e64f-d326-4a57-b896-5714f6058459,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-f482751a-7f44-4c9f-b9ce-4311f84c25e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-6098a244-3c50-46b6-9a2b-58cc319b8133,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-fa753bce-ce11-4af2-a7d4-9222ed851185,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-c859cd5c-e48e-45d4-8ab5-8109b02f799f,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-e17357be-2f02-4f7a-9d28-1b88d35a23bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-5cf2b236-42b6-4cdc-b3c8-33daa6e676f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-98b35be7-766c-4023-854d-e40a17fa702b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857395240-172.17.0.9-1592133971102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46498,DS-842f5125-6c7c-41bd-93a4-03643d6976a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-a869badf-ce22-47ab-9ab2-2a5274d07227,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-2dde7c82-9d9f-420f-a4e7-2f106e19654a,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-d3cd82d0-209f-4ed0-944d-bcbd4ea55fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-36098079-66c1-49c6-8ef1-ccfbe491cdec,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-67e8fcf5-cd93-4d04-be67-52f9ac837cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-f61f7acd-708d-470e-b3ed-259dbb3d1b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-afa8856c-32a5-448d-8704-adf079be8eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857395240-172.17.0.9-1592133971102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46498,DS-842f5125-6c7c-41bd-93a4-03643d6976a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-a869badf-ce22-47ab-9ab2-2a5274d07227,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-2dde7c82-9d9f-420f-a4e7-2f106e19654a,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-d3cd82d0-209f-4ed0-944d-bcbd4ea55fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-36098079-66c1-49c6-8ef1-ccfbe491cdec,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-67e8fcf5-cd93-4d04-be67-52f9ac837cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-f61f7acd-708d-470e-b3ed-259dbb3d1b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-afa8856c-32a5-448d-8704-adf079be8eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962292550-172.17.0.9-1592134210473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-0ebd581a-dd5f-45e1-8ee1-3ce89a0127fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-0e8e1487-e3d1-4f5c-afc2-5983f4f9c4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-86a96309-eab3-48bd-b174-25c817b39e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-ff3d789e-9782-4240-959d-dd0c76b58919,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-0f0028d6-c1fb-40c0-996f-e9bdf312c81a,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-8a8cf935-a86e-4d5d-a34b-cffe686dc6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-2628fcaf-b683-4333-8947-d6ae6ab9c996,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-762b3ebf-f205-41c5-b321-688e99254315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962292550-172.17.0.9-1592134210473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-0ebd581a-dd5f-45e1-8ee1-3ce89a0127fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-0e8e1487-e3d1-4f5c-afc2-5983f4f9c4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-86a96309-eab3-48bd-b174-25c817b39e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-ff3d789e-9782-4240-959d-dd0c76b58919,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-0f0028d6-c1fb-40c0-996f-e9bdf312c81a,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-8a8cf935-a86e-4d5d-a34b-cffe686dc6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-2628fcaf-b683-4333-8947-d6ae6ab9c996,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-762b3ebf-f205-41c5-b321-688e99254315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443090357-172.17.0.9-1592134981579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39365,DS-2b939ac4-8b74-4676-b249-1f11cf430a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-65f3d92b-7d18-45eb-a654-8a386c1650a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-ed3f871f-4b44-49b3-900c-6f84111fb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-c9b59530-1181-41fe-8284-38d3a367832f,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-6eb7a07f-4a1f-44bc-9d65-fce61f393e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-6e80f413-c00f-41df-a522-95d6f2b83339,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-d5163cde-b3b6-4778-8dbd-448ff9d6d765,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-9a08bb1f-f1ef-4b32-9384-c4ba7fb66167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443090357-172.17.0.9-1592134981579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39365,DS-2b939ac4-8b74-4676-b249-1f11cf430a62,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-65f3d92b-7d18-45eb-a654-8a386c1650a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-ed3f871f-4b44-49b3-900c-6f84111fb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-c9b59530-1181-41fe-8284-38d3a367832f,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-6eb7a07f-4a1f-44bc-9d65-fce61f393e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-6e80f413-c00f-41df-a522-95d6f2b83339,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-d5163cde-b3b6-4778-8dbd-448ff9d6d765,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-9a08bb1f-f1ef-4b32-9384-c4ba7fb66167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658863116-172.17.0.9-1592135428071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39703,DS-17b0294f-d8e2-4878-8eda-06e253b1a8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-11c47554-dd51-40a3-84bc-b843bc4ab476,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-4a5c637b-d4a4-4f00-be72-17530449ff25,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-94beb00d-2e3d-42a6-89a8-b27cf8e1c478,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-058dbd61-4b42-44da-8c5c-643966a034ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-7c095236-a491-4e24-887e-463aa8efcd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-b44fdc67-c27d-4815-9512-e038f4bb64ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-0f9158e1-b9e8-4e6b-8c85-2d7d14cbef3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658863116-172.17.0.9-1592135428071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39703,DS-17b0294f-d8e2-4878-8eda-06e253b1a8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-11c47554-dd51-40a3-84bc-b843bc4ab476,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-4a5c637b-d4a4-4f00-be72-17530449ff25,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-94beb00d-2e3d-42a6-89a8-b27cf8e1c478,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-058dbd61-4b42-44da-8c5c-643966a034ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-7c095236-a491-4e24-887e-463aa8efcd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-b44fdc67-c27d-4815-9512-e038f4bb64ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-0f9158e1-b9e8-4e6b-8c85-2d7d14cbef3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447430781-172.17.0.9-1592135767547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40478,DS-83d05d6e-ead2-4175-a110-4831015cc190,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-28d01dda-077b-4d05-a1f0-9104ab010fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-c7e0893c-bd69-4899-8f0f-6c263251c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-0b9b7ebc-91b8-4939-979a-54a5af8e7fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-9cd8fae4-666a-46c0-8a32-e3ef396c285a,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-e404354c-a85b-4628-a652-d45c6586aad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-d0270a3a-c096-4ab2-b071-32ad42e91611,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-0453abb7-03b2-4e44-8d96-9cc1af20b238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447430781-172.17.0.9-1592135767547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40478,DS-83d05d6e-ead2-4175-a110-4831015cc190,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-28d01dda-077b-4d05-a1f0-9104ab010fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-c7e0893c-bd69-4899-8f0f-6c263251c14b,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-0b9b7ebc-91b8-4939-979a-54a5af8e7fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41324,DS-9cd8fae4-666a-46c0-8a32-e3ef396c285a,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-e404354c-a85b-4628-a652-d45c6586aad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-d0270a3a-c096-4ab2-b071-32ad42e91611,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-0453abb7-03b2-4e44-8d96-9cc1af20b238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 3 out of 50
result: might be true error
Total execution time in seconds : 5087
