reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811077357-172.17.0.11-1592142416086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-59fc7429-8d24-47ac-848c-5b27281284d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-8cd9feea-2dfc-46a4-b3d5-d374942ae3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-e4b246e3-6798-4759-aac6-c61a451c16ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-29b04159-0c12-454c-8155-c58b6ec96ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-3324148f-9a8c-4333-a162-cb0d022da79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-4a9e8870-9efc-4c4b-9c26-31b8a4100606,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-8d989672-bfa7-4153-8689-e70509ef981a,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-5467ddf5-549c-4e34-9c48-8a67e154759a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811077357-172.17.0.11-1592142416086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38821,DS-59fc7429-8d24-47ac-848c-5b27281284d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-8cd9feea-2dfc-46a4-b3d5-d374942ae3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-e4b246e3-6798-4759-aac6-c61a451c16ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-29b04159-0c12-454c-8155-c58b6ec96ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-3324148f-9a8c-4333-a162-cb0d022da79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-4a9e8870-9efc-4c4b-9c26-31b8a4100606,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-8d989672-bfa7-4153-8689-e70509ef981a,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-5467ddf5-549c-4e34-9c48-8a67e154759a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414644419-172.17.0.11-1592142522205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33856,DS-2d36a76d-57d8-4a41-b9d9-c980620bfa69,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-8a6334d1-7807-4e90-a60a-d52b914ca836,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-060cfcf5-4155-4a5a-ba35-83cd078b8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-9b8c40c2-c985-4ac9-8802-ccefd291bb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-c1d05960-b887-40fe-9f34-6b48e1b54ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-c5b0dc31-bc78-40f9-b09d-1977f4c17ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-d491a51d-5a09-4b47-bc46-941afcd91b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-b9fcd90a-5538-469d-bd05-16c4283fa790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414644419-172.17.0.11-1592142522205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33856,DS-2d36a76d-57d8-4a41-b9d9-c980620bfa69,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-8a6334d1-7807-4e90-a60a-d52b914ca836,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-060cfcf5-4155-4a5a-ba35-83cd078b8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-9b8c40c2-c985-4ac9-8802-ccefd291bb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-c1d05960-b887-40fe-9f34-6b48e1b54ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-c5b0dc31-bc78-40f9-b09d-1977f4c17ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-d491a51d-5a09-4b47-bc46-941afcd91b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-b9fcd90a-5538-469d-bd05-16c4283fa790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550940061-172.17.0.11-1592142592921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45990,DS-91af19bf-b39c-4701-be9f-d28c28280f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-595eb096-a911-48e1-a105-8b269492eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-dcc2f52e-5fbf-4843-beaa-dae0487deb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-49c5c34c-6f3c-4ec5-9d26-e252cd951681,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-67f0ebcc-d809-492b-bd1a-21c91643bd27,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-89585b79-2102-4b5a-b522-0aee1dd74200,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-e85479e2-a683-4a7f-986c-53720fb562f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-675d6692-1ea0-446a-bd07-e6da72097ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550940061-172.17.0.11-1592142592921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45990,DS-91af19bf-b39c-4701-be9f-d28c28280f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-595eb096-a911-48e1-a105-8b269492eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-dcc2f52e-5fbf-4843-beaa-dae0487deb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-49c5c34c-6f3c-4ec5-9d26-e252cd951681,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-67f0ebcc-d809-492b-bd1a-21c91643bd27,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-89585b79-2102-4b5a-b522-0aee1dd74200,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-e85479e2-a683-4a7f-986c-53720fb562f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-675d6692-1ea0-446a-bd07-e6da72097ed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317782905-172.17.0.11-1592142628672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40605,DS-428c96a4-f0ad-4886-83cb-ca499f3d03c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-5585277f-36e4-4f3f-9415-9a68b416c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-3e02d4e6-ebf5-4f94-a9bc-c6e85f47f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-7115c8fa-a0dd-4f2e-adaa-9295145a1f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-56c03f2b-4c16-45fc-8be3-4882f1dc85e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-655ca9e0-a36e-4975-a47c-7482c3db6998,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-8d94826f-b34c-4e43-afc4-3670793a3cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-27baa0da-4093-4f9c-a482-a642beacee76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317782905-172.17.0.11-1592142628672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40605,DS-428c96a4-f0ad-4886-83cb-ca499f3d03c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-5585277f-36e4-4f3f-9415-9a68b416c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-3e02d4e6-ebf5-4f94-a9bc-c6e85f47f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-7115c8fa-a0dd-4f2e-adaa-9295145a1f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-56c03f2b-4c16-45fc-8be3-4882f1dc85e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-655ca9e0-a36e-4975-a47c-7482c3db6998,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-8d94826f-b34c-4e43-afc4-3670793a3cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-27baa0da-4093-4f9c-a482-a642beacee76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527422568-172.17.0.11-1592142729828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-debe5947-c61c-48ca-84e5-0bf3d8ff9301,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-a48cd454-58cd-4901-85fd-1195643f7040,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-1395f59f-1b8f-4128-81d0-8c02945de306,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-6d174726-e5ec-492e-9c7b-e8718e0b3a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-cafc94bd-2cec-4fcb-98e8-0978205fec93,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-41023022-36f8-4b62-84d7-a32f1af17b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-6a7be228-fee6-4dc9-96b6-9a82d28cccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-29b1164e-d186-4c54-8abf-216f51bd806f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527422568-172.17.0.11-1592142729828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39875,DS-debe5947-c61c-48ca-84e5-0bf3d8ff9301,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-a48cd454-58cd-4901-85fd-1195643f7040,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-1395f59f-1b8f-4128-81d0-8c02945de306,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-6d174726-e5ec-492e-9c7b-e8718e0b3a13,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-cafc94bd-2cec-4fcb-98e8-0978205fec93,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-41023022-36f8-4b62-84d7-a32f1af17b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-6a7be228-fee6-4dc9-96b6-9a82d28cccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-29b1164e-d186-4c54-8abf-216f51bd806f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737643285-172.17.0.11-1592143047679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38704,DS-600b6bb2-9ab2-4103-b6ef-b70c930aaa79,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-8b312fab-e02c-4ac6-a020-bcbdf85acebe,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-9135e9db-5d64-443b-9180-84dab2b5b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-7cdce476-5312-47a4-bc6f-1f6973f2c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-9687e882-f770-48ae-b735-4dc24dfe668d,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-3281a1a5-eeca-4003-a286-9b40e7bdd82b,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-f0da6c51-febd-4654-aed2-87a5e47eb2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-9c54093a-5755-4d35-843a-7131b26de83e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737643285-172.17.0.11-1592143047679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38704,DS-600b6bb2-9ab2-4103-b6ef-b70c930aaa79,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-8b312fab-e02c-4ac6-a020-bcbdf85acebe,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-9135e9db-5d64-443b-9180-84dab2b5b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-7cdce476-5312-47a4-bc6f-1f6973f2c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-9687e882-f770-48ae-b735-4dc24dfe668d,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-3281a1a5-eeca-4003-a286-9b40e7bdd82b,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-f0da6c51-febd-4654-aed2-87a5e47eb2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-9c54093a-5755-4d35-843a-7131b26de83e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411859418-172.17.0.11-1592143265484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33247,DS-2e4db4d1-eb8a-470c-900d-372265776089,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-aa4054da-0f26-40bc-b182-66170437177c,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-a57f679a-b826-4401-a5d1-b15c45fa4880,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-e0969f1e-fa8e-4a23-8890-0272e0ca8c57,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-e8a7d5ea-0b87-4766-88a5-182f717ca130,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-785c35da-3b33-4af7-8408-d112fdf61ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-8acb7ccb-5e22-468a-8e5d-4cd343fb75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-4d2ea6b6-2bcd-4bbf-872f-84f9ad5e33f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411859418-172.17.0.11-1592143265484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33247,DS-2e4db4d1-eb8a-470c-900d-372265776089,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-aa4054da-0f26-40bc-b182-66170437177c,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-a57f679a-b826-4401-a5d1-b15c45fa4880,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-e0969f1e-fa8e-4a23-8890-0272e0ca8c57,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-e8a7d5ea-0b87-4766-88a5-182f717ca130,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-785c35da-3b33-4af7-8408-d112fdf61ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-8acb7ccb-5e22-468a-8e5d-4cd343fb75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-4d2ea6b6-2bcd-4bbf-872f-84f9ad5e33f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564545449-172.17.0.11-1592143374562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32947,DS-3f7de0ad-2e13-4c97-9dc0-2b52dff8206b,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-568c4085-333f-4e31-908d-db65fea1a439,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-ee81680e-4885-4ddd-bdaa-4a89dc95d75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-793330ad-57f0-47c5-9088-a23395ade73c,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-b77277dc-ec8e-4874-b598-a07c00546739,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-7a2e3984-5536-484e-b361-eca2f5508c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-1a7dde58-cd68-484f-b7a8-a8c37c67527f,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-fbac495d-364c-4efd-8e85-83e0c4020a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564545449-172.17.0.11-1592143374562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32947,DS-3f7de0ad-2e13-4c97-9dc0-2b52dff8206b,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-568c4085-333f-4e31-908d-db65fea1a439,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-ee81680e-4885-4ddd-bdaa-4a89dc95d75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-793330ad-57f0-47c5-9088-a23395ade73c,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-b77277dc-ec8e-4874-b598-a07c00546739,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-7a2e3984-5536-484e-b361-eca2f5508c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-1a7dde58-cd68-484f-b7a8-a8c37c67527f,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-fbac495d-364c-4efd-8e85-83e0c4020a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614621728-172.17.0.11-1592144318805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35655,DS-f025d906-23a0-4b00-be22-e9b923b12752,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-ed5d3855-7e3a-479d-a496-6ffdb6922e10,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-e0b98022-1fdd-4d5a-915b-18cec4880740,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-b4c08b63-f2b8-49aa-8cb2-e83c4c634f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-2bb14172-e413-4dbc-bde1-9b50b6757875,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-80b737df-8d9e-4a49-a64d-b4b248449fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-d8cb9096-ff39-4f93-a2a6-1d28aed5d12f,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-d9adedec-3f77-4f01-9e4a-2d7fe281a2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614621728-172.17.0.11-1592144318805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35655,DS-f025d906-23a0-4b00-be22-e9b923b12752,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-ed5d3855-7e3a-479d-a496-6ffdb6922e10,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-e0b98022-1fdd-4d5a-915b-18cec4880740,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-b4c08b63-f2b8-49aa-8cb2-e83c4c634f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-2bb14172-e413-4dbc-bde1-9b50b6757875,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-80b737df-8d9e-4a49-a64d-b4b248449fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-d8cb9096-ff39-4f93-a2a6-1d28aed5d12f,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-d9adedec-3f77-4f01-9e4a-2d7fe281a2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103922157-172.17.0.11-1592145685801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39161,DS-73fea4bf-c4c4-4f4e-9b71-ba49e4eda457,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-e8fb7a87-2337-4d1f-946f-a8d1261f74b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-b1502d7d-21e5-4062-9a62-089d6f580f59,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-2d80ce25-ad9e-498c-9bcf-acab86e82185,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-e32e4e10-e952-458f-82f2-4e0994812cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-952cc26d-c1f0-4a6d-8e68-87bdb3f86f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-67525561-43a7-449e-9343-cb7828e41967,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-2f1945ca-0304-46f7-9004-a87496550773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103922157-172.17.0.11-1592145685801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39161,DS-73fea4bf-c4c4-4f4e-9b71-ba49e4eda457,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-e8fb7a87-2337-4d1f-946f-a8d1261f74b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-b1502d7d-21e5-4062-9a62-089d6f580f59,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-2d80ce25-ad9e-498c-9bcf-acab86e82185,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-e32e4e10-e952-458f-82f2-4e0994812cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-952cc26d-c1f0-4a6d-8e68-87bdb3f86f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-67525561-43a7-449e-9343-cb7828e41967,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-2f1945ca-0304-46f7-9004-a87496550773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191004261-172.17.0.11-1592145714842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-9e227a43-b86c-4a93-8681-c872d75f8ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-8efad7d3-251e-4641-b7a3-eaa70a743e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-71d1d41b-ef16-4c15-88d5-29d5e22809c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-9284b2a6-df3b-458c-8169-7641234725bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-1a5336a4-735e-47c2-80f3-66dfc7edd17d,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-b057cde9-084e-4d19-bf78-775a28d15d76,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-ac89ab88-f4cb-4c40-b9c6-0336af1c4c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-d8c43a9d-3667-4a40-8ac0-4b9cbf080a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191004261-172.17.0.11-1592145714842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-9e227a43-b86c-4a93-8681-c872d75f8ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-8efad7d3-251e-4641-b7a3-eaa70a743e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-71d1d41b-ef16-4c15-88d5-29d5e22809c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-9284b2a6-df3b-458c-8169-7641234725bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-1a5336a4-735e-47c2-80f3-66dfc7edd17d,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-b057cde9-084e-4d19-bf78-775a28d15d76,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-ac89ab88-f4cb-4c40-b9c6-0336af1c4c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-d8c43a9d-3667-4a40-8ac0-4b9cbf080a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083601418-172.17.0.11-1592146339393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41110,DS-b880d815-5cfb-40d0-a1d2-9741d9bd43e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-3eb844ac-1c33-46a5-9463-1c16609b88de,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-bbdff5b4-cd08-4d90-a01e-60b2be373a49,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-07105fd4-3902-488e-8665-eb9e51975a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-b3c06e43-6558-405a-95ae-f8c318ea6e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-a3cae20b-9d2c-41f6-b902-598763d681a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-41674ba6-c9a1-42ae-b995-d141edc1e6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-10094be5-734e-4f6a-9a46-02f519c14554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083601418-172.17.0.11-1592146339393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41110,DS-b880d815-5cfb-40d0-a1d2-9741d9bd43e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-3eb844ac-1c33-46a5-9463-1c16609b88de,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-bbdff5b4-cd08-4d90-a01e-60b2be373a49,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-07105fd4-3902-488e-8665-eb9e51975a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-b3c06e43-6558-405a-95ae-f8c318ea6e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-a3cae20b-9d2c-41f6-b902-598763d681a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-41674ba6-c9a1-42ae-b995-d141edc1e6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-10094be5-734e-4f6a-9a46-02f519c14554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661449849-172.17.0.11-1592146397613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40161,DS-b4e4d696-9326-4083-ab32-6a794438acb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-df498630-2f02-4f47-a6f3-5c9ebc60b18a,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-57f8ef46-d678-4d62-bb6b-8861a333c60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-9080a157-9853-46f6-afb4-22bd5fcf944d,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-ee03f553-ffd9-482b-814f-24a7f3adce84,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-9690672c-73b3-4250-9c99-fcbef4ce35c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-6fba03cd-1156-457b-b97c-847f9943b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-f89a5c7e-bb9f-4382-a861-ef8d39ce6758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661449849-172.17.0.11-1592146397613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40161,DS-b4e4d696-9326-4083-ab32-6a794438acb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-df498630-2f02-4f47-a6f3-5c9ebc60b18a,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-57f8ef46-d678-4d62-bb6b-8861a333c60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-9080a157-9853-46f6-afb4-22bd5fcf944d,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-ee03f553-ffd9-482b-814f-24a7f3adce84,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-9690672c-73b3-4250-9c99-fcbef4ce35c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-6fba03cd-1156-457b-b97c-847f9943b6da,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-f89a5c7e-bb9f-4382-a861-ef8d39ce6758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500893131-172.17.0.11-1592147037372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-0adc6acd-d240-416f-bd55-e5b8de18913e,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6132f371-1d22-4538-a961-3446f65beba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-ae29eb57-0488-4bf0-960b-0cac90210a03,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-9494ade1-db56-4bc9-b4df-45bb98d413e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-e50cdc60-8232-4c23-8d3f-befa5fa9bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-5ce9f9ce-8685-4e48-b34a-ab4162e5fd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-7a761873-642c-4e53-917e-a97148204755,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-3364c095-e621-4801-b4bb-cc9e4cd83423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500893131-172.17.0.11-1592147037372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-0adc6acd-d240-416f-bd55-e5b8de18913e,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6132f371-1d22-4538-a961-3446f65beba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-ae29eb57-0488-4bf0-960b-0cac90210a03,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-9494ade1-db56-4bc9-b4df-45bb98d413e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-e50cdc60-8232-4c23-8d3f-befa5fa9bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-5ce9f9ce-8685-4e48-b34a-ab4162e5fd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-7a761873-642c-4e53-917e-a97148204755,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-3364c095-e621-4801-b4bb-cc9e4cd83423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924519802-172.17.0.11-1592147190251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-a760f22d-be41-46f0-a1b9-135dfc5a1970,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-bc11ebb3-aa70-46b1-b28a-492f0f770325,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-f202c162-8236-49d0-94ee-24d8fd93c467,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-190634a3-3dc4-4255-a0d6-259d1842dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-b382b6f1-91ae-42b3-ad60-6733e9c84294,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-e155097a-684e-41a0-ad54-d4bb57a33804,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-bf4f5a55-7997-42aa-8889-817b2d2fd5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-8ce58ada-56ac-4039-8994-58b8d7ab0605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924519802-172.17.0.11-1592147190251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39944,DS-a760f22d-be41-46f0-a1b9-135dfc5a1970,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-bc11ebb3-aa70-46b1-b28a-492f0f770325,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-f202c162-8236-49d0-94ee-24d8fd93c467,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-190634a3-3dc4-4255-a0d6-259d1842dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-b382b6f1-91ae-42b3-ad60-6733e9c84294,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-e155097a-684e-41a0-ad54-d4bb57a33804,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-bf4f5a55-7997-42aa-8889-817b2d2fd5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-8ce58ada-56ac-4039-8994-58b8d7ab0605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 4982
