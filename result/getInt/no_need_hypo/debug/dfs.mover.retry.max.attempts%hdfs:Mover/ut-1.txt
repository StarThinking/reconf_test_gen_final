msx-listener test started org.apache.hadoop.hdfs.server.mover.TestMover#testMoverFailedRetry
msx-listener unitTestCounterInClass = 0
msx-reconfagent reconf_vvmode=v1v2, reconf_parameter=dfs.mover.retry.max.attempts, reconf_component=hdfs:Mover, reconf_v1=2, reconf_v2=5, reconf_point=-1
2020-07-01 04:16:27,362 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-07-01 04:16:27,880 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-07-01 04:16:27,890 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-07-01 04:16:27,891 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-07-01 04:16:27,891 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-07-01 04:16:27,896 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-07-01 04:16:27,897 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-07-01 04:16:27,897 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-07-01 04:16:27,897 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-07-01 04:16:27,934 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-07-01 04:16:27,937 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-07-01 04:16:27,938 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:27,938 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-07-01 04:16:27,938 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-07-01 04:16:27,938 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:27,942 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-07-01 04:16:27,943 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Jul 01 04:16:27
2020-07-01 04:16:27,945 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-07-01 04:16:27,945 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-07-01 04:16:27,946 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-07-01 04:16:27,946 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-07-01 04:16:27,959 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:27,960 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:27,962 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-07-01 04:16:27,963 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-07-01 04:16:27,964 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-07-01 04:16:27,965 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:27,968 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-07-01 04:16:27,968 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-07-01 04:16:27,968 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-07-01 04:16:27,969 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-07-01 04:16:27,969 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-07-01 04:16:27,969 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-07-01 04:16:27,970 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-07-01 04:16:27,970 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-07-01 04:16:27,970 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-07-01 04:16:27,970 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-07-01 04:16:27,970 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-07-01 04:16:27,996 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-07-01 04:16:27,996 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-07-01 04:16:27,996 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-07-01 04:16:27,996 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-07-01 04:16:28,005 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-07-01 04:16:28,006 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-07-01 04:16:28,006 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-07-01 04:16:28,006 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-07-01 04:16:28,011 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-07-01 04:16:28,012 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-07-01 04:16:28,012 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-07-01 04:16:28,012 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-07-01 04:16:28,016 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-07-01 04:16:28,018 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-07-01 04:16:28,021 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-07-01 04:16:28,022 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-07-01 04:16:28,022 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-07-01 04:16:28,022 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-07-01 04:16:28,029 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-07-01 04:16:28,029 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-07-01 04:16:28,029 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-07-01 04:16:28,032 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-07-01 04:16:28,032 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-07-01 04:16:28,034 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-07-01 04:16:28,034 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-07-01 04:16:28,035 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-07-01 04:16:28,035 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-07-01 04:16:28,058 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:28,072 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-07-01 04:16:28,075 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-07-01 04:16:28,113 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-07-01 04:16:28,113 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-07-01 04:16:28,230 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-07-01 04:16:28,230 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-07-01 04:16:28,251 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-07-01 04:16:28,254 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1640)) - createNameNode []
2020-07-01 04:16:28,330 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-07-01 04:16:28,547 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-07-01 04:16:28,547 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
msx-reconfagent conf 1337335626 itself is unique for hdfs:NameNode 931496835
msx-reconfagent performReconf for comoponent hdfs:NameNode 931496835 uniqueConf 1337335626 originConf 1337335626
msx-reconfagent hdfs:NameNode init 931496835, irrelevant component. Set value as v1 2
2020-07-01 04:16:28,570 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-07-01 04:16:28,599 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@49c7b90e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-07-01 04:16:28,611 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-07-01 04:16:28,615 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-07-01 04:16:28,627 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1930ms
2020-07-01 04:16:28,715 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-07-01 04:16:28,720 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-07-01 04:16:28,720 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-07-01 04:16:28,731 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-07-01 04:16:28,733 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-07-01 04:16:28,733 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-07-01 04:16:28,733 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-07-01 04:16:28,757 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-07-01 04:16:28,757 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-07-01 04:16:28,763 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40297
2020-07-01 04:16:28,765 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-07-01 04:16:28,818 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4201c465{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-07-01 04:16:28,819 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cb107fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-07-01 04:16:28,859 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@51bf5add{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-07-01 04:16:28,871 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@456d6c1e{HTTP/1.1,[http/1.1]}{localhost:40297}
2020-07-01 04:16:28,871 [main] INFO  server.Server (Server.java:doStart(419)) - Started @2175ms
2020-07-01 04:16:28,882 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-07-01 04:16:28,883 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-07-01 04:16:28,883 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-07-01 04:16:28,883 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-07-01 04:16:28,883 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-07-01 04:16:28,884 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-07-01 04:16:28,884 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-07-01 04:16:28,884 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-07-01 04:16:28,885 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-07-01 04:16:28,885 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:28,885 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-07-01 04:16:28,885 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-07-01 04:16:28,886 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:28,886 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-07-01 04:16:28,887 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Jul 01 04:16:28
2020-07-01 04:16:28,887 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-07-01 04:16:28,887 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-07-01 04:16:28,887 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-07-01 04:16:28,887 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-07-01 04:16:28,898 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:28,898 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:28,899 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-07-01 04:16:28,899 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-07-01 04:16:28,899 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-07-01 04:16:28,899 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:28,900 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-07-01 04:16:28,900 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-07-01 04:16:28,900 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-07-01 04:16:28,900 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-07-01 04:16:28,900 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-07-01 04:16:28,900 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-07-01 04:16:28,900 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-07-01 04:16:28,900 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-07-01 04:16:28,901 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-07-01 04:16:28,901 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-07-01 04:16:28,901 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-07-01 04:16:28,901 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-07-01 04:16:28,901 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-07-01 04:16:28,902 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-07-01 04:16:28,902 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-07-01 04:16:28,907 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-07-01 04:16:28,908 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-07-01 04:16:28,908 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-07-01 04:16:28,908 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-07-01 04:16:28,908 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-07-01 04:16:28,908 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-07-01 04:16:28,908 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-07-01 04:16:28,908 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-07-01 04:16:28,908 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-07-01 04:16:28,909 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-07-01 04:16:28,910 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-07-01 04:16:28,910 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-07-01 04:16:28,910 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-07-01 04:16:28,910 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-07-01 04:16:28,910 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-07-01 04:16:28,910 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-07-01 04:16:28,910 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-07-01 04:16:28,910 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-07-01 04:16:28,911 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-07-01 04:16:28,919 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 124408@6f17dc04dd7d
2020-07-01 04:16:28,921 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 124408@6f17dc04dd7d
2020-07-01 04:16:28,923 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-07-01 04:16:28,923 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-07-01 04:16:28,923 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-07-01 04:16:28,923 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-07-01 04:16:28,953 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-07-01 04:16:28,957 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-07-01 04:16:28,958 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-07-01 04:16:28,961 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-07-01 04:16:28,962 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-07-01 04:16:28,982 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-07-01 04:16:28,982 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 71 msecs
2020-07-01 04:16:29,114 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-07-01 04:16:29,151 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-07-01 04:16:29,162 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-07-01 04:16:29,400 [Listener at localhost/38886] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38886 to access this namenode/service.
2020-07-01 04:16:29,402 [Listener at localhost/38886] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-07-01 04:16:29,418 [Listener at localhost/38886] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-07-01 04:16:29,428 [Listener at localhost/38886] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-07-01 04:16:29,429 [Listener at localhost/38886] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-07-01 04:16:29,429 [Listener at localhost/38886] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-07-01 04:16:29,429 [Listener at localhost/38886] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-07-01 04:16:29,434 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-07-01 04:16:29,434 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-07-01 04:16:29,434 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-07-01 04:16:29,435 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-07-01 04:16:29,435 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-07-01 04:16:29,435 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-07-01 04:16:29,449 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-07-01 04:16:29,449 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-07-01 04:16:29,451 [Listener at localhost/38886] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38886
2020-07-01 04:16:29,456 [Listener at localhost/38886] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-07-01 04:16:29,456 [Listener at localhost/38886] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-07-01 04:16:29,465 [Listener at localhost/38886] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-07-01 04:16:29,470 [CacheReplicationMonitor(2145468008)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-07-01 04:16:29,480 [Listener at localhost/38886] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-07-01 04:16:29,530 [Listener at localhost/38886] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-07-01 04:16:29,546 [Listener at localhost/38886] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-07-01 04:16:29,565 [Listener at localhost/38886] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
msx-reconfagent conf 264978436 itself is unique for hdfs:DataNode 2075568954
msx-reconfagent performReconf for comoponent hdfs:DataNode 2075568954 uniqueConf 264978436 originConf 264978436
msx-reconfagent hdfs:DataNode init 2075568954, irrelevant component. Set value as v1 2
2020-07-01 04:16:29,571 [Listener at localhost/38886] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-07-01 04:16:29,575 [Listener at localhost/38886] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-07-01 04:16:29,579 [Listener at localhost/38886] INFO  datanode.DataNode (DataNode.java:<init>(506)) - Configured hostname is 127.0.0.1
2020-07-01 04:16:29,580 [Listener at localhost/38886] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-07-01 04:16:29,580 [Listener at localhost/38886] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:29,581 [Listener at localhost/38886] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:29,585 [Listener at localhost/38886] INFO  datanode.DataNode (DataNode.java:startDataNode(1406)) - Starting DataNode with maxLockedMemory = 0
2020-07-01 04:16:29,590 [Listener at localhost/38886] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1154)) - Opened streaming server at /127.0.0.1:38813
2020-07-01 04:16:29,591 [Listener at localhost/38886] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-07-01 04:16:29,592 [Listener at localhost/38886] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-07-01 04:16:29,605 [Listener at localhost/38886] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-07-01 04:16:29,606 [Listener at localhost/38886] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-07-01 04:16:29,606 [Listener at localhost/38886] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-07-01 04:16:29,607 [Listener at localhost/38886] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-07-01 04:16:29,609 [Listener at localhost/38886] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-07-01 04:16:29,609 [Listener at localhost/38886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-07-01 04:16:29,609 [Listener at localhost/38886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-07-01 04:16:29,610 [Listener at localhost/38886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-07-01 04:16:29,612 [Listener at localhost/38886] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45125
2020-07-01 04:16:29,612 [Listener at localhost/38886] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-07-01 04:16:29,613 [Listener at localhost/38886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a2c13a8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-07-01 04:16:29,614 [Listener at localhost/38886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b44435b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-07-01 04:16:29,618 [Listener at localhost/38886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3a3e4aff{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-07-01 04:16:29,619 [Listener at localhost/38886] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5d2a4eed{HTTP/1.1,[http/1.1]}{localhost:45125}
2020-07-01 04:16:29,619 [Listener at localhost/38886] INFO  server.Server (Server.java:doStart(419)) - Started @2923ms
2020-07-01 04:16:30,006 [Listener at localhost/38886] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36758
2020-07-01 04:16:30,007 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7c351808] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-07-01 04:16:30,009 [Listener at localhost/38886] INFO  datanode.DataNode (DataNode.java:startDataNode(1434)) - dnUserName = root
2020-07-01 04:16:30,010 [Listener at localhost/38886] INFO  datanode.DataNode (DataNode.java:startDataNode(1435)) - supergroup = supergroup
2020-07-01 04:16:30,028 [Listener at localhost/38886] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-07-01 04:16:30,029 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-07-01 04:16:30,034 [Listener at localhost/36211] INFO  datanode.DataNode (DataNode.java:initIpcServer(1040)) - Opened IPC server at /127.0.0.1:36211
2020-07-01 04:16:30,044 [Listener at localhost/36211] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-07-01 04:16:30,045 [Listener at localhost/36211] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-07-01 04:16:30,053 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38886 starting to offer service
2020-07-01 04:16:30,057 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-07-01 04:16:30,057 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-07-01 04:16:30,059 [Listener at localhost/36211] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-07-01 04:16:30,060 [Listener at localhost/36211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-07-01 04:16:30,061 [Listener at localhost/36211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-07-01 04:16:30,063 [Listener at localhost/36211] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
msx-reconfagent conf 144445623 itself is unique for hdfs:DataNode 438151297
msx-reconfagent performReconf for comoponent hdfs:DataNode 438151297 uniqueConf 144445623 originConf 144445623
msx-reconfagent hdfs:DataNode init 438151297, irrelevant component. Set value as v1 2
2020-07-01 04:16:30,063 [Listener at localhost/36211] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-07-01 04:16:30,063 [Listener at localhost/36211] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-07-01 04:16:30,064 [Listener at localhost/36211] INFO  datanode.DataNode (DataNode.java:<init>(506)) - Configured hostname is 127.0.0.1
2020-07-01 04:16:30,064 [Listener at localhost/36211] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-07-01 04:16:30,064 [Listener at localhost/36211] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:30,064 [Listener at localhost/36211] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:30,065 [Listener at localhost/36211] INFO  datanode.DataNode (DataNode.java:startDataNode(1406)) - Starting DataNode with maxLockedMemory = 0
2020-07-01 04:16:30,065 [Listener at localhost/36211] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1154)) - Opened streaming server at /127.0.0.1:36714
2020-07-01 04:16:30,065 [Listener at localhost/36211] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-07-01 04:16:30,065 [Listener at localhost/36211] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-07-01 04:16:30,066 [Listener at localhost/36211] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-07-01 04:16:30,068 [Listener at localhost/36211] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-07-01 04:16:30,068 [Listener at localhost/36211] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-07-01 04:16:30,068 [Listener at localhost/36211] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-07-01 04:16:30,070 [Listener at localhost/36211] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-07-01 04:16:30,071 [Listener at localhost/36211] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-07-01 04:16:30,071 [Listener at localhost/36211] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-07-01 04:16:30,071 [Listener at localhost/36211] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-07-01 04:16:30,072 [Listener at localhost/36211] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33622
2020-07-01 04:16:30,072 [Listener at localhost/36211] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-07-01 04:16:30,074 [Listener at localhost/36211] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b139eab{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-07-01 04:16:30,074 [Listener at localhost/36211] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@611df6e3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-07-01 04:16:30,079 [Listener at localhost/36211] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@35beb15e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-07-01 04:16:30,080 [Listener at localhost/36211] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41fe9859{HTTP/1.1,[http/1.1]}{localhost:33622}
2020-07-01 04:16:30,080 [Listener at localhost/36211] INFO  server.Server (Server.java:doStart(419)) - Started @3384ms
2020-07-01 04:16:30,129 [Listener at localhost/36211] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43092
2020-07-01 04:16:30,129 [Listener at localhost/36211] INFO  datanode.DataNode (DataNode.java:startDataNode(1434)) - dnUserName = root
2020-07-01 04:16:30,129 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c67e137] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-07-01 04:16:30,129 [Listener at localhost/36211] INFO  datanode.DataNode (DataNode.java:startDataNode(1435)) - supergroup = supergroup
2020-07-01 04:16:30,130 [Listener at localhost/36211] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-07-01 04:16:30,131 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-07-01 04:16:30,136 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:initIpcServer(1040)) - Opened IPC server at /127.0.0.1:37376
2020-07-01 04:16:30,141 [Listener at localhost/37376] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-07-01 04:16:30,142 [Listener at localhost/37376] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-07-01 04:16:30,143 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38886 starting to offer service
2020-07-01 04:16:30,143 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-07-01 04:16:30,143 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-07-01 04:16:30,146 [Listener at localhost/37376] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-07-01 04:16:30,147 [Listener at localhost/37376] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-07-01 04:16:30,148 [Listener at localhost/37376] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-07-01 04:16:30,150 [Listener at localhost/37376] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
msx-reconfagent conf 1774690057 itself is unique for hdfs:DataNode 1751500625
msx-reconfagent performReconf for comoponent hdfs:DataNode 1751500625 uniqueConf 1774690057 originConf 1774690057
msx-reconfagent hdfs:DataNode init 1751500625, irrelevant component. Set value as v1 2
2020-07-01 04:16:30,150 [Listener at localhost/37376] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-07-01 04:16:30,150 [Listener at localhost/37376] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-07-01 04:16:30,150 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:<init>(506)) - Configured hostname is 127.0.0.1
2020-07-01 04:16:30,151 [Listener at localhost/37376] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-07-01 04:16:30,151 [Listener at localhost/37376] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:30,151 [Listener at localhost/37376] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:30,151 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:startDataNode(1406)) - Starting DataNode with maxLockedMemory = 0
2020-07-01 04:16:30,151 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1154)) - Opened streaming server at /127.0.0.1:41505
2020-07-01 04:16:30,152 [Listener at localhost/37376] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-07-01 04:16:30,152 [Listener at localhost/37376] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-07-01 04:16:30,153 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-07-01 04:16:30,154 [Listener at localhost/37376] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-07-01 04:16:30,155 [Listener at localhost/37376] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-07-01 04:16:30,155 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-07-01 04:16:30,156 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-07-01 04:16:30,157 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-07-01 04:16:30,157 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-07-01 04:16:30,158 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-07-01 04:16:30,158 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34992
2020-07-01 04:16:30,159 [Listener at localhost/37376] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-07-01 04:16:30,160 [Listener at localhost/37376] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35fe2125{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-07-01 04:16:30,160 [Listener at localhost/37376] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@34645867{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-07-01 04:16:30,164 [Listener at localhost/37376] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3af17be2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-07-01 04:16:30,165 [Listener at localhost/37376] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@f9879ac{HTTP/1.1,[http/1.1]}{localhost:34992}
2020-07-01 04:16:30,165 [Listener at localhost/37376] INFO  server.Server (Server.java:doStart(419)) - Started @3469ms
2020-07-01 04:16:30,191 [Listener at localhost/37376] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33667
2020-07-01 04:16:30,192 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:startDataNode(1434)) - dnUserName = root
2020-07-01 04:16:30,192 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f4d427e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-07-01 04:16:30,192 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:startDataNode(1435)) - supergroup = supergroup
2020-07-01 04:16:30,193 [Listener at localhost/37376] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-07-01 04:16:30,193 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-07-01 04:16:30,198 [Listener at localhost/45263] INFO  datanode.DataNode (DataNode.java:initIpcServer(1040)) - Opened IPC server at /127.0.0.1:45263
2020-07-01 04:16:30,202 [Listener at localhost/45263] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-07-01 04:16:30,203 [Listener at localhost/45263] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-07-01 04:16:30,203 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38886 starting to offer service
2020-07-01 04:16:30,204 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-07-01 04:16:30,204 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-07-01 04:16:30,283 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38886
2020-07-01 04:16:30,283 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38886
2020-07-01 04:16:30,283 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38886
2020-07-01 04:16:30,284 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-07-01 04:16:30,284 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-07-01 04:16:30,284 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-07-01 04:16:30,286 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 124408@6f17dc04dd7d
2020-07-01 04:16:30,286 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 124408@6f17dc04dd7d
2020-07-01 04:16:30,286 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1408103429. Formatting...
2020-07-01 04:16:30,286 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 124408@6f17dc04dd7d
2020-07-01 04:16:30,286 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1408103429. Formatting...
2020-07-01 04:16:30,286 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1408103429. Formatting...
2020-07-01 04:16:30,287 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d88bec20-efa8-4053-9e30-c5639d8cfeab for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-07-01 04:16:30,287 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-69264f21-7154-4c8f-b7b4-e077ad53716c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-07-01 04:16:30,287 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3bb791f7-6bf3-4b55-8b27-15a0af9785a1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-07-01 04:16:30,290 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 124408@6f17dc04dd7d
2020-07-01 04:16:30,290 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1408103429. Formatting...
2020-07-01 04:16:30,290 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 124408@6f17dc04dd7d
2020-07-01 04:16:30,290 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e0179383-7f61-47c1-849b-d6c94bb32f26 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-07-01 04:16:30,291 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1408103429. Formatting...
2020-07-01 04:16:30,291 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 124408@6f17dc04dd7d
2020-07-01 04:16:30,291 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f73794e0-c8ef-41c8-8dfc-34a5e612ad94 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-07-01 04:16:30,291 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1408103429. Formatting...
2020-07-01 04:16:30,291 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-07d40a63-7a8f-4e7d-a440-626f691376e1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-07-01 04:16:30,305 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,305 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,306 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-500806141-172.17.0.12-1593576988050 is not formatted. Formatting ...
2020-07-01 04:16:30,306 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-500806141-172.17.0.12-1593576988050 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current
2020-07-01 04:16:30,308 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,308 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,308 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,308 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,308 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-500806141-172.17.0.12-1593576988050 is not formatted. Formatting ...
2020-07-01 04:16:30,308 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-500806141-172.17.0.12-1593576988050 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current
2020-07-01 04:16:30,308 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-500806141-172.17.0.12-1593576988050 is not formatted. Formatting ...
2020-07-01 04:16:30,308 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-500806141-172.17.0.12-1593576988050 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-500806141-172.17.0.12-1593576988050/current
2020-07-01 04:16:30,317 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,317 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,317 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-500806141-172.17.0.12-1593576988050 is not formatted. Formatting ...
2020-07-01 04:16:30,317 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-500806141-172.17.0.12-1593576988050 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/current
2020-07-01 04:16:30,318 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,318 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,318 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-500806141-172.17.0.12-1593576988050 is not formatted. Formatting ...
2020-07-01 04:16:30,318 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-500806141-172.17.0.12-1593576988050 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/current
2020-07-01 04:16:30,319 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1752)) - Setting up storage: nsid=1408103429;bpid=BP-500806141-172.17.0.12-1593576988050;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1408103429;c=1593576988050;bpid=BP-500806141-172.17.0.12-1593576988050;dnuuid=null
2020-07-01 04:16:30,320 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1752)) - Setting up storage: nsid=1408103429;bpid=BP-500806141-172.17.0.12-1593576988050;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1408103429;c=1593576988050;bpid=BP-500806141-172.17.0.12-1593576988050;dnuuid=null
2020-07-01 04:16:30,321 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1552)) - Generated and persisted new Datanode UUID 301dd7ed-e0f8-4483-a319-d576aeb9b885
2020-07-01 04:16:30,321 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1552)) - Generated and persisted new Datanode UUID d2e8358b-d4a4-4899-9f1f-905623a79ea0
2020-07-01 04:16:30,322 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,323 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,323 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-500806141-172.17.0.12-1593576988050 is not formatted. Formatting ...
2020-07-01 04:16:30,323 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-500806141-172.17.0.12-1593576988050 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-500806141-172.17.0.12-1593576988050/current
2020-07-01 04:16:30,325 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1752)) - Setting up storage: nsid=1408103429;bpid=BP-500806141-172.17.0.12-1593576988050;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1408103429;c=1593576988050;bpid=BP-500806141-172.17.0.12-1593576988050;dnuuid=null
2020-07-01 04:16:30,327 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1552)) - Generated and persisted new Datanode UUID d9264e7b-2ff9-484e-b674-70ee44494fac
2020-07-01 04:16:30,435 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d88bec20-efa8-4053-9e30-c5639d8cfeab
2020-07-01 04:16:30,435 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-07-01 04:16:30,435 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-69264f21-7154-4c8f-b7b4-e077ad53716c
2020-07-01 04:16:30,436 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-07-01 04:16:30,436 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3bb791f7-6bf3-4b55-8b27-15a0af9785a1
2020-07-01 04:16:30,436 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-07-01 04:16:30,437 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e0179383-7f61-47c1-849b-d6c94bb32f26
2020-07-01 04:16:30,437 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: ARCHIVE
2020-07-01 04:16:30,438 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f73794e0-c8ef-41c8-8dfc-34a5e612ad94
2020-07-01 04:16:30,438 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: ARCHIVE
2020-07-01 04:16:30,439 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-07-01 04:16:30,439 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-07-01 04:16:30,439 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-07d40a63-7a8f-4e7d-a440-626f691376e1
2020-07-01 04:16:30,439 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: ARCHIVE
2020-07-01 04:16:30,440 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-07-01 04:16:30,443 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-07-01 04:16:30,444 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-07-01 04:16:30,445 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-07-01 04:16:30,451 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-07-01 04:16:30,451 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-07-01 04:16:30,451 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-07-01 04:16:30,453 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-07-01 04:16:30,453 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-07-01 04:16:30,453 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-07-01 04:16:30,453 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-07-01 04:16:30,453 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-07-01 04:16:30,453 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-07-01 04:16:30,453 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,453 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,453 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,454 [Thread-123] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-07-01 04:16:30,454 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-07-01 04:16:30,455 [Thread-124] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-07-01 04:16:30,455 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-07-01 04:16:30,455 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-07-01 04:16:30,455 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-07-01 04:16:30,491 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-500806141-172.17.0.12-1593576988050 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 37ms
2020-07-01 04:16:30,493 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-500806141-172.17.0.12-1593576988050 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 37ms
2020-07-01 04:16:30,494 [Thread-123] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-500806141-172.17.0.12-1593576988050 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 39ms
2020-07-01 04:16:30,494 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-500806141-172.17.0.12-1593576988050: 40ms
2020-07-01 04:16:30,495 [Thread-124] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-500806141-172.17.0.12-1593576988050 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 41ms
2020-07-01 04:16:30,496 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-500806141-172.17.0.12-1593576988050: 42ms
2020-07-01 04:16:30,496 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-500806141-172.17.0.12-1593576988050 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 41ms
2020-07-01 04:16:30,496 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-500806141-172.17.0.12-1593576988050 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 41ms
2020-07-01 04:16:30,496 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-500806141-172.17.0.12-1593576988050: 42ms
2020-07-01 04:16:30,497 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-07-01 04:16:30,497 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-07-01 04:16:30,497 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-07-01 04:16:30,497 [Thread-136] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-500806141-172.17.0.12-1593576988050/current/replicas doesn't exist 
2020-07-01 04:16:30,497 [Thread-137] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/replicas doesn't exist 
2020-07-01 04:16:30,497 [Thread-135] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/replicas doesn't exist 
2020-07-01 04:16:30,497 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-07-01 04:16:30,497 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-07-01 04:16:30,498 [Thread-138] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/current/replicas doesn't exist 
2020-07-01 04:16:30,498 [Thread-140] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/current/replicas doesn't exist 
2020-07-01 04:16:30,497 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-07-01 04:16:30,498 [Thread-139] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-500806141-172.17.0.12-1593576988050/current/replicas doesn't exist 
2020-07-01 04:16:30,499 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-07-01 04:16:30,499 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-07-01 04:16:30,499 [Thread-135] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 3ms
2020-07-01 04:16:30,499 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-500806141-172.17.0.12-1593576988050: 4ms
2020-07-01 04:16:30,500 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-07-01 04:16:30,500 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-07-01 04:16:30,500 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-500806141-172.17.0.12-1593576988050: 4ms
2020-07-01 04:16:30,500 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 3ms
2020-07-01 04:16:30,500 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-500806141-172.17.0.12-1593576988050: 4ms
2020-07-01 04:16:30,502 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-07-01 04:16:30,502 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-07-01 04:16:30,502 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-07-01 04:16:30,502 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-07-01 04:16:30,502 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-07-01 04:16:30,502 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-500806141-172.17.0.12-1593576988050 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-07-01 04:16:30,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f73794e0-c8ef-41c8-8dfc-34a5e612ad94): finished scanning block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-69264f21-7154-4c8f-b7b4-e077ad53716c): finished scanning block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-3bb791f7-6bf3-4b55-8b27-15a0af9785a1): finished scanning block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-07d40a63-7a8f-4e7d-a440-626f691376e1): finished scanning block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e0179383-7f61-47c1-849b-d6c94bb32f26): finished scanning block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,503 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d88bec20-efa8-4053-9e30-c5639d8cfeab): finished scanning block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,524 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 7/1/20 6:06 AM with interval of 21600000ms
2020-07-01 04:16:30,524 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 7/1/20 9:18 AM with interval of 21600000ms
2020-07-01 04:16:30,524 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 7/1/20 6:46 AM with interval of 21600000ms
2020-07-01 04:16:30,524 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f73794e0-c8ef-41c8-8dfc-34a5e612ad94): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-07-01 04:16:30,524 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e0179383-7f61-47c1-849b-d6c94bb32f26): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-07-01 04:16:30,524 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-d88bec20-efa8-4053-9e30-c5639d8cfeab): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-07-01 04:16:30,524 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-07d40a63-7a8f-4e7d-a440-626f691376e1): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-07-01 04:16:30,524 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-3bb791f7-6bf3-4b55-8b27-15a0af9785a1): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-07-01 04:16:30,524 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-69264f21-7154-4c8f-b7b4-e077ad53716c): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-07-01 04:16:30,529 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-500806141-172.17.0.12-1593576988050 (Datanode Uuid d9264e7b-2ff9-484e-b674-70ee44494fac) service to localhost/127.0.0.1:38886 beginning handshake with NN
2020-07-01 04:16:30,529 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-500806141-172.17.0.12-1593576988050 (Datanode Uuid d2e8358b-d4a4-4899-9f1f-905623a79ea0) service to localhost/127.0.0.1:38886 beginning handshake with NN
2020-07-01 04:16:30,529 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-500806141-172.17.0.12-1593576988050 (Datanode Uuid 301dd7ed-e0f8-4483-a319-d576aeb9b885) service to localhost/127.0.0.1:38886 beginning handshake with NN
2020-07-01 04:16:30,537 [IPC Server handler 2 on default port 38886] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38813, datanodeUuid=d2e8358b-d4a4-4899-9f1f-905623a79ea0, infoPort=36758, infoSecurePort=0, ipcPort=36211, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050) storage d2e8358b-d4a4-4899-9f1f-905623a79ea0
2020-07-01 04:16:30,539 [IPC Server handler 2 on default port 38886] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:30,540 [IPC Server handler 2 on default port 38886] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d2e8358b-d4a4-4899-9f1f-905623a79ea0 (127.0.0.1:38813).
2020-07-01 04:16:30,542 [IPC Server handler 1 on default port 38886] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41505, datanodeUuid=d9264e7b-2ff9-484e-b674-70ee44494fac, infoPort=33667, infoSecurePort=0, ipcPort=45263, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050) storage d9264e7b-2ff9-484e-b674-70ee44494fac
2020-07-01 04:16:30,542 [IPC Server handler 1 on default port 38886] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:30,543 [IPC Server handler 1 on default port 38886] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d9264e7b-2ff9-484e-b674-70ee44494fac (127.0.0.1:41505).
2020-07-01 04:16:30,543 [IPC Server handler 3 on default port 38886] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36714, datanodeUuid=301dd7ed-e0f8-4483-a319-d576aeb9b885, infoPort=43092, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050) storage 301dd7ed-e0f8-4483-a319-d576aeb9b885
2020-07-01 04:16:30,543 [IPC Server handler 3 on default port 38886] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:30,543 [IPC Server handler 3 on default port 38886] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 301dd7ed-e0f8-4483-a319-d576aeb9b885 (127.0.0.1:36714).
2020-07-01 04:16:30,547 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-500806141-172.17.0.12-1593576988050 (Datanode Uuid d9264e7b-2ff9-484e-b674-70ee44494fac) service to localhost/127.0.0.1:38886 successfully registered with NN
2020-07-01 04:16:30,547 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-500806141-172.17.0.12-1593576988050 (Datanode Uuid 301dd7ed-e0f8-4483-a319-d576aeb9b885) service to localhost/127.0.0.1:38886 successfully registered with NN
2020-07-01 04:16:30,547 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-500806141-172.17.0.12-1593576988050 (Datanode Uuid d2e8358b-d4a4-4899-9f1f-905623a79ea0) service to localhost/127.0.0.1:38886 successfully registered with NN
2020-07-01 04:16:30,547 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38886 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-07-01 04:16:30,547 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38886 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-07-01 04:16:30,547 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38886 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-07-01 04:16:30,563 [IPC Server handler 4 on default port 38886] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-69264f21-7154-4c8f-b7b4-e077ad53716c for DN 127.0.0.1:41505
2020-07-01 04:16:30,564 [IPC Server handler 4 on default port 38886] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f73794e0-c8ef-41c8-8dfc-34a5e612ad94 for DN 127.0.0.1:41505
2020-07-01 04:16:30,564 [IPC Server handler 6 on default port 38886] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3bb791f7-6bf3-4b55-8b27-15a0af9785a1 for DN 127.0.0.1:38813
2020-07-01 04:16:30,564 [IPC Server handler 6 on default port 38886] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07d40a63-7a8f-4e7d-a440-626f691376e1 for DN 127.0.0.1:38813
2020-07-01 04:16:30,564 [IPC Server handler 5 on default port 38886] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d88bec20-efa8-4053-9e30-c5639d8cfeab for DN 127.0.0.1:36714
2020-07-01 04:16:30,565 [IPC Server handler 5 on default port 38886] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0179383-7f61-47c1-849b-d6c94bb32f26 for DN 127.0.0.1:36714
2020-07-01 04:16:30,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1d8ee8ea816764c3: Processing first storage report for DS-07d40a63-7a8f-4e7d-a440-626f691376e1 from datanode d2e8358b-d4a4-4899-9f1f-905623a79ea0
2020-07-01 04:16:30,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1d8ee8ea816764c3: from storage DS-07d40a63-7a8f-4e7d-a440-626f691376e1 node DatanodeRegistration(127.0.0.1:38813, datanodeUuid=d2e8358b-d4a4-4899-9f1f-905623a79ea0, infoPort=36758, infoSecurePort=0, ipcPort=36211, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-07-01 04:16:30,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x441a7ed29b1256c1: Processing first storage report for DS-69264f21-7154-4c8f-b7b4-e077ad53716c from datanode d9264e7b-2ff9-484e-b674-70ee44494fac
2020-07-01 04:16:30,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x441a7ed29b1256c1: from storage DS-69264f21-7154-4c8f-b7b4-e077ad53716c node DatanodeRegistration(127.0.0.1:41505, datanodeUuid=d9264e7b-2ff9-484e-b674-70ee44494fac, infoPort=33667, infoSecurePort=0, ipcPort=45263, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-07-01 04:16:30,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd362b10930b8f0ba: Processing first storage report for DS-d88bec20-efa8-4053-9e30-c5639d8cfeab from datanode 301dd7ed-e0f8-4483-a319-d576aeb9b885
2020-07-01 04:16:30,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd362b10930b8f0ba: from storage DS-d88bec20-efa8-4053-9e30-c5639d8cfeab node DatanodeRegistration(127.0.0.1:36714, datanodeUuid=301dd7ed-e0f8-4483-a319-d576aeb9b885, infoPort=43092, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-07-01 04:16:30,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1d8ee8ea816764c3: Processing first storage report for DS-3bb791f7-6bf3-4b55-8b27-15a0af9785a1 from datanode d2e8358b-d4a4-4899-9f1f-905623a79ea0
2020-07-01 04:16:30,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1d8ee8ea816764c3: from storage DS-3bb791f7-6bf3-4b55-8b27-15a0af9785a1 node DatanodeRegistration(127.0.0.1:38813, datanodeUuid=d2e8358b-d4a4-4899-9f1f-905623a79ea0, infoPort=36758, infoSecurePort=0, ipcPort=36211, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-07-01 04:16:30,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x441a7ed29b1256c1: Processing first storage report for DS-f73794e0-c8ef-41c8-8dfc-34a5e612ad94 from datanode d9264e7b-2ff9-484e-b674-70ee44494fac
2020-07-01 04:16:30,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x441a7ed29b1256c1: from storage DS-f73794e0-c8ef-41c8-8dfc-34a5e612ad94 node DatanodeRegistration(127.0.0.1:41505, datanodeUuid=d9264e7b-2ff9-484e-b674-70ee44494fac, infoPort=33667, infoSecurePort=0, ipcPort=45263, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-07-01 04:16:30,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd362b10930b8f0ba: Processing first storage report for DS-e0179383-7f61-47c1-849b-d6c94bb32f26 from datanode 301dd7ed-e0f8-4483-a319-d576aeb9b885
2020-07-01 04:16:30,595 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd362b10930b8f0ba: from storage DS-e0179383-7f61-47c1-849b-d6c94bb32f26 node DatanodeRegistration(127.0.0.1:36714, datanodeUuid=301dd7ed-e0f8-4483-a319-d576aeb9b885, infoPort=43092, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=1408103429;c=1593576988050), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-07-01 04:16:30,600 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:30,613 [Listener at localhost/45263] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-07-01 04:16:30,613 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x441a7ed29b1256c1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-07-01 04:16:30,613 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1d8ee8ea816764c3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-07-01 04:16:30,613 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd362b10930b8f0ba,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 32 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-07-01 04:16:30,614 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,613 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,614 [BP-500806141-172.17.0.12-1593576988050 heartbeating to localhost/127.0.0.1:38886] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-500806141-172.17.0.12-1593576988050
2020-07-01 04:16:30,621 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:30,623 [Listener at localhost/45263] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-07-01 04:16:30,671 [IPC Server handler 2 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testMoverFailedRetry	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-07-01 04:16:30,724 [IPC Server handler 1 on default port 38886] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:36714, 127.0.0.1:38813 for /testMoverFailedRetry
2020-07-01 04:16:30,741 [Thread-153] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:30,795 [DataXceiver for client DFSClient_NONMAPREDUCE_1941053366_1 at /127.0.0.1:52934 [Receiving block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 src: /127.0.0.1:52934 dest: /127.0.0.1:36714
2020-07-01 04:16:30,817 [DataXceiver for client DFSClient_NONMAPREDUCE_1941053366_1 at /127.0.0.1:52934 [Receiving block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:30,819 [DataXceiver for client DFSClient_NONMAPREDUCE_1941053366_1 at /127.0.0.1:43202 [Receiving block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 src: /127.0.0.1:43202 dest: /127.0.0.1:38813
2020-07-01 04:16:30,857 [PacketResponder: BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43202, dest: /127.0.0.1:38813, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1941053366_1, offset: 0, srvID: d2e8358b-d4a4-4899-9f1f-905623a79ea0, blockid: BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001, duration(ns): 15034154
2020-07-01 04:16:30,857 [PacketResponder: BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-07-01 04:16:30,861 [PacketResponder: BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38813]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52934, dest: /127.0.0.1:36714, bytes: 40, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1941053366_1, offset: 0, srvID: 301dd7ed-e0f8-4483-a319-d576aeb9b885, blockid: BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001, duration(ns): 20969009
2020-07-01 04:16:30,861 [PacketResponder: BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38813]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38813] terminating
2020-07-01 04:16:30,873 [IPC Server handler 6 on default port 38886] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /testMoverFailedRetry
2020-07-01 04:16:31,280 [IPC Server handler 8 on default port 38886] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testMoverFailedRetry is closed by DFSClient_NONMAPREDUCE_1941053366_1
2020-07-01 04:16:31,290 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:31,302 [Listener at localhost/45263] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:31,303 [Listener at localhost/45263] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:deleteData(153)) - Deleting block file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:31,305 [Listener at localhost/45263] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2202)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesByDeletingBlockFile(MiniDFSCluster.java:2234)
	at org.apache.hadoop.hdfs.server.mover.TestMover.testMoverFailedRetry(TestMover.java:733)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-07-01 04:16:31,314 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/testMoverFailedRetry	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
msx-debug Mover's static run
2020-07-01 04:16:31,321 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:31,321 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-07-01 04:16:31,322 [Listener at localhost/45263] INFO  mover.Mover (Mover.java:run(649)) - namenodes = {hdfs://localhost:38886=[/testMoverFailedRetry]}
2020-07-01 04:16:31,377 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-07-01 04:16:31,383 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/system/mover.id	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-07-01 04:16:31,387 [IPC Server handler 6 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
msx-reconfagent conf 1179381257 itself is unique for hdfs:Mover 130721104
msx-reconfagent performReconf for comoponent hdfs:Mover 130721104 uniqueConf 1179381257 originConf 1179381257
msx-reconfagent hdfs:Mover init 130721104, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:16:31,390 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:31,391 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:16:31,411 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:31,423 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:31,423 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:31,424 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:31,433 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:31,438 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:31,448 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:31,449 [pool-47-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:31,457 [pool-47-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:31,466 [DataXceiver for client /127.0.0.1:43206 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:31,469 [DataXceiver for client /127.0.0.1:43206 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43206 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:16:31,469 [pool-47-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:16:31,471 [pool-47-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:16:31,471 [pool-47-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 0, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 1
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 650013863
msx-reconfagent performReconf for comoponent hdfs:Mover 52451302 uniqueConf 650013863 originConf 1179381257
msx-reconfagent hdfs:Mover init 52451302, irrelevant init point 2. Set value as v1 2
2020-07-01 04:16:35,451 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:35,452 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:16:35,456 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:35,458 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:35,458 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:35,458 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:35,461 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:35,463 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:35,466 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:35,467 [pool-48-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:35,468 [pool-48-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:35,470 [DataXceiver for client /127.0.0.1:43208 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:35,471 [DataXceiver for client /127.0.0.1:43208 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43208 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:16:35,471 [pool-48-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:16:35,472 [pool-48-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:16:35,473 [pool-48-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 1, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 2
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 105321150
msx-reconfagent performReconf for comoponent hdfs:Mover 123337428 uniqueConf 105321150 originConf 1179381257
msx-reconfagent hdfs:Mover init 123337428, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:16:39,468 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:39,468 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:16:39,471 [IPC Server handler 5 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:39,473 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:39,474 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:39,474 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:39,475 [IPC Server handler 6 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:39,477 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:39,479 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:39,480 [pool-49-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:39,480 [pool-49-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:39,483 [DataXceiver for client /127.0.0.1:43210 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:39,483 [DataXceiver for client /127.0.0.1:43210 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43210 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:16:39,484 [pool-49-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:16:39,485 [pool-49-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:16:39,485 [pool-49-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 2, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 3
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 2016038911
msx-reconfagent performReconf for comoponent hdfs:Mover 820878444 uniqueConf 2016038911 originConf 1179381257
msx-reconfagent hdfs:Mover init 820878444, irrelevant init point 4. Set value as v1 2
2020-07-01 04:16:43,481 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:43,481 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:16:43,485 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:43,486 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:43,487 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:43,487 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:43,488 [IPC Server handler 2 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:43,490 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:43,492 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:16:43,493 [pool-50-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:16:43,493 [pool-50-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:43,496 [DataXceiver for client /127.0.0.1:52946 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:43,497 [DataXceiver for client /127.0.0.1:52946 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52946 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:16:43,497 [pool-50-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:16:43,499 [pool-50-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:16:43,499 [pool-50-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 3, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 4
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 95322593
msx-reconfagent performReconf for comoponent hdfs:Mover 1509713998 uniqueConf 95322593 originConf 1179381257
msx-reconfagent hdfs:Mover init 1509713998, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:16:47,494 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:47,494 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:16:47,498 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:47,499 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:47,499 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:47,500 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:47,501 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:47,502 [IPC Server handler 5 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:47,504 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:47,505 [pool-51-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:47,505 [pool-51-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:47,508 [DataXceiver for client /127.0.0.1:43214 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:47,508 [DataXceiver for client /127.0.0.1:43214 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43214 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:16:47,508 [pool-51-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:16:47,510 [pool-51-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:16:47,510 [pool-51-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 4, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 5
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1617156106
msx-reconfagent performReconf for comoponent hdfs:Mover 1525114112 uniqueConf 1617156106 originConf 1179381257
msx-reconfagent hdfs:Mover init 1525114112, irrelevant init point 6. Set value as v1 2
2020-07-01 04:16:51,506 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:51,507 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:16:51,510 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:51,511 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:51,511 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:51,511 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:51,512 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:51,514 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:51,517 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:16:51,517 [pool-52-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:16:51,518 [pool-52-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:51,521 [DataXceiver for client /127.0.0.1:52950 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:51,521 [DataXceiver for client /127.0.0.1:52950 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52950 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:16:51,521 [pool-52-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:16:51,523 [pool-52-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:16:51,523 [pool-52-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 5, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 6
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1416665097
msx-reconfagent performReconf for comoponent hdfs:Mover 895366343 uniqueConf 1416665097 originConf 1179381257
msx-reconfagent hdfs:Mover init 895366343, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:16:55,518 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:55,519 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:16:55,522 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:55,524 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:55,524 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:55,524 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:55,526 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:55,528 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:55,530 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:16:55,531 [pool-53-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:16:55,532 [pool-53-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:55,534 [DataXceiver for client /127.0.0.1:52952 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:55,535 [DataXceiver for client /127.0.0.1:52952 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52952 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:16:55,535 [pool-53-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:16:55,537 [pool-53-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:16:55,537 [pool-53-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 6, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 7
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1624211687
msx-reconfagent performReconf for comoponent hdfs:Mover 619929778 uniqueConf 1624211687 originConf 1179381257
msx-reconfagent hdfs:Mover init 619929778, irrelevant init point 8. Set value as v1 2
2020-07-01 04:16:59,532 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:16:59,533 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:16:59,536 [IPC Server handler 6 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:59,537 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:16:59,537 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:16:59,537 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:16:59,539 [IPC Server handler 5 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:16:59,540 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:16:59,543 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:59,543 [pool-54-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:16:59,544 [pool-54-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:16:59,546 [DataXceiver for client /127.0.0.1:43220 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:16:59,547 [DataXceiver for client /127.0.0.1:43220 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43220 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:16:59,547 [pool-54-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:16:59,548 [pool-54-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:16:59,549 [pool-54-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 7, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 8
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1220806149
msx-reconfagent performReconf for comoponent hdfs:Mover 1997344422 uniqueConf 1220806149 originConf 1179381257
msx-reconfagent hdfs:Mover init 1997344422, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:17:03,545 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:03,545 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:03,548 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:03,550 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:03,550 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:03,550 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:03,551 [IPC Server handler 2 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:03,553 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:03,555 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:03,556 [pool-55-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:03,556 [pool-55-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:03,561 [DataXceiver for client /127.0.0.1:43222 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:03,561 [DataXceiver for client /127.0.0.1:43222 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43222 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:03,561 [pool-55-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:03,563 [pool-55-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:17:03,563 [pool-55-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 8, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 9
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 74885833
msx-reconfagent performReconf for comoponent hdfs:Mover 454160179 uniqueConf 74885833 originConf 1179381257
msx-reconfagent hdfs:Mover init 454160179, irrelevant init point 10. Set value as v1 2
2020-07-01 04:17:07,558 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:07,558 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:07,561 [IPC Server handler 5 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:07,563 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:07,563 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:07,563 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:07,564 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:07,566 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:07,568 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:07,569 [pool-56-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:07,569 [pool-56-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:07,572 [DataXceiver for client /127.0.0.1:52958 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:07,572 [DataXceiver for client /127.0.0.1:52958 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52958 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:07,572 [pool-56-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:07,576 [pool-56-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:17:07,576 [pool-56-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 9, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 10
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 515520300
msx-reconfagent performReconf for comoponent hdfs:Mover 791408866 uniqueConf 515520300 originConf 1179381257
msx-reconfagent hdfs:Mover init 791408866, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:17:11,570 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:11,571 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:11,577 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:11,580 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:11,580 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:11,580 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:11,581 [IPC Server handler 2 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:11,585 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:11,587 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:11,588 [pool-57-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:11,589 [pool-57-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:11,594 [DataXceiver for client /127.0.0.1:43226 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:11,595 [DataXceiver for client /127.0.0.1:43226 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43226 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:11,595 [pool-57-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:11,596 [pool-57-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:17:11,597 [pool-57-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 10, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 11
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1428494531
msx-reconfagent performReconf for comoponent hdfs:Mover 637091966 uniqueConf 1428494531 originConf 1179381257
msx-reconfagent hdfs:Mover init 637091966, irrelevant init point 12. Set value as v1 2
2020-07-01 04:17:15,589 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:15,590 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:15,592 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:15,593 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:15,594 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:15,594 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:15,595 [IPC Server handler 6 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:15,597 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:15,599 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:15,600 [pool-58-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:15,601 [pool-58-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:15,603 [DataXceiver for client /127.0.0.1:43228 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:15,604 [DataXceiver for client /127.0.0.1:43228 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43228 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:15,604 [pool-58-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:15,606 [pool-58-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:17:15,606 [pool-58-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 11, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 12
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 910123336
msx-reconfagent performReconf for comoponent hdfs:Mover 1504321715 uniqueConf 910123336 originConf 1179381257
msx-reconfagent hdfs:Mover init 1504321715, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:17:19,601 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:19,602 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:19,605 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:19,607 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:19,607 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:19,607 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:19,608 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:19,610 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:19,612 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:19,612 [pool-59-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:19,613 [pool-59-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:19,616 [DataXceiver for client /127.0.0.1:43230 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:19,616 [DataXceiver for client /127.0.0.1:43230 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43230 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:19,616 [pool-59-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:19,618 [pool-59-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:17:19,618 [pool-59-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 12, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 13
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 328197868
msx-reconfagent performReconf for comoponent hdfs:Mover 455668354 uniqueConf 328197868 originConf 1179381257
msx-reconfagent hdfs:Mover init 455668354, irrelevant init point 14. Set value as v1 2
2020-07-01 04:17:23,615 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:23,615 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:23,618 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:23,619 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:23,620 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:23,620 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:23,621 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:23,622 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:23,624 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:23,625 [pool-60-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:23,626 [pool-60-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:23,629 [DataXceiver for client /127.0.0.1:52966 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:23,629 [DataXceiver for client /127.0.0.1:52966 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52966 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:23,629 [pool-60-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:23,631 [pool-60-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:17:23,631 [pool-60-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 13, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 14
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1209451152
msx-reconfagent performReconf for comoponent hdfs:Mover 696739588 uniqueConf 1209451152 originConf 1179381257
msx-reconfagent hdfs:Mover init 696739588, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:17:27,626 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:27,627 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:27,630 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:27,633 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:27,634 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:27,634 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:27,635 [IPC Server handler 5 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:27,637 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:27,639 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:27,640 [pool-61-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:27,640 [pool-61-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:27,643 [DataXceiver for client /127.0.0.1:43234 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:27,643 [DataXceiver for client /127.0.0.1:43234 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43234 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:27,643 [pool-61-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:27,645 [pool-61-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:17:27,645 [pool-61-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 14, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 15
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 82825098
msx-reconfagent performReconf for comoponent hdfs:Mover 373437697 uniqueConf 82825098 originConf 1179381257
msx-reconfagent hdfs:Mover init 373437697, irrelevant init point 16. Set value as v1 2
2020-07-01 04:17:31,641 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:31,642 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:31,645 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:31,647 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:31,647 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:31,647 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:31,649 [IPC Server handler 2 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:31,651 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:31,654 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:31,654 [pool-62-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:31,655 [pool-62-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:31,657 [DataXceiver for client /127.0.0.1:52970 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:31,658 [DataXceiver for client /127.0.0.1:52970 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52970 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:31,658 [pool-62-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:31,659 [pool-62-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:17:31,659 [pool-62-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 15, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 16
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 2093319848
msx-reconfagent performReconf for comoponent hdfs:Mover 1168079523 uniqueConf 2093319848 originConf 1179381257
msx-reconfagent hdfs:Mover init 1168079523, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:17:35,655 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:35,656 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:35,658 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:35,660 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:35,660 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:35,660 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:35,661 [IPC Server handler 6 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:35,663 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:35,665 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:35,665 [pool-63-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:35,666 [pool-63-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:35,670 [DataXceiver for client /127.0.0.1:52972 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:35,670 [DataXceiver for client /127.0.0.1:52972 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52972 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:35,670 [pool-63-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:35,672 [pool-63-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:17:35,672 [pool-63-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 16, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 17
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 2052489518
msx-reconfagent performReconf for comoponent hdfs:Mover 1151512955 uniqueConf 2052489518 originConf 1179381257
msx-reconfagent hdfs:Mover init 1151512955, irrelevant init point 18. Set value as v1 2
2020-07-01 04:17:39,666 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:39,667 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:39,669 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:39,670 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:39,671 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:39,671 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:39,672 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:39,674 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:39,676 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:39,676 [pool-64-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:39,677 [pool-64-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:39,680 [DataXceiver for client /127.0.0.1:52974 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:39,680 [DataXceiver for client /127.0.0.1:52974 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52974 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:39,680 [pool-64-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:39,682 [pool-64-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:17:39,682 [pool-64-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 17, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 18
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 793269462
msx-reconfagent performReconf for comoponent hdfs:Mover 2125470482 uniqueConf 793269462 originConf 1179381257
msx-reconfagent hdfs:Mover init 2125470482, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:17:43,678 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:43,678 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:43,680 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:43,682 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:43,682 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:43,682 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:43,683 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:43,685 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:43,687 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:43,687 [pool-65-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:43,688 [pool-65-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:43,691 [DataXceiver for client /127.0.0.1:52976 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:43,691 [DataXceiver for client /127.0.0.1:52976 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52976 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:43,691 [pool-65-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:43,693 [pool-65-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:17:43,693 [pool-65-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 18, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 19
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 15094126
msx-reconfagent performReconf for comoponent hdfs:Mover 2121317689 uniqueConf 15094126 originConf 1179381257
msx-reconfagent hdfs:Mover init 2121317689, irrelevant init point 20. Set value as v1 2
2020-07-01 04:17:47,688 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:47,689 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:47,691 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:47,692 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:47,693 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:47,693 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:47,694 [IPC Server handler 5 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:47,696 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:47,698 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:47,698 [pool-66-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:47,699 [pool-66-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:47,702 [DataXceiver for client /127.0.0.1:43244 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:47,702 [DataXceiver for client /127.0.0.1:43244 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43244 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:47,702 [pool-66-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:47,707 [pool-66-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:17:47,707 [pool-66-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 19, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 20
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 948960194
msx-reconfagent performReconf for comoponent hdfs:Mover 1139609587 uniqueConf 948960194 originConf 1179381257
msx-reconfagent hdfs:Mover init 1139609587, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:17:51,700 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:51,701 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:51,704 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:51,706 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:51,706 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:51,706 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:51,707 [IPC Server handler 2 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:51,708 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:51,710 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:51,711 [pool-67-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:51,712 [pool-67-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:51,714 [DataXceiver for client /127.0.0.1:52980 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:51,715 [DataXceiver for client /127.0.0.1:52980 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52980 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:51,715 [pool-67-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:51,717 [pool-67-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:17:51,717 [pool-67-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 20, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 21
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1720797452
msx-reconfagent performReconf for comoponent hdfs:Mover 1302877661 uniqueConf 1720797452 originConf 1179381257
msx-reconfagent hdfs:Mover init 1302877661, irrelevant init point 22. Set value as v1 2
2020-07-01 04:17:55,712 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:55,713 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:55,715 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:55,716 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:55,717 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:55,717 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:55,718 [IPC Server handler 6 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:55,719 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:55,722 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:55,722 [pool-68-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:17:55,723 [pool-68-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:55,726 [DataXceiver for client /127.0.0.1:43248 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:55,726 [DataXceiver for client /127.0.0.1:43248 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43248 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:55,726 [pool-68-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:55,728 [pool-68-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:17:55,728 [pool-68-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 21, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 22
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 567656864
msx-reconfagent performReconf for comoponent hdfs:Mover 777813771 uniqueConf 567656864 originConf 1179381257
msx-reconfagent hdfs:Mover init 777813771, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:17:59,723 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:17:59,724 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:17:59,727 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:59,729 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:17:59,729 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:17:59,729 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:17:59,730 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:17:59,732 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:17:59,733 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:59,734 [pool-69-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:17:59,735 [pool-69-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:17:59,737 [DataXceiver for client /127.0.0.1:52984 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:17:59,738 [DataXceiver for client /127.0.0.1:52984 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52984 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:17:59,738 [pool-69-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:17:59,739 [pool-69-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:17:59,739 [pool-69-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 22, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 23
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 519019247
msx-reconfagent performReconf for comoponent hdfs:Mover 1401295795 uniqueConf 519019247 originConf 1179381257
msx-reconfagent hdfs:Mover init 1401295795, irrelevant init point 24. Set value as v1 2
2020-07-01 04:18:03,735 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:18:03,735 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:18:03,737 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:03,739 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:18:03,739 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:18:03,739 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:18:03,740 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:03,741 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:18:03,744 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:03,745 [pool-70-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:03,745 [pool-70-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:18:03,750 [DataXceiver for client /127.0.0.1:52986 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:18:03,751 [DataXceiver for client /127.0.0.1:52986 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52986 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:18:03,751 [pool-70-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:18:03,753 [pool-70-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:18:03,753 [pool-70-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 23, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 24
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1052842393
msx-reconfagent performReconf for comoponent hdfs:Mover 1572442646 uniqueConf 1052842393 originConf 1179381257
msx-reconfagent hdfs:Mover init 1572442646, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:18:07,745 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:18:07,746 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:18:07,748 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:07,749 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:18:07,749 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:18:07,749 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:18:07,750 [IPC Server handler 5 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:07,753 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:18:07,754 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:18:07,755 [pool-71-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:18:07,756 [pool-71-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:18:07,758 [DataXceiver for client /127.0.0.1:43254 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:18:07,759 [DataXceiver for client /127.0.0.1:43254 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43254 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:18:07,759 [pool-71-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:18:07,761 [pool-71-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:18:07,761 [pool-71-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 24, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 25
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 416049054
msx-reconfagent performReconf for comoponent hdfs:Mover 167013780 uniqueConf 416049054 originConf 1179381257
msx-reconfagent hdfs:Mover init 167013780, irrelevant init point 26. Set value as v1 2
2020-07-01 04:18:11,756 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:18:11,756 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:18:11,759 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:11,760 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:18:11,760 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:18:11,760 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:18:11,761 [IPC Server handler 2 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:11,762 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:18:11,764 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:11,764 [pool-72-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:11,765 [pool-72-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:18:11,768 [DataXceiver for client /127.0.0.1:52990 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:18:11,768 [DataXceiver for client /127.0.0.1:52990 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52990 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:18:11,768 [pool-72-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:18:11,771 [pool-72-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:18:11,771 [pool-72-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 25, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 26
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 108982313
msx-reconfagent performReconf for comoponent hdfs:Mover 743219449 uniqueConf 108982313 originConf 1179381257
msx-reconfagent hdfs:Mover init 743219449, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:18:15,765 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:18:15,766 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:18:15,768 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:15,769 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:18:15,769 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:18:15,769 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:18:15,770 [IPC Server handler 6 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:15,771 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:18:15,773 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:15,773 [pool-73-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:15,774 [pool-73-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:18:15,777 [DataXceiver for client /127.0.0.1:52992 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:18:15,777 [DataXceiver for client /127.0.0.1:52992 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52992 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:18:15,777 [pool-73-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:18:15,779 [pool-73-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:18:15,779 [pool-73-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 26, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 27
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 659937029
msx-reconfagent performReconf for comoponent hdfs:Mover 1851255134 uniqueConf 659937029 originConf 1179381257
msx-reconfagent hdfs:Mover init 1851255134, irrelevant init point 28. Set value as v1 2
2020-07-01 04:18:19,774 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:18:19,775 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:18:19,777 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:19,777 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:18:19,778 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:18:19,778 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:18:19,779 [IPC Server handler 7 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:19,780 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:18:19,783 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:19,783 [pool-74-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:19,784 [pool-74-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:18:19,786 [DataXceiver for client /127.0.0.1:52994 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:18:19,787 [DataXceiver for client /127.0.0.1:52994 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52994 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:18:19,787 [pool-74-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:18:19,788 [pool-74-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:18:19,789 [pool-74-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 27, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 28
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1443675930
msx-reconfagent performReconf for comoponent hdfs:Mover 121678773 uniqueConf 1443675930 originConf 1179381257
msx-reconfagent hdfs:Mover init 121678773, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:18:23,784 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:18:23,784 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:18:23,786 [IPC Server handler 9 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:23,787 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:18:23,788 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:18:23,788 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:18:23,789 [IPC Server handler 1 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:23,790 [IPC Server handler 4 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:18:23,791 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:18:23,792 [pool-75-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
2020-07-01 04:18:23,793 [pool-75-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:18:23,795 [DataXceiver for client /127.0.0.1:43262 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:18:23,796 [DataXceiver for client /127.0.0.1:43262 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from d2e8358b-d4a4-4899-9f1f-905623a79ea0]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38813:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:43262 dst: /127.0.0.1:38813
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:18:23,796 [pool-75-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:38813:DISK to 127.0.0.1:38813:ARCHIVE through 127.0.0.1:38813
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:18:23,797 [pool-75-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
2020-07-01 04:18:23,798 [pool-75-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:38813 activateDelay 10.0 seconds
msx-debug retryCount = 28, retryMaxAttempts = 5
msx-debug after retryCount.incrementAndGet() retryCount = 29
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 1468343491
msx-reconfagent performReconf for comoponent hdfs:Mover 1427775702 uniqueConf 1468343491 originConf 1179381257
msx-reconfagent hdfs:Mover init 1427775702, irrelevant init point 30. Set value as v1 2
2020-07-01 04:18:27,793 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:18:27,793 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:18:27,795 [IPC Server handler 0 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:27,797 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
2020-07-01 04:18:27,797 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38813
2020-07-01 04:18:27,797 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:18:27,798 [IPC Server handler 5 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:27,799 [IPC Server handler 8 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/testMoverFailedRetry	dst=null	perm=null	proto=rpc
2020-07-01 04:18:27,801 [Listener at localhost/45263] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:27,801 [pool-76-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
2020-07-01 04:18:27,802 [pool-76-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-07-01 04:18:27,805 [DataXceiver for client /127.0.0.1:52998 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1259)) - opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
2020-07-01 04:18:27,805 [DataXceiver for client /127.0.0.1:52998 [Replacing block BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 from 301dd7ed-e0f8-4483-a319-d576aeb9b885]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:36714:DataXceiver error processing REPLACE_BLOCK operation  src: /127.0.0.1:52998 dst: /127.0.0.1:36714
java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:926)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:904)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.moveBlockToTmpLocation(FsVolumeImpl.java:1441)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyReplicaToVolume(FsDatasetImpl.java:1037)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlock(FsDatasetImpl.java:1000)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.moveBlockAcrossStorage(FsDatasetImpl.java:977)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.replaceBlock(DataXceiver.java:1183)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReplaceBlock(Receiver.java:274)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:110)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: Source '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825' does not exist
	at org.apache.hadoop.hdfs.server.common.Storage.nativeCopyFileUnbuffered(Storage.java:1312)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.nativeCopyFileUnbuffered(FileIoProvider.java:630)
	at org.apache.hadoop.hdfs.server.datanode.LocalReplica.copyBlockdata(LocalReplica.java:412)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.copyBlockFiles(FsDatasetImpl.java:924)
	... 10 more
2020-07-01 04:18:27,805 [pool-76-thread-1] WARN  balancer.Dispatcher (Dispatcher.java:dispatch(398)) - Failed to move blk_1073741825_1001 with size=40 from 127.0.0.1:36714:DISK to 127.0.0.1:36714:ARCHIVE through 127.0.0.1:36714
java.io.IOException: Got error, status=ERROR, status message opReplaceBlock BP-500806141-172.17.0.12-1593576988050:blk_1073741825_1001 received exception java.io.IOException: Failed to copy FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 40
  getBytesOnDisk()  = 40
  getVisibleLength()= 40
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-500806141-172.17.0.12-1593576988050/current/finalized/subdir0/subdir0/blk_1073741825 block file to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-500806141-172.17.0.12-1593576988050/tmp/subdir0/subdir0/blk_1073741825, reportedBlock move is failed
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.receiveResponse(Dispatcher.java:462)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.dispatch(Dispatcher.java:393)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$PendingMove.access$3100(Dispatcher.java:235)
	at org.apache.hadoop.hdfs.server.balancer.Dispatcher$1.run(Dispatcher.java:1158)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-07-01 04:18:27,807 [pool-76-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
2020-07-01 04:18:27,807 [pool-76-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:activateDelay(696)) - DDatanode:127.0.0.1:36714 activateDelay 10.0 seconds
msx-debug retryCount = 29, retryMaxAttempts = 2
msx-debug after retryCount.incrementAndGet() retryCount = 30
msx-debug after m.run()
Mover status == ExitStatus.IN_PROGRESS
msx-reconfagent WARN: conf 1179381257 is shared with component hdfs:Mover, let copy and return new conf 2047984839
msx-reconfagent performReconf for comoponent hdfs:Mover 2114537280 uniqueConf 2047984839 originConf 1179381257
msx-reconfagent hdfs:Mover init 2114537280, PERFORM V1V2 FF_ODD RECONF -1. Set value as v2 5
2020-07-01 04:18:31,802 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-07-01 04:18:31,803 [Listener at localhost/45263] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1424)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
msx-debug before m.run()
msx-debug Mover:run
2020-07-01 04:18:31,804 [IPC Server handler 3 on default port 38886] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-07-01 04:18:31,806 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41505
2020-07-01 04:18:31,806 [Listener at localhost/45263] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36714
