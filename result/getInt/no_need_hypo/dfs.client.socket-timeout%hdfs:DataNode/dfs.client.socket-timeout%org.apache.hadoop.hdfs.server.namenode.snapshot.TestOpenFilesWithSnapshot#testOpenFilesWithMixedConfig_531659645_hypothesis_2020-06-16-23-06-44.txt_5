reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45321,DS-53ce8930-d7d8-4221-9272-f819490b540c,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-635f7682-ea7d-4cf3-82e0-3daadf601eb6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45321,DS-53ce8930-d7d8-4221-9272-f819490b540c,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-635f7682-ea7d-4cf3-82e0-3daadf601eb6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45321,DS-53ce8930-d7d8-4221-9272-f819490b540c,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-635f7682-ea7d-4cf3-82e0-3daadf601eb6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45321,DS-53ce8930-d7d8-4221-9272-f819490b540c,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-635f7682-ea7d-4cf3-82e0-3daadf601eb6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38978,DS-ce5e4517-322f-48ca-baa9-8d6bfcd3d043,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-38e5fe38-d89d-4036-947e-31d7cdb76867,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38978,DS-ce5e4517-322f-48ca-baa9-8d6bfcd3d043,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-38e5fe38-d89d-4036-947e-31d7cdb76867,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38978,DS-ce5e4517-322f-48ca-baa9-8d6bfcd3d043,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-38e5fe38-d89d-4036-947e-31d7cdb76867,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38978,DS-ce5e4517-322f-48ca-baa9-8d6bfcd3d043,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-38e5fe38-d89d-4036-947e-31d7cdb76867,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-3d143146-afbe-4076-8f32-f1c0951c9c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-4e3c6560-d801-4990-9bd9-a9af8eef2908,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-3d143146-afbe-4076-8f32-f1c0951c9c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-4e3c6560-d801-4990-9bd9-a9af8eef2908,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-3d143146-afbe-4076-8f32-f1c0951c9c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-4e3c6560-d801-4990-9bd9-a9af8eef2908,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-3d143146-afbe-4076-8f32-f1c0951c9c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-4e3c6560-d801-4990-9bd9-a9af8eef2908,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-e887e4fe-bca2-4f02-a3fb-82d4fe40eb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-1694e0a2-0729-4e7b-b164-09f2465b5f59,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-1694e0a2-0729-4e7b-b164-09f2465b5f59,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-e887e4fe-bca2-4f02-a3fb-82d4fe40eb5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-e887e4fe-bca2-4f02-a3fb-82d4fe40eb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-1694e0a2-0729-4e7b-b164-09f2465b5f59,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-1694e0a2-0729-4e7b-b164-09f2465b5f59,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-e887e4fe-bca2-4f02-a3fb-82d4fe40eb5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-ed5b689c-55ed-4df9-af24-be7f171061ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-0664bb25-bc0d-44c9-abf3-79f5c3915503,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35489,DS-0664bb25-bc0d-44c9-abf3-79f5c3915503,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-ed5b689c-55ed-4df9-af24-be7f171061ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-ed5b689c-55ed-4df9-af24-be7f171061ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-0664bb25-bc0d-44c9-abf3-79f5c3915503,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35489,DS-0664bb25-bc0d-44c9-abf3-79f5c3915503,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-ed5b689c-55ed-4df9-af24-be7f171061ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-158800d3-4b48-4a97-b914-93118c691ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-d286f15b-e846-491c-8600-092167012614,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-158800d3-4b48-4a97-b914-93118c691ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-d286f15b-e846-491c-8600-092167012614,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-158800d3-4b48-4a97-b914-93118c691ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-d286f15b-e846-491c-8600-092167012614,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-158800d3-4b48-4a97-b914-93118c691ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-d286f15b-e846-491c-8600-092167012614,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-a35bfec1-d3a9-4510-88ed-9db7fb321cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-db9d6024-241a-4ba4-a402-9af4967e16a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-a35bfec1-d3a9-4510-88ed-9db7fb321cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-db9d6024-241a-4ba4-a402-9af4967e16a5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-a35bfec1-d3a9-4510-88ed-9db7fb321cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-db9d6024-241a-4ba4-a402-9af4967e16a5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-a35bfec1-d3a9-4510-88ed-9db7fb321cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-db9d6024-241a-4ba4-a402-9af4967e16a5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-390b72a4-3d92-44d8-b567-912ec9165177,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-646c9cf5-4e37-4f50-a181-7ac79fc998b0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41526,DS-646c9cf5-4e37-4f50-a181-7ac79fc998b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-390b72a4-3d92-44d8-b567-912ec9165177,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-390b72a4-3d92-44d8-b567-912ec9165177,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-646c9cf5-4e37-4f50-a181-7ac79fc998b0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41526,DS-646c9cf5-4e37-4f50-a181-7ac79fc998b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-390b72a4-3d92-44d8-b567-912ec9165177,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-fc4d35ec-da8c-4970-8696-56a1d2a65c84,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-0b2b5e21-759f-46a2-86f5-99e39ed0846b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-fc4d35ec-da8c-4970-8696-56a1d2a65c84,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-0b2b5e21-759f-46a2-86f5-99e39ed0846b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-fc4d35ec-da8c-4970-8696-56a1d2a65c84,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-0b2b5e21-759f-46a2-86f5-99e39ed0846b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-fc4d35ec-da8c-4970-8696-56a1d2a65c84,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-0b2b5e21-759f-46a2-86f5-99e39ed0846b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-37e60c4b-9c2b-4a1d-9cb2-10d063708593,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-feb56df3-b93e-42ee-9b92-5bb7e85b0d5a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-feb56df3-b93e-42ee-9b92-5bb7e85b0d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-37e60c4b-9c2b-4a1d-9cb2-10d063708593,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-37e60c4b-9c2b-4a1d-9cb2-10d063708593,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-feb56df3-b93e-42ee-9b92-5bb7e85b0d5a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38247,DS-feb56df3-b93e-42ee-9b92-5bb7e85b0d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-37e60c4b-9c2b-4a1d-9cb2-10d063708593,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40278,DS-426358dd-2594-44e4-94ee-dd5358a9b3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-171df2f0-dbd2-4d56-8045-6c21495aac29,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41117,DS-171df2f0-dbd2-4d56-8045-6c21495aac29,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-426358dd-2594-44e4-94ee-dd5358a9b3b0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40278,DS-426358dd-2594-44e4-94ee-dd5358a9b3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-171df2f0-dbd2-4d56-8045-6c21495aac29,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41117,DS-171df2f0-dbd2-4d56-8045-6c21495aac29,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-426358dd-2594-44e4-94ee-dd5358a9b3b0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39773,DS-774faf97-3376-4d25-9fb3-2654444763a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-3473ce96-73c6-4631-9727-2e4ea2fac59e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34571,DS-3473ce96-73c6-4631-9727-2e4ea2fac59e,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-774faf97-3376-4d25-9fb3-2654444763a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39773,DS-774faf97-3376-4d25-9fb3-2654444763a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-3473ce96-73c6-4631-9727-2e4ea2fac59e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34571,DS-3473ce96-73c6-4631-9727-2e4ea2fac59e,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-774faf97-3376-4d25-9fb3-2654444763a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-bcd2738a-b0c2-4b5f-bb96-739adc5907fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-804802e0-08e3-4e64-9038-6b87b43ffd13,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-bcd2738a-b0c2-4b5f-bb96-739adc5907fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-804802e0-08e3-4e64-9038-6b87b43ffd13,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-bcd2738a-b0c2-4b5f-bb96-739adc5907fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-804802e0-08e3-4e64-9038-6b87b43ffd13,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-bcd2738a-b0c2-4b5f-bb96-739adc5907fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-804802e0-08e3-4e64-9038-6b87b43ffd13,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-b9f2edca-ce55-4e9f-b2e3-cb7ceaeb6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-5dec6ba0-183f-4987-b61c-dc3895a13c72,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-b9f2edca-ce55-4e9f-b2e3-cb7ceaeb6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-5dec6ba0-183f-4987-b61c-dc3895a13c72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-b9f2edca-ce55-4e9f-b2e3-cb7ceaeb6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-5dec6ba0-183f-4987-b61c-dc3895a13c72,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-b9f2edca-ce55-4e9f-b2e3-cb7ceaeb6c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-5dec6ba0-183f-4987-b61c-dc3895a13c72,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-ef0b9ff1-4493-4db3-9cc2-db0d9b1ebe18,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-838ce5bc-8a81-4934-ac9b-9608b4f325af,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-ef0b9ff1-4493-4db3-9cc2-db0d9b1ebe18,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-838ce5bc-8a81-4934-ac9b-9608b4f325af,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-ef0b9ff1-4493-4db3-9cc2-db0d9b1ebe18,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-838ce5bc-8a81-4934-ac9b-9608b4f325af,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-ef0b9ff1-4493-4db3-9cc2-db0d9b1ebe18,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-838ce5bc-8a81-4934-ac9b-9608b4f325af,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-dae6864e-c9fd-4ada-986f-98fcbec73675,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-799bf402-915e-4221-82ac-464f6c0f0898,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-dae6864e-c9fd-4ada-986f-98fcbec73675,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-799bf402-915e-4221-82ac-464f6c0f0898,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-dae6864e-c9fd-4ada-986f-98fcbec73675,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-799bf402-915e-4221-82ac-464f6c0f0898,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-dae6864e-c9fd-4ada-986f-98fcbec73675,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-799bf402-915e-4221-82ac-464f6c0f0898,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-79bb6865-c5eb-4012-b613-249e0c7d2457,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-ca141cc4-0545-4f61-a633-b039f4e241b2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39995,DS-ca141cc4-0545-4f61-a633-b039f4e241b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-79bb6865-c5eb-4012-b613-249e0c7d2457,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33043,DS-79bb6865-c5eb-4012-b613-249e0c7d2457,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-ca141cc4-0545-4f61-a633-b039f4e241b2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39995,DS-ca141cc4-0545-4f61-a633-b039f4e241b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-79bb6865-c5eb-4012-b613-249e0c7d2457,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-95eb2d2b-4d9f-4030-b753-69ed4140d65d,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-626b1b4b-428a-405f-b307-12da09c0ffb4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-95eb2d2b-4d9f-4030-b753-69ed4140d65d,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-626b1b4b-428a-405f-b307-12da09c0ffb4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-95eb2d2b-4d9f-4030-b753-69ed4140d65d,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-626b1b4b-428a-405f-b307-12da09c0ffb4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36534,DS-95eb2d2b-4d9f-4030-b753-69ed4140d65d,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-626b1b4b-428a-405f-b307-12da09c0ffb4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34376,DS-11d5af9a-74ff-4a25-94aa-f4c9156aea05,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-7e3b13e9-9595-431c-94aa-6c5439515082,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34376,DS-11d5af9a-74ff-4a25-94aa-f4c9156aea05,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-7e3b13e9-9595-431c-94aa-6c5439515082,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34376,DS-11d5af9a-74ff-4a25-94aa-f4c9156aea05,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-7e3b13e9-9595-431c-94aa-6c5439515082,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34376,DS-11d5af9a-74ff-4a25-94aa-f4c9156aea05,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-7e3b13e9-9595-431c-94aa-6c5439515082,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot#testOpenFilesWithMixedConfig
reconfPoint: -1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-47c5187d-2253-4e3b-b26f-4355753eafe0,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-aa2c7a1e-4e7b-4fe5-aa4b-90d4c44142e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-47c5187d-2253-4e3b-b26f-4355753eafe0,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-aa2c7a1e-4e7b-4fe5-aa4b-90d4c44142e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-47c5187d-2253-4e3b-b26f-4355753eafe0,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-aa2c7a1e-4e7b-4fe5-aa4b-90d4c44142e3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-47c5187d-2253-4e3b-b26f-4355753eafe0,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-aa2c7a1e-4e7b-4fe5-aa4b-90d4c44142e3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1304)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1372)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1598)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1499)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1481)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 18 out of 50
v1v1v2v2 failed with probability 2 out of 50
result: might be true error
Total execution time in seconds : 3513
