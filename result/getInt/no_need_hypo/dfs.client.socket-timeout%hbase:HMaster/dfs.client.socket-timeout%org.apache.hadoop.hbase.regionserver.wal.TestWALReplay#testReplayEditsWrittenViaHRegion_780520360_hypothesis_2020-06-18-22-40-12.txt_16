reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38841,DS-b696cccd-842e-485d-9873-f3a45bb68022,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-3ef41e4e-0c74-4349-a03b-b487c3cc43a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38841,DS-b696cccd-842e-485d-9873-f3a45bb68022,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-3ef41e4e-0c74-4349-a03b-b487c3cc43a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38841,DS-b696cccd-842e-485d-9873-f3a45bb68022,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-3ef41e4e-0c74-4349-a03b-b487c3cc43a3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38841,DS-b696cccd-842e-485d-9873-f3a45bb68022,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-3ef41e4e-0c74-4349-a03b-b487c3cc43a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-27fdb446-51e5-4e72-95da-5b193e59290a,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-96512bb5-068b-43b1-b030-db95e0875854,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-27fdb446-51e5-4e72-95da-5b193e59290a,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-96512bb5-068b-43b1-b030-db95e0875854,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-27fdb446-51e5-4e72-95da-5b193e59290a,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-96512bb5-068b-43b1-b030-db95e0875854,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-27fdb446-51e5-4e72-95da-5b193e59290a,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-96512bb5-068b-43b1-b030-db95e0875854,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38668,DS-3bc94562-c1fc-4445-9172-bdd74ce2fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-24235cc8-75bf-482e-b4c9-efed114283b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38668,DS-3bc94562-c1fc-4445-9172-bdd74ce2fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-24235cc8-75bf-482e-b4c9-efed114283b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38668,DS-3bc94562-c1fc-4445-9172-bdd74ce2fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-24235cc8-75bf-482e-b4c9-efed114283b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38668,DS-3bc94562-c1fc-4445-9172-bdd74ce2fd06,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-24235cc8-75bf-482e-b4c9-efed114283b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-f8aa28e1-264e-40b1-923a-9245556830bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-9fc67be6-3a64-4a8b-add4-72fa220bffe9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-f8aa28e1-264e-40b1-923a-9245556830bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-9fc67be6-3a64-4a8b-add4-72fa220bffe9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-f8aa28e1-264e-40b1-923a-9245556830bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-9fc67be6-3a64-4a8b-add4-72fa220bffe9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-f8aa28e1-264e-40b1-923a-9245556830bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-9fc67be6-3a64-4a8b-add4-72fa220bffe9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-49cc2614-1276-4ca3-9a8d-d93a0fb9e563,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-87d51e3b-c2d5-4715-9a0e-6dd5217a202d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-49cc2614-1276-4ca3-9a8d-d93a0fb9e563,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-87d51e3b-c2d5-4715-9a0e-6dd5217a202d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-49cc2614-1276-4ca3-9a8d-d93a0fb9e563,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-87d51e3b-c2d5-4715-9a0e-6dd5217a202d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-49cc2614-1276-4ca3-9a8d-d93a0fb9e563,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-87d51e3b-c2d5-4715-9a0e-6dd5217a202d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=37, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=37, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37858,DS-6a536cab-b317-47b5-adf7-b33ce9572f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-85af79a4-24d5-48ba-b610-c360b4ab6a36,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-85af79a4-24d5-48ba-b610-c360b4ab6a36,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-6a536cab-b317-47b5-adf7-b33ce9572f0c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-830a36dc-1cb0-480c-adad-ffb74a429ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-f22fdbb0-0ed1-4b8e-a02b-5f73677fb52f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-830a36dc-1cb0-480c-adad-ffb74a429ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-f22fdbb0-0ed1-4b8e-a02b-5f73677fb52f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-830a36dc-1cb0-480c-adad-ffb74a429ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-f22fdbb0-0ed1-4b8e-a02b-5f73677fb52f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-830a36dc-1cb0-480c-adad-ffb74a429ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-f22fdbb0-0ed1-4b8e-a02b-5f73677fb52f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35048,DS-c32feaf3-774d-48bb-9c7f-bc794d27f720,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-a9a8bf0e-8e6d-4d99-aac3-9d42fc6b75e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35048,DS-c32feaf3-774d-48bb-9c7f-bc794d27f720,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-a9a8bf0e-8e6d-4d99-aac3-9d42fc6b75e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35048,DS-c32feaf3-774d-48bb-9c7f-bc794d27f720,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-a9a8bf0e-8e6d-4d99-aac3-9d42fc6b75e1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35048,DS-c32feaf3-774d-48bb-9c7f-bc794d27f720,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-a9a8bf0e-8e6d-4d99-aac3-9d42fc6b75e1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36177,DS-428215fc-066d-4489-a404-1fd1eb79369e,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-82679c04-10d0-4938-864e-68c45f6e508c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34084,DS-82679c04-10d0-4938-864e-68c45f6e508c,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-428215fc-066d-4489-a404-1fd1eb79369e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36177,DS-428215fc-066d-4489-a404-1fd1eb79369e,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-82679c04-10d0-4938-864e-68c45f6e508c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34084,DS-82679c04-10d0-4938-864e-68c45f6e508c,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-428215fc-066d-4489-a404-1fd1eb79369e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-b83dfcf6-5f83-41dc-8a7f-f78043ab1a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-498a207f-6f5b-4487-af7e-a82cebce01b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-b83dfcf6-5f83-41dc-8a7f-f78043ab1a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-498a207f-6f5b-4487-af7e-a82cebce01b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-b83dfcf6-5f83-41dc-8a7f-f78043ab1a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-498a207f-6f5b-4487-af7e-a82cebce01b4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35969,DS-b83dfcf6-5f83-41dc-8a7f-f78043ab1a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-498a207f-6f5b-4487-af7e-a82cebce01b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44960,DS-da7d2d91-5639-4157-a4b9-38a32dbe958d,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-64d3be4d-6983-4987-9b47-c17d1baf568e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44960,DS-da7d2d91-5639-4157-a4b9-38a32dbe958d,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-64d3be4d-6983-4987-9b47-c17d1baf568e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44960,DS-da7d2d91-5639-4157-a4b9-38a32dbe958d,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-64d3be4d-6983-4987-9b47-c17d1baf568e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44960,DS-da7d2d91-5639-4157-a4b9-38a32dbe958d,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-64d3be4d-6983-4987-9b47-c17d1baf568e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-d0ec9b1b-44a1-4e7a-8cc3-1e5d36ad7839,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-a8fc9e55-a690-4e3a-9cf1-a9ba02245262,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-d0ec9b1b-44a1-4e7a-8cc3-1e5d36ad7839,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-a8fc9e55-a690-4e3a-9cf1-a9ba02245262,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-d0ec9b1b-44a1-4e7a-8cc3-1e5d36ad7839,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-a8fc9e55-a690-4e3a-9cf1-a9ba02245262,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-d0ec9b1b-44a1-4e7a-8cc3-1e5d36ad7839,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-a8fc9e55-a690-4e3a-9cf1-a9ba02245262,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-08a2771f-617d-41e9-aa90-be5ec9a842b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-4a0df42c-614b-4279-bfee-f9ff82ba6f04,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-08a2771f-617d-41e9-aa90-be5ec9a842b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-4a0df42c-614b-4279-bfee-f9ff82ba6f04,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-08a2771f-617d-41e9-aa90-be5ec9a842b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-4a0df42c-614b-4279-bfee-f9ff82ba6f04,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42761,DS-08a2771f-617d-41e9-aa90-be5ec9a842b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-4a0df42c-614b-4279-bfee-f9ff82ba6f04,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-32bc0ebc-f2a6-4d06-8af4-9a2db78ff02b,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2bb69100-426f-4f93-b056-202f7d9e45cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-32bc0ebc-f2a6-4d06-8af4-9a2db78ff02b,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2bb69100-426f-4f93-b056-202f7d9e45cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-32bc0ebc-f2a6-4d06-8af4-9a2db78ff02b,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2bb69100-426f-4f93-b056-202f7d9e45cc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-32bc0ebc-f2a6-4d06-8af4-9a2db78ff02b,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-2bb69100-426f-4f93-b056-202f7d9e45cc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-573751a8-de38-4909-b9fb-0bf3bc99372a,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-68bdb7ca-6769-4a8f-8de3-1e88896a04a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-573751a8-de38-4909-b9fb-0bf3bc99372a,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-68bdb7ca-6769-4a8f-8de3-1e88896a04a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-573751a8-de38-4909-b9fb-0bf3bc99372a,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-68bdb7ca-6769-4a8f-8de3-1e88896a04a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43139,DS-573751a8-de38-4909-b9fb-0bf3bc99372a,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-68bdb7ca-6769-4a8f-8de3-1e88896a04a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-f84a5746-f58a-47ab-9feb-7913a45c0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-82862895-5305-460f-b9a6-247f166e205c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-f84a5746-f58a-47ab-9feb-7913a45c0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-82862895-5305-460f-b9a6-247f166e205c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-f84a5746-f58a-47ab-9feb-7913a45c0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-82862895-5305-460f-b9a6-247f166e205c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-f84a5746-f58a-47ab-9feb-7913a45c0d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-82862895-5305-460f-b9a6-247f166e205c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35780,DS-926366cb-0dbe-4b6d-b344-9a9f506366a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-13edd619-ebfa-49b6-a488-16bb07b315d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35780,DS-926366cb-0dbe-4b6d-b344-9a9f506366a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-13edd619-ebfa-49b6-a488-16bb07b315d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35780,DS-926366cb-0dbe-4b6d-b344-9a9f506366a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-13edd619-ebfa-49b6-a488-16bb07b315d9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35780,DS-926366cb-0dbe-4b6d-b344-9a9f506366a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-13edd619-ebfa-49b6-a488-16bb07b315d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39958,DS-e4d5c07d-5423-435b-873b-fdf2380fad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-d222dbfa-03f7-4319-9131-a5f3c008ec82,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-d222dbfa-03f7-4319-9131-a5f3c008ec82,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-e4d5c07d-5423-435b-873b-fdf2380fad2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39958,DS-e4d5c07d-5423-435b-873b-fdf2380fad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-d222dbfa-03f7-4319-9131-a5f3c008ec82,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-d222dbfa-03f7-4319-9131-a5f3c008ec82,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-e4d5c07d-5423-435b-873b-fdf2380fad2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43778,DS-b3aadaff-b59a-4ca7-bfd2-ec26902c77ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-6658721e-009b-456e-8807-b0714c8bf065,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43778,DS-b3aadaff-b59a-4ca7-bfd2-ec26902c77ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-6658721e-009b-456e-8807-b0714c8bf065,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43778,DS-b3aadaff-b59a-4ca7-bfd2-ec26902c77ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-6658721e-009b-456e-8807-b0714c8bf065,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43778,DS-b3aadaff-b59a-4ca7-bfd2-ec26902c77ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-6658721e-009b-456e-8807-b0714c8bf065,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32980,DS-af9401c3-eb33-4f69-afc2-7d5737d1dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-50547759-3a50-47ae-8e82-a5d178ca5d88,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-50547759-3a50-47ae-8e82-a5d178ca5d88,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-af9401c3-eb33-4f69-afc2-7d5737d1dc2e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32980,DS-af9401c3-eb33-4f69-afc2-7d5737d1dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-50547759-3a50-47ae-8e82-a5d178ca5d88,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-50547759-3a50-47ae-8e82-a5d178ca5d88,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-af9401c3-eb33-4f69-afc2-7d5737d1dc2e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-e1f71c09-09a2-40ab-bc3b-1ff989232703,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-8dabbd3d-8fe6-49dc-91e9-e0fa84722581,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-e1f71c09-09a2-40ab-bc3b-1ff989232703,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-8dabbd3d-8fe6-49dc-91e9-e0fa84722581,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-e1f71c09-09a2-40ab-bc3b-1ff989232703,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-8dabbd3d-8fe6-49dc-91e9-e0fa84722581,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-e1f71c09-09a2-40ab-bc3b-1ff989232703,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-8dabbd3d-8fe6-49dc-91e9-e0fa84722581,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-e6d77453-2a5f-4de4-8c32-270145a88378,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-40c506f5-9cba-41fd-9861-dcd4e46094ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-e6d77453-2a5f-4de4-8c32-270145a88378,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-40c506f5-9cba-41fd-9861-dcd4e46094ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-e6d77453-2a5f-4de4-8c32-270145a88378,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-40c506f5-9cba-41fd-9861-dcd4e46094ec,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-e6d77453-2a5f-4de4-8c32-270145a88378,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-40c506f5-9cba-41fd-9861-dcd4e46094ec,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37477,DS-dfe0c3eb-8461-4f70-950f-a8d30b0c6556,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-a688bfe4-3498-44e8-9a7a-1825545c7050,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40467,DS-a688bfe4-3498-44e8-9a7a-1825545c7050,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-dfe0c3eb-8461-4f70-950f-a8d30b0c6556,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37477,DS-dfe0c3eb-8461-4f70-950f-a8d30b0c6556,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-a688bfe4-3498-44e8-9a7a-1825545c7050,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40467,DS-a688bfe4-3498-44e8-9a7a-1825545c7050,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-dfe0c3eb-8461-4f70-950f-a8d30b0c6556,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38662,DS-f4641a6b-b6f6-4e70-b1ff-47a2d5f1292a,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-1f417225-7ea2-4398-a631-6700e1071550,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-1f417225-7ea2-4398-a631-6700e1071550,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-f4641a6b-b6f6-4e70-b1ff-47a2d5f1292a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38662,DS-f4641a6b-b6f6-4e70-b1ff-47a2d5f1292a,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-1f417225-7ea2-4398-a631-6700e1071550,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-1f417225-7ea2-4398-a631-6700e1071550,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-f4641a6b-b6f6-4e70-b1ff-47a2d5f1292a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37947,DS-48e9c7b9-8d2a-4fe4-9fe3-40dd1cd3852b,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-6e5ce607-eb84-42c0-b05c-33a454b49267,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-6e5ce607-eb84-42c0-b05c-33a454b49267,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-48e9c7b9-8d2a-4fe4-9fe3-40dd1cd3852b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37947,DS-48e9c7b9-8d2a-4fe4-9fe3-40dd1cd3852b,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-6e5ce607-eb84-42c0-b05c-33a454b49267,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-6e5ce607-eb84-42c0-b05c-33a454b49267,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-48e9c7b9-8d2a-4fe4-9fe3-40dd1cd3852b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-f2bf771d-7146-48f3-8115-e62602f880e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-b2ae6c9d-45c6-4565-8617-f457cc7628a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-f2bf771d-7146-48f3-8115-e62602f880e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-b2ae6c9d-45c6-4565-8617-f457cc7628a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-f2bf771d-7146-48f3-8115-e62602f880e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-b2ae6c9d-45c6-4565-8617-f457cc7628a2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-f2bf771d-7146-48f3-8115-e62602f880e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-b2ae6c9d-45c6-4565-8617-f457cc7628a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-06061dad-0547-4157-9dc9-4bdb4fbc4e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-ccf1b558-3402-49d1-b829-543f3e8a6522,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-06061dad-0547-4157-9dc9-4bdb4fbc4e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-ccf1b558-3402-49d1-b829-543f3e8a6522,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-06061dad-0547-4157-9dc9-4bdb4fbc4e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-ccf1b558-3402-49d1-b829-543f3e8a6522,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-06061dad-0547-4157-9dc9-4bdb4fbc4e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-ccf1b558-3402-49d1-b829-543f3e8a6522,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-19a0106d-b33e-4a26-853a-9f45a6d0a37f,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-6766674c-1306-4d63-b54b-41d03071c4a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-19a0106d-b33e-4a26-853a-9f45a6d0a37f,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-6766674c-1306-4d63-b54b-41d03071c4a1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-19a0106d-b33e-4a26-853a-9f45a6d0a37f,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-6766674c-1306-4d63-b54b-41d03071c4a1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-19a0106d-b33e-4a26-853a-9f45a6d0a37f,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-6766674c-1306-4d63-b54b-41d03071c4a1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-a463fed2-4243-4388-b819-90ed2f4ae978,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-60052ba3-d399-4195-8cc6-ad56ec4a3cc2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-a463fed2-4243-4388-b819-90ed2f4ae978,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-60052ba3-d399-4195-8cc6-ad56ec4a3cc2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-a463fed2-4243-4388-b819-90ed2f4ae978,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-60052ba3-d399-4195-8cc6-ad56ec4a3cc2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-a463fed2-4243-4388-b819-90ed2f4ae978,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-60052ba3-d399-4195-8cc6-ad56ec4a3cc2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-17866f8a-fbe9-45e2-8f1d-e3bd8ab18240,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-f8582d96-1294-4b02-9f68-a024b362130b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-17866f8a-fbe9-45e2-8f1d-e3bd8ab18240,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-f8582d96-1294-4b02-9f68-a024b362130b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-17866f8a-fbe9-45e2-8f1d-e3bd8ab18240,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-f8582d96-1294-4b02-9f68-a024b362130b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32983,DS-17866f8a-fbe9-45e2-8f1d-e3bd8ab18240,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-f8582d96-1294-4b02-9f68-a024b362130b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-b288cfcc-57a1-4080-873a-30e3887b950e,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-0fe96036-5401-42f4-9225-28bd55ad3eee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-b288cfcc-57a1-4080-873a-30e3887b950e,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-0fe96036-5401-42f4-9225-28bd55ad3eee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-b288cfcc-57a1-4080-873a-30e3887b950e,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-0fe96036-5401-42f4-9225-28bd55ad3eee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-b288cfcc-57a1-4080-873a-30e3887b950e,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-0fe96036-5401-42f4-9225-28bd55ad3eee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33868,DS-1df891fe-0cbb-4d29-94b1-26cbe6d2a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-7b7f05c2-e4c1-4287-83d2-80af3f48d300,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33868,DS-1df891fe-0cbb-4d29-94b1-26cbe6d2a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-7b7f05c2-e4c1-4287-83d2-80af3f48d300,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33868,DS-1df891fe-0cbb-4d29-94b1-26cbe6d2a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-7b7f05c2-e4c1-4287-83d2-80af3f48d300,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33868,DS-1df891fe-0cbb-4d29-94b1-26cbe6d2a6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-7b7f05c2-e4c1-4287-83d2-80af3f48d300,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-0ff91bd2-ff3a-4da7-b3e7-ecd2f28fb36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-fe952137-f70d-4282-afbf-c93bb8e3832d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-0ff91bd2-ff3a-4da7-b3e7-ecd2f28fb36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-fe952137-f70d-4282-afbf-c93bb8e3832d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-0ff91bd2-ff3a-4da7-b3e7-ecd2f28fb36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-fe952137-f70d-4282-afbf-c93bb8e3832d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-0ff91bd2-ff3a-4da7-b3e7-ecd2f28fb36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-fe952137-f70d-4282-afbf-c93bb8e3832d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45649,DS-cf1fea80-a83d-4262-8e13-d37a0881bced,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-db3d7f98-cfd8-421f-affe-9f01045892ee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45649,DS-cf1fea80-a83d-4262-8e13-d37a0881bced,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-db3d7f98-cfd8-421f-affe-9f01045892ee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45649,DS-cf1fea80-a83d-4262-8e13-d37a0881bced,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-db3d7f98-cfd8-421f-affe-9f01045892ee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45649,DS-cf1fea80-a83d-4262-8e13-d37a0881bced,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-db3d7f98-cfd8-421f-affe-9f01045892ee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-d4b6f1f7-7546-488b-96f0-a832a34f7cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-1e20d346-0f60-439f-821c-a4d81713c3c6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-1e20d346-0f60-439f-821c-a4d81713c3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-d4b6f1f7-7546-488b-96f0-a832a34f7cd8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39038,DS-d4b6f1f7-7546-488b-96f0-a832a34f7cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-1e20d346-0f60-439f-821c-a4d81713c3c6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-1e20d346-0f60-439f-821c-a4d81713c3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-d4b6f1f7-7546-488b-96f0-a832a34f7cd8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-fc907b04-e0b6-4a91-9bf6-3e2b27d4526c,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-16b90211-dc03-42cb-bc77-0739e3a8984f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46504,DS-16b90211-dc03-42cb-bc77-0739e3a8984f,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-fc907b04-e0b6-4a91-9bf6-3e2b27d4526c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-fc907b04-e0b6-4a91-9bf6-3e2b27d4526c,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-16b90211-dc03-42cb-bc77-0739e3a8984f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46504,DS-16b90211-dc03-42cb-bc77-0739e3a8984f,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-fc907b04-e0b6-4a91-9bf6-3e2b27d4526c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-ddcf6c48-56e9-476e-9da6-8ec673cbd11b,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-4059e9b2-2f3f-4b32-938e-85e74ae8d44d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40119,DS-4059e9b2-2f3f-4b32-938e-85e74ae8d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-ddcf6c48-56e9-476e-9da6-8ec673cbd11b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-ddcf6c48-56e9-476e-9da6-8ec673cbd11b,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-4059e9b2-2f3f-4b32-938e-85e74ae8d44d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40119,DS-4059e9b2-2f3f-4b32-938e-85e74ae8d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-ddcf6c48-56e9-476e-9da6-8ec673cbd11b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38600,DS-6dc1bf29-4fbf-4a65-b56c-2e1e6f7dc38b,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-b9f691ac-c061-4ff3-b3ab-f5b33dae621a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39963,DS-b9f691ac-c061-4ff3-b3ab-f5b33dae621a,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-6dc1bf29-4fbf-4a65-b56c-2e1e6f7dc38b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38600,DS-6dc1bf29-4fbf-4a65-b56c-2e1e6f7dc38b,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-b9f691ac-c061-4ff3-b3ab-f5b33dae621a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39963,DS-b9f691ac-c061-4ff3-b3ab-f5b33dae621a,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-6dc1bf29-4fbf-4a65-b56c-2e1e6f7dc38b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-56b5de1c-35da-48eb-9cff-00bc808e48fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-e147484e-b729-46a6-a88c-82c200166b13,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-56b5de1c-35da-48eb-9cff-00bc808e48fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-e147484e-b729-46a6-a88c-82c200166b13,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-56b5de1c-35da-48eb-9cff-00bc808e48fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-e147484e-b729-46a6-a88c-82c200166b13,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-56b5de1c-35da-48eb-9cff-00bc808e48fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-e147484e-b729-46a6-a88c-82c200166b13,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-aa7b6c0c-600f-44e2-aadb-503ad944dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-39c9a049-8dc1-45fd-a5a0-cc943ce68170,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-aa7b6c0c-600f-44e2-aadb-503ad944dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-39c9a049-8dc1-45fd-a5a0-cc943ce68170,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-aa7b6c0c-600f-44e2-aadb-503ad944dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-39c9a049-8dc1-45fd-a5a0-cc943ce68170,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-aa7b6c0c-600f-44e2-aadb-503ad944dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-39c9a049-8dc1-45fd-a5a0-cc943ce68170,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-65b4e59a-14a1-4b6f-924c-392031b67a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-5791390b-8654-4f42-a619-fe5c9d621316,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40224,DS-5791390b-8654-4f42-a619-fe5c9d621316,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-65b4e59a-14a1-4b6f-924c-392031b67a4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-65b4e59a-14a1-4b6f-924c-392031b67a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-5791390b-8654-4f42-a619-fe5c9d621316,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40224,DS-5791390b-8654-4f42-a619-fe5c9d621316,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-65b4e59a-14a1-4b6f-924c-392031b67a4e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-94a10e41-da29-4670-885a-dd4c2e9b18ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-10d3fb81-2767-43ed-9831-dcbc466285f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-94a10e41-da29-4670-885a-dd4c2e9b18ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-10d3fb81-2767-43ed-9831-dcbc466285f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-94a10e41-da29-4670-885a-dd4c2e9b18ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-10d3fb81-2767-43ed-9831-dcbc466285f9,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-94a10e41-da29-4670-885a-dd4c2e9b18ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-10d3fb81-2767-43ed-9831-dcbc466285f9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-0d78b9d8-b215-4b16-bbff-96f9b43c2e36,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-6e508427-566a-4a19-bd1f-23aec7d15606,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-0d78b9d8-b215-4b16-bbff-96f9b43c2e36,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-6e508427-566a-4a19-bd1f-23aec7d15606,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-0d78b9d8-b215-4b16-bbff-96f9b43c2e36,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-6e508427-566a-4a19-bd1f-23aec7d15606,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-0d78b9d8-b215-4b16-bbff-96f9b43c2e36,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-6e508427-566a-4a19-bd1f-23aec7d15606,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44561,DS-3958fea0-7f4a-4ac5-a682-193f1a9034dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-d139a231-4b8d-4cf2-b1a9-e9807a9383cf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44561,DS-3958fea0-7f4a-4ac5-a682-193f1a9034dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-d139a231-4b8d-4cf2-b1a9-e9807a9383cf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44561,DS-3958fea0-7f4a-4ac5-a682-193f1a9034dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-d139a231-4b8d-4cf2-b1a9-e9807a9383cf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44561,DS-3958fea0-7f4a-4ac5-a682-193f1a9034dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-d139a231-4b8d-4cf2-b1a9-e9807a9383cf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46301,DS-c1e53e09-daed-42aa-8e6e-cdac3bd890bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-853bb2bd-cd11-4f29-a5cf-25c0a2254194,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37667,DS-853bb2bd-cd11-4f29-a5cf-25c0a2254194,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-c1e53e09-daed-42aa-8e6e-cdac3bd890bb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46301,DS-c1e53e09-daed-42aa-8e6e-cdac3bd890bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-853bb2bd-cd11-4f29-a5cf-25c0a2254194,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37667,DS-853bb2bd-cd11-4f29-a5cf-25c0a2254194,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-c1e53e09-daed-42aa-8e6e-cdac3bd890bb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-e6c47797-3afa-4de2-8709-b0344dfcd8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-9dda7561-9b90-4b76-b043-4b017cfd2830,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32959,DS-9dda7561-9b90-4b76-b043-4b017cfd2830,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-e6c47797-3afa-4de2-8709-b0344dfcd8c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-e6c47797-3afa-4de2-8709-b0344dfcd8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-9dda7561-9b90-4b76-b043-4b017cfd2830,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32959,DS-9dda7561-9b90-4b76-b043-4b017cfd2830,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-e6c47797-3afa-4de2-8709-b0344dfcd8c2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44801,DS-4cacd880-2ef2-497b-98a8-b1d125ef7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-974991b4-19ab-4bb3-a36a-80a498627376,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44801,DS-4cacd880-2ef2-497b-98a8-b1d125ef7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-974991b4-19ab-4bb3-a36a-80a498627376,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44801,DS-4cacd880-2ef2-497b-98a8-b1d125ef7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-974991b4-19ab-4bb3-a36a-80a498627376,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44801,DS-4cacd880-2ef2-497b-98a8-b1d125ef7eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-974991b4-19ab-4bb3-a36a-80a498627376,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34027,DS-7a726596-dbba-49f1-a5b2-c595148d209e,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-50cfdef8-2c3d-4315-8ac0-daa003a56166,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-50cfdef8-2c3d-4315-8ac0-daa003a56166,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-7a726596-dbba-49f1-a5b2-c595148d209e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34027,DS-7a726596-dbba-49f1-a5b2-c595148d209e,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-50cfdef8-2c3d-4315-8ac0-daa003a56166,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-50cfdef8-2c3d-4315-8ac0-daa003a56166,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-7a726596-dbba-49f1-a5b2-c595148d209e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33792,DS-ca1a9ba1-4fcd-4fde-8c96-4448f34a7d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-0bcc3829-a003-4c82-a5d0-c22379b82306,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33792,DS-ca1a9ba1-4fcd-4fde-8c96-4448f34a7d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-0bcc3829-a003-4c82-a5d0-c22379b82306,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33792,DS-ca1a9ba1-4fcd-4fde-8c96-4448f34a7d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-0bcc3829-a003-4c82-a5d0-c22379b82306,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33792,DS-ca1a9ba1-4fcd-4fde-8c96-4448f34a7d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-0bcc3829-a003-4c82-a5d0-c22379b82306,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-0d3899ae-0075-40d6-a1ce-fc156c5b657e,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-187d4e97-a954-4d98-b51d-e5e96a63f86a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-0d3899ae-0075-40d6-a1ce-fc156c5b657e,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-187d4e97-a954-4d98-b51d-e5e96a63f86a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-0d3899ae-0075-40d6-a1ce-fc156c5b657e,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-187d4e97-a954-4d98-b51d-e5e96a63f86a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-0d3899ae-0075-40d6-a1ce-fc156c5b657e,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-187d4e97-a954-4d98-b51d-e5e96a63f86a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#testReplayEditsWrittenViaHRegion
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-ef1bd18c-c77c-4e5f-a972-40ac38d65601,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-c5ed844c-954a-4545-88fa-032d1a1f31fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-ef1bd18c-c77c-4e5f-a972-40ac38d65601,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-c5ed844c-954a-4545-88fa-032d1a1f31fa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-ef1bd18c-c77c-4e5f-a972-40ac38d65601,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-c5ed844c-954a-4545-88fa-032d1a1f31fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39302,DS-ef1bd18c-c77c-4e5f-a972-40ac38d65601,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-c5ed844c-954a-4545-88fa-032d1a1f31fa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 1 out of 50
result: might be true error
Total execution time in seconds : 12668
