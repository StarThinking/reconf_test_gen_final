reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43182,DS-ff2f0ff2-21c9-4429-bdfe-d095560c9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-fd744ce7-9aec-471f-a06f-25a8b8d2f260,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43182,DS-ff2f0ff2-21c9-4429-bdfe-d095560c9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-fd744ce7-9aec-471f-a06f-25a8b8d2f260,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43182,DS-ff2f0ff2-21c9-4429-bdfe-d095560c9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-fd744ce7-9aec-471f-a06f-25a8b8d2f260,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43182,DS-ff2f0ff2-21c9-4429-bdfe-d095560c9d77,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-fd744ce7-9aec-471f-a06f-25a8b8d2f260,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33189,DS-09ae07bf-a8fa-4dfb-99ed-5552c62e8b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-db52c5fc-65e8-46c4-8605-1ab3f0bcfae5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-db52c5fc-65e8-46c4-8605-1ab3f0bcfae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-09ae07bf-a8fa-4dfb-99ed-5552c62e8b01,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33189,DS-09ae07bf-a8fa-4dfb-99ed-5552c62e8b01,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-db52c5fc-65e8-46c4-8605-1ab3f0bcfae5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-db52c5fc-65e8-46c4-8605-1ab3f0bcfae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-09ae07bf-a8fa-4dfb-99ed-5552c62e8b01,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-865f0927-ec42-4149-a02d-951726724c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-4ca6db9d-ec69-4524-931d-b92b4cd6b2f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-4ca6db9d-ec69-4524-931d-b92b4cd6b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-865f0927-ec42-4149-a02d-951726724c4b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-865f0927-ec42-4149-a02d-951726724c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-4ca6db9d-ec69-4524-931d-b92b4cd6b2f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-4ca6db9d-ec69-4524-931d-b92b4cd6b2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-865f0927-ec42-4149-a02d-951726724c4b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-44a0b3f8-d88d-427e-a8e1-bffd074b443c,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-e6f90b20-11f5-4e64-839e-f5e8139d5705,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41330,DS-e6f90b20-11f5-4e64-839e-f5e8139d5705,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-44a0b3f8-d88d-427e-a8e1-bffd074b443c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41424,DS-44a0b3f8-d88d-427e-a8e1-bffd074b443c,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-e6f90b20-11f5-4e64-839e-f5e8139d5705,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41330,DS-e6f90b20-11f5-4e64-839e-f5e8139d5705,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-44a0b3f8-d88d-427e-a8e1-bffd074b443c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-2761f8a6-e5bf-491a-9f6f-03e0a5f332fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-30ca46bd-57f0-408e-bb59-c6a06a4f7f64,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-2761f8a6-e5bf-491a-9f6f-03e0a5f332fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-30ca46bd-57f0-408e-bb59-c6a06a4f7f64,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-2761f8a6-e5bf-491a-9f6f-03e0a5f332fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-30ca46bd-57f0-408e-bb59-c6a06a4f7f64,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-2761f8a6-e5bf-491a-9f6f-03e0a5f332fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-30ca46bd-57f0-408e-bb59-c6a06a4f7f64,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-b69de012-1664-4797-96a8-da2095b35270,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-44bb0689-1dee-4471-ae83-c0e395c1b2be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36549,DS-44bb0689-1dee-4471-ae83-c0e395c1b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-b69de012-1664-4797-96a8-da2095b35270,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-b69de012-1664-4797-96a8-da2095b35270,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-44bb0689-1dee-4471-ae83-c0e395c1b2be,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36549,DS-44bb0689-1dee-4471-ae83-c0e395c1b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-b69de012-1664-4797-96a8-da2095b35270,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34054,DS-9177c1aa-d7f1-401d-9b54-8d8b8b6c74f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-2815d781-fa38-4cc8-a74a-107978dabd16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34054,DS-9177c1aa-d7f1-401d-9b54-8d8b8b6c74f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-2815d781-fa38-4cc8-a74a-107978dabd16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34054,DS-9177c1aa-d7f1-401d-9b54-8d8b8b6c74f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-2815d781-fa38-4cc8-a74a-107978dabd16,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34054,DS-9177c1aa-d7f1-401d-9b54-8d8b8b6c74f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-2815d781-fa38-4cc8-a74a-107978dabd16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34581,DS-19a6b73e-ec87-4296-80b8-ea37b959b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-c8a255f6-7e4d-48cd-b658-5ed7cb622a81,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40954,DS-c8a255f6-7e4d-48cd-b658-5ed7cb622a81,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-19a6b73e-ec87-4296-80b8-ea37b959b99c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34581,DS-19a6b73e-ec87-4296-80b8-ea37b959b99c,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-c8a255f6-7e4d-48cd-b658-5ed7cb622a81,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40954,DS-c8a255f6-7e4d-48cd-b658-5ed7cb622a81,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-19a6b73e-ec87-4296-80b8-ea37b959b99c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-29779b30-3a6a-4f77-b357-94ef46a1b203,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-60b4182d-e0c5-46ef-838c-fc71d64799c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-60b4182d-e0c5-46ef-838c-fc71d64799c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-29779b30-3a6a-4f77-b357-94ef46a1b203,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40326,DS-29779b30-3a6a-4f77-b357-94ef46a1b203,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-60b4182d-e0c5-46ef-838c-fc71d64799c8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-60b4182d-e0c5-46ef-838c-fc71d64799c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-29779b30-3a6a-4f77-b357-94ef46a1b203,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-68cfd09a-301d-4761-b080-2119b4f60923,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-6f169f65-b398-4f1a-b6f5-ae0660df2b2c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39956,DS-6f169f65-b398-4f1a-b6f5-ae0660df2b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-68cfd09a-301d-4761-b080-2119b4f60923,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32827,DS-68cfd09a-301d-4761-b080-2119b4f60923,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-6f169f65-b398-4f1a-b6f5-ae0660df2b2c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39956,DS-6f169f65-b398-4f1a-b6f5-ae0660df2b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-68cfd09a-301d-4761-b080-2119b4f60923,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-beaf76f5-d077-4db7-97b9-67ee1e51cd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-697beb8b-19de-48fe-a28c-4dc10b77de2f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-beaf76f5-d077-4db7-97b9-67ee1e51cd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-697beb8b-19de-48fe-a28c-4dc10b77de2f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-beaf76f5-d077-4db7-97b9-67ee1e51cd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-697beb8b-19de-48fe-a28c-4dc10b77de2f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-beaf76f5-d077-4db7-97b9-67ee1e51cd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-697beb8b-19de-48fe-a28c-4dc10b77de2f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38064,DS-808aa812-4af2-4236-b8d8-34f961821126,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-533752cf-bc82-481f-a169-ddffc4818d72,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-533752cf-bc82-481f-a169-ddffc4818d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-808aa812-4af2-4236-b8d8-34f961821126,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38064,DS-808aa812-4af2-4236-b8d8-34f961821126,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-533752cf-bc82-481f-a169-ddffc4818d72,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33770,DS-533752cf-bc82-481f-a169-ddffc4818d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-808aa812-4af2-4236-b8d8-34f961821126,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-e8be6885-01a2-4a28-9764-2616f6be1f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-91b57ac1-e094-465d-85e2-5f3570d2290b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-e8be6885-01a2-4a28-9764-2616f6be1f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-91b57ac1-e094-465d-85e2-5f3570d2290b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-e8be6885-01a2-4a28-9764-2616f6be1f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-91b57ac1-e094-465d-85e2-5f3570d2290b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-e8be6885-01a2-4a28-9764-2616f6be1f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-91b57ac1-e094-465d-85e2-5f3570d2290b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-0809c80d-eb34-4fab-9577-fec5c1817704,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-8df67cc1-aca8-4e5d-8e75-177551af2ba1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44610,DS-8df67cc1-aca8-4e5d-8e75-177551af2ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-0809c80d-eb34-4fab-9577-fec5c1817704,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-0809c80d-eb34-4fab-9577-fec5c1817704,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-8df67cc1-aca8-4e5d-8e75-177551af2ba1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44610,DS-8df67cc1-aca8-4e5d-8e75-177551af2ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-0809c80d-eb34-4fab-9577-fec5c1817704,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-b102928f-5c06-4b20-a5f4-1cbf52a7c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-18eda341-0e57-4e2c-bd60-b340d0502f78,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-b102928f-5c06-4b20-a5f4-1cbf52a7c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-18eda341-0e57-4e2c-bd60-b340d0502f78,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-b102928f-5c06-4b20-a5f4-1cbf52a7c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-18eda341-0e57-4e2c-bd60-b340d0502f78,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-b102928f-5c06-4b20-a5f4-1cbf52a7c3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-18eda341-0e57-4e2c-bd60-b340d0502f78,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-9923504e-1a6a-433a-b131-9b40947c1e6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-9923504e-1a6a-433a-b131-9b40947c1e6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-9923504e-1a6a-433a-b131-9b40947c1e6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35708,DS-9923504e-1a6a-433a-b131-9b40947c1e6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-9ff1b152-647f-4a8b-b21e-8fdb4b232417,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-6db4f566-8278-4c95-aee4-f8278b5231de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-9ff1b152-647f-4a8b-b21e-8fdb4b232417,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-6db4f566-8278-4c95-aee4-f8278b5231de,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-9ff1b152-647f-4a8b-b21e-8fdb4b232417,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-6db4f566-8278-4c95-aee4-f8278b5231de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-9ff1b152-647f-4a8b-b21e-8fdb4b232417,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-6db4f566-8278-4c95-aee4-f8278b5231de,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-cb6e5615-466c-4221-bd77-13f55ecaae34,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-cb6e5615-466c-4221-bd77-13f55ecaae34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-cb6e5615-466c-4221-bd77-13f55ecaae34,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43834,DS-cb6e5615-466c-4221-bd77-13f55ecaae34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-4c9afddf-454d-428e-92c5-cf2f9a55d46a,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-589e592d-6960-4394-87b1-6b42665752f8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-4c9afddf-454d-428e-92c5-cf2f9a55d46a,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-589e592d-6960-4394-87b1-6b42665752f8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-4c9afddf-454d-428e-92c5-cf2f9a55d46a,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-589e592d-6960-4394-87b1-6b42665752f8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35884,DS-4c9afddf-454d-428e-92c5-cf2f9a55d46a,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-589e592d-6960-4394-87b1-6b42665752f8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-c1b506e3-4585-4175-aa5f-21a9a987672e,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-cbfd7dbf-d222-424e-8049-aface066f4ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-c1b506e3-4585-4175-aa5f-21a9a987672e,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-cbfd7dbf-d222-424e-8049-aface066f4ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-c1b506e3-4585-4175-aa5f-21a9a987672e,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-cbfd7dbf-d222-424e-8049-aface066f4ea,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-c1b506e3-4585-4175-aa5f-21a9a987672e,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-cbfd7dbf-d222-424e-8049-aface066f4ea,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-4964752a-3afd-42ea-8695-af733e4aaf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-a955b3d7-89cc-4380-96b8-6b76703cb795,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-4964752a-3afd-42ea-8695-af733e4aaf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-a955b3d7-89cc-4380-96b8-6b76703cb795,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-4964752a-3afd-42ea-8695-af733e4aaf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-a955b3d7-89cc-4380-96b8-6b76703cb795,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-4964752a-3afd-42ea-8695-af733e4aaf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-a955b3d7-89cc-4380-96b8-6b76703cb795,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-6a21ae38-1879-458d-9131-6b7425377a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-e9bf3cec-9ab2-4364-8611-2fddb7b22de5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-6a21ae38-1879-458d-9131-6b7425377a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-e9bf3cec-9ab2-4364-8611-2fddb7b22de5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-6a21ae38-1879-458d-9131-6b7425377a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-e9bf3cec-9ab2-4364-8611-2fddb7b22de5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41798,DS-6a21ae38-1879-458d-9131-6b7425377a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-e9bf3cec-9ab2-4364-8611-2fddb7b22de5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41532,DS-97f6440b-a931-41d1-9672-ec54f182d611,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-b7425e93-c461-422e-81fc-5fe9246b5e62,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41532,DS-97f6440b-a931-41d1-9672-ec54f182d611,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-b7425e93-c461-422e-81fc-5fe9246b5e62,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41532,DS-97f6440b-a931-41d1-9672-ec54f182d611,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-b7425e93-c461-422e-81fc-5fe9246b5e62,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41532,DS-97f6440b-a931-41d1-9672-ec54f182d611,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-b7425e93-c461-422e-81fc-5fe9246b5e62,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46787,DS-0d763d83-75d3-4fa6-8dbd-82ab2085b142,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-64589819-c873-44ac-90c0-0a10c4d69585,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40491,DS-64589819-c873-44ac-90c0-0a10c4d69585,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-0d763d83-75d3-4fa6-8dbd-82ab2085b142,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46787,DS-0d763d83-75d3-4fa6-8dbd-82ab2085b142,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-64589819-c873-44ac-90c0-0a10c4d69585,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40491,DS-64589819-c873-44ac-90c0-0a10c4d69585,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-0d763d83-75d3-4fa6-8dbd-82ab2085b142,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42176,DS-397e6038-3852-4ed5-8e6a-02344765d5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-33f5ee6b-b72f-40cf-b102-13fe22f96fbc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-33f5ee6b-b72f-40cf-b102-13fe22f96fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-397e6038-3852-4ed5-8e6a-02344765d5fc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42176,DS-397e6038-3852-4ed5-8e6a-02344765d5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-33f5ee6b-b72f-40cf-b102-13fe22f96fbc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-33f5ee6b-b72f-40cf-b102-13fe22f96fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-397e6038-3852-4ed5-8e6a-02344765d5fc,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-f79e53b0-a7a9-4196-8339-f0a997d9a4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1c4d8b6a-3980-4bed-a359-ec341be4ae86,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-f79e53b0-a7a9-4196-8339-f0a997d9a4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1c4d8b6a-3980-4bed-a359-ec341be4ae86,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-f79e53b0-a7a9-4196-8339-f0a997d9a4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1c4d8b6a-3980-4bed-a359-ec341be4ae86,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-f79e53b0-a7a9-4196-8339-f0a997d9a4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-1c4d8b6a-3980-4bed-a359-ec341be4ae86,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35834,DS-dd8f5e50-061f-4e68-8e72-49fbebe3f420,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-c6fff4c7-bfcd-4291-b6d1-f10312a063c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-c6fff4c7-bfcd-4291-b6d1-f10312a063c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-dd8f5e50-061f-4e68-8e72-49fbebe3f420,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35834,DS-dd8f5e50-061f-4e68-8e72-49fbebe3f420,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-c6fff4c7-bfcd-4291-b6d1-f10312a063c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34045,DS-c6fff4c7-bfcd-4291-b6d1-f10312a063c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-dd8f5e50-061f-4e68-8e72-49fbebe3f420,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-66bf7681-a402-4a88-b246-bc1fd284efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-e76b3eac-1dbd-4413-96fa-afcf2d9297fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-66bf7681-a402-4a88-b246-bc1fd284efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-e76b3eac-1dbd-4413-96fa-afcf2d9297fa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-66bf7681-a402-4a88-b246-bc1fd284efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-e76b3eac-1dbd-4413-96fa-afcf2d9297fa,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-66bf7681-a402-4a88-b246-bc1fd284efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-e76b3eac-1dbd-4413-96fa-afcf2d9297fa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-34b69355-9f2e-4687-905f-e969c91c09a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-402a916a-5429-4031-8389-17a618be723e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-34b69355-9f2e-4687-905f-e969c91c09a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-402a916a-5429-4031-8389-17a618be723e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-34b69355-9f2e-4687-905f-e969c91c09a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-402a916a-5429-4031-8389-17a618be723e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36558,DS-34b69355-9f2e-4687-905f-e969c91c09a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-402a916a-5429-4031-8389-17a618be723e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35345,DS-6998cdf6-2e37-4d24-bd1d-b47750c74e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-90ba12e9-6cd4-45ea-bfc0-df440051525f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40947,DS-90ba12e9-6cd4-45ea-bfc0-df440051525f,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-6998cdf6-2e37-4d24-bd1d-b47750c74e17,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35345,DS-6998cdf6-2e37-4d24-bd1d-b47750c74e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-90ba12e9-6cd4-45ea-bfc0-df440051525f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40947,DS-90ba12e9-6cd4-45ea-bfc0-df440051525f,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-6998cdf6-2e37-4d24-bd1d-b47750c74e17,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39450,DS-90b20d59-0d64-4ea8-b1a8-e29ec79fa1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-1a705867-b8eb-4104-aa2e-df4dbbf87a0c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33472,DS-1a705867-b8eb-4104-aa2e-df4dbbf87a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-90b20d59-0d64-4ea8-b1a8-e29ec79fa1c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39450,DS-90b20d59-0d64-4ea8-b1a8-e29ec79fa1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-1a705867-b8eb-4104-aa2e-df4dbbf87a0c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33472,DS-1a705867-b8eb-4104-aa2e-df4dbbf87a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-90b20d59-0d64-4ea8-b1a8-e29ec79fa1c0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45503,DS-eb917290-4c3e-4eee-ba51-fc24cb6c702a,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-27e65d35-2d0f-4ff2-b843-520232e4f71b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-27e65d35-2d0f-4ff2-b843-520232e4f71b,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-eb917290-4c3e-4eee-ba51-fc24cb6c702a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45503,DS-eb917290-4c3e-4eee-ba51-fc24cb6c702a,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-27e65d35-2d0f-4ff2-b843-520232e4f71b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-27e65d35-2d0f-4ff2-b843-520232e4f71b,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-eb917290-4c3e-4eee-ba51-fc24cb6c702a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37742,DS-386de48c-816d-4a51-9864-0b1ca0ec6f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-c557bc36-4714-4f12-9203-ff8a54df08d0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37742,DS-386de48c-816d-4a51-9864-0b1ca0ec6f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-c557bc36-4714-4f12-9203-ff8a54df08d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37742,DS-386de48c-816d-4a51-9864-0b1ca0ec6f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-c557bc36-4714-4f12-9203-ff8a54df08d0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37742,DS-386de48c-816d-4a51-9864-0b1ca0ec6f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-c557bc36-4714-4f12-9203-ff8a54df08d0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-847ea649-70ea-4cd4-8b60-826866cae091,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-00519591-bedd-4add-8754-92034be2f901,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-847ea649-70ea-4cd4-8b60-826866cae091,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-00519591-bedd-4add-8754-92034be2f901,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-847ea649-70ea-4cd4-8b60-826866cae091,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-00519591-bedd-4add-8754-92034be2f901,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-847ea649-70ea-4cd4-8b60-826866cae091,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-00519591-bedd-4add-8754-92034be2f901,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43226,DS-28d1f796-3121-4640-b457-014dc67c2578,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-c9f4d42a-2b6f-4cca-9104-16234481c675,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43226,DS-28d1f796-3121-4640-b457-014dc67c2578,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-c9f4d42a-2b6f-4cca-9104-16234481c675,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43226,DS-28d1f796-3121-4640-b457-014dc67c2578,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-c9f4d42a-2b6f-4cca-9104-16234481c675,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43226,DS-28d1f796-3121-4640-b457-014dc67c2578,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-c9f4d42a-2b6f-4cca-9104-16234481c675,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36547,DS-1e9eabe7-7fc9-4923-861c-cc12eea2f144,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-68bd6c6d-9f61-4241-875a-d4eb517d189f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36547,DS-1e9eabe7-7fc9-4923-861c-cc12eea2f144,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-68bd6c6d-9f61-4241-875a-d4eb517d189f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36547,DS-1e9eabe7-7fc9-4923-861c-cc12eea2f144,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-68bd6c6d-9f61-4241-875a-d4eb517d189f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36547,DS-1e9eabe7-7fc9-4923-861c-cc12eea2f144,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-68bd6c6d-9f61-4241-875a-d4eb517d189f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-4917a29b-f4cb-4dc2-9841-47fb14b65f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-1f7d0bcc-dce9-4191-9ee9-bf0d17ae93ad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38355,DS-1f7d0bcc-dce9-4191-9ee9-bf0d17ae93ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-4917a29b-f4cb-4dc2-9841-47fb14b65f57,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-4917a29b-f4cb-4dc2-9841-47fb14b65f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-1f7d0bcc-dce9-4191-9ee9-bf0d17ae93ad,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38355,DS-1f7d0bcc-dce9-4191-9ee9-bf0d17ae93ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-4917a29b-f4cb-4dc2-9841-47fb14b65f57,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34991,DS-d4f529c5-04d9-4bb2-b3f9-3041683b1439,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-817e195d-9ce6-4c38-89b5-cb409a869953,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34991,DS-d4f529c5-04d9-4bb2-b3f9-3041683b1439,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-817e195d-9ce6-4c38-89b5-cb409a869953,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34991,DS-d4f529c5-04d9-4bb2-b3f9-3041683b1439,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-817e195d-9ce6-4c38-89b5-cb409a869953,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34991,DS-d4f529c5-04d9-4bb2-b3f9-3041683b1439,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-817e195d-9ce6-4c38-89b5-cb409a869953,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-9a51ee98-631f-465c-a605-0c8dc9598a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-203aafd6-926b-488c-9e85-aa26d8969dbf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-9a51ee98-631f-465c-a605-0c8dc9598a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-203aafd6-926b-488c-9e85-aa26d8969dbf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-9a51ee98-631f-465c-a605-0c8dc9598a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-203aafd6-926b-488c-9e85-aa26d8969dbf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34258,DS-9a51ee98-631f-465c-a605-0c8dc9598a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-203aafd6-926b-488c-9e85-aa26d8969dbf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-f65098fb-b081-4630-acbf-d4ca8b951cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-9db247d3-0c65-40e8-8870-be2772b0e7f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-f65098fb-b081-4630-acbf-d4ca8b951cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-9db247d3-0c65-40e8-8870-be2772b0e7f7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-f65098fb-b081-4630-acbf-d4ca8b951cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-9db247d3-0c65-40e8-8870-be2772b0e7f7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-f65098fb-b081-4630-acbf-d4ca8b951cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-9db247d3-0c65-40e8-8870-be2772b0e7f7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38065,DS-04dbbbdf-5495-43bc-866a-666065bc099e,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-eb23c0af-b1dc-4f73-b351-1fb17d7b2c62,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38065,DS-04dbbbdf-5495-43bc-866a-666065bc099e,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-eb23c0af-b1dc-4f73-b351-1fb17d7b2c62,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38065,DS-04dbbbdf-5495-43bc-866a-666065bc099e,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-eb23c0af-b1dc-4f73-b351-1fb17d7b2c62,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38065,DS-04dbbbdf-5495-43bc-866a-666065bc099e,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-eb23c0af-b1dc-4f73-b351-1fb17d7b2c62,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=184, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=184, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34774,DS-38b98232-aa58-41eb-af08-b518cab719a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-da2fb6d1-8baf-4c63-9e32-ba70aa131b5e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34774,DS-38b98232-aa58-41eb-af08-b518cab719a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-da2fb6d1-8baf-4c63-9e32-ba70aa131b5e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-2127302a-fc6f-4b85-bdd9-665715cbf137,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-5e4d5488-7573-4ec8-9987-c73c1cd45642,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-2127302a-fc6f-4b85-bdd9-665715cbf137,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-5e4d5488-7573-4ec8-9987-c73c1cd45642,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-2127302a-fc6f-4b85-bdd9-665715cbf137,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-5e4d5488-7573-4ec8-9987-c73c1cd45642,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38861,DS-2127302a-fc6f-4b85-bdd9-665715cbf137,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-5e4d5488-7573-4ec8-9987-c73c1cd45642,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-2770a90e-2e0b-4163-94a5-7db2983a9479,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-9142fa4f-6143-4cd7-be66-53ebf137a266,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-2770a90e-2e0b-4163-94a5-7db2983a9479,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-9142fa4f-6143-4cd7-be66-53ebf137a266,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-2770a90e-2e0b-4163-94a5-7db2983a9479,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-9142fa4f-6143-4cd7-be66-53ebf137a266,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37577,DS-2770a90e-2e0b-4163-94a5-7db2983a9479,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-9142fa4f-6143-4cd7-be66-53ebf137a266,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-579cceb8-b84b-4b0e-b368-ce0f3f7efaed,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-01213cda-8114-47db-b687-9b074e54240e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-01213cda-8114-47db-b687-9b074e54240e,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-579cceb8-b84b-4b0e-b368-ce0f3f7efaed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-579cceb8-b84b-4b0e-b368-ce0f3f7efaed,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-01213cda-8114-47db-b687-9b074e54240e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-01213cda-8114-47db-b687-9b074e54240e,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-579cceb8-b84b-4b0e-b368-ce0f3f7efaed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-01b0e59d-9627-4537-b567-90cf9c28b619,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-94b85f4b-ebb0-40a6-8d71-57761af58744,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-01b0e59d-9627-4537-b567-90cf9c28b619,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-94b85f4b-ebb0-40a6-8d71-57761af58744,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-01b0e59d-9627-4537-b567-90cf9c28b619,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-94b85f4b-ebb0-40a6-8d71-57761af58744,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-01b0e59d-9627-4537-b567-90cf9c28b619,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-94b85f4b-ebb0-40a6-8d71-57761af58744,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-ea36f83b-0df0-4c2a-a623-7330557707f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-086e38b3-c108-4725-be3a-94ff872d9eaf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-ea36f83b-0df0-4c2a-a623-7330557707f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-086e38b3-c108-4725-be3a-94ff872d9eaf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-ea36f83b-0df0-4c2a-a623-7330557707f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-086e38b3-c108-4725-be3a-94ff872d9eaf,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-ea36f83b-0df0-4c2a-a623-7330557707f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-086e38b3-c108-4725-be3a-94ff872d9eaf,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45891,DS-0a6689e3-152f-45ab-8d21-03fc118e1ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-72a3e227-8f35-4a8c-b043-903ae9f646c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43074,DS-72a3e227-8f35-4a8c-b043-903ae9f646c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-0a6689e3-152f-45ab-8d21-03fc118e1ed7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45891,DS-0a6689e3-152f-45ab-8d21-03fc118e1ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-72a3e227-8f35-4a8c-b043-903ae9f646c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43074,DS-72a3e227-8f35-4a8c-b043-903ae9f646c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-0a6689e3-152f-45ab-8d21-03fc118e1ed7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34540,DS-911982f0-4921-4f8b-aaab-bfbd9c75f5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-fea48101-a81f-4670-bccf-01e63c62a313,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-fea48101-a81f-4670-bccf-01e63c62a313,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-911982f0-4921-4f8b-aaab-bfbd9c75f5a0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34540,DS-911982f0-4921-4f8b-aaab-bfbd9c75f5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-fea48101-a81f-4670-bccf-01e63c62a313,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-fea48101-a81f-4670-bccf-01e63c62a313,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-911982f0-4921-4f8b-aaab-bfbd9c75f5a0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-eb327d9c-0bd8-4982-9129-9a450aba019e,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-915fdc68-2061-4836-9c33-284244b11545,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39325,DS-915fdc68-2061-4836-9c33-284244b11545,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-eb327d9c-0bd8-4982-9129-9a450aba019e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40757,DS-eb327d9c-0bd8-4982-9129-9a450aba019e,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-915fdc68-2061-4836-9c33-284244b11545,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39325,DS-915fdc68-2061-4836-9c33-284244b11545,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-eb327d9c-0bd8-4982-9129-9a450aba019e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-99d7f2e0-c64f-4b12-b2a4-8b72dbaf794f,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0c408ec1-0762-4a8b-baca-03cefa5d3b74,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-99d7f2e0-c64f-4b12-b2a4-8b72dbaf794f,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0c408ec1-0762-4a8b-baca-03cefa5d3b74,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-99d7f2e0-c64f-4b12-b2a4-8b72dbaf794f,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0c408ec1-0762-4a8b-baca-03cefa5d3b74,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-99d7f2e0-c64f-4b12-b2a4-8b72dbaf794f,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0c408ec1-0762-4a8b-baca-03cefa5d3b74,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-6d291bf4-36cd-45c9-96ae-9e99c88ed631,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-f7d21e76-6dd2-4d8b-a2cc-de9fab979489,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-6d291bf4-36cd-45c9-96ae-9e99c88ed631,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-f7d21e76-6dd2-4d8b-a2cc-de9fab979489,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-6d291bf4-36cd-45c9-96ae-9e99c88ed631,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-f7d21e76-6dd2-4d8b-a2cc-de9fab979489,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-6d291bf4-36cd-45c9-96ae-9e99c88ed631,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-f7d21e76-6dd2-4d8b-a2cc-de9fab979489,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-bc070697-47b7-479b-806a-e1d1781544a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-877356bd-62a6-4650-a474-7451629c629a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-bc070697-47b7-479b-806a-e1d1781544a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-877356bd-62a6-4650-a474-7451629c629a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-bc070697-47b7-479b-806a-e1d1781544a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-877356bd-62a6-4650-a474-7451629c629a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-bc070697-47b7-479b-806a-e1d1781544a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-877356bd-62a6-4650-a474-7451629c629a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-6e6fb793-4eda-4579-93b3-bd695d7d4386,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-6e6fb793-4eda-4579-93b3-bd695d7d4386,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-6e6fb793-4eda-4579-93b3-bd695d7d4386,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-6e6fb793-4eda-4579-93b3-bd695d7d4386,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-28299cd3-e192-4904-9ea1-6e2efec79247,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-e0b4338c-ed9f-408d-a766-ce27aaeb06f1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-e0b4338c-ed9f-408d-a766-ce27aaeb06f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-28299cd3-e192-4904-9ea1-6e2efec79247,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-28299cd3-e192-4904-9ea1-6e2efec79247,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-e0b4338c-ed9f-408d-a766-ce27aaeb06f1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-e0b4338c-ed9f-408d-a766-ce27aaeb06f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-28299cd3-e192-4904-9ea1-6e2efec79247,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42324,DS-3ce42b3e-3f3f-4f05-9d3b-a30dbe907c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-935dc2d9-8153-4913-82c7-5cf69cee2206,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-935dc2d9-8153-4913-82c7-5cf69cee2206,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-3ce42b3e-3f3f-4f05-9d3b-a30dbe907c22,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42324,DS-3ce42b3e-3f3f-4f05-9d3b-a30dbe907c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-935dc2d9-8153-4913-82c7-5cf69cee2206,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-935dc2d9-8153-4913-82c7-5cf69cee2206,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-3ce42b3e-3f3f-4f05-9d3b-a30dbe907c22,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-75208140-5f43-40d0-9ad5-4470f819635b,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-a882df09-057a-4a4b-b2de-93c6e53f68c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-a882df09-057a-4a4b-b2de-93c6e53f68c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-75208140-5f43-40d0-9ad5-4470f819635b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-75208140-5f43-40d0-9ad5-4470f819635b,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-a882df09-057a-4a4b-b2de-93c6e53f68c2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-a882df09-057a-4a4b-b2de-93c6e53f68c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-75208140-5f43-40d0-9ad5-4470f819635b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-03ded4ea-f9eb-4251-b523-6f120f8a7b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-98e9c01e-540e-4bbb-89da-f682d0e07ed5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33995,DS-98e9c01e-540e-4bbb-89da-f682d0e07ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-03ded4ea-f9eb-4251-b523-6f120f8a7b50,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-03ded4ea-f9eb-4251-b523-6f120f8a7b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-98e9c01e-540e-4bbb-89da-f682d0e07ed5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33995,DS-98e9c01e-540e-4bbb-89da-f682d0e07ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-03ded4ea-f9eb-4251-b523-6f120f8a7b50,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-b00dded5-f099-4e95-8ec5-42aa6702c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-2da6ff76-046c-4e3a-b9a8-5e70a05c37c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-b00dded5-f099-4e95-8ec5-42aa6702c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-2da6ff76-046c-4e3a-b9a8-5e70a05c37c1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-b00dded5-f099-4e95-8ec5-42aa6702c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-2da6ff76-046c-4e3a-b9a8-5e70a05c37c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-b00dded5-f099-4e95-8ec5-42aa6702c6af,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-2da6ff76-046c-4e3a-b9a8-5e70a05c37c1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-a45b5420-7756-4068-8c95-c55301522b70,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-7b6c4476-2a65-4983-aafe-308f08269646,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-a45b5420-7756-4068-8c95-c55301522b70,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-7b6c4476-2a65-4983-aafe-308f08269646,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-a45b5420-7756-4068-8c95-c55301522b70,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-7b6c4476-2a65-4983-aafe-308f08269646,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39496,DS-a45b5420-7756-4068-8c95-c55301522b70,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-7b6c4476-2a65-4983-aafe-308f08269646,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32897,DS-5b44d231-3e99-4040-9a2d-34334538a478,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-ff1eb9f3-e1ab-418f-9909-fcdf5a39e70c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32897,DS-5b44d231-3e99-4040-9a2d-34334538a478,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-ff1eb9f3-e1ab-418f-9909-fcdf5a39e70c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32897,DS-5b44d231-3e99-4040-9a2d-34334538a478,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-ff1eb9f3-e1ab-418f-9909-fcdf5a39e70c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32897,DS-5b44d231-3e99-4040-9a2d-34334538a478,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-ff1eb9f3-e1ab-418f-9909-fcdf5a39e70c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46217,DS-e269caf4-bd8e-4d6a-b585-88fbfb5a380b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46217,DS-e269caf4-bd8e-4d6a-b585-88fbfb5a380b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46217,DS-e269caf4-bd8e-4d6a-b585-88fbfb5a380b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46217,DS-e269caf4-bd8e-4d6a-b585-88fbfb5a380b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-57e2d4a3-bc71-4fc3-b883-f4bab2a202a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-7655e53a-0e18-4db9-baa6-d771e8440125,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-7655e53a-0e18-4db9-baa6-d771e8440125,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-57e2d4a3-bc71-4fc3-b883-f4bab2a202a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-57e2d4a3-bc71-4fc3-b883-f4bab2a202a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-7655e53a-0e18-4db9-baa6-d771e8440125,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45522,DS-7655e53a-0e18-4db9-baa6-d771e8440125,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-57e2d4a3-bc71-4fc3-b883-f4bab2a202a2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-b67e2fba-1361-4ae1-ba78-e99adfd87aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-d5e33dd9-236f-4129-9df6-4f3533122660,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-b67e2fba-1361-4ae1-ba78-e99adfd87aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-d5e33dd9-236f-4129-9df6-4f3533122660,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-b67e2fba-1361-4ae1-ba78-e99adfd87aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-d5e33dd9-236f-4129-9df6-4f3533122660,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-b67e2fba-1361-4ae1-ba78-e99adfd87aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-d5e33dd9-236f-4129-9df6-4f3533122660,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41924,DS-b31c0210-6d96-42eb-b9ab-5cf68960b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-991c374e-6360-48b7-8d31-f283f5e1dcf2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-991c374e-6360-48b7-8d31-f283f5e1dcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-b31c0210-6d96-42eb-b9ab-5cf68960b15a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41924,DS-b31c0210-6d96-42eb-b9ab-5cf68960b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-991c374e-6360-48b7-8d31-f283f5e1dcf2,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-991c374e-6360-48b7-8d31-f283f5e1dcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-b31c0210-6d96-42eb-b9ab-5cf68960b15a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727 has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-993ea400-6d30-4cdc-b29d-7d68aff0ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-6ba9cbab-02f0-4f10-9c22-d66b98596191,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-993ea400-6d30-4cdc-b29d-7d68aff0ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-6ba9cbab-02f0-4f10-9c22-d66b98596191,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-993ea400-6d30-4cdc-b29d-7d68aff0ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-6ba9cbab-02f0-4f10-9c22-d66b98596191,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-993ea400-6d30-4cdc-b29d-7d68aff0ad74,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-6ba9cbab-02f0-4f10-9c22-d66b98596191,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-9c431727-4972-4df3-9868-6cc8ffa73029,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-2366dde2-62c0-44e0-abf8-b72580bc055b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40561,DS-2366dde2-62c0-44e0-abf8-b72580bc055b,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-9c431727-4972-4df3-9868-6cc8ffa73029,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-9c431727-4972-4df3-9868-6cc8ffa73029,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-2366dde2-62c0-44e0-abf8-b72580bc055b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40561,DS-2366dde2-62c0-44e0-abf8-b72580bc055b,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-9c431727-4972-4df3-9868-6cc8ffa73029,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40438,DS-b89fd6a7-f4f4-476c-825a-e87d18e4f9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-3e9a928c-e63c-486d-9160-3585fd7c4371,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-3e9a928c-e63c-486d-9160-3585fd7c4371,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-b89fd6a7-f4f4-476c-825a-e87d18e4f9aa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40438,DS-b89fd6a7-f4f4-476c-825a-e87d18e4f9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-3e9a928c-e63c-486d-9160-3585fd7c4371,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-3e9a928c-e63c-486d-9160-3585fd7c4371,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-b89fd6a7-f4f4-476c-825a-e87d18e4f9aa,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-200123c4-b00d-4651-9146-9919fa382391,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-bf4a7cad-bef2-406c-b93b-41605da81989,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-200123c4-b00d-4651-9146-9919fa382391,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-bf4a7cad-bef2-406c-b93b-41605da81989,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-200123c4-b00d-4651-9146-9919fa382391,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-bf4a7cad-bef2-406c-b93b-41605da81989,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-200123c4-b00d-4651-9146-9919fa382391,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-bf4a7cad-bef2-406c-b93b-41605da81989,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-231f45e1-7322-4aa4-99c9-1fce04e35c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-dfc623f5-1570-4c2a-ad4f-c9530fbf6f7f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-dfc623f5-1570-4c2a-ad4f-c9530fbf6f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-231f45e1-7322-4aa4-99c9-1fce04e35c88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43801,DS-231f45e1-7322-4aa4-99c9-1fce04e35c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-dfc623f5-1570-4c2a-ad4f-c9530fbf6f7f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-dfc623f5-1570-4c2a-ad4f-c9530fbf6f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43801,DS-231f45e1-7322-4aa4-99c9-1fce04e35c88,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-be2ae11c-9d11-42a5-8dde-8185cc66d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-222ea9d3-0ada-4cce-9610-f5ad58382b50,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-be2ae11c-9d11-42a5-8dde-8185cc66d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-222ea9d3-0ada-4cce-9610-f5ad58382b50,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-be2ae11c-9d11-42a5-8dde-8185cc66d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-222ea9d3-0ada-4cce-9610-f5ad58382b50,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-be2ae11c-9d11-42a5-8dde-8185cc66d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-222ea9d3-0ada-4cce-9610-f5ad58382b50,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: might be true error
Total execution time in seconds : 9580
