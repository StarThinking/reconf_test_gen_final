reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44087,DS-9cf544ea-34e2-4c18-8fa2-5fc7d27f7395,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-7446f9f8-89d4-4b34-8bf5-ea882aca14f8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44087,DS-9cf544ea-34e2-4c18-8fa2-5fc7d27f7395,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-7446f9f8-89d4-4b34-8bf5-ea882aca14f8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44087,DS-9cf544ea-34e2-4c18-8fa2-5fc7d27f7395,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-7446f9f8-89d4-4b34-8bf5-ea882aca14f8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44087,DS-9cf544ea-34e2-4c18-8fa2-5fc7d27f7395,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-7446f9f8-89d4-4b34-8bf5-ea882aca14f8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34050,DS-3e49a4a1-0373-4ec3-a81a-1172980b8956,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-0f9d0387-5566-4eca-a088-fbdff19931fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34050,DS-3e49a4a1-0373-4ec3-a81a-1172980b8956,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-0f9d0387-5566-4eca-a088-fbdff19931fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34050,DS-3e49a4a1-0373-4ec3-a81a-1172980b8956,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-0f9d0387-5566-4eca-a088-fbdff19931fe,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34050,DS-3e49a4a1-0373-4ec3-a81a-1172980b8956,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-0f9d0387-5566-4eca-a088-fbdff19931fe,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33777,DS-3a443d42-dc9f-4a15-8788-37ac273ab346,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-2f8e9bf2-3a95-4ad4-a4c8-3aa1935592e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33777,DS-3a443d42-dc9f-4a15-8788-37ac273ab346,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-2f8e9bf2-3a95-4ad4-a4c8-3aa1935592e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33777,DS-3a443d42-dc9f-4a15-8788-37ac273ab346,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-2f8e9bf2-3a95-4ad4-a4c8-3aa1935592e4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33777,DS-3a443d42-dc9f-4a15-8788-37ac273ab346,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-2f8e9bf2-3a95-4ad4-a4c8-3aa1935592e4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33644,DS-7c08aca6-9822-4429-9069-e3a5dd3f9590,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-cadb2a31-b442-4623-86ae-5d241e4e14e7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33644,DS-7c08aca6-9822-4429-9069-e3a5dd3f9590,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-cadb2a31-b442-4623-86ae-5d241e4e14e7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33644,DS-7c08aca6-9822-4429-9069-e3a5dd3f9590,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-cadb2a31-b442-4623-86ae-5d241e4e14e7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33644,DS-7c08aca6-9822-4429-9069-e3a5dd3f9590,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-cadb2a31-b442-4623-86ae-5d241e4e14e7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-33aa7dc0-cd99-4159-87f1-b2bd286905ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-1aa871b8-9a2c-4b0a-bba6-b110746e726e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-33aa7dc0-cd99-4159-87f1-b2bd286905ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-1aa871b8-9a2c-4b0a-bba6-b110746e726e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-33aa7dc0-cd99-4159-87f1-b2bd286905ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-1aa871b8-9a2c-4b0a-bba6-b110746e726e,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44472,DS-33aa7dc0-cd99-4159-87f1-b2bd286905ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-1aa871b8-9a2c-4b0a-bba6-b110746e726e,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-b0deea78-5ab6-43c2-a812-af78312082da,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-ca9e0d23-290f-47cf-adb9-d8e19827468a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-ca9e0d23-290f-47cf-adb9-d8e19827468a,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-b0deea78-5ab6-43c2-a812-af78312082da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-b0deea78-5ab6-43c2-a812-af78312082da,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-ca9e0d23-290f-47cf-adb9-d8e19827468a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-ca9e0d23-290f-47cf-adb9-d8e19827468a,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-b0deea78-5ab6-43c2-a812-af78312082da,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-a5c32bea-0c0f-4004-b644-f98c91f41b16,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-24ac628c-c421-4376-a8e3-c099ed8e4937,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-24ac628c-c421-4376-a8e3-c099ed8e4937,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-a5c32bea-0c0f-4004-b644-f98c91f41b16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-a5c32bea-0c0f-4004-b644-f98c91f41b16,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-24ac628c-c421-4376-a8e3-c099ed8e4937,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-24ac628c-c421-4376-a8e3-c099ed8e4937,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-a5c32bea-0c0f-4004-b644-f98c91f41b16,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-5bb6b716-507b-4869-b071-cbbac64a6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-140385f8-fdc5-4573-acf6-70bc8f382930,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-5bb6b716-507b-4869-b071-cbbac64a6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-140385f8-fdc5-4573-acf6-70bc8f382930,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-5bb6b716-507b-4869-b071-cbbac64a6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-140385f8-fdc5-4573-acf6-70bc8f382930,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36303,DS-5bb6b716-507b-4869-b071-cbbac64a6ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-140385f8-fdc5-4573-acf6-70bc8f382930,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-8ab9e9b5-b04c-48c0-ae52-93dc07186f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-817143f9-f082-468b-849e-50411efc50b8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-8ab9e9b5-b04c-48c0-ae52-93dc07186f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-817143f9-f082-468b-849e-50411efc50b8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-8ab9e9b5-b04c-48c0-ae52-93dc07186f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-817143f9-f082-468b-849e-50411efc50b8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44054,DS-8ab9e9b5-b04c-48c0-ae52-93dc07186f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-817143f9-f082-468b-849e-50411efc50b8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayCompressed#testDatalossWhenInputError
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42857,DS-ad475f86-c0e7-44cd-96f3-6f6add8cc17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-f8de85c6-cb00-4418-b1fb-06a174752a73,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42857,DS-ad475f86-c0e7-44cd-96f3-6f6add8cc17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-f8de85c6-cb00-4418-b1fb-06a174752a73,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42857,DS-ad475f86-c0e7-44cd-96f3-6f6add8cc17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-f8de85c6-cb00-4418-b1fb-06a174752a73,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42857,DS-ad475f86-c0e7-44cd-96f3-6f6add8cc17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-f8de85c6-cb00-4418-b1fb-06a174752a73,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 2932
