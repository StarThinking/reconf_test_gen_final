reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45672,DS-16910a79-7fd8-40bc-ae20-68d584013f60,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-b8edeaef-61a6-4dd6-999c-5f6a779eab00,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-b8edeaef-61a6-4dd6-999c-5f6a779eab00,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-16910a79-7fd8-40bc-ae20-68d584013f60,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45672,DS-16910a79-7fd8-40bc-ae20-68d584013f60,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-b8edeaef-61a6-4dd6-999c-5f6a779eab00,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-b8edeaef-61a6-4dd6-999c-5f6a779eab00,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-16910a79-7fd8-40bc-ae20-68d584013f60,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-16b6a0f1-353b-4e41-ae40-fe25a42e2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-47ff1961-0f56-49cf-a405-8c68f2c917d8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-47ff1961-0f56-49cf-a405-8c68f2c917d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-16b6a0f1-353b-4e41-ae40-fe25a42e2dc2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-16b6a0f1-353b-4e41-ae40-fe25a42e2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-47ff1961-0f56-49cf-a405-8c68f2c917d8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38143,DS-47ff1961-0f56-49cf-a405-8c68f2c917d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-16b6a0f1-353b-4e41-ae40-fe25a42e2dc2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-f2d08be0-cc86-4216-828c-dc9d1fc208c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-ac441f90-a626-4aee-aab3-c6837fdaa2ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-f2d08be0-cc86-4216-828c-dc9d1fc208c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-ac441f90-a626-4aee-aab3-c6837fdaa2ca,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-f2d08be0-cc86-4216-828c-dc9d1fc208c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-ac441f90-a626-4aee-aab3-c6837fdaa2ca,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-f2d08be0-cc86-4216-828c-dc9d1fc208c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-ac441f90-a626-4aee-aab3-c6837fdaa2ca,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-5301606a-33c7-4142-8ddd-da364e645fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-4bfd66d2-e4bf-410e-849c-578ca3638092,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-5301606a-33c7-4142-8ddd-da364e645fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-4bfd66d2-e4bf-410e-849c-578ca3638092,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-5301606a-33c7-4142-8ddd-da364e645fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-4bfd66d2-e4bf-410e-849c-578ca3638092,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33415,DS-5301606a-33c7-4142-8ddd-da364e645fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-4bfd66d2-e4bf-410e-849c-578ca3638092,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-7eafd8b0-b99f-48d2-b5b6-f354468f144d,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-4314e368-cff4-45a3-87aa-ce27c2c50443,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-7eafd8b0-b99f-48d2-b5b6-f354468f144d,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-4314e368-cff4-45a3-87aa-ce27c2c50443,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-7eafd8b0-b99f-48d2-b5b6-f354468f144d,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-4314e368-cff4-45a3-87aa-ce27c2c50443,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36701,DS-7eafd8b0-b99f-48d2-b5b6-f354468f144d,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-4314e368-cff4-45a3-87aa-ce27c2c50443,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-7de3ca48-f2f8-47a1-b21c-4c53ce0ec82c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-760af680-6a03-4b9f-bab4-212de25c3f1a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-7de3ca48-f2f8-47a1-b21c-4c53ce0ec82c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-760af680-6a03-4b9f-bab4-212de25c3f1a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-7de3ca48-f2f8-47a1-b21c-4c53ce0ec82c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-760af680-6a03-4b9f-bab4-212de25c3f1a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46159,DS-7de3ca48-f2f8-47a1-b21c-4c53ce0ec82c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-760af680-6a03-4b9f-bab4-212de25c3f1a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-54879d64-b235-47f7-8793-db0c57143328,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-5ad95bd8-95eb-445a-ad32-0e043b3c84d0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34827,DS-5ad95bd8-95eb-445a-ad32-0e043b3c84d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-54879d64-b235-47f7-8793-db0c57143328,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43294,DS-54879d64-b235-47f7-8793-db0c57143328,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-5ad95bd8-95eb-445a-ad32-0e043b3c84d0,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34827,DS-5ad95bd8-95eb-445a-ad32-0e043b3c84d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-54879d64-b235-47f7-8793-db0c57143328,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40465,DS-905b027a-083b-4954-8f13-df9ae457fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-923344cc-6685-4b1c-9229-f16eba8d135d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40465,DS-905b027a-083b-4954-8f13-df9ae457fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-923344cc-6685-4b1c-9229-f16eba8d135d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40465,DS-905b027a-083b-4954-8f13-df9ae457fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-923344cc-6685-4b1c-9229-f16eba8d135d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40465,DS-905b027a-083b-4954-8f13-df9ae457fc19,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-923344cc-6685-4b1c-9229-f16eba8d135d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36819,DS-e8fe57e4-c7e4-4fdf-b81d-08e8bd7f3cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-73e53ee2-2518-40f8-9c07-a721ec680778,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-73e53ee2-2518-40f8-9c07-a721ec680778,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-e8fe57e4-c7e4-4fdf-b81d-08e8bd7f3cb0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36819,DS-e8fe57e4-c7e4-4fdf-b81d-08e8bd7f3cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-73e53ee2-2518-40f8-9c07-a721ec680778,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-73e53ee2-2518-40f8-9c07-a721ec680778,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-e8fe57e4-c7e4-4fdf-b81d-08e8bd7f3cb0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplay#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33701,DS-cbb10e5f-1d6d-47d4-8565-6c4d91bab043,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-7d57a43c-d764-45eb-83a1-e98f4d56f7de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36852,DS-7d57a43c-d764-45eb-83a1-e98f4d56f7de,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-cbb10e5f-1d6d-47d4-8565-6c4d91bab043,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33701,DS-cbb10e5f-1d6d-47d4-8565-6c4d91bab043,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-7d57a43c-d764-45eb-83a1-e98f4d56f7de,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36852,DS-7d57a43c-d764-45eb-83a1-e98f4d56f7de,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-cbb10e5f-1d6d-47d4-8565-6c4d91bab043,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1812
