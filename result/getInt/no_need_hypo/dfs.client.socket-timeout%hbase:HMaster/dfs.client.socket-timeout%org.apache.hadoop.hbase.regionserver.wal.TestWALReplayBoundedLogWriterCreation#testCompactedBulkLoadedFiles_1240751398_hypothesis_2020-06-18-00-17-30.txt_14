reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-489ccb62-3fcf-4fa8-8f8f-6948942aafd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-b9f25c32-b4d3-4676-b913-7bfcac0c07bb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43635,DS-b9f25c32-b4d3-4676-b913-7bfcac0c07bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-489ccb62-3fcf-4fa8-8f8f-6948942aafd0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-489ccb62-3fcf-4fa8-8f8f-6948942aafd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-b9f25c32-b4d3-4676-b913-7bfcac0c07bb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43635,DS-b9f25c32-b4d3-4676-b913-7bfcac0c07bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-489ccb62-3fcf-4fa8-8f8f-6948942aafd0,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-505e4f03-e75d-44a7-a480-9a4e314dcb75,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-ad2c9e94-6dc9-4071-8e86-c3be877bc8ee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-505e4f03-e75d-44a7-a480-9a4e314dcb75,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-ad2c9e94-6dc9-4071-8e86-c3be877bc8ee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-505e4f03-e75d-44a7-a480-9a4e314dcb75,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-ad2c9e94-6dc9-4071-8e86-c3be877bc8ee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-505e4f03-e75d-44a7-a480-9a4e314dcb75,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-ad2c9e94-6dc9-4071-8e86-c3be877bc8ee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32784,DS-ba408cc3-6555-4f37-841a-c75e8ed199d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-54e2cad1-42b2-4ef0-a699-924ea9c485c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-54e2cad1-42b2-4ef0-a699-924ea9c485c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-ba408cc3-6555-4f37-841a-c75e8ed199d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32784,DS-ba408cc3-6555-4f37-841a-c75e8ed199d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-54e2cad1-42b2-4ef0-a699-924ea9c485c3,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-54e2cad1-42b2-4ef0-a699-924ea9c485c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-ba408cc3-6555-4f37-841a-c75e8ed199d9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-e12c97c0-25c3-47f1-a7eb-5743d4e9e41a,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-af1e5832-2ce9-42e7-a10f-2a5a127dcdfb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-af1e5832-2ce9-42e7-a10f-2a5a127dcdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-e12c97c0-25c3-47f1-a7eb-5743d4e9e41a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-e12c97c0-25c3-47f1-a7eb-5743d4e9e41a,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-af1e5832-2ce9-42e7-a10f-2a5a127dcdfb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-af1e5832-2ce9-42e7-a10f-2a5a127dcdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-e12c97c0-25c3-47f1-a7eb-5743d4e9e41a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-9b85d243-fedd-41be-9589-02eafcc78f04,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-5107f3e0-98a3-4afd-8bb9-7ba3c26904df,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32911,DS-5107f3e0-98a3-4afd-8bb9-7ba3c26904df,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-9b85d243-fedd-41be-9589-02eafcc78f04,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38711,DS-9b85d243-fedd-41be-9589-02eafcc78f04,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-5107f3e0-98a3-4afd-8bb9-7ba3c26904df,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32911,DS-5107f3e0-98a3-4afd-8bb9-7ba3c26904df,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-9b85d243-fedd-41be-9589-02eafcc78f04,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-1db36f02-386d-4abb-991b-80a494d44eac,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-ffdf2a05-97ae-4777-b59f-beee484f1693,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-1db36f02-386d-4abb-991b-80a494d44eac,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-ffdf2a05-97ae-4777-b59f-beee484f1693,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-1db36f02-386d-4abb-991b-80a494d44eac,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-ffdf2a05-97ae-4777-b59f-beee484f1693,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-1db36f02-386d-4abb-991b-80a494d44eac,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-ffdf2a05-97ae-4777-b59f-beee484f1693,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-69739060-274e-4577-aa24-9a0730324768,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-0d1cca73-1a55-41c7-b34b-75576bbc14d7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-69739060-274e-4577-aa24-9a0730324768,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-0d1cca73-1a55-41c7-b34b-75576bbc14d7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-69739060-274e-4577-aa24-9a0730324768,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-0d1cca73-1a55-41c7-b34b-75576bbc14d7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-69739060-274e-4577-aa24-9a0730324768,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-0d1cca73-1a55-41c7-b34b-75576bbc14d7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-654ace7a-2740-4b8e-8ccf-3d8d1f30809d,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-8f9e259a-2db4-4e02-b58f-a892b51a3101,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-654ace7a-2740-4b8e-8ccf-3d8d1f30809d,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-8f9e259a-2db4-4e02-b58f-a892b51a3101,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-654ace7a-2740-4b8e-8ccf-3d8d1f30809d,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-8f9e259a-2db4-4e02-b58f-a892b51a3101,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42523,DS-654ace7a-2740-4b8e-8ccf-3d8d1f30809d,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-8f9e259a-2db4-4e02-b58f-a892b51a3101,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39380,DS-b931893f-a50a-45d1-bf24-d75f2690cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-91f20a68-a864-4ba6-b343-2157d40e4882,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44615,DS-91f20a68-a864-4ba6-b343-2157d40e4882,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-b931893f-a50a-45d1-bf24-d75f2690cd41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39380,DS-b931893f-a50a-45d1-bf24-d75f2690cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-91f20a68-a864-4ba6-b343-2157d40e4882,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44615,DS-91f20a68-a864-4ba6-b343-2157d40e4882,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-b931893f-a50a-45d1-bf24-d75f2690cd41,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: region: testCompactedBulkLoadedFiles,,1592440930035.adac27f029cffb242fb594c3cfd55b0a.
stackTrace: org.apache.hadoop.hbase.DroppedSnapshotException: region: testCompactedBulkLoadedFiles,,1592440930035.adac27f029cffb242fb594c3cfd55b0a.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2858)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2527)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2499)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2389)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:6232)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:6116)
	at org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.testCompactedBulkLoadedFiles(AbstractTestWALReplay.java:431)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-25e6dafa-bf15-49cb-8f4f-c0446f2c6e09,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-42714de4-090a-4cd5-84bf-8c7ed57fb4fd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-42714de4-090a-4cd5-84bf-8c7ed57fb4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-25e6dafa-bf15-49cb-8f4f-c0446f2c6e09,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33165,DS-da1f9e76-804a-4082-99a5-ef98e3a735c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-32158df1-792d-4fd7-8df0-ded39f5c9106,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-32158df1-792d-4fd7-8df0-ded39f5c9106,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-da1f9e76-804a-4082-99a5-ef98e3a735c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33165,DS-da1f9e76-804a-4082-99a5-ef98e3a735c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-32158df1-792d-4fd7-8df0-ded39f5c9106,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-32158df1-792d-4fd7-8df0-ded39f5c9106,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-da1f9e76-804a-4082-99a5-ef98e3a735c6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41682,DS-05b1eb9e-879d-446b-83db-8f2c40d36d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-74f98677-7b86-4ed5-ae59-7aa3f0872ff8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-74f98677-7b86-4ed5-ae59-7aa3f0872ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-05b1eb9e-879d-446b-83db-8f2c40d36d42,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41682,DS-05b1eb9e-879d-446b-83db-8f2c40d36d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-74f98677-7b86-4ed5-ae59-7aa3f0872ff8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44459,DS-74f98677-7b86-4ed5-ae59-7aa3f0872ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-05b1eb9e-879d-446b-83db-8f2c40d36d42,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42998,DS-bb0d32de-5d91-4a11-90a4-7ed41785f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-3109acdb-d54f-450d-9c36-90cc84ef9e28,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42998,DS-bb0d32de-5d91-4a11-90a4-7ed41785f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-3109acdb-d54f-450d-9c36-90cc84ef9e28,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42998,DS-bb0d32de-5d91-4a11-90a4-7ed41785f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-3109acdb-d54f-450d-9c36-90cc84ef9e28,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42998,DS-bb0d32de-5d91-4a11-90a4-7ed41785f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-3109acdb-d54f-450d-9c36-90cc84ef9e28,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36712,DS-5d633368-7215-4327-8271-369fb6025675,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-56acd6cd-ec88-4686-bb16-11d6aa6befed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36712,DS-5d633368-7215-4327-8271-369fb6025675,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-56acd6cd-ec88-4686-bb16-11d6aa6befed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36712,DS-5d633368-7215-4327-8271-369fb6025675,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-56acd6cd-ec88-4686-bb16-11d6aa6befed,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36712,DS-5d633368-7215-4327-8271-369fb6025675,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-56acd6cd-ec88-4686-bb16-11d6aa6befed,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: region: testCompactedBulkLoadedFiles,,1592441765444.e754db67cc76d89d3ad2884ea35ea049.
stackTrace: org.apache.hadoop.hbase.DroppedSnapshotException: region: testCompactedBulkLoadedFiles,,1592441765444.e754db67cc76d89d3ad2884ea35ea049.
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2858)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2527)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2499)
	at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2389)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:6232)
	at org.apache.hadoop.hbase.regionserver.HRegion.bulkLoadHFiles(HRegion.java:6116)
	at org.apache.hadoop.hbase.regionserver.wal.AbstractTestWALReplay.testCompactedBulkLoadedFiles(AbstractTestWALReplay.java:431)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=6, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	... 1 more
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40927,DS-17baf031-0a72-4141-a356-785a47c0bc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-512b296b-272e-4397-9472-051108583b6b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40927,DS-17baf031-0a72-4141-a356-785a47c0bc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-512b296b-272e-4397-9472-051108583b6b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-a1943a2c-c2fd-4142-9afd-f8b5d6f2c434,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-e3adff39-6d47-470f-90c0-49ae52bda7a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-a1943a2c-c2fd-4142-9afd-f8b5d6f2c434,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-e3adff39-6d47-470f-90c0-49ae52bda7a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-a1943a2c-c2fd-4142-9afd-f8b5d6f2c434,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-e3adff39-6d47-470f-90c0-49ae52bda7a8,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-a1943a2c-c2fd-4142-9afd-f8b5d6f2c434,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-e3adff39-6d47-470f-90c0-49ae52bda7a8,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-c16a2d21-2a22-4c1e-af09-9fa40c73bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-ada37b10-fa02-489e-bf83-dc22b9b25160,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-ada37b10-fa02-489e-bf83-dc22b9b25160,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-c16a2d21-2a22-4c1e-af09-9fa40c73bb76,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-c16a2d21-2a22-4c1e-af09-9fa40c73bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-ada37b10-fa02-489e-bf83-dc22b9b25160,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-ada37b10-fa02-489e-bf83-dc22b9b25160,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-c16a2d21-2a22-4c1e-af09-9fa40c73bb76,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-dc172beb-6457-406b-ae1f-1cf6cca8a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-c4c1d4b7-7989-4deb-be7f-6a37ada44ba7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-dc172beb-6457-406b-ae1f-1cf6cca8a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-c4c1d4b7-7989-4deb-be7f-6a37ada44ba7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-dc172beb-6457-406b-ae1f-1cf6cca8a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-c4c1d4b7-7989-4deb-be7f-6a37ada44ba7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-dc172beb-6457-406b-ae1f-1cf6cca8a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-c4c1d4b7-7989-4deb-be7f-6a37ada44ba7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35186,DS-001fba9e-a8bd-4539-98b7-5c56d7635c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-bdfe7a26-eaff-4579-bd70-eac03f74d497,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35186,DS-001fba9e-a8bd-4539-98b7-5c56d7635c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-bdfe7a26-eaff-4579-bd70-eac03f74d497,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35186,DS-001fba9e-a8bd-4539-98b7-5c56d7635c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-bdfe7a26-eaff-4579-bd70-eac03f74d497,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35186,DS-001fba9e-a8bd-4539-98b7-5c56d7635c69,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-bdfe7a26-eaff-4579-bd70-eac03f74d497,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40567,DS-762bfc6b-7332-4158-a803-28b5a773e632,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-d172cb3b-1536-43ac-ad30-b12313be8065,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40567,DS-762bfc6b-7332-4158-a803-28b5a773e632,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-d172cb3b-1536-43ac-ad30-b12313be8065,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40567,DS-762bfc6b-7332-4158-a803-28b5a773e632,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-d172cb3b-1536-43ac-ad30-b12313be8065,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40567,DS-762bfc6b-7332-4158-a803-28b5a773e632,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-d172cb3b-1536-43ac-ad30-b12313be8065,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-1f745ad1-1f16-4d88-a186-9706c32c13ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-660eb21b-1128-42e4-b98a-5be55bb1de13,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-1f745ad1-1f16-4d88-a186-9706c32c13ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-660eb21b-1128-42e4-b98a-5be55bb1de13,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-1f745ad1-1f16-4d88-a186-9706c32c13ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-660eb21b-1128-42e4-b98a-5be55bb1de13,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34153,DS-1f745ad1-1f16-4d88-a186-9706c32c13ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-660eb21b-1128-42e4-b98a-5be55bb1de13,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35793,DS-b66ffa96-6fe7-4047-80f7-acf5c1c291b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-3012a8f0-3c11-4278-905e-efa8d8c875a6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35793,DS-b66ffa96-6fe7-4047-80f7-acf5c1c291b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-3012a8f0-3c11-4278-905e-efa8d8c875a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:35793,DS-b66ffa96-6fe7-4047-80f7-acf5c1c291b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-3012a8f0-3c11-4278-905e-efa8d8c875a6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35793,DS-b66ffa96-6fe7-4047-80f7-acf5c1c291b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-3012a8f0-3c11-4278-905e-efa8d8c875a6,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34324,DS-8bc11cd9-b6a7-48c6-8951-cb5bf8f68c43,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-c184a9f7-69f0-4aac-ae49-00424d7fb416,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34324,DS-8bc11cd9-b6a7-48c6-8951-cb5bf8f68c43,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-c184a9f7-69f0-4aac-ae49-00424d7fb416,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34324,DS-8bc11cd9-b6a7-48c6-8951-cb5bf8f68c43,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-c184a9f7-69f0-4aac-ae49-00424d7fb416,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34324,DS-8bc11cd9-b6a7-48c6-8951-cb5bf8f68c43,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-c184a9f7-69f0-4aac-ae49-00424d7fb416,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39382,DS-3c903c1b-d434-4606-9c4f-b1c438d1ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-e6546069-8813-47da-8f71-13f925b58edd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35057,DS-e6546069-8813-47da-8f71-13f925b58edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-3c903c1b-d434-4606-9c4f-b1c438d1ebe2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39382,DS-3c903c1b-d434-4606-9c4f-b1c438d1ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-e6546069-8813-47da-8f71-13f925b58edd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35057,DS-e6546069-8813-47da-8f71-13f925b58edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-3c903c1b-d434-4606-9c4f-b1c438d1ebe2,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-c2c2e72a-7ed3-4b98-b41c-4fc3dd6523f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-55346a46-72be-40af-bff3-a2095d365f79,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-c2c2e72a-7ed3-4b98-b41c-4fc3dd6523f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-55346a46-72be-40af-bff3-a2095d365f79,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-c2c2e72a-7ed3-4b98-b41c-4fc3dd6523f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-55346a46-72be-40af-bff3-a2095d365f79,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-c2c2e72a-7ed3-4b98-b41c-4fc3dd6523f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-55346a46-72be-40af-bff3-a2095d365f79,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37834,DS-66690ac5-5216-4f44-b9c0-951975c4e4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-57f5dbfd-54de-4615-a1f6-4c56fd9655c6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-57f5dbfd-54de-4615-a1f6-4c56fd9655c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-66690ac5-5216-4f44-b9c0-951975c4e4ef,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37834,DS-66690ac5-5216-4f44-b9c0-951975c4e4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-57f5dbfd-54de-4615-a1f6-4c56fd9655c6,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-57f5dbfd-54de-4615-a1f6-4c56fd9655c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-66690ac5-5216-4f44-b9c0-951975c4e4ef,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-2a71edaf-9705-4463-8c63-7c95d0aec283,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-33f12edb-8654-4240-b715-34ea2defc5ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-2a71edaf-9705-4463-8c63-7c95d0aec283,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-33f12edb-8654-4240-b715-34ea2defc5ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-2a71edaf-9705-4463-8c63-7c95d0aec283,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-33f12edb-8654-4240-b715-34ea2defc5ff,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41370,DS-2a71edaf-9705-4463-8c63-7c95d0aec283,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-33f12edb-8654-4240-b715-34ea2defc5ff,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38760,DS-b2e1cf4c-7ce4-44e8-8043-a105599ea730,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-13e641a6-c562-4fe4-9778-6c6fc194417c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35351,DS-13e641a6-c562-4fe4-9778-6c6fc194417c,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-b2e1cf4c-7ce4-44e8-8043-a105599ea730,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:38760,DS-b2e1cf4c-7ce4-44e8-8043-a105599ea730,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-13e641a6-c562-4fe4-9778-6c6fc194417c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35351,DS-13e641a6-c562-4fe4-9778-6c6fc194417c,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-b2e1cf4c-7ce4-44e8-8043-a105599ea730,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-d4d73072-ce32-4a61-9982-2a324e64c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-94259dd5-6aef-447c-aa91-164bb5a62de4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-d4d73072-ce32-4a61-9982-2a324e64c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-94259dd5-6aef-447c-aa91-164bb5a62de4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-d4d73072-ce32-4a61-9982-2a324e64c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-94259dd5-6aef-447c-aa91-164bb5a62de4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-d4d73072-ce32-4a61-9982-2a324e64c7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-94259dd5-6aef-447c-aa91-164bb5a62de4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43075,DS-1ba95163-1e99-4a00-a12b-fd2d914b5ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-059ecf93-2586-4956-a4f1-1d5b4382597b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43075,DS-1ba95163-1e99-4a00-a12b-fd2d914b5ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-059ecf93-2586-4956-a4f1-1d5b4382597b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43075,DS-1ba95163-1e99-4a00-a12b-fd2d914b5ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-059ecf93-2586-4956-a4f1-1d5b4382597b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43075,DS-1ba95163-1e99-4a00-a12b-fd2d914b5ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-059ecf93-2586-4956-a4f1-1d5b4382597b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42512,DS-e46a9234-1bdd-4c46-af2c-3787e3268f2a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42512,DS-e46a9234-1bdd-4c46-af2c-3787e3268f2a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42512,DS-e46a9234-1bdd-4c46-af2c-3787e3268f2a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42512,DS-e46a9234-1bdd-4c46-af2c-3787e3268f2a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44488,DS-def81ec0-c3a1-43a6-95cb-b329d9dfce57,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-28ddd37d-8065-4755-b729-a3a4267be5cb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44488,DS-def81ec0-c3a1-43a6-95cb-b329d9dfce57,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-28ddd37d-8065-4755-b729-a3a4267be5cb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44488,DS-def81ec0-c3a1-43a6-95cb-b329d9dfce57,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-28ddd37d-8065-4755-b729-a3a4267be5cb,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44488,DS-def81ec0-c3a1-43a6-95cb-b329d9dfce57,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-28ddd37d-8065-4755-b729-a3a4267be5cb,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-446e5de3-9787-4d33-bd0b-6370a37c09fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-b1895cd1-4eda-4679-bacc-54ca25ca9866,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-446e5de3-9787-4d33-bd0b-6370a37c09fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-b1895cd1-4eda-4679-bacc-54ca25ca9866,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-446e5de3-9787-4d33-bd0b-6370a37c09fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-b1895cd1-4eda-4679-bacc-54ca25ca9866,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-446e5de3-9787-4d33-bd0b-6370a37c09fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-b1895cd1-4eda-4679-bacc-54ca25ca9866,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44923,DS-763bc6af-276e-49cd-a2c3-60b62f16e582,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-8c308d68-9ea2-4369-80fe-419a9bffc91f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44923,DS-763bc6af-276e-49cd-a2c3-60b62f16e582,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-8c308d68-9ea2-4369-80fe-419a9bffc91f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44923,DS-763bc6af-276e-49cd-a2c3-60b62f16e582,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-8c308d68-9ea2-4369-80fe-419a9bffc91f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44923,DS-763bc6af-276e-49cd-a2c3-60b62f16e582,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-8c308d68-9ea2-4369-80fe-419a9bffc91f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37629,DS-9b312da3-3e5a-4447-860d-8a0b7f6f158a,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-9a413144-d1cc-4a88-9b00-6df8fb8c6c6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37629,DS-9b312da3-3e5a-4447-860d-8a0b7f6f158a,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-9a413144-d1cc-4a88-9b00-6df8fb8c6c6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37629,DS-9b312da3-3e5a-4447-860d-8a0b7f6f158a,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-9a413144-d1cc-4a88-9b00-6df8fb8c6c6f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37629,DS-9b312da3-3e5a-4447-860d-8a0b7f6f158a,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-9a413144-d1cc-4a88-9b00-6df8fb8c6c6f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
Warn: test org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles has not been updated !
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: 
stackTrace: 


Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-fbdb25c0-0f59-45f0-abfb-793c4eb63c26,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-fe9ef138-580e-4365-a9b8-86dc9c9f3895,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-fbdb25c0-0f59-45f0-abfb-793c4eb63c26,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-fe9ef138-580e-4365-a9b8-86dc9c9f3895,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-fbdb25c0-0f59-45f0-abfb-793c4eb63c26,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-fe9ef138-580e-4365-a9b8-86dc9c9f3895,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-fbdb25c0-0f59-45f0-abfb-793c4eb63c26,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-fe9ef138-580e-4365-a9b8-86dc9c9f3895,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37983,DS-fd1a7cce-def0-400b-8c11-4bab76a7c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-1b142a1e-241b-4e38-a02d-023d88018f93,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-1b142a1e-241b-4e38-a02d-023d88018f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-fd1a7cce-def0-400b-8c11-4bab76a7c83f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37983,DS-fd1a7cce-def0-400b-8c11-4bab76a7c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-1b142a1e-241b-4e38-a02d-023d88018f93,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-1b142a1e-241b-4e38-a02d-023d88018f93,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-fd1a7cce-def0-400b-8c11-4bab76a7c83f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36347,DS-d1ea4979-b3e2-46d3-9052-cb2dc38599a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-107c621e-aa2d-4099-9a1c-cdbabe6e4113,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39970,DS-107c621e-aa2d-4099-9a1c-cdbabe6e4113,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-d1ea4979-b3e2-46d3-9052-cb2dc38599a9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36347,DS-d1ea4979-b3e2-46d3-9052-cb2dc38599a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-107c621e-aa2d-4099-9a1c-cdbabe6e4113,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39970,DS-107c621e-aa2d-4099-9a1c-cdbabe6e4113,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-d1ea4979-b3e2-46d3-9052-cb2dc38599a9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39690,DS-0c6b6c61-5c5d-464b-9c6e-d5201f1d273f,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-53058e08-0be0-4a84-b851-8a53f1aa2db7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33552,DS-53058e08-0be0-4a84-b851-8a53f1aa2db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-0c6b6c61-5c5d-464b-9c6e-d5201f1d273f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39690,DS-0c6b6c61-5c5d-464b-9c6e-d5201f1d273f,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-53058e08-0be0-4a84-b851-8a53f1aa2db7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33552,DS-53058e08-0be0-4a84-b851-8a53f1aa2db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-0c6b6c61-5c5d-464b-9c6e-d5201f1d273f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40990,DS-15bfe4db-30fc-429d-9e98-d42e2ac8ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-2ab37e07-1781-4ba3-b29b-a28848d4ec0d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40990,DS-15bfe4db-30fc-429d-9e98-d42e2ac8ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-2ab37e07-1781-4ba3-b29b-a28848d4ec0d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40990,DS-15bfe4db-30fc-429d-9e98-d42e2ac8ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-2ab37e07-1781-4ba3-b29b-a28848d4ec0d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40990,DS-15bfe4db-30fc-429d-9e98-d42e2ac8ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-2ab37e07-1781-4ba3-b29b-a28848d4ec0d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-d86edc9c-1ae0-4d2e-b783-6db3dfd6c144,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-750cbb67-d3d0-4edd-a658-bc43a9623ece,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-d86edc9c-1ae0-4d2e-b783-6db3dfd6c144,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-750cbb67-d3d0-4edd-a658-bc43a9623ece,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-d86edc9c-1ae0-4d2e-b783-6db3dfd6c144,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-750cbb67-d3d0-4edd-a658-bc43a9623ece,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-d86edc9c-1ae0-4d2e-b783-6db3dfd6c144,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-750cbb67-d3d0-4edd-a658-bc43a9623ece,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33437,DS-439b6197-7cd2-4e7e-bf34-fed101be9336,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-15eda51c-a863-400a-a37b-3bcb63220e9a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34152,DS-15eda51c-a863-400a-a37b-3bcb63220e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-439b6197-7cd2-4e7e-bf34-fed101be9336,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33437,DS-439b6197-7cd2-4e7e-bf34-fed101be9336,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-15eda51c-a863-400a-a37b-3bcb63220e9a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34152,DS-15eda51c-a863-400a-a37b-3bcb63220e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-439b6197-7cd2-4e7e-bf34-fed101be9336,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-8f1b82f0-6a08-4c5e-aaae-9b39aef6374c,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-f8ad42d0-f25c-4734-8e97-df21a9b70940,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-8f1b82f0-6a08-4c5e-aaae-9b39aef6374c,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-f8ad42d0-f25c-4734-8e97-df21a9b70940,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-8f1b82f0-6a08-4c5e-aaae-9b39aef6374c,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-f8ad42d0-f25c-4734-8e97-df21a9b70940,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-8f1b82f0-6a08-4c5e-aaae-9b39aef6374c,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-f8ad42d0-f25c-4734-8e97-df21a9b70940,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-211dade4-fef4-42dd-a28a-857392b19f2d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-211dade4-fef4-42dd-a28a-857392b19f2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-211dade4-fef4-42dd-a28a-857392b19f2d,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33976,DS-211dade4-fef4-42dd-a28a-857392b19f2d,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-14efa48a-c769-44a1-a68e-93f5e87416ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-9fbd9667-882a-4cf8-8b7d-c049c32e6254,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-14efa48a-c769-44a1-a68e-93f5e87416ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-9fbd9667-882a-4cf8-8b7d-c049c32e6254,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-14efa48a-c769-44a1-a68e-93f5e87416ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-9fbd9667-882a-4cf8-8b7d-c049c32e6254,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33306,DS-14efa48a-c769-44a1-a68e-93f5e87416ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-9fbd9667-882a-4cf8-8b7d-c049c32e6254,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-2f265542-76f7-405b-b126-75aa399ed3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-cb557054-c855-4ac4-9338-f2232f630d34,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-2f265542-76f7-405b-b126-75aa399ed3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-cb557054-c855-4ac4-9338-f2232f630d34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-2f265542-76f7-405b-b126-75aa399ed3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-cb557054-c855-4ac4-9338-f2232f630d34,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-2f265542-76f7-405b-b126-75aa399ed3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-cb557054-c855-4ac4-9338-f2232f630d34,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-687c9376-1bb9-4b89-baa5-fcc22780f285,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-de2b0091-36a9-47c5-9cdd-9dd4fe17912a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-687c9376-1bb9-4b89-baa5-fcc22780f285,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-de2b0091-36a9-47c5-9cdd-9dd4fe17912a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-687c9376-1bb9-4b89-baa5-fcc22780f285,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-de2b0091-36a9-47c5-9cdd-9dd4fe17912a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40210,DS-687c9376-1bb9-4b89-baa5-fcc22780f285,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-de2b0091-36a9-47c5-9cdd-9dd4fe17912a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-a4a532de-68da-40f2-af5f-b4e351f7dc86,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-77a42a9d-da57-46da-9c63-bddccc0a65a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-a4a532de-68da-40f2-af5f-b4e351f7dc86,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-77a42a9d-da57-46da-9c63-bddccc0a65a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-a4a532de-68da-40f2-af5f-b4e351f7dc86,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-77a42a9d-da57-46da-9c63-bddccc0a65a4,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-a4a532de-68da-40f2-af5f-b4e351f7dc86,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-77a42a9d-da57-46da-9c63-bddccc0a65a4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-cabc801a-eec7-4f61-8c37-7b5323398785,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-d89f35d2-3932-4c3b-8953-4ebae65ce31c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-cabc801a-eec7-4f61-8c37-7b5323398785,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-d89f35d2-3932-4c3b-8953-4ebae65ce31c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-cabc801a-eec7-4f61-8c37-7b5323398785,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-d89f35d2-3932-4c3b-8953-4ebae65ce31c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42588,DS-cabc801a-eec7-4f61-8c37-7b5323398785,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-d89f35d2-3932-4c3b-8953-4ebae65ce31c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-84d4de3c-7b7d-4b43-aea1-bc86fdb9e9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-5ddd5b1b-f840-4502-ba94-38d10d96b674,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-84d4de3c-7b7d-4b43-aea1-bc86fdb9e9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-5ddd5b1b-f840-4502-ba94-38d10d96b674,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-84d4de3c-7b7d-4b43-aea1-bc86fdb9e9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-5ddd5b1b-f840-4502-ba94-38d10d96b674,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44906,DS-84d4de3c-7b7d-4b43-aea1-bc86fdb9e9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-5ddd5b1b-f840-4502-ba94-38d10d96b674,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-25901f24-383c-4bbe-8daa-1a13456ed290,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-3e857528-8bf0-4407-9ceb-11edbb6dcbcd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33936,DS-3e857528-8bf0-4407-9ceb-11edbb6dcbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-25901f24-383c-4bbe-8daa-1a13456ed290,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-25901f24-383c-4bbe-8daa-1a13456ed290,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-3e857528-8bf0-4407-9ceb-11edbb6dcbcd,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:33936,DS-3e857528-8bf0-4407-9ceb-11edbb6dcbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-25901f24-383c-4bbe-8daa-1a13456ed290,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45394,DS-d5e3b208-07af-4c9f-b96a-18fb042992a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-93108b03-fae4-417d-b54f-c94c4477e203,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45394,DS-d5e3b208-07af-4c9f-b96a-18fb042992a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-93108b03-fae4-417d-b54f-c94c4477e203,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:45394,DS-d5e3b208-07af-4c9f-b96a-18fb042992a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-93108b03-fae4-417d-b54f-c94c4477e203,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:45394,DS-d5e3b208-07af-4c9f-b96a-18fb042992a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-93108b03-fae4-417d-b54f-c94c4477e203,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-15f0c038-b004-46d6-b02e-73b2aada1e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-e09af73e-bed8-4555-92f4-7dd5a029f5dc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43713,DS-e09af73e-bed8-4555-92f4-7dd5a029f5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-15f0c038-b004-46d6-b02e-73b2aada1e38,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-15f0c038-b004-46d6-b02e-73b2aada1e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-e09af73e-bed8-4555-92f4-7dd5a029f5dc,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43713,DS-e09af73e-bed8-4555-92f4-7dd5a029f5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-15f0c038-b004-46d6-b02e-73b2aada1e38,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42510,DS-c382856f-d407-40a4-8f54-a2e2fbc2e7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-78aefd18-e716-473e-9d4b-dbb08f65076a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42510,DS-c382856f-d407-40a4-8f54-a2e2fbc2e7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-78aefd18-e716-473e-9d4b-dbb08f65076a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:42510,DS-c382856f-d407-40a4-8f54-a2e2fbc2e7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-78aefd18-e716-473e-9d4b-dbb08f65076a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:42510,DS-c382856f-d407-40a4-8f54-a2e2fbc2e7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-78aefd18-e716-473e-9d4b-dbb08f65076a,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-934f837a-f66c-44dd-8a65-dc55a81e47c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-7b00c304-2487-4c41-a971-2538560af811,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-934f837a-f66c-44dd-8a65-dc55a81e47c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-7b00c304-2487-4c41-a971-2538560af811,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-934f837a-f66c-44dd-8a65-dc55a81e47c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-7b00c304-2487-4c41-a971-2538560af811,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-934f837a-f66c-44dd-8a65-dc55a81e47c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-7b00c304-2487-4c41-a971-2538560af811,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Append sequenceId=5, requesting roll of WAL
stackTrace: org.apache.hadoop.hbase.regionserver.wal.DamagedWALException: Append sequenceId=5, requesting roll of WAL
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.append(FSHLog.java:1081)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:964)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog$RingBufferEventHandler.onEvent(FSHLog.java:873)
	at com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:129)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-bf85f03b-a91f-48ea-8957-3e68cbbadb02,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-d087847a-6389-4ef7-9d5f-f8faf668132f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34893,DS-bf85f03b-a91f-48ea-8957-3e68cbbadb02,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-d087847a-6389-4ef7-9d5f-f8faf668132f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36917,DS-5b818f99-4125-4a10-939b-640b5fe6acde,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-0f760dfa-8fd3-41d0-988c-0f5d3f6dfd75,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-0f760dfa-8fd3-41d0-988c-0f5d3f6dfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-5b818f99-4125-4a10-939b-640b5fe6acde,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36917,DS-5b818f99-4125-4a10-939b-640b5fe6acde,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-0f760dfa-8fd3-41d0-988c-0f5d3f6dfd75,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-0f760dfa-8fd3-41d0-988c-0f5d3f6dfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-5b818f99-4125-4a10-939b-640b5fe6acde,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-7a639748-a584-4d85-a974-7bdf1b3bc8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-66798cf2-4b15-4c68-8dd0-2ffc4564c02f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44289,DS-66798cf2-4b15-4c68-8dd0-2ffc4564c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-7a639748-a584-4d85-a974-7bdf1b3bc8b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-7a639748-a584-4d85-a974-7bdf1b3bc8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-66798cf2-4b15-4c68-8dd0-2ffc4564c02f,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44289,DS-66798cf2-4b15-4c68-8dd0-2ffc4564c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-7a639748-a584-4d85-a974-7bdf1b3bc8b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-d7d2bec7-89f1-4259-b612-5096ea81ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-bff28100-7758-4a17-b43e-ed62a9e32bee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-d7d2bec7-89f1-4259-b612-5096ea81ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-bff28100-7758-4a17-b43e-ed62a9e32bee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-d7d2bec7-89f1-4259-b612-5096ea81ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-bff28100-7758-4a17-b43e-ed62a9e32bee,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-d7d2bec7-89f1-4259-b612-5096ea81ea78,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-bff28100-7758-4a17-b43e-ed62a9e32bee,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-d6963112-0086-4324-b139-08400aec3a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-3b67955f-b546-4dd8-8989-5f875e08f9c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-d6963112-0086-4324-b139-08400aec3a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-3b67955f-b546-4dd8-8989-5f875e08f9c1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-d6963112-0086-4324-b139-08400aec3a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-3b67955f-b546-4dd8-8989-5f875e08f9c1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-d6963112-0086-4324-b139-08400aec3a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-3b67955f-b546-4dd8-8989-5f875e08f9c1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-cbd3b18c-6930-42b3-9042-8412faa2a95a,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-3d620126-cc13-48b9-9b1e-01644e3837d1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-cbd3b18c-6930-42b3-9042-8412faa2a95a,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-3d620126-cc13-48b9-9b1e-01644e3837d1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-cbd3b18c-6930-42b3-9042-8412faa2a95a,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-3d620126-cc13-48b9-9b1e-01644e3837d1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-cbd3b18c-6930-42b3-9042-8412faa2a95a,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-3d620126-cc13-48b9-9b1e-01644e3837d1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39887,DS-939fb4f1-46bb-4105-b1ae-abec37b229be,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-8893fb42-b023-4bb5-8acc-ec58bd6dd001,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39887,DS-939fb4f1-46bb-4105-b1ae-abec37b229be,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-8893fb42-b023-4bb5-8acc-ec58bd6dd001,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39887,DS-939fb4f1-46bb-4105-b1ae-abec37b229be,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-8893fb42-b023-4bb5-8acc-ec58bd6dd001,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39887,DS-939fb4f1-46bb-4105-b1ae-abec37b229be,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-8893fb42-b023-4bb5-8acc-ec58bd6dd001,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 60
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#testCompactedBulkLoadedFiles
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39131,DS-88fade34-f51d-45bc-93d6-3b4cfc8b9082,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-cdb612b4-d251-40f5-9d12-9af499abcad1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39131,DS-88fade34-f51d-45bc-93d6-3b4cfc8b9082,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-cdb612b4-d251-40f5-9d12-9af499abcad1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:39131,DS-88fade34-f51d-45bc-93d6-3b4cfc8b9082,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-cdb612b4-d251-40f5-9d12-9af499abcad1,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:39131,DS-88fade34-f51d-45bc-93d6-3b4cfc8b9082,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-cdb612b4-d251-40f5-9d12-9af499abcad1,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 50 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: might be true error
Total execution time in seconds : 10142
