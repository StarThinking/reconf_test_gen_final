reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-6f69beea-df37-4470-9d9b-482780eb2f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-8c80c92b-cb64-400f-9eae-77c629250aa7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-6f69beea-df37-4470-9d9b-482780eb2f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-8c80c92b-cb64-400f-9eae-77c629250aa7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-6f69beea-df37-4470-9d9b-482780eb2f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-8c80c92b-cb64-400f-9eae-77c629250aa7,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-6f69beea-df37-4470-9d9b-482780eb2f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-8c80c92b-cb64-400f-9eae-77c629250aa7,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46028,DS-09a67456-6a87-4ad4-8fcf-ae192b6740a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-1582fe53-f7b9-4729-b936-d310ecd9a7b5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46028,DS-09a67456-6a87-4ad4-8fcf-ae192b6740a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-1582fe53-f7b9-4729-b936-d310ecd9a7b5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46028,DS-09a67456-6a87-4ad4-8fcf-ae192b6740a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-1582fe53-f7b9-4729-b936-d310ecd9a7b5,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46028,DS-09a67456-6a87-4ad4-8fcf-ae192b6740a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-1582fe53-f7b9-4729-b936-d310ecd9a7b5,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46445,DS-e27ab1bc-c142-4ea5-a0de-c366e8d1551f,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-7e811d5d-96e3-4075-acbf-ab5113edb11a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-7e811d5d-96e3-4075-acbf-ab5113edb11a,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-e27ab1bc-c142-4ea5-a0de-c366e8d1551f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:46445,DS-e27ab1bc-c142-4ea5-a0de-c366e8d1551f,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-7e811d5d-96e3-4075-acbf-ab5113edb11a,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-7e811d5d-96e3-4075-acbf-ab5113edb11a,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-e27ab1bc-c142-4ea5-a0de-c366e8d1551f,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-37b1410d-abb2-4973-b4ad-3a4d8b454eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-8b92e4d4-03c9-4490-9bb5-1d33285d4a21,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34760,DS-8b92e4d4-03c9-4490-9bb5-1d33285d4a21,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-37b1410d-abb2-4973-b4ad-3a4d8b454eb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-37b1410d-abb2-4973-b4ad-3a4d8b454eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-8b92e4d4-03c9-4490-9bb5-1d33285d4a21,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34760,DS-8b92e4d4-03c9-4490-9bb5-1d33285d4a21,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-37b1410d-abb2-4973-b4ad-3a4d8b454eb9,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-513767b8-a2b6-4173-a7ba-5c3b58a6037b,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-50bd4cda-d520-4bee-b13d-13bbb6b8a185,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-513767b8-a2b6-4173-a7ba-5c3b58a6037b,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-50bd4cda-d520-4bee-b13d-13bbb6b8a185,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-513767b8-a2b6-4173-a7ba-5c3b58a6037b,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-50bd4cda-d520-4bee-b13d-13bbb6b8a185,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-513767b8-a2b6-4173-a7ba-5c3b58a6037b,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-50bd4cda-d520-4bee-b13d-13bbb6b8a185,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-46b86845-6123-4c29-b68e-9a384e5749a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-5e2bafbe-620c-4a10-bd04-1eebbb503072,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44388,DS-5e2bafbe-620c-4a10-bd04-1eebbb503072,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-46b86845-6123-4c29-b68e-9a384e5749a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-46b86845-6123-4c29-b68e-9a384e5749a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-5e2bafbe-620c-4a10-bd04-1eebbb503072,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:44388,DS-5e2bafbe-620c-4a10-bd04-1eebbb503072,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-46b86845-6123-4c29-b68e-9a384e5749a3,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-25fe77ff-048f-43e6-8241-b15a6e8cebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-1641a13e-dd65-41c8-9b74-06e9b776d507,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-25fe77ff-048f-43e6-8241-b15a6e8cebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-1641a13e-dd65-41c8-9b74-06e9b776d507,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-25fe77ff-048f-43e6-8241-b15a6e8cebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-1641a13e-dd65-41c8-9b74-06e9b776d507,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-25fe77ff-048f-43e6-8241-b15a6e8cebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-1641a13e-dd65-41c8-9b74-06e9b776d507,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-39f3dcbe-bd62-40d4-99dc-df9741210e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-dba03709-b910-4a9d-9df4-1909d19fd74c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-39f3dcbe-bd62-40d4-99dc-df9741210e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-dba03709-b910-4a9d-9df4-1909d19fd74c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-39f3dcbe-bd62-40d4-99dc-df9741210e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-dba03709-b910-4a9d-9df4-1909d19fd74c,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:37491,DS-39f3dcbe-bd62-40d4-99dc-df9741210e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-dba03709-b910-4a9d-9df4-1909d19fd74c,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37009,DS-731d552c-3ad1-43c9-bd64-7ff3b2eb2222,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-94f15483-18df-439c-94c7-0203e7a35736,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46204,DS-94f15483-18df-439c-94c7-0203e7a35736,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-731d552c-3ad1-43c9-bd64-7ff3b2eb2222,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:37009,DS-731d552c-3ad1-43c9-bd64-7ff3b2eb2222,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-94f15483-18df-439c-94c7-0203e7a35736,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:46204,DS-94f15483-18df-439c-94c7-0203e7a35736,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-731d552c-3ad1-43c9-bd64-7ff3b2eb2222,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket-timeout
component: hbase:HMaster
v1: 600
v2: 60000
testProject: hbase
unitTest: org.apache.hadoop.hbase.regionserver.wal.TestWALReplayBoundedLogWriterCreation#test2727
reconfPoint: 1
result: -1
failureMessage: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-6ca8000f-e8ec-4a4f-9c6c-bd25432b2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-944da7d3-28c7-41b9-8d6e-eaaea2ab9265,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-6ca8000f-e8ec-4a4f-9c6c-bd25432b2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-944da7d3-28c7-41b9-8d6e-eaaea2ab9265,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
stackTrace: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-6ca8000f-e8ec-4a4f-9c6c-bd25432b2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-944da7d3-28c7-41b9-8d6e-eaaea2ab9265,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-6ca8000f-e8ec-4a4f-9c6c-bd25432b2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-944da7d3-28c7-41b9-8d6e-eaaea2ab9265,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.
	at org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1281)
	at org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1353)
	at org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1568)
	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1469)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
early stop after 10 is satisfied
v1v2 failed with probability 10 out of 10
v1v1v2v2 failed with probability 0 out of 10
result: might be true error
Total execution time in seconds : 1902
