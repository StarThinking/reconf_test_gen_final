reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396786553-172.17.0.3-1590299785288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-95ccb23a-8d22-45fc-b120-c5824dc20885,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-75d46c43-04a9-4a21-bac6-e28b57ae6014,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-4d4ae3a3-8e7f-4fdc-9ae0-1b0f2f9ffb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-85b2d1d1-3754-42bd-9a1e-fe9986b3398c,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-d1bf9985-323b-4aae-a8b0-4ba0e6a329d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-b80e9ab4-8253-442b-966b-4ea5ebf59a04,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-0182d91d-c018-4654-9a53-2f601c949b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-8514056b-e82e-4277-92e6-91034ba67b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396786553-172.17.0.3-1590299785288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-95ccb23a-8d22-45fc-b120-c5824dc20885,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-75d46c43-04a9-4a21-bac6-e28b57ae6014,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-4d4ae3a3-8e7f-4fdc-9ae0-1b0f2f9ffb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-85b2d1d1-3754-42bd-9a1e-fe9986b3398c,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-d1bf9985-323b-4aae-a8b0-4ba0e6a329d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-b80e9ab4-8253-442b-966b-4ea5ebf59a04,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-0182d91d-c018-4654-9a53-2f601c949b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-8514056b-e82e-4277-92e6-91034ba67b80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742130084-172.17.0.3-1590300355219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36758,DS-c191061b-88d7-4c7b-bba1-787c04f2c6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-be533ebc-c82b-448f-8265-12968036efaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-b7785d71-2f27-4b21-b141-3f2f39b11e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-48dbded7-b4c3-4ad0-94ce-0498e6038974,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-ed31bf7d-253b-4a9d-b91f-3dbd97239a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-ada88cc9-b18c-4366-885e-e4116be9a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-c1839c11-a3c3-40d8-8973-616954baed09,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-e75fc4ca-b66b-40a2-89d4-b855da431e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742130084-172.17.0.3-1590300355219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36758,DS-c191061b-88d7-4c7b-bba1-787c04f2c6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-be533ebc-c82b-448f-8265-12968036efaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-b7785d71-2f27-4b21-b141-3f2f39b11e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-48dbded7-b4c3-4ad0-94ce-0498e6038974,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-ed31bf7d-253b-4a9d-b91f-3dbd97239a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-ada88cc9-b18c-4366-885e-e4116be9a31d,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-c1839c11-a3c3-40d8-8973-616954baed09,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-e75fc4ca-b66b-40a2-89d4-b855da431e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937444417-172.17.0.3-1590300458026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45607,DS-050e52fd-8287-4246-9647-a9df42fdbd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-604d8bad-0d44-40be-a573-decbbe0f5c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-542bc0dd-b116-4ef0-a83a-02a3b9e79c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-c8bdc04c-2cba-4342-ac52-a1611cebbbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-5efd7b73-a81c-4fff-959d-58200172071e,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-60ef1812-d9d7-40dd-880e-07e540945f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-210410b0-bbaf-4e17-b42f-3c758fb0f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-3e7accc1-1f80-410f-9749-1e7e276ec161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937444417-172.17.0.3-1590300458026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45607,DS-050e52fd-8287-4246-9647-a9df42fdbd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-604d8bad-0d44-40be-a573-decbbe0f5c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-542bc0dd-b116-4ef0-a83a-02a3b9e79c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-c8bdc04c-2cba-4342-ac52-a1611cebbbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-5efd7b73-a81c-4fff-959d-58200172071e,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-60ef1812-d9d7-40dd-880e-07e540945f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-210410b0-bbaf-4e17-b42f-3c758fb0f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-3e7accc1-1f80-410f-9749-1e7e276ec161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629929992-172.17.0.3-1590300960248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33885,DS-604b06d1-4776-4034-9618-e01a8b055bee,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-16d86461-47bc-4779-830f-c4f70a6d9903,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-7630291a-796b-4442-9bf1-df62f62a8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-4adfb290-eb58-48b2-950a-e1db00600328,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-ce104917-2ee5-4723-97c1-726e7529360a,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-b82f8a62-f7a3-4daf-8511-3a61e2e7e87d,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-07411ee7-ac29-47c5-97e6-9dd01383b2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-fd6a68f1-4ac0-4a1a-a875-ad84a4a9fef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629929992-172.17.0.3-1590300960248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33885,DS-604b06d1-4776-4034-9618-e01a8b055bee,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-16d86461-47bc-4779-830f-c4f70a6d9903,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-7630291a-796b-4442-9bf1-df62f62a8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-4adfb290-eb58-48b2-950a-e1db00600328,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-ce104917-2ee5-4723-97c1-726e7529360a,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-b82f8a62-f7a3-4daf-8511-3a61e2e7e87d,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-07411ee7-ac29-47c5-97e6-9dd01383b2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-fd6a68f1-4ac0-4a1a-a875-ad84a4a9fef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28874436-172.17.0.3-1590301145431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-159ebac5-ed06-48a1-85ff-ad558ff132e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-f1fddf1c-cefe-4d8e-8a90-3c5c45900ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-f61461e5-3a7e-437f-8a32-8723caedd2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-fd37650d-61f5-41c4-821e-5ec07eab28e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-b192f137-7c1d-4781-a922-3b096a6b4249,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-32307a97-d5d1-4903-9bf9-5d7cf0fa4486,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-52872faa-f470-4c22-b99e-f380a347a153,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-d8bf99ca-c695-4e8b-8851-d4111c31e2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28874436-172.17.0.3-1590301145431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-159ebac5-ed06-48a1-85ff-ad558ff132e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-f1fddf1c-cefe-4d8e-8a90-3c5c45900ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-f61461e5-3a7e-437f-8a32-8723caedd2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-fd37650d-61f5-41c4-821e-5ec07eab28e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-b192f137-7c1d-4781-a922-3b096a6b4249,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-32307a97-d5d1-4903-9bf9-5d7cf0fa4486,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-52872faa-f470-4c22-b99e-f380a347a153,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-d8bf99ca-c695-4e8b-8851-d4111c31e2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973553034-172.17.0.3-1590301221116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37222,DS-05e6ddf8-bf2f-4076-becb-319599da7d47,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-6592ab4e-65c3-4956-b549-7841cd67f172,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-84e27ecd-88ae-4983-910e-67bcf8a1b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-671695b7-ef10-4ac2-a76d-9a98a6cdc652,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-fd9f12f2-9e37-448e-8c11-4eafae1e40dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-629e51e7-80a2-43c1-ac72-d6210277b8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-664cb048-89df-4f8f-9292-37ac36fd68c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-8cb05a2e-5907-4580-afeb-ae8e8b525141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973553034-172.17.0.3-1590301221116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37222,DS-05e6ddf8-bf2f-4076-becb-319599da7d47,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-6592ab4e-65c3-4956-b549-7841cd67f172,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-84e27ecd-88ae-4983-910e-67bcf8a1b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-671695b7-ef10-4ac2-a76d-9a98a6cdc652,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-fd9f12f2-9e37-448e-8c11-4eafae1e40dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-629e51e7-80a2-43c1-ac72-d6210277b8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-664cb048-89df-4f8f-9292-37ac36fd68c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-8cb05a2e-5907-4580-afeb-ae8e8b525141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209426151-172.17.0.3-1590301373265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-9c72812f-7198-4d18-8ba7-aefbe93303a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-c59004d2-a4d3-4b87-a6a3-ff85667bf599,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-29d67aa4-63e5-41dc-b23f-0bf5c9578b49,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-3760fd81-8bfd-48c2-8b63-c24dd355db06,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-12129200-e4e9-4683-a016-30889b5d1ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-fc58d2a4-0251-4980-80de-c1e28471b7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-04d12336-0f50-43e2-8247-4c79a6bfa79c,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-7570d5b9-19cf-4bac-b1be-86368caa19b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209426151-172.17.0.3-1590301373265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-9c72812f-7198-4d18-8ba7-aefbe93303a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-c59004d2-a4d3-4b87-a6a3-ff85667bf599,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-29d67aa4-63e5-41dc-b23f-0bf5c9578b49,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-3760fd81-8bfd-48c2-8b63-c24dd355db06,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-12129200-e4e9-4683-a016-30889b5d1ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-fc58d2a4-0251-4980-80de-c1e28471b7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-04d12336-0f50-43e2-8247-4c79a6bfa79c,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-7570d5b9-19cf-4bac-b1be-86368caa19b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587807577-172.17.0.3-1590301520658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-c8032d30-43b0-4d20-9f0b-fc6a3c0137b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-537119ea-c75a-451f-840d-52b824dc0773,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-c7ea5a98-7413-4fc1-bfd1-21c2c95a6608,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-0e741dfd-416e-41ff-928a-6a06a883febb,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-c48ad60a-0775-4006-8c0c-735409bb785e,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-e3b1d917-9209-4ad3-933a-903a1d2465c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-59e56cf2-d1d9-4b43-9f31-22005f1e4625,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-9d727066-14e6-4dc3-ab69-d60f9086515d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587807577-172.17.0.3-1590301520658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-c8032d30-43b0-4d20-9f0b-fc6a3c0137b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-537119ea-c75a-451f-840d-52b824dc0773,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-c7ea5a98-7413-4fc1-bfd1-21c2c95a6608,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-0e741dfd-416e-41ff-928a-6a06a883febb,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-c48ad60a-0775-4006-8c0c-735409bb785e,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-e3b1d917-9209-4ad3-933a-903a1d2465c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-59e56cf2-d1d9-4b43-9f31-22005f1e4625,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-9d727066-14e6-4dc3-ab69-d60f9086515d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192817573-172.17.0.3-1590301709729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44711,DS-ec123326-f1c6-47f1-b27b-9784d4a99bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-d0dacbc8-12e2-412b-8a98-391adf48838e,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-37aa1025-4269-475b-8d6a-8910608528c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-cdddb981-4054-44f6-b89a-e20fd5fe1c27,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-39b57da6-4b72-40de-8b43-179878045f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-78dcc04a-7c12-4501-aaa1-d1560749eff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-ff8c7826-a679-4090-afc9-310f52e24908,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-e15e4a11-3bf9-4b3d-9a2f-0322cba8295b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192817573-172.17.0.3-1590301709729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44711,DS-ec123326-f1c6-47f1-b27b-9784d4a99bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-d0dacbc8-12e2-412b-8a98-391adf48838e,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-37aa1025-4269-475b-8d6a-8910608528c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-cdddb981-4054-44f6-b89a-e20fd5fe1c27,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-39b57da6-4b72-40de-8b43-179878045f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-78dcc04a-7c12-4501-aaa1-d1560749eff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-ff8c7826-a679-4090-afc9-310f52e24908,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-e15e4a11-3bf9-4b3d-9a2f-0322cba8295b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114832029-172.17.0.3-1590301747165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-d61beb6e-e383-4f6b-8845-640070103bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-1179a77b-51db-49fb-9568-6520e3f6e2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-ba3a746f-28d3-4b22-9a32-b3b52f78daed,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-4f32f0d6-cc40-4511-9cd3-f64b77d25aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-153532e8-6203-4c4f-9f48-1ae06ab202e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-6e4a56b4-a2b3-43d1-8f09-86554cd2152f,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-9ca64642-6c86-4b0a-bfd9-00a99478146d,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-d59a8d43-414f-465b-b079-d32ea720a463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114832029-172.17.0.3-1590301747165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-d61beb6e-e383-4f6b-8845-640070103bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-1179a77b-51db-49fb-9568-6520e3f6e2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-ba3a746f-28d3-4b22-9a32-b3b52f78daed,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-4f32f0d6-cc40-4511-9cd3-f64b77d25aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-153532e8-6203-4c4f-9f48-1ae06ab202e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-6e4a56b4-a2b3-43d1-8f09-86554cd2152f,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-9ca64642-6c86-4b0a-bfd9-00a99478146d,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-d59a8d43-414f-465b-b079-d32ea720a463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535698251-172.17.0.3-1590301905923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-e03f461d-80dc-41b9-a9b3-6a866178d74c,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-327e2b28-6937-4ef6-bf3d-5f4a0938a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-fb9bc045-75b4-4090-b94a-ab5a23e02523,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-112221f7-41d8-4daa-a534-54435b781a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-b4b4af92-f8f2-4e8f-9ecf-60eb9484081f,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-55b5a995-6b59-433b-825a-b55c7487566b,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-5e34df65-b5b7-4cff-88d8-1a0cde4b7fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-f81fea7d-66ae-4cae-ab6e-26c0eb4dac82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535698251-172.17.0.3-1590301905923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-e03f461d-80dc-41b9-a9b3-6a866178d74c,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-327e2b28-6937-4ef6-bf3d-5f4a0938a7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-fb9bc045-75b4-4090-b94a-ab5a23e02523,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-112221f7-41d8-4daa-a534-54435b781a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-b4b4af92-f8f2-4e8f-9ecf-60eb9484081f,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-55b5a995-6b59-433b-825a-b55c7487566b,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-5e34df65-b5b7-4cff-88d8-1a0cde4b7fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-f81fea7d-66ae-4cae-ab6e-26c0eb4dac82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400453800-172.17.0.3-1590303130746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-6916a2e5-e7a2-41b1-b1e1-d3bc5fcc91a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-b62ecec8-ed23-4925-bb2c-396ef535366e,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-290e25a4-6a98-407c-aff6-154a356cb95b,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-1fa1b78e-0a88-4cd1-9230-d37b7daa37b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-74aa2439-8b5a-4f31-a4ad-8db7c30898e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-57d22eb4-e4b1-4597-8f8d-2d7a9a6103a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-63b09d20-e4a4-4246-b5b9-179d82bfc5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-c10a9f8a-12c7-482b-a800-9935da2f2e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400453800-172.17.0.3-1590303130746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-6916a2e5-e7a2-41b1-b1e1-d3bc5fcc91a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-b62ecec8-ed23-4925-bb2c-396ef535366e,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-290e25a4-6a98-407c-aff6-154a356cb95b,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-1fa1b78e-0a88-4cd1-9230-d37b7daa37b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-74aa2439-8b5a-4f31-a4ad-8db7c30898e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-57d22eb4-e4b1-4597-8f8d-2d7a9a6103a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-63b09d20-e4a4-4246-b5b9-179d82bfc5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-c10a9f8a-12c7-482b-a800-9935da2f2e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073886636-172.17.0.3-1590303207325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-6bdc40d5-6830-4930-8dff-0bbc34583cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-b504a9af-901b-4541-bea2-803d6a9860c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-89ccc83b-3a76-42f9-82ca-3744873ee0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-f292a0a9-1c8d-40e1-8f97-ca7fb3760915,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-8d00a99a-64d0-4764-b150-464de656a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-621a796f-c2d2-4391-a867-968260dad51e,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-9489cdf3-738e-4d47-8017-07795f42506e,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-170e2f6d-d9ec-494d-9c33-76e259d33457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073886636-172.17.0.3-1590303207325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34129,DS-6bdc40d5-6830-4930-8dff-0bbc34583cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-b504a9af-901b-4541-bea2-803d6a9860c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-89ccc83b-3a76-42f9-82ca-3744873ee0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-f292a0a9-1c8d-40e1-8f97-ca7fb3760915,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-8d00a99a-64d0-4764-b150-464de656a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-621a796f-c2d2-4391-a867-968260dad51e,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-9489cdf3-738e-4d47-8017-07795f42506e,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-170e2f6d-d9ec-494d-9c33-76e259d33457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696217974-172.17.0.3-1590303696315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45390,DS-1ff84b25-7e16-41bb-ae5b-e94208bd5d60,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-1ad5bd59-e1ba-4d35-a3c2-678b9a0d8eab,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-b71cd44e-94f3-4d97-b18f-e8cc1563cbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-ce3cd051-bfec-49db-bf9c-829ce970bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-cbf7383f-cfe2-4482-89b2-08c47c4d580b,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-87200425-b184-43f5-9e52-9d8d5e5eeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-fe53ee95-ef17-4bf7-b18b-e29eeab373dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-910ce24f-5f40-4271-9b08-58d51d671a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696217974-172.17.0.3-1590303696315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45390,DS-1ff84b25-7e16-41bb-ae5b-e94208bd5d60,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-1ad5bd59-e1ba-4d35-a3c2-678b9a0d8eab,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-b71cd44e-94f3-4d97-b18f-e8cc1563cbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-ce3cd051-bfec-49db-bf9c-829ce970bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-cbf7383f-cfe2-4482-89b2-08c47c4d580b,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-87200425-b184-43f5-9e52-9d8d5e5eeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-fe53ee95-ef17-4bf7-b18b-e29eeab373dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-910ce24f-5f40-4271-9b08-58d51d671a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: NameNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832013-172.17.0.3-1590304905183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-97ed038a-acc2-4409-8b54-775640afbd94,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-fd51db08-7a98-4205-950d-c34590935d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-65e29364-097f-4fdc-8490-55b86bac6707,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-2c2bb754-5ac7-454e-93f2-7d9bcd56e97c,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-6d65208f-08e4-45b2-a74d-6e4a968de363,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-f18ee260-d8d3-4ba5-a0ee-891a21998797,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-d16e76ed-0114-4e07-82d3-a4d644f96ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-467b3969-42a3-4e1c-8966-ddb268e80d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832013-172.17.0.3-1590304905183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-97ed038a-acc2-4409-8b54-775640afbd94,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-fd51db08-7a98-4205-950d-c34590935d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-65e29364-097f-4fdc-8490-55b86bac6707,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-2c2bb754-5ac7-454e-93f2-7d9bcd56e97c,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-6d65208f-08e4-45b2-a74d-6e4a968de363,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-f18ee260-d8d3-4ba5-a0ee-891a21998797,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-d16e76ed-0114-4e07-82d3-a4d644f96ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-467b3969-42a3-4e1c-8966-ddb268e80d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5761
