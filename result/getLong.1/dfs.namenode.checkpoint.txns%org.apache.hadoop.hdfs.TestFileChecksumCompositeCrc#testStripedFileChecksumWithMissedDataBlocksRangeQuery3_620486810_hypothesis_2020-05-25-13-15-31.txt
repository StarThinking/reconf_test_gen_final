reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946344165-172.17.0.21-1590413198412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46020,DS-becd8495-594f-4d96-8cbd-a533662a8435,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-f9b9eb83-3c18-4931-84a4-c525cb6ba692,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-da3f25f9-2560-4b2a-b5c8-f9ad6daa6833,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-cd26822c-83b3-4519-8060-454af8d175cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-7613d640-ca8c-47ef-97e1-7a836606140a,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-7142b227-2f32-41dc-9e72-4370e7b12985,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-a7862741-2395-461e-8520-14f239d5d442,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-a3bc5683-dae2-46e1-9da5-cc069dade328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946344165-172.17.0.21-1590413198412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46020,DS-becd8495-594f-4d96-8cbd-a533662a8435,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-f9b9eb83-3c18-4931-84a4-c525cb6ba692,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-da3f25f9-2560-4b2a-b5c8-f9ad6daa6833,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-cd26822c-83b3-4519-8060-454af8d175cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-7613d640-ca8c-47ef-97e1-7a836606140a,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-7142b227-2f32-41dc-9e72-4370e7b12985,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-a7862741-2395-461e-8520-14f239d5d442,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-a3bc5683-dae2-46e1-9da5-cc069dade328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176377513-172.17.0.21-1590413351403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-f196dc16-7d09-4a73-9679-72ce64070dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-8084a8a1-0efb-4947-a762-a7e793cd2885,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-2780bc66-4511-48b2-8256-9587ad174642,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-fcf470d9-ae6d-47ac-880d-d1c876cab290,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-00b8b3df-1bee-44bc-833a-05b9c6303032,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-0e8d273b-06e3-43f6-9d42-5e4b26f7bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-e528d130-b3cc-458e-9dd8-4b7eba767d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-2b34ced5-df69-4ca8-9020-2b22182ae7f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176377513-172.17.0.21-1590413351403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-f196dc16-7d09-4a73-9679-72ce64070dff,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-8084a8a1-0efb-4947-a762-a7e793cd2885,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-2780bc66-4511-48b2-8256-9587ad174642,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-fcf470d9-ae6d-47ac-880d-d1c876cab290,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-00b8b3df-1bee-44bc-833a-05b9c6303032,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-0e8d273b-06e3-43f6-9d42-5e4b26f7bfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-e528d130-b3cc-458e-9dd8-4b7eba767d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-2b34ced5-df69-4ca8-9020-2b22182ae7f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79254662-172.17.0.21-1590413386233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-0415d6d8-601f-4706-a30b-a0ab9b411a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-1bb4f4c9-0c88-405b-9080-ef28938609e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-65183429-3b4b-450a-b187-dea5e528f05f,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-4957961b-a5b0-4812-8ce6-22faa2e0756d,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-952a1371-cdf4-4719-bdc3-a7133100618d,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-4a45827f-23dd-4a72-9c7a-92023e4cc33b,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-8a838cec-eac2-4806-b733-afbe58930d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-88bc8674-d8eb-4a26-9a0a-0b59cb9f3d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79254662-172.17.0.21-1590413386233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-0415d6d8-601f-4706-a30b-a0ab9b411a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-1bb4f4c9-0c88-405b-9080-ef28938609e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-65183429-3b4b-450a-b187-dea5e528f05f,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-4957961b-a5b0-4812-8ce6-22faa2e0756d,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-952a1371-cdf4-4719-bdc3-a7133100618d,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-4a45827f-23dd-4a72-9c7a-92023e4cc33b,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-8a838cec-eac2-4806-b733-afbe58930d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-88bc8674-d8eb-4a26-9a0a-0b59cb9f3d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663722770-172.17.0.21-1590413544178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-d835ec87-56b0-49ba-af4e-0e7c39e05f02,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-61072378-2d7c-4da0-a0b6-9e5677079060,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-32d59fc0-6bf1-43e7-a73f-7c6f0a4b8780,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-75c9f0cc-724e-4063-a3c7-71398ea2f613,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-73c3719c-d1d8-43ce-8d89-ce0edfebfce6,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-7c62c6ed-acbd-41c6-9f85-75de2c0b1731,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-1c45e109-1bb7-424c-bc76-eda511660f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-67a26b28-abfd-4d0d-bf83-33f26d9abf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663722770-172.17.0.21-1590413544178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-d835ec87-56b0-49ba-af4e-0e7c39e05f02,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-61072378-2d7c-4da0-a0b6-9e5677079060,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-32d59fc0-6bf1-43e7-a73f-7c6f0a4b8780,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-75c9f0cc-724e-4063-a3c7-71398ea2f613,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-73c3719c-d1d8-43ce-8d89-ce0edfebfce6,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-7c62c6ed-acbd-41c6-9f85-75de2c0b1731,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-1c45e109-1bb7-424c-bc76-eda511660f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-67a26b28-abfd-4d0d-bf83-33f26d9abf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486212141-172.17.0.21-1590413819064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-e95bdf4f-78ba-4994-a3cb-9d02d5b07781,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-d9666fa9-f631-40e6-acb1-81792d0f9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-331daac8-aa9b-45dd-977a-595a9cb112f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-deb3fd4d-9a4f-436b-b841-aab72e57ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-f3ab1043-c26d-45a0-9242-de4b04c34a47,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-d442b107-ecd8-4413-882a-2838d96207eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-84893826-a9ad-4ee2-b49c-87705f9b2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-34b7fcde-1de9-453c-a7b5-dc4904c7cee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486212141-172.17.0.21-1590413819064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-e95bdf4f-78ba-4994-a3cb-9d02d5b07781,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-d9666fa9-f631-40e6-acb1-81792d0f9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-331daac8-aa9b-45dd-977a-595a9cb112f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-deb3fd4d-9a4f-436b-b841-aab72e57ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-f3ab1043-c26d-45a0-9242-de4b04c34a47,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-d442b107-ecd8-4413-882a-2838d96207eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-84893826-a9ad-4ee2-b49c-87705f9b2f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-34b7fcde-1de9-453c-a7b5-dc4904c7cee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416151967-172.17.0.21-1590413861050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40577,DS-7f0183e5-c4a2-40df-b9bd-c43105945686,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-23c8bb31-53ea-4b93-b4fd-6ad274554f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-c0636633-ade6-42e4-adc1-b49dd1905d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-6ca78154-3ac1-4f0b-8fb1-ff7f84ce77ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-e9999eb8-d225-4c6b-8a9c-2a5aa8c99332,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-5771d113-7549-44ff-a39d-60e5607ec18e,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-58bb49b6-81f6-4b57-a5c8-f0a14dfa5888,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-237edaba-ed65-444b-bca3-e3f29cfe1199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416151967-172.17.0.21-1590413861050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40577,DS-7f0183e5-c4a2-40df-b9bd-c43105945686,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-23c8bb31-53ea-4b93-b4fd-6ad274554f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-c0636633-ade6-42e4-adc1-b49dd1905d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-6ca78154-3ac1-4f0b-8fb1-ff7f84ce77ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-e9999eb8-d225-4c6b-8a9c-2a5aa8c99332,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-5771d113-7549-44ff-a39d-60e5607ec18e,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-58bb49b6-81f6-4b57-a5c8-f0a14dfa5888,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-237edaba-ed65-444b-bca3-e3f29cfe1199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75152130-172.17.0.21-1590414121766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-d04f84df-26b2-45aa-8153-baa74b42a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-2a871ac1-19ba-46ed-869b-7040a4136b30,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-0092ddcf-83e2-4336-a737-94a32d242248,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-c4be2052-7e7a-4ead-858e-e26425a45ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-57e0ae74-6faf-434c-8ccd-e32704418c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-15c5887c-b300-4054-9830-9898f21f959f,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-e0c6649c-3697-4d96-8bff-8ac45e8e49f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-a69c0a80-9cab-4a43-9238-1ce75b811bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75152130-172.17.0.21-1590414121766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-d04f84df-26b2-45aa-8153-baa74b42a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-2a871ac1-19ba-46ed-869b-7040a4136b30,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-0092ddcf-83e2-4336-a737-94a32d242248,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-c4be2052-7e7a-4ead-858e-e26425a45ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-57e0ae74-6faf-434c-8ccd-e32704418c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-15c5887c-b300-4054-9830-9898f21f959f,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-e0c6649c-3697-4d96-8bff-8ac45e8e49f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-a69c0a80-9cab-4a43-9238-1ce75b811bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624463633-172.17.0.21-1590414267223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-d2128002-d8bb-4ffd-89f0-61e3573f5124,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-ee409af7-b538-4c1f-9bcf-fbb1afacb9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-cab35a94-5b8f-4647-9af9-dbc712ee7ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-035b10e1-f491-4c72-8fc2-b45f54af23e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-8584a741-6571-488c-b884-8b29501a797f,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-8632e6a4-35a6-4a0c-a4a1-1308167cae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-21a4c2de-c378-4331-9b5d-9838d92ab8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-c3b81665-12e8-4d44-ac0c-760a0ebe1483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624463633-172.17.0.21-1590414267223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-d2128002-d8bb-4ffd-89f0-61e3573f5124,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-ee409af7-b538-4c1f-9bcf-fbb1afacb9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-cab35a94-5b8f-4647-9af9-dbc712ee7ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-035b10e1-f491-4c72-8fc2-b45f54af23e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-8584a741-6571-488c-b884-8b29501a797f,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-8632e6a4-35a6-4a0c-a4a1-1308167cae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-21a4c2de-c378-4331-9b5d-9838d92ab8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-c3b81665-12e8-4d44-ac0c-760a0ebe1483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141189565-172.17.0.21-1590415222408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-a3ddef4f-16e7-456c-8381-696c88102208,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-507faaba-c0e2-4ffd-967b-587a7ec76e08,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a391488a-dc35-4be0-afb3-6c86a24120e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-30ce0e08-6cd1-43cc-850a-a9f8228fb0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-d7ab9ff3-8861-4f3c-a309-f298cf1994d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-4229fb9d-14c5-4577-ab37-5ee3957ed5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-90df1309-2925-46f0-b49a-eff5a0a45293,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-2e6d110d-9926-4535-90fa-3377347e30dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141189565-172.17.0.21-1590415222408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-a3ddef4f-16e7-456c-8381-696c88102208,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-507faaba-c0e2-4ffd-967b-587a7ec76e08,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a391488a-dc35-4be0-afb3-6c86a24120e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-30ce0e08-6cd1-43cc-850a-a9f8228fb0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-d7ab9ff3-8861-4f3c-a309-f298cf1994d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-4229fb9d-14c5-4577-ab37-5ee3957ed5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-90df1309-2925-46f0-b49a-eff5a0a45293,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-2e6d110d-9926-4535-90fa-3377347e30dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076753388-172.17.0.21-1590415364611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41713,DS-25d96817-2589-4db3-9b98-2c031ff67718,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-dce6bcf8-468d-4db0-abe4-0641fc8420ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-7530d78b-c09f-4790-bfd5-ee20d0370a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-7e78f2b7-b6c8-4f75-9857-ca423d1695ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-424f0c5e-7da4-4909-8c62-563b96319785,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-71b99598-47c6-4151-a936-d3974c527eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-c9481949-405a-480a-8328-d8b3b9068b42,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-7bccb892-f71d-4fdb-93c7-41eaf33803c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076753388-172.17.0.21-1590415364611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41713,DS-25d96817-2589-4db3-9b98-2c031ff67718,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-dce6bcf8-468d-4db0-abe4-0641fc8420ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-7530d78b-c09f-4790-bfd5-ee20d0370a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-7e78f2b7-b6c8-4f75-9857-ca423d1695ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-424f0c5e-7da4-4909-8c62-563b96319785,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-71b99598-47c6-4151-a936-d3974c527eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-c9481949-405a-480a-8328-d8b3b9068b42,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-7bccb892-f71d-4fdb-93c7-41eaf33803c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011961121-172.17.0.21-1590415950595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40357,DS-f2e634b4-a373-4a15-849c-149579b4962d,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-89a5c1c0-9b93-4a71-be3b-82b3d90f5b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-081882ab-568b-44ae-8033-967cf98ecdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-e54421d6-f03b-42fe-98c7-0a9d203a6795,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-0c0a858d-6540-435a-a727-2ed4084fd624,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-0bd95c04-8878-4738-8cd7-f2e8b22bf08a,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-2d915459-5ea6-4b71-82c7-7c8426cb3edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-33da1cb6-382f-4ef7-b0ca-80ef1e6e84c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011961121-172.17.0.21-1590415950595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40357,DS-f2e634b4-a373-4a15-849c-149579b4962d,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-89a5c1c0-9b93-4a71-be3b-82b3d90f5b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-081882ab-568b-44ae-8033-967cf98ecdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-e54421d6-f03b-42fe-98c7-0a9d203a6795,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-0c0a858d-6540-435a-a727-2ed4084fd624,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-0bd95c04-8878-4738-8cd7-f2e8b22bf08a,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-2d915459-5ea6-4b71-82c7-7c8426cb3edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-33da1cb6-382f-4ef7-b0ca-80ef1e6e84c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759755890-172.17.0.21-1590415982413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41085,DS-8961a9f1-0b98-42ad-9b28-9d72d0e6a442,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-7f33e5c9-925a-4f21-9f4c-4dd50e509b07,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-ad1526b7-25f0-45bb-a6a0-13b312f1011c,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-450ad930-207e-41ef-8d60-dd1936ce7d17,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-fec2af18-05d8-4702-ace2-5a4e31c55b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-cc47dc6f-45b2-4113-90a1-e4db6ae1e4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-8e06e16f-b986-4339-bb3c-b1c5aadadb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-956e2e8b-c418-4ce5-a4b9-932410537f76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759755890-172.17.0.21-1590415982413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41085,DS-8961a9f1-0b98-42ad-9b28-9d72d0e6a442,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-7f33e5c9-925a-4f21-9f4c-4dd50e509b07,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-ad1526b7-25f0-45bb-a6a0-13b312f1011c,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-450ad930-207e-41ef-8d60-dd1936ce7d17,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-fec2af18-05d8-4702-ace2-5a4e31c55b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-cc47dc6f-45b2-4113-90a1-e4db6ae1e4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-8e06e16f-b986-4339-bb3c-b1c5aadadb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-956e2e8b-c418-4ce5-a4b9-932410537f76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: NameNode
v1: 1000000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995852648-172.17.0.21-1590415998286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38789,DS-50d78342-c3a1-464c-95d6-e9f13c6a377d,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-005a74e3-3b42-4907-af6a-97034c6c705f,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-d8212703-bf7a-47a7-a93d-e8465af50345,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-0222f857-590c-4f8f-9eb8-95f3cff9cc30,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-aff1c49e-92ae-4b12-8abf-49f34121688e,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-25a4fd4b-cfc1-4af4-8fc3-9326a8162a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-4ee0d5ff-a1d3-4bf6-ab34-38b0ccc3b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-bf3106c0-d65f-4fbe-abbb-9a9f0a8e1a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995852648-172.17.0.21-1590415998286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38789,DS-50d78342-c3a1-464c-95d6-e9f13c6a377d,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-005a74e3-3b42-4907-af6a-97034c6c705f,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-d8212703-bf7a-47a7-a93d-e8465af50345,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-0222f857-590c-4f8f-9eb8-95f3cff9cc30,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-aff1c49e-92ae-4b12-8abf-49f34121688e,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-25a4fd4b-cfc1-4af4-8fc3-9326a8162a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-4ee0d5ff-a1d3-4bf6-ab34-38b0ccc3b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-bf3106c0-d65f-4fbe-abbb-9a9f0a8e1a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 3714
