reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112717232-172.17.0.21-1590394175575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-b93404ad-d65c-4339-8d71-2ed60731f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-39e451a6-7bb0-4811-9d25-2a1dc3dae768,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-a9b4c987-0980-4b62-a552-45576b924728,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-71af7eb8-7107-4ad3-8c75-152f3a2177a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-588a7d94-0bd2-4d0c-a730-293682bc4b98,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-7ce299db-253f-4db5-919d-4f814e7f4d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-cb194c28-c630-496c-88d1-e25096e7f666,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-d705bc68-579d-4a07-b494-a8e26aa18fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112717232-172.17.0.21-1590394175575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-b93404ad-d65c-4339-8d71-2ed60731f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-39e451a6-7bb0-4811-9d25-2a1dc3dae768,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-a9b4c987-0980-4b62-a552-45576b924728,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-71af7eb8-7107-4ad3-8c75-152f3a2177a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-588a7d94-0bd2-4d0c-a730-293682bc4b98,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-7ce299db-253f-4db5-919d-4f814e7f4d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-cb194c28-c630-496c-88d1-e25096e7f666,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-d705bc68-579d-4a07-b494-a8e26aa18fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375143156-172.17.0.21-1590394424336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41593,DS-b7546484-f7b8-42aa-bc2d-712eb436e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-adc4ac37-0061-495d-8eec-eb5c46f92da2,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-49b99274-4d3e-413e-b425-2f698ddeaa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-133122e4-e9cb-4843-8881-83b4d231ccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-6cc7f583-e0a5-46e7-ba68-73146aefaf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-6210b9d3-76c0-4c32-b679-a5ae648530f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-e1c2a0c5-7356-4061-842a-d6e212203097,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-2713b3ac-019e-4339-bf17-39338e2641ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375143156-172.17.0.21-1590394424336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41593,DS-b7546484-f7b8-42aa-bc2d-712eb436e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-adc4ac37-0061-495d-8eec-eb5c46f92da2,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-49b99274-4d3e-413e-b425-2f698ddeaa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-133122e4-e9cb-4843-8881-83b4d231ccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-6cc7f583-e0a5-46e7-ba68-73146aefaf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-6210b9d3-76c0-4c32-b679-a5ae648530f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-e1c2a0c5-7356-4061-842a-d6e212203097,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-2713b3ac-019e-4339-bf17-39338e2641ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077575368-172.17.0.21-1590394488238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37817,DS-b38e6c58-6b95-4a14-88aa-07752e12bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-659dcb84-fb6a-4365-96a0-2ba1e8613bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-e1662013-dad3-435c-ace7-41c4d94513c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-94f74f30-e0d0-4ca2-ac92-9a74995341d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-5ec94543-fac8-4f75-bf65-5d70e10dee56,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-b9382624-c60e-4768-a468-48955d0d2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-13bf6b4d-0c24-4043-835f-c54ab6cb3b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-925166e9-a483-43d9-b63e-fdec0f92faf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077575368-172.17.0.21-1590394488238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37817,DS-b38e6c58-6b95-4a14-88aa-07752e12bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-659dcb84-fb6a-4365-96a0-2ba1e8613bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-e1662013-dad3-435c-ace7-41c4d94513c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-94f74f30-e0d0-4ca2-ac92-9a74995341d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-5ec94543-fac8-4f75-bf65-5d70e10dee56,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-b9382624-c60e-4768-a468-48955d0d2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-13bf6b4d-0c24-4043-835f-c54ab6cb3b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-925166e9-a483-43d9-b63e-fdec0f92faf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501089448-172.17.0.21-1590394746230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-0e81236d-fe3e-4fe6-9b18-e43cab9c63e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-4414b474-4124-4211-aa16-6c1d6193ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-11c3dbce-670a-4ac7-830a-2b11c8e7e5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-947967ad-1d8f-4a66-9292-06e4fda044d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-070046b5-5838-43ab-865f-61aa3df1e4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-2a598b04-6f18-47df-a1a0-deab02c0886f,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-0b5c34f7-eceb-4269-a563-aeecbb4674f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-4060ed5a-208a-447a-9be1-8bd16adb5f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501089448-172.17.0.21-1590394746230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-0e81236d-fe3e-4fe6-9b18-e43cab9c63e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-4414b474-4124-4211-aa16-6c1d6193ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-11c3dbce-670a-4ac7-830a-2b11c8e7e5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-947967ad-1d8f-4a66-9292-06e4fda044d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-070046b5-5838-43ab-865f-61aa3df1e4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-2a598b04-6f18-47df-a1a0-deab02c0886f,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-0b5c34f7-eceb-4269-a563-aeecbb4674f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-4060ed5a-208a-447a-9be1-8bd16adb5f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780911229-172.17.0.21-1590394850366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46385,DS-1bb74ee5-5877-4aa1-8ff5-22d724ec12ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-bf8dc68b-c2ba-41c3-9f0c-ef10fe154a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-bcc60fa0-a2bd-4d2a-bd55-417b502f50f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-266cb640-e956-4e19-ac24-1eaeed815c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-33976f81-7985-4bfe-94fe-3449dbac1c23,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-7b54dbe1-cb56-4fc8-b65b-57f630b9bb22,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-15988531-84ac-4488-b41c-ea1baa3d77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-abb0a7bd-09a8-4379-8663-e772802342b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780911229-172.17.0.21-1590394850366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46385,DS-1bb74ee5-5877-4aa1-8ff5-22d724ec12ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-bf8dc68b-c2ba-41c3-9f0c-ef10fe154a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-bcc60fa0-a2bd-4d2a-bd55-417b502f50f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-266cb640-e956-4e19-ac24-1eaeed815c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-33976f81-7985-4bfe-94fe-3449dbac1c23,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-7b54dbe1-cb56-4fc8-b65b-57f630b9bb22,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-15988531-84ac-4488-b41c-ea1baa3d77eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-abb0a7bd-09a8-4379-8663-e772802342b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569096210-172.17.0.21-1590395105330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39787,DS-99f0064d-27cf-41ce-99b4-130dd00d3557,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-16533be2-2a28-4e7f-9370-bb712a480440,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-a617e06a-7279-4ab6-8888-3a5c51c4a369,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-8287d620-2361-4274-a6b0-e9c54b1cc8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-8f3b88ee-5136-4785-ad15-b1d3c54184bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-ec3bd363-d0a6-4e7d-9d1d-6e0d88f20b80,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-e74c369f-c81f-44a4-8216-0587034d3dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-ebe4c5f2-4d62-42d5-ab9e-cbd53fced339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569096210-172.17.0.21-1590395105330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39787,DS-99f0064d-27cf-41ce-99b4-130dd00d3557,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-16533be2-2a28-4e7f-9370-bb712a480440,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-a617e06a-7279-4ab6-8888-3a5c51c4a369,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-8287d620-2361-4274-a6b0-e9c54b1cc8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-8f3b88ee-5136-4785-ad15-b1d3c54184bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-ec3bd363-d0a6-4e7d-9d1d-6e0d88f20b80,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-e74c369f-c81f-44a4-8216-0587034d3dba,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-ebe4c5f2-4d62-42d5-ab9e-cbd53fced339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900284651-172.17.0.21-1590395138185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-2e17f7f3-60db-485a-946d-e32a78bfea37,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-4ab39ea1-e976-46bc-bf7f-0d6e52c4b9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-a033a176-7170-4cb3-b255-6a42c03c29d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-293269db-0798-430c-bd7e-72d7ba4cf424,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-1a0b1ce3-5e6e-45c7-af01-0b7ecc32f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-e4424ca2-5c52-4411-8dc5-f197f036f767,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-de35c0e4-6269-4f8e-aa3e-3378c9ef5ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-96d7f5dc-005b-4d89-a6da-7fb0b1269c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1900284651-172.17.0.21-1590395138185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-2e17f7f3-60db-485a-946d-e32a78bfea37,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-4ab39ea1-e976-46bc-bf7f-0d6e52c4b9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-a033a176-7170-4cb3-b255-6a42c03c29d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-293269db-0798-430c-bd7e-72d7ba4cf424,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-1a0b1ce3-5e6e-45c7-af01-0b7ecc32f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-e4424ca2-5c52-4411-8dc5-f197f036f767,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-de35c0e4-6269-4f8e-aa3e-3378c9ef5ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-96d7f5dc-005b-4d89-a6da-7fb0b1269c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756906034-172.17.0.21-1590395169553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-51e54d68-eac9-4e7e-a3a4-a1ac64769851,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-dfaa5f95-ba63-4e05-9860-c398e2786731,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-6a38c89f-7e0c-4985-8d3b-2380b500d025,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-058cb8ed-2071-4c18-9f3c-743659d01a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-6e67fec3-9fce-4c6d-aae9-1ca9d6aa9b04,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-de430d26-8445-40f6-b826-f5c65f07e5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-6acd01a7-f75e-427b-a977-8c21e0e8cd86,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-d3a33d00-72c8-4a1f-9227-e6a9d3040532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756906034-172.17.0.21-1590395169553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-51e54d68-eac9-4e7e-a3a4-a1ac64769851,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-dfaa5f95-ba63-4e05-9860-c398e2786731,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-6a38c89f-7e0c-4985-8d3b-2380b500d025,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-058cb8ed-2071-4c18-9f3c-743659d01a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-6e67fec3-9fce-4c6d-aae9-1ca9d6aa9b04,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-de430d26-8445-40f6-b826-f5c65f07e5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-6acd01a7-f75e-427b-a977-8c21e0e8cd86,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-d3a33d00-72c8-4a1f-9227-e6a9d3040532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565585254-172.17.0.21-1590395452558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-0da00b98-992f-4e16-b454-0050763923cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-e786c855-a2c1-44d3-bfa0-e955a62d6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-dd87af70-beab-4771-be14-06a8a87229ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-064eef8d-186a-4141-a352-aba7ef9018d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-aca6658a-d44a-4078-a65f-22c9ef11ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-a117d581-64af-4ab7-bcb4-db75e29ce0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-70f827fc-e24c-4a98-8a72-0310adbb1855,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-cff0792d-c057-421a-a68a-f840f94e4b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565585254-172.17.0.21-1590395452558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36468,DS-0da00b98-992f-4e16-b454-0050763923cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-e786c855-a2c1-44d3-bfa0-e955a62d6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-dd87af70-beab-4771-be14-06a8a87229ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-064eef8d-186a-4141-a352-aba7ef9018d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-aca6658a-d44a-4078-a65f-22c9ef11ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-a117d581-64af-4ab7-bcb4-db75e29ce0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-70f827fc-e24c-4a98-8a72-0310adbb1855,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-cff0792d-c057-421a-a68a-f840f94e4b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991451313-172.17.0.21-1590395556486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44137,DS-983e8968-122d-46c5-a200-c1647d08e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-64bdc815-6deb-4439-88b6-398689b58f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-51934e2e-d410-4227-b6a3-36ca87d5a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-9bc96cbc-a206-4530-bd97-3d0be64bfe05,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-02a51f9c-b065-46ba-87d1-9f81411f5d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-58989319-04b8-436a-947f-de17ea0cfc96,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-da86c501-3c26-4231-9656-ebfd6645ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-684b0d61-360d-46c5-ac74-237f9378db35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991451313-172.17.0.21-1590395556486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44137,DS-983e8968-122d-46c5-a200-c1647d08e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-64bdc815-6deb-4439-88b6-398689b58f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-51934e2e-d410-4227-b6a3-36ca87d5a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-9bc96cbc-a206-4530-bd97-3d0be64bfe05,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-02a51f9c-b065-46ba-87d1-9f81411f5d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-58989319-04b8-436a-947f-de17ea0cfc96,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-da86c501-3c26-4231-9656-ebfd6645ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-684b0d61-360d-46c5-ac74-237f9378db35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358324511-172.17.0.21-1590395700583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-8f5fcacb-5be7-4ef1-95d0-6a8c01dab21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-fc3d35fa-85ac-4a18-a0de-e6b777a3cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-d18bcc7d-581d-4c4f-ac26-df256ec59d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-db209e65-54ea-443c-a8d0-6b2e1dd867f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-2cf5a41e-a59a-4739-9d5f-ec97ee44c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-212ce347-4957-4845-872a-cf60fac1c27e,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-6e5ee299-507f-4371-a9c4-4a2883c5272f,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-505879dc-bc5b-4841-be2d-4c8a52270b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358324511-172.17.0.21-1590395700583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-8f5fcacb-5be7-4ef1-95d0-6a8c01dab21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-fc3d35fa-85ac-4a18-a0de-e6b777a3cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-d18bcc7d-581d-4c4f-ac26-df256ec59d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-db209e65-54ea-443c-a8d0-6b2e1dd867f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-2cf5a41e-a59a-4739-9d5f-ec97ee44c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-212ce347-4957-4845-872a-cf60fac1c27e,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-6e5ee299-507f-4371-a9c4-4a2883c5272f,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-505879dc-bc5b-4841-be2d-4c8a52270b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222550670-172.17.0.21-1590395746667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-665ccade-81b0-4218-b3b6-f26071be11de,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-7063eaab-1dc6-4486-8252-62485e56828b,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-11fc4248-6659-4746-9215-6cf0c3df0049,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-bcc4c318-23bd-492a-ba63-196f55a0075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-f7ab7133-8de1-49c3-bb21-966e6ccda9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-3cb5dfc4-134c-40c7-9422-0badcc65b0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-1d4025bd-2c36-43f7-8f16-ea8e99555851,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-1286906a-fd43-44b9-b2a7-7e1ec36c5243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222550670-172.17.0.21-1590395746667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45245,DS-665ccade-81b0-4218-b3b6-f26071be11de,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-7063eaab-1dc6-4486-8252-62485e56828b,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-11fc4248-6659-4746-9215-6cf0c3df0049,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-bcc4c318-23bd-492a-ba63-196f55a0075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-f7ab7133-8de1-49c3-bb21-966e6ccda9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-3cb5dfc4-134c-40c7-9422-0badcc65b0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-1d4025bd-2c36-43f7-8f16-ea8e99555851,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-1286906a-fd43-44b9-b2a7-7e1ec36c5243,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859035448-172.17.0.21-1590395826646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-926d133e-9875-4793-af22-24c881ab8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-9daf20ac-321b-43f6-8f03-a04b6a3e06ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-63ddf1d7-a846-404f-ac0d-9e166ecbbad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-87e67d29-1780-4aa5-8353-731e42a0773e,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-6f867606-601c-43cf-aaf7-d09eb0766bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-fb353b1a-1bd0-4833-9bb4-3b9e4bd31e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-60d92986-b307-402d-a952-633266ccf9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-997fa337-6413-45cc-9e3f-5a9d25ea9a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859035448-172.17.0.21-1590395826646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40032,DS-926d133e-9875-4793-af22-24c881ab8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-9daf20ac-321b-43f6-8f03-a04b6a3e06ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-63ddf1d7-a846-404f-ac0d-9e166ecbbad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-87e67d29-1780-4aa5-8353-731e42a0773e,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-6f867606-601c-43cf-aaf7-d09eb0766bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-fb353b1a-1bd0-4833-9bb4-3b9e4bd31e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-60d92986-b307-402d-a952-633266ccf9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-997fa337-6413-45cc-9e3f-5a9d25ea9a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271532123-172.17.0.21-1590397022060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40715,DS-f61bd4e3-b58c-4e08-a334-8b6969844049,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-c0b5ab43-e48c-4d50-9e5a-f0455e6d2992,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-653e2f10-f6b7-4712-aeff-86d9825c39f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-b7f98e85-a4b1-4315-b6f8-5597f01dde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-f3ac8453-72fd-4849-a025-c15a86ab4620,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-36b5c3b9-7858-4266-9445-39b56c7196d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-10d6d252-a89b-4d88-bdaf-8e59af88b587,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-51153de6-0b8a-4acd-b247-620f8d059652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271532123-172.17.0.21-1590397022060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40715,DS-f61bd4e3-b58c-4e08-a334-8b6969844049,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-c0b5ab43-e48c-4d50-9e5a-f0455e6d2992,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-653e2f10-f6b7-4712-aeff-86d9825c39f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-b7f98e85-a4b1-4315-b6f8-5597f01dde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-f3ac8453-72fd-4849-a025-c15a86ab4620,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-36b5c3b9-7858-4266-9445-39b56c7196d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-10d6d252-a89b-4d88-bdaf-8e59af88b587,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-51153de6-0b8a-4acd-b247-620f8d059652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: NameNode
v1: 864000000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473456872-172.17.0.21-1590398756003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-e791d1c3-df4a-478a-a766-f0a7a8ce5392,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-2d70d02f-93f7-48c3-bd45-dbd0b4e3901a,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-73d491f4-8583-43b1-80f7-fad46684f2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-33e69cd5-70d6-424a-be34-b34bc9c22bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-eb9442ff-72f7-480b-a414-4ba2266a38bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-c1e3a33d-2ee2-434b-87ea-eb891801b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-4dd8a354-d83f-475b-8c79-fa1f6b5e6e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-f9615b50-89c0-4f01-af27-0c2ea17ed402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473456872-172.17.0.21-1590398756003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-e791d1c3-df4a-478a-a766-f0a7a8ce5392,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-2d70d02f-93f7-48c3-bd45-dbd0b4e3901a,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-73d491f4-8583-43b1-80f7-fad46684f2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-33e69cd5-70d6-424a-be34-b34bc9c22bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-eb9442ff-72f7-480b-a414-4ba2266a38bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-c1e3a33d-2ee2-434b-87ea-eb891801b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-4dd8a354-d83f-475b-8c79-fa1f6b5e6e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-f9615b50-89c0-4f01-af27-0c2ea17ed402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5310
