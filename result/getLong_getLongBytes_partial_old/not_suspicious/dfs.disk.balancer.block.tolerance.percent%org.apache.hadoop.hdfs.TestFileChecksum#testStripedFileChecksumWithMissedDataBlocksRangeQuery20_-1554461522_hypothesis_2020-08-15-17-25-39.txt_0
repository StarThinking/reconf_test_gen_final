reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992504280-172.17.0.10-1597512714988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41094,DS-f6b99db6-1922-4071-a449-580db498ae95,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-337d9069-0c9c-4da8-a438-a9eafd4f91c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-9544e943-83f0-412a-ba56-579a595834de,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-5f2c71fa-f6e0-4a8d-8ff0-c1f1d1b88d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-c9b5ffad-45a8-4b44-98aa-4320c50fd521,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-5c739cb5-1b3a-49f7-b41a-1df5ba2dae83,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-29666aaf-e8d6-48b9-937a-a9be64391b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-1a99db89-8b07-47f8-9f9e-444c993c1686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992504280-172.17.0.10-1597512714988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41094,DS-f6b99db6-1922-4071-a449-580db498ae95,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-337d9069-0c9c-4da8-a438-a9eafd4f91c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-9544e943-83f0-412a-ba56-579a595834de,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-5f2c71fa-f6e0-4a8d-8ff0-c1f1d1b88d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-c9b5ffad-45a8-4b44-98aa-4320c50fd521,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-5c739cb5-1b3a-49f7-b41a-1df5ba2dae83,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-29666aaf-e8d6-48b9-937a-a9be64391b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-1a99db89-8b07-47f8-9f9e-444c993c1686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396075988-172.17.0.10-1597513024933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-b0146caa-f376-4e92-8e2f-f782511f4f19,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-837b2746-4bb0-48d3-9df6-db2e520fa484,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-25c54ecd-4ef5-47d3-896a-4f7679b20bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-41211a63-1aa1-4a21-8ea1-debbc79f0455,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-a1805dae-6364-4e20-ae1a-c6ff4c01c057,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-6fc9a9c2-3529-4dee-b396-7d968b8c6dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-38001ad5-1c81-4d86-816b-b361fdbb8fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-ca0582e1-a913-452c-bdcd-034bfd0a7501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396075988-172.17.0.10-1597513024933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46015,DS-b0146caa-f376-4e92-8e2f-f782511f4f19,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-837b2746-4bb0-48d3-9df6-db2e520fa484,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-25c54ecd-4ef5-47d3-896a-4f7679b20bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-41211a63-1aa1-4a21-8ea1-debbc79f0455,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-a1805dae-6364-4e20-ae1a-c6ff4c01c057,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-6fc9a9c2-3529-4dee-b396-7d968b8c6dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-38001ad5-1c81-4d86-816b-b361fdbb8fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-ca0582e1-a913-452c-bdcd-034bfd0a7501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488157513-172.17.0.10-1597513875095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33053,DS-472fc642-b5b7-4d8b-aada-d4604601e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-d712f35a-4d73-478d-b8df-b834eaacf0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-0ad1ad33-8597-4d00-aaf2-551dbff1287d,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-f0ddf1d7-328b-47cf-a61d-6152a0b7d611,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-55161e72-f261-4147-8ebb-09b6556b4153,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-67e78701-d697-44b2-b910-a8946b2de5db,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-2e1e5616-4b22-4771-9d7e-995288b77353,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-792db33c-07cd-4caf-89ad-f4d4177ee3c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488157513-172.17.0.10-1597513875095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33053,DS-472fc642-b5b7-4d8b-aada-d4604601e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-d712f35a-4d73-478d-b8df-b834eaacf0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-0ad1ad33-8597-4d00-aaf2-551dbff1287d,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-f0ddf1d7-328b-47cf-a61d-6152a0b7d611,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-55161e72-f261-4147-8ebb-09b6556b4153,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-67e78701-d697-44b2-b910-a8946b2de5db,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-2e1e5616-4b22-4771-9d7e-995288b77353,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-792db33c-07cd-4caf-89ad-f4d4177ee3c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1605620044-172.17.0.10-1597513995026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-931fe16c-0b45-4d25-b4a0-6bf1d783b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-9c7ffd53-9430-4b77-95ed-b268b82fcb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-a2c52d12-95b0-4c02-8669-dc155cb4545d,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-44b9799a-29e7-4e51-b625-01d961205c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-86ed3505-6e30-4496-b2ca-f374ebb7da69,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-a87d791c-a683-467e-b280-587164c68233,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-a8fd280c-3b04-4594-99be-ffe61201635e,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-e47c2265-cd81-41e2-8ce0-f8c484204aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1605620044-172.17.0.10-1597513995026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-931fe16c-0b45-4d25-b4a0-6bf1d783b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-9c7ffd53-9430-4b77-95ed-b268b82fcb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-a2c52d12-95b0-4c02-8669-dc155cb4545d,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-44b9799a-29e7-4e51-b625-01d961205c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-86ed3505-6e30-4496-b2ca-f374ebb7da69,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-a87d791c-a683-467e-b280-587164c68233,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-a8fd280c-3b04-4594-99be-ffe61201635e,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-e47c2265-cd81-41e2-8ce0-f8c484204aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690747404-172.17.0.10-1597514646896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-efa520df-30fc-4707-8f81-855b26e9070c,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-1ef5133e-f5c6-4a7c-995e-27e934ad6cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-57bb9013-96a0-4404-869b-46f1d75b5147,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-d1f4b50b-a60f-431b-adb4-ae96e4724429,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-0a2228f1-5690-4606-abdf-831f48948356,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-11291b85-9f1f-43fb-a600-e28e1501b7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-6e06c9a9-fe15-4616-a7af-1227b6748cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-cbea40e5-f787-4601-9e17-e103c2e877f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690747404-172.17.0.10-1597514646896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40340,DS-efa520df-30fc-4707-8f81-855b26e9070c,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-1ef5133e-f5c6-4a7c-995e-27e934ad6cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-57bb9013-96a0-4404-869b-46f1d75b5147,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-d1f4b50b-a60f-431b-adb4-ae96e4724429,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-0a2228f1-5690-4606-abdf-831f48948356,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-11291b85-9f1f-43fb-a600-e28e1501b7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-6e06c9a9-fe15-4616-a7af-1227b6748cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-cbea40e5-f787-4601-9e17-e103c2e877f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345542005-172.17.0.10-1597514712687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-781d203c-a57c-457a-82ee-d7b602bd58b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-37857a16-5d19-43c9-8774-992004a94fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-4f0c068e-1421-454d-b9b1-dce1dc0a42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-e2e1055e-fc3c-4524-b6e3-d1e9dd6e937f,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-c02a1a0b-2254-46ff-a963-739e5642662e,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-49b1bb8c-7096-46c0-841c-415b830ceddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-f12e57f4-f94e-443c-9594-39bd73fe30c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-f1f553a6-a8e0-4ec5-9bcb-dc023a257972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345542005-172.17.0.10-1597514712687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40107,DS-781d203c-a57c-457a-82ee-d7b602bd58b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-37857a16-5d19-43c9-8774-992004a94fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-4f0c068e-1421-454d-b9b1-dce1dc0a42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-e2e1055e-fc3c-4524-b6e3-d1e9dd6e937f,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-c02a1a0b-2254-46ff-a963-739e5642662e,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-49b1bb8c-7096-46c0-841c-415b830ceddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-f12e57f4-f94e-443c-9594-39bd73fe30c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-f1f553a6-a8e0-4ec5-9bcb-dc023a257972,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689334260-172.17.0.10-1597514970259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-47f053ee-a340-43d0-a33b-43bb22bfdda7,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-6499fa46-386a-4b55-850d-54d55096ef38,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-dbf3c16d-c78b-42e9-beaf-3c372dc93a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-ee82709a-ec23-4348-a878-b4b0cdc6872e,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-a0a4eafd-9473-44e7-bbd2-2823492b97a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-340504cd-f812-4af2-a47f-82f08ec2977c,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-05cc378c-325d-4adc-b9f9-e646e13ef606,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-46c54360-c660-42ce-9540-07dcb846268d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689334260-172.17.0.10-1597514970259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-47f053ee-a340-43d0-a33b-43bb22bfdda7,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-6499fa46-386a-4b55-850d-54d55096ef38,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-dbf3c16d-c78b-42e9-beaf-3c372dc93a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-ee82709a-ec23-4348-a878-b4b0cdc6872e,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-a0a4eafd-9473-44e7-bbd2-2823492b97a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-340504cd-f812-4af2-a47f-82f08ec2977c,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-05cc378c-325d-4adc-b9f9-e646e13ef606,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-46c54360-c660-42ce-9540-07dcb846268d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405584381-172.17.0.10-1597515006303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32982,DS-67843657-c3d2-433b-8d6c-987845edb61a,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-50e91848-4a2a-434f-a495-2fc5f003cb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-45c7ede0-0b9b-44e9-88e5-1f1f59558272,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-e862b115-528c-44dd-bab1-576b06c58d76,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-9f18b8e8-40ac-4573-8287-16e28dee30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-09aa59de-bd00-448b-a596-27d01565b121,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-68910c53-642b-4a51-80bb-bdea01667a89,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-dc7fa889-3f0d-4bf4-abc4-c8214081e702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405584381-172.17.0.10-1597515006303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32982,DS-67843657-c3d2-433b-8d6c-987845edb61a,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-50e91848-4a2a-434f-a495-2fc5f003cb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-45c7ede0-0b9b-44e9-88e5-1f1f59558272,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-e862b115-528c-44dd-bab1-576b06c58d76,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-9f18b8e8-40ac-4573-8287-16e28dee30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-09aa59de-bd00-448b-a596-27d01565b121,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-68910c53-642b-4a51-80bb-bdea01667a89,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-dc7fa889-3f0d-4bf4-abc4-c8214081e702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272770156-172.17.0.10-1597515071444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-822e9216-4c4d-43e3-958d-28f71d35f626,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-fbcd4783-1aed-4d77-8b41-03ef60893920,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-6af4ff94-a525-4761-a2bf-56119add3c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-6a6e220c-0ea5-4a34-9270-fa599f4e499f,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-f2e58af8-4105-4db4-930e-7ce991078c90,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-0947e095-e686-4016-a431-9fe8008c354a,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-ee2dd36c-c027-4602-a4a5-f6546e415ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-b5ed5ade-6376-4133-b620-cb0398c7efd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272770156-172.17.0.10-1597515071444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-822e9216-4c4d-43e3-958d-28f71d35f626,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-fbcd4783-1aed-4d77-8b41-03ef60893920,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-6af4ff94-a525-4761-a2bf-56119add3c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-6a6e220c-0ea5-4a34-9270-fa599f4e499f,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-f2e58af8-4105-4db4-930e-7ce991078c90,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-0947e095-e686-4016-a431-9fe8008c354a,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-ee2dd36c-c027-4602-a4a5-f6546e415ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-b5ed5ade-6376-4133-b620-cb0398c7efd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127668945-172.17.0.10-1597515232312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45426,DS-2925acdf-bcb4-4251-a264-e8b311263515,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-8bb1e1d6-d4f3-4efa-9bed-7118e1a6e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-d4f18d09-6b17-4cb1-a766-65769b3afb98,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-aeda14e9-2934-4a5f-b05b-c5fe765efb56,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-7987943d-46f7-4d22-a971-b0c91ce42eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-27830844-7320-4d8d-b6d1-5daab3d78e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-6063ee0c-1523-4886-a101-4071b03d3c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-2860fb2d-4a5f-465b-af59-32154ef580a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127668945-172.17.0.10-1597515232312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45426,DS-2925acdf-bcb4-4251-a264-e8b311263515,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-8bb1e1d6-d4f3-4efa-9bed-7118e1a6e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-d4f18d09-6b17-4cb1-a766-65769b3afb98,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-aeda14e9-2934-4a5f-b05b-c5fe765efb56,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-7987943d-46f7-4d22-a971-b0c91ce42eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-27830844-7320-4d8d-b6d1-5daab3d78e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-6063ee0c-1523-4886-a101-4071b03d3c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-2860fb2d-4a5f-465b-af59-32154ef580a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700832114-172.17.0.10-1597515471238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38171,DS-e429ca7c-3834-47b9-b501-8af4754e0c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-98fb1a26-555b-4038-9902-25f24633980e,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-09fa0d54-c3af-4e7c-99fc-81f2cfb3b818,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-30baaff1-aab5-4544-9cb5-e7278fd38157,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-b7768df6-53fe-452d-9a46-d5cb3fb41756,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-cf3e317d-f757-4fdd-9282-8c6f02621a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-a6ef943b-d42e-4759-a331-b0803d9db21c,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-4035d307-18da-4541-8a77-986e25d5991b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700832114-172.17.0.10-1597515471238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38171,DS-e429ca7c-3834-47b9-b501-8af4754e0c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-98fb1a26-555b-4038-9902-25f24633980e,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-09fa0d54-c3af-4e7c-99fc-81f2cfb3b818,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-30baaff1-aab5-4544-9cb5-e7278fd38157,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-b7768df6-53fe-452d-9a46-d5cb3fb41756,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-cf3e317d-f757-4fdd-9282-8c6f02621a33,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-a6ef943b-d42e-4759-a331-b0803d9db21c,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-4035d307-18da-4541-8a77-986e25d5991b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896607390-172.17.0.10-1597516106725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44860,DS-db6c6d09-ccce-4ebd-83cf-e007b4d9d44b,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-06a5d477-370e-41ee-acd0-d466eba8082e,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0f96ece9-b63d-4592-9b4d-5b687f0f6e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-e0c1f833-fcfd-432f-ba0d-fdcd4b59e218,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-267df7ee-e12b-4123-a7b6-099f858fbd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-c151ac9a-75a1-4d36-8665-d7698b06b36f,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-9fa3a044-dfa4-4d87-a36c-92318559cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-09371723-36b3-4a34-bf42-0dbfa375373d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896607390-172.17.0.10-1597516106725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44860,DS-db6c6d09-ccce-4ebd-83cf-e007b4d9d44b,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-06a5d477-370e-41ee-acd0-d466eba8082e,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0f96ece9-b63d-4592-9b4d-5b687f0f6e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-e0c1f833-fcfd-432f-ba0d-fdcd4b59e218,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-267df7ee-e12b-4123-a7b6-099f858fbd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-c151ac9a-75a1-4d36-8665-d7698b06b36f,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-9fa3a044-dfa4-4d87-a36c-92318559cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-09371723-36b3-4a34-bf42-0dbfa375373d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274316024-172.17.0.10-1597516423274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-0b71cffb-4930-4879-9988-453d179edc55,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-6f7c5980-5699-4e6d-b907-5b0fb068ffcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-551fad06-2d2b-4f99-b005-1d972da4063e,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-8fa707dc-9012-44ae-b935-e72a2d6fe9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-48ea2f93-2e25-4e77-8eda-b963b9611d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-4ab1d9f1-8efd-4271-945b-0c5d08e9923c,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-1444b34a-6cb7-4191-8f3b-7173319e7c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-c1029678-f2f5-4be9-9285-82cc73ad78bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274316024-172.17.0.10-1597516423274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40676,DS-0b71cffb-4930-4879-9988-453d179edc55,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-6f7c5980-5699-4e6d-b907-5b0fb068ffcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-551fad06-2d2b-4f99-b005-1d972da4063e,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-8fa707dc-9012-44ae-b935-e72a2d6fe9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-48ea2f93-2e25-4e77-8eda-b963b9611d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-4ab1d9f1-8efd-4271-945b-0c5d08e9923c,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-1444b34a-6cb7-4191-8f3b-7173319e7c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-c1029678-f2f5-4be9-9285-82cc73ad78bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662278194-172.17.0.10-1597516606431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-a93965c9-da21-4fe3-ae22-7d8572c7c641,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-e7e9309c-2aab-4a70-b1fa-be2fd188e1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-116645d6-9a00-4350-979b-cf31d7f8ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-acc1891b-4f46-473f-a9c1-aa2fde204b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-471e125c-02b6-42bb-80c1-edd7697daab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-4ae26474-ac3f-45a5-b49f-e9a7fc8992d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-b5bfff51-c1fb-426f-8022-d93022f5dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-0c5d0cc3-48b8-4761-abb2-7bf8dbadee92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662278194-172.17.0.10-1597516606431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-a93965c9-da21-4fe3-ae22-7d8572c7c641,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-e7e9309c-2aab-4a70-b1fa-be2fd188e1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-116645d6-9a00-4350-979b-cf31d7f8ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-acc1891b-4f46-473f-a9c1-aa2fde204b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-471e125c-02b6-42bb-80c1-edd7697daab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-4ae26474-ac3f-45a5-b49f-e9a7fc8992d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-b5bfff51-c1fb-426f-8022-d93022f5dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-0c5d0cc3-48b8-4761-abb2-7bf8dbadee92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389481142-172.17.0.10-1597516644876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-3d124e34-039d-4036-9545-32813da15379,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-2abcadfe-5463-4002-90b5-198e44e4f30d,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-f56a21c0-f352-4902-bf34-4ea1546ef56d,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-318d38e1-9469-4fa6-83c2-93fda3be0018,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-51af4b0c-1977-4cb7-955b-5780de47a74f,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-94a97cd6-91a7-42b4-bd11-1966405b7cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-0b43426a-b862-4088-8e9c-b7cec7feaafc,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-59dcf528-00d1-4147-9b2c-4de1980c104d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389481142-172.17.0.10-1597516644876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-3d124e34-039d-4036-9545-32813da15379,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-2abcadfe-5463-4002-90b5-198e44e4f30d,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-f56a21c0-f352-4902-bf34-4ea1546ef56d,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-318d38e1-9469-4fa6-83c2-93fda3be0018,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-51af4b0c-1977-4cb7-955b-5780de47a74f,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-94a97cd6-91a7-42b4-bd11-1966405b7cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-0b43426a-b862-4088-8e9c-b7cec7feaafc,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-59dcf528-00d1-4147-9b2c-4de1980c104d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256109864-172.17.0.10-1597517685809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-c5929953-7945-44cf-96d7-a3e94977c43f,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-0e4f2917-d5c3-492a-973f-720342e30d60,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-4325a99e-66fb-47b8-9735-21a80d21e824,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-be8adc17-75ea-4fd0-a548-9bfac8de9fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-7f5a2368-9bfb-4158-8499-953d3d80dcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-8de8eea4-e33b-41c7-91b6-b0ea42b027fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-86682a79-a504-4445-96cf-3b5e7f890069,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-0423abfe-077c-48d3-b063-fe023c06a2ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256109864-172.17.0.10-1597517685809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-c5929953-7945-44cf-96d7-a3e94977c43f,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-0e4f2917-d5c3-492a-973f-720342e30d60,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-4325a99e-66fb-47b8-9735-21a80d21e824,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-be8adc17-75ea-4fd0-a548-9bfac8de9fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-7f5a2368-9bfb-4158-8499-953d3d80dcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-8de8eea4-e33b-41c7-91b6-b0ea42b027fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-86682a79-a504-4445-96cf-3b5e7f890069,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-0423abfe-077c-48d3-b063-fe023c06a2ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328266781-172.17.0.10-1597517792736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32852,DS-5da6e9db-f200-4c18-84b6-251d9bdfcadf,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-0dbc3380-7ad7-4ba0-ae4d-bf97873842ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-f204dbbe-65d9-4544-b581-c8e1f8ca81e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-76133941-31c0-4f5d-a151-a986e03ad5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-ed797f23-f09f-4b59-848d-ff4e77fa6a59,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-7de8875a-cb94-42ff-b4a8-9e69908c243c,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-c8e7cca7-1d03-46df-9737-eaf8090b0484,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-37527937-b5dc-41c0-bd43-9eb5ef896e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328266781-172.17.0.10-1597517792736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32852,DS-5da6e9db-f200-4c18-84b6-251d9bdfcadf,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-0dbc3380-7ad7-4ba0-ae4d-bf97873842ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-f204dbbe-65d9-4544-b581-c8e1f8ca81e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-76133941-31c0-4f5d-a151-a986e03ad5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-ed797f23-f09f-4b59-848d-ff4e77fa6a59,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-7de8875a-cb94-42ff-b4a8-9e69908c243c,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-c8e7cca7-1d03-46df-9737-eaf8090b0484,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-37527937-b5dc-41c0-bd43-9eb5ef896e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5686
