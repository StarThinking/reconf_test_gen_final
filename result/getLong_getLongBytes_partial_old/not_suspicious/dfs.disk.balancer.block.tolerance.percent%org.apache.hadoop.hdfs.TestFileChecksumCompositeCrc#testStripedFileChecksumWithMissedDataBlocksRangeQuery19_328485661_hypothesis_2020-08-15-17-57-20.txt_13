reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680249850-172.17.0.19-1597514553377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37629,DS-6d9b6aea-0732-4249-b806-e9895c6ce9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-5996492e-d8db-4eb5-a863-723682be5a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-2c46df38-c1a5-40e5-9af4-277460bb6faf,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-103e7395-22f9-40a6-b7bd-9abeb99edf05,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-b4663937-8253-437f-9593-9e13b5ee4c20,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-459a10f4-a6a9-46e4-bf96-17ccc441bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-5a8fa495-e7f8-4242-9c37-291c9e5289bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-dd4d50d0-432f-40df-9b04-a0f3ff0d48ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680249850-172.17.0.19-1597514553377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37629,DS-6d9b6aea-0732-4249-b806-e9895c6ce9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-5996492e-d8db-4eb5-a863-723682be5a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-2c46df38-c1a5-40e5-9af4-277460bb6faf,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-103e7395-22f9-40a6-b7bd-9abeb99edf05,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-b4663937-8253-437f-9593-9e13b5ee4c20,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-459a10f4-a6a9-46e4-bf96-17ccc441bf89,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-5a8fa495-e7f8-4242-9c37-291c9e5289bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-dd4d50d0-432f-40df-9b04-a0f3ff0d48ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898411234-172.17.0.19-1597514589591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38888,DS-4a6ff887-be29-4400-a9b0-c2cb2b55c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-14dd93bf-8c66-44f2-8d27-af038364363b,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-af678f1b-b5af-410c-b505-2b5fd6bd5673,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-bb2e6305-f9e5-4451-b307-c41e4ce006c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-19e70bad-d0ad-4cdf-968c-5c994031bb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-3c8db762-0d59-4018-913f-553444caf856,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-c7fc5062-a312-4cda-97e8-03dc552b8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-ef533b09-fcf9-4c6f-95cd-29ebe5aef690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898411234-172.17.0.19-1597514589591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38888,DS-4a6ff887-be29-4400-a9b0-c2cb2b55c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-14dd93bf-8c66-44f2-8d27-af038364363b,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-af678f1b-b5af-410c-b505-2b5fd6bd5673,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-bb2e6305-f9e5-4451-b307-c41e4ce006c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-19e70bad-d0ad-4cdf-968c-5c994031bb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-3c8db762-0d59-4018-913f-553444caf856,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-c7fc5062-a312-4cda-97e8-03dc552b8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-ef533b09-fcf9-4c6f-95cd-29ebe5aef690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124442217-172.17.0.19-1597515044081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43216,DS-83b9ff58-4dc3-47dc-be6e-9b848c393049,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-f698d2b6-f4ca-48fc-8397-4a2f8d6e3c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-71f945a5-fcf7-4be8-92f9-a9150e3a9ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-5d8988a8-4a41-47c1-9cb2-1a01b23dac21,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-317d5c93-a034-4358-af12-1889caccdf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-83ddd561-50e5-4e88-b735-e37adbf84478,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-e448ceb7-f0e2-475c-8f93-c5c8fa57efaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-3132f9c5-aeeb-4ed7-aabd-adc921ac2714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124442217-172.17.0.19-1597515044081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43216,DS-83b9ff58-4dc3-47dc-be6e-9b848c393049,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-f698d2b6-f4ca-48fc-8397-4a2f8d6e3c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-71f945a5-fcf7-4be8-92f9-a9150e3a9ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-5d8988a8-4a41-47c1-9cb2-1a01b23dac21,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-317d5c93-a034-4358-af12-1889caccdf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-83ddd561-50e5-4e88-b735-e37adbf84478,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-e448ceb7-f0e2-475c-8f93-c5c8fa57efaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-3132f9c5-aeeb-4ed7-aabd-adc921ac2714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070974864-172.17.0.19-1597516163331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39927,DS-1643c9c5-9311-4321-9b48-b28a3bd417e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-ea9ee4ac-5000-4b75-95ac-bcab12c51504,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-9352a386-cc49-4254-89c5-309ee98d243e,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-78da606c-e556-456e-a81d-68372fc77cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-b58cae08-f6a5-4df2-aca8-aa9e9347c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-2c096076-62f9-4ec4-a125-16924f854525,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-96294517-8326-4a3a-8bb2-895394d39adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-3b8874a5-bf77-4ed9-818c-cde5f76222d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070974864-172.17.0.19-1597516163331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39927,DS-1643c9c5-9311-4321-9b48-b28a3bd417e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-ea9ee4ac-5000-4b75-95ac-bcab12c51504,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-9352a386-cc49-4254-89c5-309ee98d243e,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-78da606c-e556-456e-a81d-68372fc77cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-b58cae08-f6a5-4df2-aca8-aa9e9347c1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-2c096076-62f9-4ec4-a125-16924f854525,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-96294517-8326-4a3a-8bb2-895394d39adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-3b8874a5-bf77-4ed9-818c-cde5f76222d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394865923-172.17.0.19-1597516197893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44915,DS-1d30c126-a920-4a41-8cf8-0303c11f8bff,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-a50d8db9-b01e-445a-87f0-8633900573aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-299ee178-cc15-42c7-8144-e04fa8b26674,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-cca094b9-7df2-4263-9677-7214d01c8fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-84b115f7-e530-41a9-823f-881cf8a73c23,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-332b27bf-01c7-467d-98ae-25c13b1fe106,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-af114c50-53c3-460d-b2f9-0c996297154c,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-91bb4c10-c484-43cc-b8a5-9e603d14c1f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394865923-172.17.0.19-1597516197893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44915,DS-1d30c126-a920-4a41-8cf8-0303c11f8bff,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-a50d8db9-b01e-445a-87f0-8633900573aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-299ee178-cc15-42c7-8144-e04fa8b26674,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-cca094b9-7df2-4263-9677-7214d01c8fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-84b115f7-e530-41a9-823f-881cf8a73c23,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-332b27bf-01c7-467d-98ae-25c13b1fe106,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-af114c50-53c3-460d-b2f9-0c996297154c,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-91bb4c10-c484-43cc-b8a5-9e603d14c1f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669946686-172.17.0.19-1597516373514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-964f1810-37da-491e-9155-49ae443a8ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-4eb2646f-a2b9-4137-9cd1-f59f892842c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-07915f57-c11f-433f-b3c8-40749dd79aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-bdb6aef1-7e8f-4364-910f-8b4fc510d243,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-21b9aec7-bcd9-409c-942c-2fe4465744d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-a5280ff1-05f3-44d1-9ed7-72f023137685,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-fa08ca9b-fb89-4ce8-8d11-2ee6d57e28a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-d4cbe217-c36f-4ef5-beb3-0753bfb08e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669946686-172.17.0.19-1597516373514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-964f1810-37da-491e-9155-49ae443a8ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-4eb2646f-a2b9-4137-9cd1-f59f892842c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-07915f57-c11f-433f-b3c8-40749dd79aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-bdb6aef1-7e8f-4364-910f-8b4fc510d243,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-21b9aec7-bcd9-409c-942c-2fe4465744d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-a5280ff1-05f3-44d1-9ed7-72f023137685,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-fa08ca9b-fb89-4ce8-8d11-2ee6d57e28a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-d4cbe217-c36f-4ef5-beb3-0753bfb08e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294837285-172.17.0.19-1597516410207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-5a93eaa7-c4d3-48d0-91b6-e66c02010c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-6e509309-e712-4688-a5f5-6a6a6a09c494,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-9cebd242-2553-4a8b-ba40-a9b6876ad91d,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-9ac7b46b-bb47-4ecf-b09f-2a201a8380df,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-0d309ba1-dd8a-4501-b013-53380af24130,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-43bbb7ad-dd17-4f4c-b545-f9d918d6fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-2a02f0dd-de05-4fcb-934f-44412789cf52,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-517bb1b0-b8a4-467d-a7fa-26058bffeaa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294837285-172.17.0.19-1597516410207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-5a93eaa7-c4d3-48d0-91b6-e66c02010c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-6e509309-e712-4688-a5f5-6a6a6a09c494,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-9cebd242-2553-4a8b-ba40-a9b6876ad91d,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-9ac7b46b-bb47-4ecf-b09f-2a201a8380df,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-0d309ba1-dd8a-4501-b013-53380af24130,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-43bbb7ad-dd17-4f4c-b545-f9d918d6fec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-2a02f0dd-de05-4fcb-934f-44412789cf52,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-517bb1b0-b8a4-467d-a7fa-26058bffeaa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294281872-172.17.0.19-1597516774334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-2c7b7968-d6bc-49cc-9727-68b4724198e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-56fdb2d8-77dd-4143-b95e-2879d63b72cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-7e05fdff-f28c-4a8f-b51a-a69117fc4b69,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-c3fe15b5-31da-4d68-bff5-3146c032ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-f4eeb9c0-b354-44bd-b8ed-57f28516ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-4fb33f6c-45ef-4b78-91bd-c3295cd0afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-d2a2bd86-e1ea-4ab7-a771-6ace9f04d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-81e7c255-14d1-4b77-bc22-37e5978dca69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294281872-172.17.0.19-1597516774334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-2c7b7968-d6bc-49cc-9727-68b4724198e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-56fdb2d8-77dd-4143-b95e-2879d63b72cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-7e05fdff-f28c-4a8f-b51a-a69117fc4b69,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-c3fe15b5-31da-4d68-bff5-3146c032ecb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-f4eeb9c0-b354-44bd-b8ed-57f28516ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-4fb33f6c-45ef-4b78-91bd-c3295cd0afb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-d2a2bd86-e1ea-4ab7-a771-6ace9f04d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-81e7c255-14d1-4b77-bc22-37e5978dca69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763710512-172.17.0.19-1597517019348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35354,DS-57360c97-9233-4a8d-bb52-dce41556914a,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-01aef4fa-dcb3-4928-ba90-c4857e6bd05f,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-d4f164cc-4367-48fe-a007-ec9ba6be0d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-79c4135b-02b7-40f2-8828-af3527aeb263,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-fe570950-d9c1-4fd9-91ac-f2fced429de7,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-00dadf83-7976-4486-ba16-d55cfb6d1214,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-5b72eb1b-561c-497a-8e07-516a7d3b5c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-4b6a3907-2cc6-4d7a-bc0a-08c8dc0e75a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763710512-172.17.0.19-1597517019348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35354,DS-57360c97-9233-4a8d-bb52-dce41556914a,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-01aef4fa-dcb3-4928-ba90-c4857e6bd05f,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-d4f164cc-4367-48fe-a007-ec9ba6be0d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-79c4135b-02b7-40f2-8828-af3527aeb263,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-fe570950-d9c1-4fd9-91ac-f2fced429de7,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-00dadf83-7976-4486-ba16-d55cfb6d1214,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-5b72eb1b-561c-497a-8e07-516a7d3b5c10,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-4b6a3907-2cc6-4d7a-bc0a-08c8dc0e75a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355794945-172.17.0.19-1597517251388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-7d174b03-84e5-4eae-aa2b-c8513d3ad94e,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-5d9d8db5-e3c5-4683-8e1c-a51c5986c113,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-e4d9cc97-1883-47e2-a03d-ceb94b6883f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-9fa369bf-d88c-4dbb-a88b-a99838a9ddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-190eefdc-4131-4342-b1db-1781a5592db0,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-77b974fb-f200-4151-8553-d4585c698a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-189da74f-2f2a-4aab-9a8d-2fe0f5470bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-c7896b78-1a62-4e69-bdc4-20d0abb7e892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355794945-172.17.0.19-1597517251388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-7d174b03-84e5-4eae-aa2b-c8513d3ad94e,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-5d9d8db5-e3c5-4683-8e1c-a51c5986c113,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-e4d9cc97-1883-47e2-a03d-ceb94b6883f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-9fa369bf-d88c-4dbb-a88b-a99838a9ddf7,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-190eefdc-4131-4342-b1db-1781a5592db0,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-77b974fb-f200-4151-8553-d4585c698a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-189da74f-2f2a-4aab-9a8d-2fe0f5470bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-c7896b78-1a62-4e69-bdc4-20d0abb7e892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566604728-172.17.0.19-1597517465285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38138,DS-60533ef6-83fc-47be-b695-42a5b2ce6ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-643d5dde-c5ec-4592-bc2b-2e4b78900197,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-db743a4e-fe22-4e84-a3ad-f8f809a53dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-7919f3a5-3d7b-4b84-bb83-7bbbffb1b5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-e7d1b5d4-1d12-43b5-a44f-28a8b690fdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-c1e97b38-f50a-4ea3-a9b9-f73382a3e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-f436fcae-acb2-4767-aad7-11b9f573181b,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-d47f384e-915e-4687-801e-e743959c59b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566604728-172.17.0.19-1597517465285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38138,DS-60533ef6-83fc-47be-b695-42a5b2ce6ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-643d5dde-c5ec-4592-bc2b-2e4b78900197,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-db743a4e-fe22-4e84-a3ad-f8f809a53dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-7919f3a5-3d7b-4b84-bb83-7bbbffb1b5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-e7d1b5d4-1d12-43b5-a44f-28a8b690fdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-c1e97b38-f50a-4ea3-a9b9-f73382a3e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-f436fcae-acb2-4767-aad7-11b9f573181b,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-d47f384e-915e-4687-801e-e743959c59b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452687518-172.17.0.19-1597518849141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-eaee3ca4-1546-4a30-9cda-e2719f6cc026,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-946fc6dc-f766-4c50-a078-544647d2b02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-a4cba773-4ac5-449d-8f60-2ed5ec87c8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-d3c504e3-b8bd-41ad-832a-ede3a4802c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-2f6eecdc-e3c6-4fc2-8775-1623f8b89124,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-3e6f348c-52ee-4f1b-b8df-c4a3a2c67d80,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-110152f5-3ae5-447c-b43b-2d2bc3f19629,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-b26ad76b-a165-4a83-91c2-0aa6354df176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452687518-172.17.0.19-1597518849141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-eaee3ca4-1546-4a30-9cda-e2719f6cc026,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-946fc6dc-f766-4c50-a078-544647d2b02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-a4cba773-4ac5-449d-8f60-2ed5ec87c8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-d3c504e3-b8bd-41ad-832a-ede3a4802c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-2f6eecdc-e3c6-4fc2-8775-1623f8b89124,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-3e6f348c-52ee-4f1b-b8df-c4a3a2c67d80,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-110152f5-3ae5-447c-b43b-2d2bc3f19629,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-b26ad76b-a165-4a83-91c2-0aa6354df176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213765661-172.17.0.19-1597519327636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38431,DS-7391e7c7-572f-4811-90c5-8a118878cb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-e56a9fd3-c5db-4d03-927e-ecfe284c8163,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-b1fd3508-be92-4750-9dc4-87e5274756b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-513a7d07-256d-4ca7-a720-d31bbd25f054,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-4aa8b48a-3888-4c16-b9e7-94f4036cbcae,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-6f9ba78d-2c54-40a2-8139-5510415b932b,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-a68d3ec9-b1e9-4f67-9f3a-3643f64a7002,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-d2faf8f1-a1d0-4b79-9218-71635dfd9f58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213765661-172.17.0.19-1597519327636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38431,DS-7391e7c7-572f-4811-90c5-8a118878cb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-e56a9fd3-c5db-4d03-927e-ecfe284c8163,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-b1fd3508-be92-4750-9dc4-87e5274756b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-513a7d07-256d-4ca7-a720-d31bbd25f054,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-4aa8b48a-3888-4c16-b9e7-94f4036cbcae,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-6f9ba78d-2c54-40a2-8139-5510415b932b,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-a68d3ec9-b1e9-4f67-9f3a-3643f64a7002,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-d2faf8f1-a1d0-4b79-9218-71635dfd9f58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086331607-172.17.0.19-1597519489537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45277,DS-eb3730eb-9276-4c3b-bbcd-82b9c6a064c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-872ecc79-5791-4f29-b714-d57f62c7ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-3af2e77b-da06-4d1c-8a28-962fdb6028a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-5469744a-c163-428b-b591-642a7f0e4ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-021efa4c-8dcc-4962-8697-820d1bd9f23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-cf18659f-c0b5-4f53-a720-da9eea1a23e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-06f3ea63-4341-4177-8c30-11d9927a23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-f50ad8d4-4152-4cca-8f8f-95ed23405cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086331607-172.17.0.19-1597519489537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45277,DS-eb3730eb-9276-4c3b-bbcd-82b9c6a064c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-872ecc79-5791-4f29-b714-d57f62c7ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-3af2e77b-da06-4d1c-8a28-962fdb6028a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-5469744a-c163-428b-b591-642a7f0e4ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-021efa4c-8dcc-4962-8697-820d1bd9f23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-cf18659f-c0b5-4f53-a720-da9eea1a23e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-06f3ea63-4341-4177-8c30-11d9927a23eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-f50ad8d4-4152-4cca-8f8f-95ed23405cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849651705-172.17.0.19-1597519763988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-f4025571-4f98-447b-931b-8e500c6f5021,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-a90baf26-214b-41e6-8819-0325b2f7d9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-5b783d74-388e-4db5-9dc5-a1d2ca38e192,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-9f97fb4c-e242-47af-90df-ea6e2481be8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-d6581dc8-e955-42aa-90cc-ff44c681a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-1f1ffece-cbb5-41ef-9159-9e1d65ae8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-31fceb72-1828-4336-ba3b-586d21e39fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-91f4289a-855d-45d0-9026-1d7047860a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1849651705-172.17.0.19-1597519763988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-f4025571-4f98-447b-931b-8e500c6f5021,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-a90baf26-214b-41e6-8819-0325b2f7d9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-5b783d74-388e-4db5-9dc5-a1d2ca38e192,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-9f97fb4c-e242-47af-90df-ea6e2481be8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-d6581dc8-e955-42aa-90cc-ff44c681a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-1f1ffece-cbb5-41ef-9159-9e1d65ae8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-31fceb72-1828-4336-ba3b-586d21e39fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-91f4289a-855d-45d0-9026-1d7047860a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5580
