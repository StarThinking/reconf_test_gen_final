reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998057749-172.17.0.13-1597526579708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37837,DS-1e4c491d-baee-4096-b600-68c2a3f1a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-570dbcb6-18dd-4e44-a683-1f71a494870f,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-572bc93c-a481-47ab-9b02-b08016eb9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-09346876-f5dd-481c-976b-5aa10407e128,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-08d38fe3-57bc-40df-b8ae-8c44f4e9795c,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-e0576198-0b3f-4a88-947a-9a9fef6db239,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-609151c2-9d93-4cea-b281-877c567dd65d,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-d42e7044-ccd9-4cec-9df2-5d7ee362c4a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998057749-172.17.0.13-1597526579708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37837,DS-1e4c491d-baee-4096-b600-68c2a3f1a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-570dbcb6-18dd-4e44-a683-1f71a494870f,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-572bc93c-a481-47ab-9b02-b08016eb9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-09346876-f5dd-481c-976b-5aa10407e128,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-08d38fe3-57bc-40df-b8ae-8c44f4e9795c,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-e0576198-0b3f-4a88-947a-9a9fef6db239,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-609151c2-9d93-4cea-b281-877c567dd65d,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-d42e7044-ccd9-4cec-9df2-5d7ee362c4a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765944481-172.17.0.13-1597526993384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-0e3930c0-1381-4f68-97a6-693a9a7f31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-03407c7c-3e23-48c0-89e0-37179e1bd314,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-602302c6-e270-4894-9c04-66f7c4f3e485,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-b845b163-c411-43fb-a2e8-a55813592251,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-c7a039fe-cc80-46ec-a02c-52737780f33d,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-bd216395-fd0c-4dd2-88b8-a3117893b552,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-b59a81db-5a9d-4d03-ab8d-eb12f4f836d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-ad39bdb4-3911-463d-ba09-33722f934aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765944481-172.17.0.13-1597526993384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-0e3930c0-1381-4f68-97a6-693a9a7f31b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-03407c7c-3e23-48c0-89e0-37179e1bd314,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-602302c6-e270-4894-9c04-66f7c4f3e485,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-b845b163-c411-43fb-a2e8-a55813592251,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-c7a039fe-cc80-46ec-a02c-52737780f33d,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-bd216395-fd0c-4dd2-88b8-a3117893b552,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-b59a81db-5a9d-4d03-ab8d-eb12f4f836d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-ad39bdb4-3911-463d-ba09-33722f934aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170277496-172.17.0.13-1597527026676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-f7824a1f-5690-409f-bd21-60cc09acd3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-772439b6-9e01-41db-aa6c-2cba4f453f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-0b634b1f-0e72-41a0-91fd-bbc3ef2b4d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-fde63d5e-5799-4073-894b-2ff2250a9ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-cac985a5-46f0-4694-afca-ba8727b003c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-2f8dac4f-73b0-487c-9d5b-1a1a84e3cc99,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-63f4b37a-4095-478b-b4db-2d8ec287eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-1a41e925-f0d0-4dc0-a379-1aef0aa4bed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170277496-172.17.0.13-1597527026676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-f7824a1f-5690-409f-bd21-60cc09acd3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-772439b6-9e01-41db-aa6c-2cba4f453f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-0b634b1f-0e72-41a0-91fd-bbc3ef2b4d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-fde63d5e-5799-4073-894b-2ff2250a9ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-cac985a5-46f0-4694-afca-ba8727b003c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-2f8dac4f-73b0-487c-9d5b-1a1a84e3cc99,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-63f4b37a-4095-478b-b4db-2d8ec287eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-1a41e925-f0d0-4dc0-a379-1aef0aa4bed9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817052054-172.17.0.13-1597527221159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-4bdddbc0-49d6-4927-b262-b9a07e49ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-f96d7c18-bedf-4367-a14d-ee775be76e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-5507428f-2e31-465a-a10b-0820f3508d66,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-089a7908-accb-4751-b824-4efdb1f5d3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-742554c4-1606-4277-bef8-35e02db2edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-f5d230d0-2a08-4f4e-8a21-0fc54e498eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-52cbcae3-7b93-44b1-8284-311a05ca9c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-510933f4-6e30-43a2-bb3a-6bc052eb4567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817052054-172.17.0.13-1597527221159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-4bdddbc0-49d6-4927-b262-b9a07e49ca55,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-f96d7c18-bedf-4367-a14d-ee775be76e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-5507428f-2e31-465a-a10b-0820f3508d66,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-089a7908-accb-4751-b824-4efdb1f5d3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-742554c4-1606-4277-bef8-35e02db2edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-f5d230d0-2a08-4f4e-8a21-0fc54e498eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-52cbcae3-7b93-44b1-8284-311a05ca9c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-510933f4-6e30-43a2-bb3a-6bc052eb4567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370981018-172.17.0.13-1597527692160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-06c3c235-6bf3-4400-b232-f63f139f7bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-61a64a40-a7dd-41ef-b033-695ba653afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-a359632c-5417-4ba8-90f6-482b4d4715e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-722c030e-63aa-4c7a-b8c6-5eed7fc5fca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-e304d599-f6d9-4426-96eb-470170ca53e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-76db6d82-b181-438e-a1c7-8b0c142fbe82,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-0078beee-57b0-4f4a-a9ff-f5729e870950,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-00fcf095-f21d-4ae4-98c2-e9bf641f53fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370981018-172.17.0.13-1597527692160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-06c3c235-6bf3-4400-b232-f63f139f7bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-61a64a40-a7dd-41ef-b033-695ba653afd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-a359632c-5417-4ba8-90f6-482b4d4715e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-722c030e-63aa-4c7a-b8c6-5eed7fc5fca2,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-e304d599-f6d9-4426-96eb-470170ca53e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-76db6d82-b181-438e-a1c7-8b0c142fbe82,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-0078beee-57b0-4f4a-a9ff-f5729e870950,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-00fcf095-f21d-4ae4-98c2-e9bf641f53fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953682889-172.17.0.13-1597527828993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-0572a357-182d-477d-919a-eeb189c95e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-45b93ef9-05e7-4113-bc93-398e3de58422,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-6cd34a95-ece3-4df5-a3f4-fe09a3adff55,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-ed837d20-756b-45b4-9a88-db882cb01984,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-9d0c6cca-1189-4c87-8144-c3fa71918570,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-f4109244-78e8-420a-85e7-5d8b70e1e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-4bcc4e1d-2724-455b-8668-64830dfb8b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-331f6dd0-3fa7-45e1-8fca-3f5fa01540e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953682889-172.17.0.13-1597527828993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-0572a357-182d-477d-919a-eeb189c95e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-45b93ef9-05e7-4113-bc93-398e3de58422,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-6cd34a95-ece3-4df5-a3f4-fe09a3adff55,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-ed837d20-756b-45b4-9a88-db882cb01984,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-9d0c6cca-1189-4c87-8144-c3fa71918570,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-f4109244-78e8-420a-85e7-5d8b70e1e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-4bcc4e1d-2724-455b-8668-64830dfb8b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-331f6dd0-3fa7-45e1-8fca-3f5fa01540e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431851648-172.17.0.13-1597528168332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37507,DS-dec6eba2-4b12-41ac-b5b6-7df561e56448,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-ea8cd8a9-b4b1-459e-9da5-95dd051b7924,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-c3b61b8e-24a8-4736-b297-120c3e97b413,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-c572b1d2-a80c-46d8-aa87-8cafa210db9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-a987c624-32a6-4ce2-ad24-a9d892a1b7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-24cab5b0-ec46-4fb6-a61d-9b1dcfe141d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-651664a7-c3a1-4dd0-b636-dd6a8f2a1a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-cc0d59c9-35a8-47e4-b80f-f065e60d6f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431851648-172.17.0.13-1597528168332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37507,DS-dec6eba2-4b12-41ac-b5b6-7df561e56448,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-ea8cd8a9-b4b1-459e-9da5-95dd051b7924,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-c3b61b8e-24a8-4736-b297-120c3e97b413,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-c572b1d2-a80c-46d8-aa87-8cafa210db9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-a987c624-32a6-4ce2-ad24-a9d892a1b7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-24cab5b0-ec46-4fb6-a61d-9b1dcfe141d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-651664a7-c3a1-4dd0-b636-dd6a8f2a1a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-cc0d59c9-35a8-47e4-b80f-f065e60d6f4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803081563-172.17.0.13-1597528493124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-d7e093fa-4833-4ac5-a4f4-c96af9f8ce54,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-a5820588-99ff-4ea5-aca7-dd46ae778b57,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-de6f12ef-828e-4f8a-bf15-cc77a80de4db,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-dcd5b304-a472-4db7-8c92-d1005828b83e,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-5fda9ec5-19cb-42bc-abe4-2f5598a551ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-23e58419-4ace-47cd-bf2b-7f1d53902d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-ac6631f0-2339-42db-9ab4-85d9e2957ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-4fffd8e7-28c0-4e9d-9a5e-425d4658b571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803081563-172.17.0.13-1597528493124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36937,DS-d7e093fa-4833-4ac5-a4f4-c96af9f8ce54,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-a5820588-99ff-4ea5-aca7-dd46ae778b57,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-de6f12ef-828e-4f8a-bf15-cc77a80de4db,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-dcd5b304-a472-4db7-8c92-d1005828b83e,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-5fda9ec5-19cb-42bc-abe4-2f5598a551ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-23e58419-4ace-47cd-bf2b-7f1d53902d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-ac6631f0-2339-42db-9ab4-85d9e2957ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-4fffd8e7-28c0-4e9d-9a5e-425d4658b571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682402577-172.17.0.13-1597528522465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-d98ecc8b-9c4d-4365-a0ab-3137fb348961,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-062bce8d-fdc4-4bfd-941a-ce625f41a25a,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-cde33ce2-8643-4c52-b525-94014ba57d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-d2f2eab2-dda9-48b8-933b-e3457f2963f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-eafa656c-9db5-4745-8f25-d768d6912138,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-9376db03-978d-47e2-bae4-2cb89bc5c7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-6815856d-37cc-433a-89b4-e862b23c5064,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-0c6f9a64-a779-4bb9-a6a5-4b3d0c9464c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682402577-172.17.0.13-1597528522465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-d98ecc8b-9c4d-4365-a0ab-3137fb348961,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-062bce8d-fdc4-4bfd-941a-ce625f41a25a,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-cde33ce2-8643-4c52-b525-94014ba57d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-d2f2eab2-dda9-48b8-933b-e3457f2963f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-eafa656c-9db5-4745-8f25-d768d6912138,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-9376db03-978d-47e2-bae4-2cb89bc5c7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-6815856d-37cc-433a-89b4-e862b23c5064,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-0c6f9a64-a779-4bb9-a6a5-4b3d0c9464c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912936826-172.17.0.13-1597529190478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42573,DS-26199362-37a6-41f3-bbbe-08cc81614f07,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-ab7e6669-f3a1-4ad0-bf46-97b5d02e64d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-785c39a4-247a-466e-8de1-f60cc0d485a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-2e8b451a-1756-4e59-a5d6-b6094ecde0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-642f6f00-d5e9-4756-b3cb-6920f71aca75,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-052a672e-b5f9-4369-88f7-fd382657e893,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-3c3f4afd-4d79-4aaa-8907-46d4faab3d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-21ef0a79-7454-4dd9-b2d6-7d0ee3e7a71c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912936826-172.17.0.13-1597529190478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42573,DS-26199362-37a6-41f3-bbbe-08cc81614f07,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-ab7e6669-f3a1-4ad0-bf46-97b5d02e64d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-785c39a4-247a-466e-8de1-f60cc0d485a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-2e8b451a-1756-4e59-a5d6-b6094ecde0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-642f6f00-d5e9-4756-b3cb-6920f71aca75,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-052a672e-b5f9-4369-88f7-fd382657e893,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-3c3f4afd-4d79-4aaa-8907-46d4faab3d48,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-21ef0a79-7454-4dd9-b2d6-7d0ee3e7a71c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663010939-172.17.0.13-1597529603930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40025,DS-6d338c6a-e7dd-4fe8-8d47-d2eb0768a544,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-9da7ee4c-c2bc-4888-a74f-3e44f8259b45,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-52c1735d-cb03-4496-a50d-bcb022401025,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-85a90601-ce34-42cd-8b77-e0b8fc1ae605,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-9a286804-77c1-4584-88c8-56ee6faa2002,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-4996a156-8d86-4e72-b479-160d88dff23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-6eb4d62b-b43f-48a8-b127-1486190aa8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-5592be35-9817-49ec-a7f5-f59ad1381515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663010939-172.17.0.13-1597529603930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40025,DS-6d338c6a-e7dd-4fe8-8d47-d2eb0768a544,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-9da7ee4c-c2bc-4888-a74f-3e44f8259b45,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-52c1735d-cb03-4496-a50d-bcb022401025,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-85a90601-ce34-42cd-8b77-e0b8fc1ae605,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-9a286804-77c1-4584-88c8-56ee6faa2002,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-4996a156-8d86-4e72-b479-160d88dff23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-6eb4d62b-b43f-48a8-b127-1486190aa8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-5592be35-9817-49ec-a7f5-f59ad1381515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372807743-172.17.0.13-1597529857684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33591,DS-a3385036-a7a2-4c79-89e2-223133b55f25,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-a6a43c4e-2e87-4854-9937-efe1a59097ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-03718841-8eec-4bf0-ab7e-22df758c2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-623b9e90-4a07-4ce7-ace6-7fbf7ab22e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-43d02b36-f3ad-4af7-814c-fa58524fc8db,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-188e3c3e-6939-43a5-a9f4-74c1f95b1f62,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-d16298c3-ef71-427e-ba67-e6cfa006a4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-9ed58f1a-313e-4f83-bcea-2552b2b02dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372807743-172.17.0.13-1597529857684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33591,DS-a3385036-a7a2-4c79-89e2-223133b55f25,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-a6a43c4e-2e87-4854-9937-efe1a59097ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-03718841-8eec-4bf0-ab7e-22df758c2cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-623b9e90-4a07-4ce7-ace6-7fbf7ab22e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-43d02b36-f3ad-4af7-814c-fa58524fc8db,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-188e3c3e-6939-43a5-a9f4-74c1f95b1f62,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-d16298c3-ef71-427e-ba67-e6cfa006a4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-9ed58f1a-313e-4f83-bcea-2552b2b02dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817574208-172.17.0.13-1597530047413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-349c6079-d0bd-4588-b051-4a5213bc2694,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-3bb3b92b-f982-449b-8dcc-cf357c10c939,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-d02bbfd6-e6df-4ae2-9194-824346c1ba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-28ed7f21-1cc0-4a9d-b9cc-1751a31c9af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-9f6f4497-e44e-4f76-9136-528d24d0c908,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-5007729b-170d-44a9-a21e-028b12d48e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-999c392d-5176-4acd-afd2-fb0b6364b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-9266c96c-d312-4395-8b81-cc5e89e890fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817574208-172.17.0.13-1597530047413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-349c6079-d0bd-4588-b051-4a5213bc2694,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-3bb3b92b-f982-449b-8dcc-cf357c10c939,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-d02bbfd6-e6df-4ae2-9194-824346c1ba0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-28ed7f21-1cc0-4a9d-b9cc-1751a31c9af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-9f6f4497-e44e-4f76-9136-528d24d0c908,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-5007729b-170d-44a9-a21e-028b12d48e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-999c392d-5176-4acd-afd2-fb0b6364b74e,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-9266c96c-d312-4395-8b81-cc5e89e890fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267228418-172.17.0.13-1597530176292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-53011771-c60e-44e0-b43a-e26077900189,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-24dfb7fd-f8f4-499b-8314-2be1b632d7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-0e626317-272d-493c-b1d5-f23f7bed1dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-5575506d-deb7-4ec7-806d-07600b6125c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-b690fd59-2a23-4ba3-9dad-5a9fb44ddcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-6bca551b-1366-4404-a66c-1a38f3927073,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-3efb0e72-eff2-4a70-8bd9-aa3ec34f0247,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-ac77dded-acf2-49ea-8102-7b169538eb6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267228418-172.17.0.13-1597530176292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-53011771-c60e-44e0-b43a-e26077900189,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-24dfb7fd-f8f4-499b-8314-2be1b632d7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-0e626317-272d-493c-b1d5-f23f7bed1dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-5575506d-deb7-4ec7-806d-07600b6125c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-b690fd59-2a23-4ba3-9dad-5a9fb44ddcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-6bca551b-1366-4404-a66c-1a38f3927073,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-3efb0e72-eff2-4a70-8bd9-aa3ec34f0247,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-ac77dded-acf2-49ea-8102-7b169538eb6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804088626-172.17.0.13-1597530342435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-ad81c3d2-78b9-44cc-9ccf-2f9521865517,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-205db822-250d-4f43-a223-c5a7d0f74410,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-5bbdeab8-e584-4df9-b7d1-8b043143a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-5c60bbac-a3e6-4ede-9dfe-8e1dc0fd2538,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-c4d9e970-7786-4f15-8388-651fdc55bb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-7b3df5c6-dde1-4598-9727-f331c5e463d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-daa7c068-5dd8-46c7-afe8-d5e436a2196b,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-eb8545bc-46f6-49b3-bbce-830288648f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804088626-172.17.0.13-1597530342435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-ad81c3d2-78b9-44cc-9ccf-2f9521865517,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-205db822-250d-4f43-a223-c5a7d0f74410,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-5bbdeab8-e584-4df9-b7d1-8b043143a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-5c60bbac-a3e6-4ede-9dfe-8e1dc0fd2538,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-c4d9e970-7786-4f15-8388-651fdc55bb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-7b3df5c6-dde1-4598-9727-f331c5e463d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-daa7c068-5dd8-46c7-afe8-d5e436a2196b,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-eb8545bc-46f6-49b3-bbce-830288648f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572785191-172.17.0.13-1597530400704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-a758c8b2-96d8-4ac5-b944-f31decbaadda,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-3b9f5dd8-e6e0-4c93-b11f-da8fddbaea96,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-62b36277-949b-4af2-80fb-3d3b0796ec6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-03c9efd6-52cf-4143-877b-73667e000eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-369d43e9-beda-449d-bb7a-57547538898a,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-e3afcee2-1c03-41c0-a792-717884d22923,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-7a628158-2ab6-4c84-834b-a5c80b1afbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-3e2da8c7-9b6f-4c60-9d39-215de1257390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572785191-172.17.0.13-1597530400704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39720,DS-a758c8b2-96d8-4ac5-b944-f31decbaadda,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-3b9f5dd8-e6e0-4c93-b11f-da8fddbaea96,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-62b36277-949b-4af2-80fb-3d3b0796ec6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-03c9efd6-52cf-4143-877b-73667e000eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-369d43e9-beda-449d-bb7a-57547538898a,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-e3afcee2-1c03-41c0-a792-717884d22923,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-7a628158-2ab6-4c84-834b-a5c80b1afbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-3e2da8c7-9b6f-4c60-9d39-215de1257390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 100ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062758842-172.17.0.13-1597530540964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41523,DS-057341cf-11b6-428a-99c5-a1c4f8c5dedd,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-c3dbeea4-73eb-46be-888d-82aca489eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-add22055-2a46-4dc5-a225-13bc5bef6af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-8dc4ee2f-22e1-43a1-9c28-4d16e7003098,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-b3c6338e-f7e2-49b3-b925-359ab48ccd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-91b2e49f-cf7d-4713-8bfd-3920b3ef323b,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-ec428e15-7aaf-455d-a5b0-13164314d486,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-58fd4403-1008-424b-997d-c84945e75a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062758842-172.17.0.13-1597530540964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41523,DS-057341cf-11b6-428a-99c5-a1c4f8c5dedd,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-c3dbeea4-73eb-46be-888d-82aca489eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-add22055-2a46-4dc5-a225-13bc5bef6af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-8dc4ee2f-22e1-43a1-9c28-4d16e7003098,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-b3c6338e-f7e2-49b3-b925-359ab48ccd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-91b2e49f-cf7d-4713-8bfd-3920b3ef323b,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-ec428e15-7aaf-455d-a5b0-13164314d486,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-58fd4403-1008-424b-997d-c84945e75a27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4911
