reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510741350-172.17.0.9-1597575559840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-87e07409-5c9a-4ea8-a601-9af5a65b86ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-7156bdf6-1a1e-4aa0-b1c0-62345d20b613,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-b8ed4f46-096e-4bf1-b649-3504fe87f10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-aeccc50f-d9d0-4925-9a33-266b891cb90f,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-487978b6-fc71-45d6-96e2-8c3d9507ad80,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-ed5ce591-6c71-4af7-9895-c47b1d177254,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-2295177b-e53c-46d8-8a14-3f5bd856c00d,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-453d4644-4a8e-4755-a6eb-3b1721b974ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510741350-172.17.0.9-1597575559840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-87e07409-5c9a-4ea8-a601-9af5a65b86ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-7156bdf6-1a1e-4aa0-b1c0-62345d20b613,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-b8ed4f46-096e-4bf1-b649-3504fe87f10d,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-aeccc50f-d9d0-4925-9a33-266b891cb90f,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-487978b6-fc71-45d6-96e2-8c3d9507ad80,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-ed5ce591-6c71-4af7-9895-c47b1d177254,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-2295177b-e53c-46d8-8a14-3f5bd856c00d,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-453d4644-4a8e-4755-a6eb-3b1721b974ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674789809-172.17.0.9-1597575825193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-5be36c8a-a151-42a9-9901-85d7ce5a1651,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-b7d2759c-5d63-45d2-af71-efa1a145e3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-60792930-d617-4e8a-80c9-c747b3592935,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-b6004fe4-0fe5-400c-b9d6-cff235051b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-f8f8ab61-306a-4fb3-b228-a31dc6b6a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-63797d23-11bb-4cae-b165-72dce41b43e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-76bd7fc4-b48a-41a5-9928-187b78e4a286,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-32eef08f-8a29-456e-9514-6873cf42cc32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674789809-172.17.0.9-1597575825193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-5be36c8a-a151-42a9-9901-85d7ce5a1651,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-b7d2759c-5d63-45d2-af71-efa1a145e3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-60792930-d617-4e8a-80c9-c747b3592935,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-b6004fe4-0fe5-400c-b9d6-cff235051b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-f8f8ab61-306a-4fb3-b228-a31dc6b6a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-63797d23-11bb-4cae-b165-72dce41b43e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-76bd7fc4-b48a-41a5-9928-187b78e4a286,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-32eef08f-8a29-456e-9514-6873cf42cc32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144154312-172.17.0.9-1597576250315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33823,DS-45635bb9-7262-4244-bda1-6aff36c088e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-a8b5eefc-272e-4da1-a3c9-b6f0e622bcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-556a709c-be9f-4704-9ad8-128ea50fcb33,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-04d87948-a2ff-46ec-bf0d-79f92167c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-e054c401-f5b8-480c-8a81-ad3315259dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-3e706a65-769e-4dec-87fe-2118875c1104,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-e7acca47-0cfd-4e1d-a85c-c3d8a405c0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-843c26d9-9420-42c6-9261-9b10692c9c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144154312-172.17.0.9-1597576250315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33823,DS-45635bb9-7262-4244-bda1-6aff36c088e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-a8b5eefc-272e-4da1-a3c9-b6f0e622bcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-556a709c-be9f-4704-9ad8-128ea50fcb33,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-04d87948-a2ff-46ec-bf0d-79f92167c2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-e054c401-f5b8-480c-8a81-ad3315259dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-3e706a65-769e-4dec-87fe-2118875c1104,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-e7acca47-0cfd-4e1d-a85c-c3d8a405c0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-843c26d9-9420-42c6-9261-9b10692c9c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034363787-172.17.0.9-1597577192190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35099,DS-2a7220a3-a9ed-423c-98d4-8a4a9c94921b,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-1a95d451-844f-4383-b5e3-6787cef95bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-6bb2a0df-f99c-44b5-842a-55be54b07bee,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-c2d11f2d-3b90-4035-b171-e5e010b2641d,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-d4057f5f-a737-437e-85d0-ded78c87dea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-a8b0b3ad-05d3-4419-9d26-df55e6ec3988,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-7e035af2-7d52-4062-be81-43451da62437,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-e14a64cc-b5eb-4e8a-9ae0-091031ed47c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034363787-172.17.0.9-1597577192190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35099,DS-2a7220a3-a9ed-423c-98d4-8a4a9c94921b,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-1a95d451-844f-4383-b5e3-6787cef95bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-6bb2a0df-f99c-44b5-842a-55be54b07bee,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-c2d11f2d-3b90-4035-b171-e5e010b2641d,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-d4057f5f-a737-437e-85d0-ded78c87dea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-a8b0b3ad-05d3-4419-9d26-df55e6ec3988,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-7e035af2-7d52-4062-be81-43451da62437,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-e14a64cc-b5eb-4e8a-9ae0-091031ed47c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581048264-172.17.0.9-1597577315305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44899,DS-deb127f5-3b25-4dad-834a-9d4cc4fe636a,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-f80b91b3-268a-49fa-bbb6-919b6765b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-8e4f1a5a-2f95-4074-a35d-2f2d4c215824,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-cccda4b5-52bb-4e2b-96da-0f2f1b9aa0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-d2d6f580-4839-4908-bc92-4408b2f85819,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-48dba163-47d5-44cd-807f-8fb5c15c289e,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-7a2674b7-9a14-4239-b37f-82669c79ea27,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-25423d6a-8d73-4da9-913b-379415197a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581048264-172.17.0.9-1597577315305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44899,DS-deb127f5-3b25-4dad-834a-9d4cc4fe636a,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-f80b91b3-268a-49fa-bbb6-919b6765b20e,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-8e4f1a5a-2f95-4074-a35d-2f2d4c215824,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-cccda4b5-52bb-4e2b-96da-0f2f1b9aa0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-d2d6f580-4839-4908-bc92-4408b2f85819,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-48dba163-47d5-44cd-807f-8fb5c15c289e,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-7a2674b7-9a14-4239-b37f-82669c79ea27,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-25423d6a-8d73-4da9-913b-379415197a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624543076-172.17.0.9-1597577987331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42994,DS-348f2a21-37e8-4a90-afca-c2b41e007ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-d8abf263-b445-49e8-ac3e-3e3df8852216,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-35ff64ea-fce2-4513-8452-7ba4dea837ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-00809364-c1f2-4fd7-ada1-246e508f7e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-caef36c4-77f4-4738-8506-7a6a6966f957,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-0e6dff58-0520-493c-b071-047b40623d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-171d009b-2503-4a44-abe7-6b65992dbeda,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-2c3c3134-ab6d-4cd4-9d2f-7094674ce03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624543076-172.17.0.9-1597577987331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42994,DS-348f2a21-37e8-4a90-afca-c2b41e007ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-d8abf263-b445-49e8-ac3e-3e3df8852216,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-35ff64ea-fce2-4513-8452-7ba4dea837ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-00809364-c1f2-4fd7-ada1-246e508f7e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-caef36c4-77f4-4738-8506-7a6a6966f957,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-0e6dff58-0520-493c-b071-047b40623d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-171d009b-2503-4a44-abe7-6b65992dbeda,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-2c3c3134-ab6d-4cd4-9d2f-7094674ce03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355834567-172.17.0.9-1597578150521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-9da029a1-e221-45db-bc67-783fe610e303,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-ef74f6de-0c03-40f0-8139-781ba088c644,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-7998be33-401c-4ee8-929c-adedbe874ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-1ec884d8-8627-412e-b8d6-b43b55638886,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-ed2d230c-7f51-4558-80ba-404547d3f8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-527dba01-f6aa-4d8e-bfdf-090ea344fba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-f14f2eee-3c31-42e5-9003-94daee735f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-bf036bbb-6984-4bce-9ad2-d4764438a3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355834567-172.17.0.9-1597578150521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-9da029a1-e221-45db-bc67-783fe610e303,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-ef74f6de-0c03-40f0-8139-781ba088c644,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-7998be33-401c-4ee8-929c-adedbe874ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-1ec884d8-8627-412e-b8d6-b43b55638886,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-ed2d230c-7f51-4558-80ba-404547d3f8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-527dba01-f6aa-4d8e-bfdf-090ea344fba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-f14f2eee-3c31-42e5-9003-94daee735f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-bf036bbb-6984-4bce-9ad2-d4764438a3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60945234-172.17.0.9-1597578774771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-4c5a00d8-c4ce-48f4-b108-cfab9a29e30c,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-46086ed3-fd60-4fe3-b1e4-dca9f0488970,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-ab8d44a9-af68-4637-a529-29c430e72b46,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-4391e195-7028-4b07-8f11-798e6ff69175,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-99ced266-b81b-425d-b873-c6fcdbdf5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-cbe32fe3-46f2-4608-8908-1fc6d215cada,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-d29fcdc8-9669-4ae4-b62f-ce71cb656d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-a2debd4e-b1b2-4a79-950d-e5fa11e7d365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60945234-172.17.0.9-1597578774771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-4c5a00d8-c4ce-48f4-b108-cfab9a29e30c,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-46086ed3-fd60-4fe3-b1e4-dca9f0488970,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-ab8d44a9-af68-4637-a529-29c430e72b46,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-4391e195-7028-4b07-8f11-798e6ff69175,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-99ced266-b81b-425d-b873-c6fcdbdf5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-cbe32fe3-46f2-4608-8908-1fc6d215cada,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-d29fcdc8-9669-4ae4-b62f-ce71cb656d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-a2debd4e-b1b2-4a79-950d-e5fa11e7d365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63462932-172.17.0.9-1597578809353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44155,DS-adb57ade-5e6b-4843-8334-195dd26ceb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-79f65805-95d1-441e-afb6-ebd063f5f399,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-9064081a-9ada-4cfe-8d4e-e033c7230047,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-6c8e6129-5611-4b42-a1b6-6619971cefd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-9d2a28e2-42e6-41ad-aa9b-fb6573598fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-97ccf882-69e4-4593-a130-bd4048630dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-5d1c3157-2126-4a81-abd5-464d67184a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-9f6d6c1f-3445-428c-a3a1-c1690b927bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63462932-172.17.0.9-1597578809353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44155,DS-adb57ade-5e6b-4843-8334-195dd26ceb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-79f65805-95d1-441e-afb6-ebd063f5f399,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-9064081a-9ada-4cfe-8d4e-e033c7230047,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-6c8e6129-5611-4b42-a1b6-6619971cefd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-9d2a28e2-42e6-41ad-aa9b-fb6573598fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-97ccf882-69e4-4593-a130-bd4048630dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-5d1c3157-2126-4a81-abd5-464d67184a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-9f6d6c1f-3445-428c-a3a1-c1690b927bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460506671-172.17.0.9-1597578880592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43190,DS-085c16ed-293f-4c55-afa7-e7177edaaef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-7d849426-0c04-4f9b-aeb3-fa4630587482,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-07d1d1ae-b6dc-475f-834c-c8682608f3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-2ff87e14-0e25-4674-95a2-cc6873a01aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-470e28e0-a12b-45eb-bcf1-d91fe5826cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-d1f10be8-1e66-4f19-bbbb-3b09b5864316,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-7c763dfa-0588-43f4-b5cf-8eae9ad7008d,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-2740cd90-83e2-4718-9ccf-d9c351be3820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460506671-172.17.0.9-1597578880592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43190,DS-085c16ed-293f-4c55-afa7-e7177edaaef5,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-7d849426-0c04-4f9b-aeb3-fa4630587482,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-07d1d1ae-b6dc-475f-834c-c8682608f3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-2ff87e14-0e25-4674-95a2-cc6873a01aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-470e28e0-a12b-45eb-bcf1-d91fe5826cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-d1f10be8-1e66-4f19-bbbb-3b09b5864316,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-7c763dfa-0588-43f4-b5cf-8eae9ad7008d,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-2740cd90-83e2-4718-9ccf-d9c351be3820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545118183-172.17.0.9-1597579275109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41403,DS-4f652481-58d0-417e-a18c-40c49ffbc60b,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-ebbe278b-f64f-40e2-812d-325bc6e6d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-a7683707-25d6-4ff2-900f-057d68265902,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-804c19f8-73e2-41a7-9836-4da6272b0c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-8683b114-ba30-4994-8192-b29738a47ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-6c12f4a3-af96-40b5-846c-f0f3d66d1d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-af1b1135-4be7-4872-a5dd-68b262807ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-8fd1424c-a64f-4206-b3ab-fbd0782cb33a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545118183-172.17.0.9-1597579275109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41403,DS-4f652481-58d0-417e-a18c-40c49ffbc60b,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-ebbe278b-f64f-40e2-812d-325bc6e6d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-a7683707-25d6-4ff2-900f-057d68265902,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-804c19f8-73e2-41a7-9836-4da6272b0c31,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-8683b114-ba30-4994-8192-b29738a47ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-6c12f4a3-af96-40b5-846c-f0f3d66d1d05,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-af1b1135-4be7-4872-a5dd-68b262807ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-8fd1424c-a64f-4206-b3ab-fbd0782cb33a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249800300-172.17.0.9-1597579413047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-d739b073-78b9-4d07-a349-287b85f41324,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-9981fac2-ff16-41f9-acc3-3094f95dc6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-0a4bd69f-e39d-4e02-82e2-cdc2d17324fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-47fc398b-d537-4565-9cb5-c991b6b7b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-cc256598-2a0e-48d0-84dc-bd6a0921a1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-c8278b3b-8f49-45e5-8466-843e6bbb5834,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-25f7e473-281c-4eaa-a8f3-2c3ea771f47a,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-e8e6d4c0-aa4e-43f4-957f-05b57bb547cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249800300-172.17.0.9-1597579413047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-d739b073-78b9-4d07-a349-287b85f41324,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-9981fac2-ff16-41f9-acc3-3094f95dc6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-0a4bd69f-e39d-4e02-82e2-cdc2d17324fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-47fc398b-d537-4565-9cb5-c991b6b7b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-cc256598-2a0e-48d0-84dc-bd6a0921a1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-c8278b3b-8f49-45e5-8466-843e6bbb5834,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-25f7e473-281c-4eaa-a8f3-2c3ea771f47a,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-e8e6d4c0-aa4e-43f4-957f-05b57bb547cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577894795-172.17.0.9-1597579446247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-f207f6eb-3a66-49db-8f88-91d41e83c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-f101e7f5-2a08-43d9-a0a6-89e216036547,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-800cbe5b-be46-4440-8054-b13ed8c42917,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-39ad3578-f92b-4491-b7ed-d7da2b9cea10,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-6ae34db1-f750-4373-8763-6225028c3eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-5b090983-d621-401e-9c56-08413782f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-37dd381a-bf0d-4942-82fd-4b0de58dacdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-13f50ee9-2381-4cd9-ba05-141535197cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577894795-172.17.0.9-1597579446247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-f207f6eb-3a66-49db-8f88-91d41e83c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-f101e7f5-2a08-43d9-a0a6-89e216036547,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-800cbe5b-be46-4440-8054-b13ed8c42917,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-39ad3578-f92b-4491-b7ed-d7da2b9cea10,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-6ae34db1-f750-4373-8763-6225028c3eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-5b090983-d621-401e-9c56-08413782f65f,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-37dd381a-bf0d-4942-82fd-4b0de58dacdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-13f50ee9-2381-4cd9-ba05-141535197cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536361779-172.17.0.9-1597579663588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-4c7f7971-d23a-4fe4-b00f-d3a1ad67acf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-7ceb542d-5b77-488a-94e8-da84bc55d595,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bb2fefd9-c7cc-41c1-9d49-4e5ce8b6adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-fef74416-e57d-4301-ab14-9d095d8e43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-8f87b13b-c119-41d9-bf43-0be0e3f38d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-788a68df-de92-40dc-a56b-9b54a461246c,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-c33e1e5e-819a-492f-badc-8788808695d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-a3e4893f-faf2-44ce-9c47-c6bc85e3ffd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536361779-172.17.0.9-1597579663588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33221,DS-4c7f7971-d23a-4fe4-b00f-d3a1ad67acf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-7ceb542d-5b77-488a-94e8-da84bc55d595,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-bb2fefd9-c7cc-41c1-9d49-4e5ce8b6adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-fef74416-e57d-4301-ab14-9d095d8e43fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-8f87b13b-c119-41d9-bf43-0be0e3f38d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-788a68df-de92-40dc-a56b-9b54a461246c,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-c33e1e5e-819a-492f-badc-8788808695d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-a3e4893f-faf2-44ce-9c47-c6bc85e3ffd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613450022-172.17.0.9-1597579865188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33518,DS-fcf7a016-ee7b-40fe-8e97-f95fa643fcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-c7599f80-c3b4-4745-8b90-64532b5dc2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-bccdf255-9c89-4049-af28-f5bc7a2ddd15,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-240400d2-9fbc-4da1-9fca-bc75f8057694,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-e7f488de-5aa2-4832-a13c-2b865ac8b234,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-8f606580-b07a-4e22-96d1-9c2a61d19721,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-0f48bd0c-4e69-40ce-8622-f6ef4a6d2292,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-1afaaa1b-292c-40f5-a922-727268b312f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613450022-172.17.0.9-1597579865188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33518,DS-fcf7a016-ee7b-40fe-8e97-f95fa643fcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-c7599f80-c3b4-4745-8b90-64532b5dc2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-bccdf255-9c89-4049-af28-f5bc7a2ddd15,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-240400d2-9fbc-4da1-9fca-bc75f8057694,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-e7f488de-5aa2-4832-a13c-2b865ac8b234,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-8f606580-b07a-4e22-96d1-9c2a61d19721,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-0f48bd0c-4e69-40ce-8622-f6ef4a6d2292,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-1afaaa1b-292c-40f5-a922-727268b312f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399909566-172.17.0.9-1597579980249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-c1b5a276-ab0c-49e4-885d-c7939dea590f,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-a455e305-9c2f-48c8-8293-85dc4551d636,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-58eae0bd-3e6b-400d-a4eb-862da9904859,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-f7fa587f-7d31-4e53-8484-e2d68b4be362,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-91f7fcab-affb-4dc7-92fa-0c3ccab2eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-fed8437a-7d61-4e68-90e2-fc6456978c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-f47ab7f2-6a7e-4d2c-94fa-8155df3d890d,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-713f2ada-7ab1-45a5-afef-3a00e8b8b520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399909566-172.17.0.9-1597579980249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-c1b5a276-ab0c-49e4-885d-c7939dea590f,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-a455e305-9c2f-48c8-8293-85dc4551d636,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-58eae0bd-3e6b-400d-a4eb-862da9904859,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-f7fa587f-7d31-4e53-8484-e2d68b4be362,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-91f7fcab-affb-4dc7-92fa-0c3ccab2eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-fed8437a-7d61-4e68-90e2-fc6456978c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-f47ab7f2-6a7e-4d2c-94fa-8155df3d890d,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-713f2ada-7ab1-45a5-afef-3a00e8b8b520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235297385-172.17.0.9-1597580350985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35617,DS-3a27b8b4-97de-418e-8663-3c310c20c122,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-2362c664-32ef-44be-a911-a3945c9f7dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-9399e350-25a2-42de-814a-06651a4df863,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-487ce96e-06dc-495a-9667-0df96aa1d76e,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-2a6acc86-78c8-4722-9bfb-01526c967632,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-213dd719-caeb-4fe4-bea7-ef5b42420058,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-4d67bdec-83eb-410d-900f-3714bb0598ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-3e0ebf73-1561-4ccc-893f-79ad0bc4f171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235297385-172.17.0.9-1597580350985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35617,DS-3a27b8b4-97de-418e-8663-3c310c20c122,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-2362c664-32ef-44be-a911-a3945c9f7dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-9399e350-25a2-42de-814a-06651a4df863,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-487ce96e-06dc-495a-9667-0df96aa1d76e,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-2a6acc86-78c8-4722-9bfb-01526c967632,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-213dd719-caeb-4fe4-bea7-ef5b42420058,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-4d67bdec-83eb-410d-900f-3714bb0598ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-3e0ebf73-1561-4ccc-893f-79ad0bc4f171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47116228-172.17.0.9-1597580579491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42986,DS-ae748f04-3219-4533-bc8f-bdb5f72b2155,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-9e8caa42-c3cd-44e5-a1fa-d143a51f2b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-5365660c-e6b1-4465-99ae-6c3ff9674d48,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-ef2e515e-e25d-4a62-968d-b926f5b8ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-2fc47d6a-cdf9-4759-99c7-5ce20a418fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-95bd0c94-2146-4974-845d-d7d3412bff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-6a73330a-e574-4790-84d5-9604f8b93da7,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-3a862116-3c04-4ebb-b9ee-60cc325a1440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47116228-172.17.0.9-1597580579491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42986,DS-ae748f04-3219-4533-bc8f-bdb5f72b2155,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-9e8caa42-c3cd-44e5-a1fa-d143a51f2b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-5365660c-e6b1-4465-99ae-6c3ff9674d48,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-ef2e515e-e25d-4a62-968d-b926f5b8ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-2fc47d6a-cdf9-4759-99c7-5ce20a418fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-95bd0c94-2146-4974-845d-d7d3412bff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-6a73330a-e574-4790-84d5-9604f8b93da7,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-3a862116-3c04-4ebb-b9ee-60cc325a1440,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670874822-172.17.0.9-1597580619816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43909,DS-c6612943-0ccf-4da9-83ec-e1160c387aad,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-996fe395-d96a-44f0-8759-9625b58f88d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-a78653ef-d1d7-41c9-ad89-5c9a6904359d,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-76664081-d11c-4019-a0ae-0a4b4e8dc065,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-2dd55082-6fa1-43b1-ab38-b68f5bbab482,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-7bb5456d-eaf8-4aea-ac6c-b517cda61984,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-de7bda4f-73c8-4f3b-8d52-07b010388e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-1018dc41-1cb9-486a-8f50-c8f32553ff63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670874822-172.17.0.9-1597580619816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43909,DS-c6612943-0ccf-4da9-83ec-e1160c387aad,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-996fe395-d96a-44f0-8759-9625b58f88d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-a78653ef-d1d7-41c9-ad89-5c9a6904359d,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-76664081-d11c-4019-a0ae-0a4b4e8dc065,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-2dd55082-6fa1-43b1-ab38-b68f5bbab482,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-7bb5456d-eaf8-4aea-ac6c-b517cda61984,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-de7bda4f-73c8-4f3b-8d52-07b010388e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-1018dc41-1cb9-486a-8f50-c8f32553ff63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5698
