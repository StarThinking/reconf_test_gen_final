reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102512907-172.17.0.18-1597369556486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-83d86140-3258-47e9-9a9a-f0e81b653c95,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-acddae1f-176f-47ec-bf78-5d68d07a693e,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-cc9e8ecc-b6bc-48dc-ad69-e20355ff39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-b499bd29-3330-4c6e-b1e8-533901c56e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-d73770a9-9c49-47eb-b3be-07f579e4d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-ebb61153-4dbe-4a6b-a278-20afe374f761,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-ef7679a3-ca49-4555-bc8c-f409d0d581d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-8c5748a2-f930-4ccc-97bd-72d247ad645a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102512907-172.17.0.18-1597369556486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-83d86140-3258-47e9-9a9a-f0e81b653c95,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-acddae1f-176f-47ec-bf78-5d68d07a693e,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-cc9e8ecc-b6bc-48dc-ad69-e20355ff39dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-b499bd29-3330-4c6e-b1e8-533901c56e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-d73770a9-9c49-47eb-b3be-07f579e4d03d,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-ebb61153-4dbe-4a6b-a278-20afe374f761,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-ef7679a3-ca49-4555-bc8c-f409d0d581d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-8c5748a2-f930-4ccc-97bd-72d247ad645a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937200252-172.17.0.18-1597369662486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34570,DS-4564a06b-1b07-4577-bf37-62551e6d2845,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-6d0f0762-ea38-489e-966b-8e3a5f662ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-61375799-8512-424a-b0a3-dc7671066048,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-eb811d9b-1620-4d19-a38a-4a9782cb0e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-a9e44754-1846-4686-934f-2662d437792d,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-ae74b3a2-7014-431d-83aa-3e38949abf75,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-2226afec-5673-43ce-889d-cfc08cb80de8,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-7f9b9191-7f1a-4b4d-a86e-84d8ad9caaaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937200252-172.17.0.18-1597369662486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34570,DS-4564a06b-1b07-4577-bf37-62551e6d2845,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-6d0f0762-ea38-489e-966b-8e3a5f662ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-61375799-8512-424a-b0a3-dc7671066048,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-eb811d9b-1620-4d19-a38a-4a9782cb0e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-a9e44754-1846-4686-934f-2662d437792d,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-ae74b3a2-7014-431d-83aa-3e38949abf75,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-2226afec-5673-43ce-889d-cfc08cb80de8,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-7f9b9191-7f1a-4b4d-a86e-84d8ad9caaaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666098627-172.17.0.18-1597369919706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46779,DS-b964311c-6b4f-4389-8c11-60404a6542af,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-d7cba0dd-85b2-465c-a7c1-f7a4ae70fdff,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-ce688a73-00bf-4137-8cf2-12190f64f693,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-54eef59c-d328-489f-87da-920adcf21b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-f3d43d7e-f4d9-4737-8743-46a2a36449a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-61d2d133-eb34-4db3-9e72-8bfd49f66f44,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-09558117-a894-43ef-b580-e80fe6361b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-60b0a055-d7fc-48e2-9e72-7eb463b1b893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666098627-172.17.0.18-1597369919706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46779,DS-b964311c-6b4f-4389-8c11-60404a6542af,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-d7cba0dd-85b2-465c-a7c1-f7a4ae70fdff,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-ce688a73-00bf-4137-8cf2-12190f64f693,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-54eef59c-d328-489f-87da-920adcf21b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-f3d43d7e-f4d9-4737-8743-46a2a36449a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-61d2d133-eb34-4db3-9e72-8bfd49f66f44,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-09558117-a894-43ef-b580-e80fe6361b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-60b0a055-d7fc-48e2-9e72-7eb463b1b893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142173961-172.17.0.18-1597369957195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-6fe440cf-a4dd-4688-a186-d692f1b1ebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-e063654e-10f4-4100-a474-203cb074d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-2e51f125-9528-4f3b-ad7f-8f1c9a7e3966,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-b41959d4-038c-42e7-9d31-052881515b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-370d590d-8182-46fc-bb2a-9ebc320995ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-5b3dc8bd-f2ad-4760-9333-af10cb351526,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-5e906f93-4dc0-40cd-b593-b63c3ea3b315,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-d00e2c8d-ec46-4d0e-9123-e3ff3d71f7c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142173961-172.17.0.18-1597369957195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-6fe440cf-a4dd-4688-a186-d692f1b1ebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-e063654e-10f4-4100-a474-203cb074d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-2e51f125-9528-4f3b-ad7f-8f1c9a7e3966,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-b41959d4-038c-42e7-9d31-052881515b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-370d590d-8182-46fc-bb2a-9ebc320995ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-5b3dc8bd-f2ad-4760-9333-af10cb351526,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-5e906f93-4dc0-40cd-b593-b63c3ea3b315,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-d00e2c8d-ec46-4d0e-9123-e3ff3d71f7c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268210418-172.17.0.18-1597370109621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35982,DS-79c02639-4927-414c-8551-0672d9e40baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-f912c592-3a4a-450a-878b-3ac3e2b4e778,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-261a39af-5f5a-4e27-8c58-59c04d70a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-824527e9-07f3-4489-98bf-5607fe93bdba,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-bf13e1fb-7a04-4e49-9988-4ac97f41ca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-2f29895f-e57c-4d84-884d-24db9529ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-a059ab58-ecb7-4668-ac44-0e7d6388a5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-20bd3076-7bd3-41ec-899a-c8d35de5724f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268210418-172.17.0.18-1597370109621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35982,DS-79c02639-4927-414c-8551-0672d9e40baf,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-f912c592-3a4a-450a-878b-3ac3e2b4e778,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-261a39af-5f5a-4e27-8c58-59c04d70a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-824527e9-07f3-4489-98bf-5607fe93bdba,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-bf13e1fb-7a04-4e49-9988-4ac97f41ca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-2f29895f-e57c-4d84-884d-24db9529ab17,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-a059ab58-ecb7-4668-ac44-0e7d6388a5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-20bd3076-7bd3-41ec-899a-c8d35de5724f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2040671573-172.17.0.18-1597370145334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-ff7de6d7-984a-4cde-b785-51bb8237fb25,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-a488e9fa-58db-4c54-8386-f20587b7c3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-9712553c-029f-4e76-b625-59bbfff3ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-38412e67-c8e2-427f-a0ba-de33c9003833,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-c0276cf7-9faa-4eb8-aa15-0f5267b0c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-43ebd01f-1b43-4868-879b-b2431ae3039a,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-b3a31c5f-2c20-4558-ad99-3c7d425f5faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-5c98eb97-c9a8-4716-8509-c2118f54edf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2040671573-172.17.0.18-1597370145334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-ff7de6d7-984a-4cde-b785-51bb8237fb25,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-a488e9fa-58db-4c54-8386-f20587b7c3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-9712553c-029f-4e76-b625-59bbfff3ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-38412e67-c8e2-427f-a0ba-de33c9003833,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-c0276cf7-9faa-4eb8-aa15-0f5267b0c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-43ebd01f-1b43-4868-879b-b2431ae3039a,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-b3a31c5f-2c20-4558-ad99-3c7d425f5faf,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-5c98eb97-c9a8-4716-8509-c2118f54edf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518875808-172.17.0.18-1597370362648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-0f5dd6a8-c6f0-43a2-9e6c-c40637521b04,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-f3a6d8d2-9c43-4a0b-bb26-52ec84954695,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-846359d3-8fb8-43d3-a1b5-aa1414a01e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-dc8ebb60-94e0-4a14-96fa-aac81c275ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-38d03033-2dda-44e5-8e14-cccdf517c963,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-eab24de6-d160-4c21-a108-cfb2247104c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-97969765-756e-4c61-a32c-29d043078659,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-10e1afb7-d67a-4ed7-814c-107c1964d267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518875808-172.17.0.18-1597370362648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-0f5dd6a8-c6f0-43a2-9e6c-c40637521b04,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-f3a6d8d2-9c43-4a0b-bb26-52ec84954695,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-846359d3-8fb8-43d3-a1b5-aa1414a01e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-dc8ebb60-94e0-4a14-96fa-aac81c275ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-38d03033-2dda-44e5-8e14-cccdf517c963,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-eab24de6-d160-4c21-a108-cfb2247104c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-97969765-756e-4c61-a32c-29d043078659,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-10e1afb7-d67a-4ed7-814c-107c1964d267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199251933-172.17.0.18-1597370472151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46548,DS-dd490dd0-b7c1-41a8-8d7f-5f9bca39cd08,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-473c2eac-ce63-4443-90f6-25caed113930,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-25cac23d-1fd3-4610-b429-18dc6b0a3da7,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-3f2bbce6-2b90-446b-a05a-3569fd549fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-2df5bd9e-4853-402c-b625-1d86df7b14f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-deec1a88-8bce-4671-8f53-5329e0ea21ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-6d3652a5-3fbd-490b-8052-5d01324fb85e,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-c34c9292-2b50-4787-b58d-646bd11a097c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199251933-172.17.0.18-1597370472151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46548,DS-dd490dd0-b7c1-41a8-8d7f-5f9bca39cd08,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-473c2eac-ce63-4443-90f6-25caed113930,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-25cac23d-1fd3-4610-b429-18dc6b0a3da7,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-3f2bbce6-2b90-446b-a05a-3569fd549fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-2df5bd9e-4853-402c-b625-1d86df7b14f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-deec1a88-8bce-4671-8f53-5329e0ea21ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-6d3652a5-3fbd-490b-8052-5d01324fb85e,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-c34c9292-2b50-4787-b58d-646bd11a097c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125141285-172.17.0.18-1597370512980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-a287234a-0f79-4548-867b-576b7e41f397,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-e1231218-1c5f-4701-b6b3-7d1a81d56787,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-04a13cbf-2191-41a3-848e-e185ebd11db3,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-a7984c08-696c-49d2-9a2c-d9ebcd0758f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-6cb7cb06-9830-4159-860c-9d8377ec83f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-4e602b01-b52c-4555-a00f-c38ec73239d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-75ac4a9a-448a-4f81-959a-9249d4da51ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-e001c8a2-64b9-4db7-ad87-9e53531446d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125141285-172.17.0.18-1597370512980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-a287234a-0f79-4548-867b-576b7e41f397,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-e1231218-1c5f-4701-b6b3-7d1a81d56787,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-04a13cbf-2191-41a3-848e-e185ebd11db3,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-a7984c08-696c-49d2-9a2c-d9ebcd0758f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-6cb7cb06-9830-4159-860c-9d8377ec83f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-4e602b01-b52c-4555-a00f-c38ec73239d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-75ac4a9a-448a-4f81-959a-9249d4da51ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-e001c8a2-64b9-4db7-ad87-9e53531446d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921660216-172.17.0.18-1597371095140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42885,DS-27ca4b09-46b7-4d86-a010-ee62cf7ba558,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-710bf082-4c1a-46ab-bb3f-2fcdadf24b89,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-2d2b650c-ae33-4156-9b71-ec83860b8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-9f05a3b9-03e7-418a-87b6-a68330fbae05,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-85a91004-a7c4-4489-b0e3-2ea705b339fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-5161383e-19c9-4e4d-b853-824b2d22cf17,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-76c30192-d039-45bb-9c37-ebdc46728784,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-49535a84-7172-416e-bee5-2cc3f7e488eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921660216-172.17.0.18-1597371095140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42885,DS-27ca4b09-46b7-4d86-a010-ee62cf7ba558,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-710bf082-4c1a-46ab-bb3f-2fcdadf24b89,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-2d2b650c-ae33-4156-9b71-ec83860b8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-9f05a3b9-03e7-418a-87b6-a68330fbae05,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-85a91004-a7c4-4489-b0e3-2ea705b339fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-5161383e-19c9-4e4d-b853-824b2d22cf17,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-76c30192-d039-45bb-9c37-ebdc46728784,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-49535a84-7172-416e-bee5-2cc3f7e488eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667519530-172.17.0.18-1597371175467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35224,DS-6131901c-0e80-4f8f-8795-45d069c951c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-bb67dc1e-f2ac-4389-9d58-947e307806fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-e51e255e-c9cd-46e6-92c3-be337629b168,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-216d0dbf-90f6-466d-b493-ce7d2acceeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-15947014-9f4d-46b9-b3b3-de3dbc31b83a,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-f477903f-a1f4-4ddd-aa06-7c64fab2805c,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-d1d9ca3b-2703-4e78-a66a-48922d9bbb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-ff5b5a40-9f09-49ff-947e-e0b4d4042a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667519530-172.17.0.18-1597371175467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35224,DS-6131901c-0e80-4f8f-8795-45d069c951c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-bb67dc1e-f2ac-4389-9d58-947e307806fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-e51e255e-c9cd-46e6-92c3-be337629b168,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-216d0dbf-90f6-466d-b493-ce7d2acceeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-15947014-9f4d-46b9-b3b3-de3dbc31b83a,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-f477903f-a1f4-4ddd-aa06-7c64fab2805c,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-d1d9ca3b-2703-4e78-a66a-48922d9bbb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-ff5b5a40-9f09-49ff-947e-e0b4d4042a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884698578-172.17.0.18-1597371766711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-4d3e8763-db31-4064-93cc-c56df2416dad,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-28f4758f-57df-481b-b513-19f536512f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-1243ad5b-5be9-46d5-b138-f2fbc64e89cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-a02af6a7-89bb-4819-a95f-c43f9ac9f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-32f7bb9b-1385-49d1-9f4a-76e3f1523611,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-06e73948-65a1-4838-abbf-15654271fe14,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-00d08d53-f097-43fc-98d3-8f3cde6c802a,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-6f5d4525-0154-4525-969c-3f5629c77ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884698578-172.17.0.18-1597371766711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-4d3e8763-db31-4064-93cc-c56df2416dad,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-28f4758f-57df-481b-b513-19f536512f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-1243ad5b-5be9-46d5-b138-f2fbc64e89cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-a02af6a7-89bb-4819-a95f-c43f9ac9f8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-32f7bb9b-1385-49d1-9f4a-76e3f1523611,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-06e73948-65a1-4838-abbf-15654271fe14,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-00d08d53-f097-43fc-98d3-8f3cde6c802a,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-6f5d4525-0154-4525-969c-3f5629c77ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1895050141-172.17.0.18-1597371953555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-1d51ae5d-f718-4899-97b0-328a4bd3e855,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-2195a18e-3402-4091-83b2-0235f2dc91fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-29abddc7-6609-41b5-8724-259e2a39fc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-6a7b6907-538c-4c33-8af9-b83109b42763,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-8114e0cb-a0d2-4486-9124-422c1acb2a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-fd9a0fec-8de0-4b70-aae9-032d1ee5e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-586a1fcd-5931-4b75-9dfc-8dce7d4c75d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-3d0ba77f-d04b-4d61-83b7-a275fcd95d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1895050141-172.17.0.18-1597371953555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-1d51ae5d-f718-4899-97b0-328a4bd3e855,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-2195a18e-3402-4091-83b2-0235f2dc91fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-29abddc7-6609-41b5-8724-259e2a39fc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-6a7b6907-538c-4c33-8af9-b83109b42763,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-8114e0cb-a0d2-4486-9124-422c1acb2a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-fd9a0fec-8de0-4b70-aae9-032d1ee5e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-586a1fcd-5931-4b75-9dfc-8dce7d4c75d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-3d0ba77f-d04b-4d61-83b7-a275fcd95d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312255029-172.17.0.18-1597372055912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-ea860e27-27cc-412d-87e7-1126b551e2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-5d111b82-27f4-4e55-b6a7-5e5fda66e99c,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-d4e02758-51a7-45a4-8d3f-7aca1da7e0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-a8b1603d-f336-4b1e-a8d7-764f7d22baea,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-d587cc8d-ca9f-414c-a187-19f3a876a512,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-11e92a77-5f31-480d-8e7d-8feb6391e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-8a5fb2b9-6480-481c-8009-1f359c6e5fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-0be3b0db-7c99-436c-aa39-c69b4daa00bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312255029-172.17.0.18-1597372055912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37777,DS-ea860e27-27cc-412d-87e7-1126b551e2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-5d111b82-27f4-4e55-b6a7-5e5fda66e99c,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-d4e02758-51a7-45a4-8d3f-7aca1da7e0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-a8b1603d-f336-4b1e-a8d7-764f7d22baea,DISK], DatanodeInfoWithStorage[127.0.0.1:33156,DS-d587cc8d-ca9f-414c-a187-19f3a876a512,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-11e92a77-5f31-480d-8e7d-8feb6391e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-8a5fb2b9-6480-481c-8009-1f359c6e5fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-0be3b0db-7c99-436c-aa39-c69b4daa00bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464362903-172.17.0.18-1597372831982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40814,DS-e68d9321-e9a1-451c-90bf-1309989c41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-4699d80d-edd4-40e3-9dfa-38f094d97d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-f9de0115-41fa-492d-964a-ecd50584bb98,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-382c3c47-c895-4b9e-9119-0d812d968adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-6fd06185-e350-4459-a573-16032d205546,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-a60f7873-ff7a-4147-a339-b8387b6a1ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-091ba9cc-51f1-4675-896c-2d43cc7063c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-7025a02b-220d-4139-9a7b-83809a1cb02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464362903-172.17.0.18-1597372831982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40814,DS-e68d9321-e9a1-451c-90bf-1309989c41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-4699d80d-edd4-40e3-9dfa-38f094d97d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-f9de0115-41fa-492d-964a-ecd50584bb98,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-382c3c47-c895-4b9e-9119-0d812d968adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-6fd06185-e350-4459-a573-16032d205546,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-a60f7873-ff7a-4147-a339-b8387b6a1ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-091ba9cc-51f1-4675-896c-2d43cc7063c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-7025a02b-220d-4139-9a7b-83809a1cb02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460015582-172.17.0.18-1597373528278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42017,DS-2f7955dc-c4b3-49bb-825a-5844f708b50a,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-5c679f55-3f08-4e80-9458-257f0baa926f,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-c154c5e0-af35-4dc3-8826-4d973e4c48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-dc73a63c-a396-4273-9811-75c1e105c491,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-653daf84-a60c-4faf-a412-afb22cdc51ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-f7ac75e9-c38e-4ec8-b3de-9b3bd2282311,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-119d9918-9617-4838-9aca-ab7bfe1f2ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-f4dba6a3-bbda-472d-9c9c-508d036ace37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460015582-172.17.0.18-1597373528278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42017,DS-2f7955dc-c4b3-49bb-825a-5844f708b50a,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-5c679f55-3f08-4e80-9458-257f0baa926f,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-c154c5e0-af35-4dc3-8826-4d973e4c48d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-dc73a63c-a396-4273-9811-75c1e105c491,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-653daf84-a60c-4faf-a412-afb22cdc51ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-f7ac75e9-c38e-4ec8-b3de-9b3bd2282311,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-119d9918-9617-4838-9aca-ab7bfe1f2ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-f4dba6a3-bbda-472d-9c9c-508d036ace37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52693292-172.17.0.18-1597374073068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-9c35e0b5-ac71-42f1-8b26-635ad96b5579,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-d6597e44-0faa-47b0-8e79-29d5c3607fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-9f5f95ab-43f9-4105-9326-709412ce6bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-6712d5be-8d4b-4ccc-b99d-1acd16f2bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-30650384-dc84-4101-a480-51e2893c1ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-e6de93ee-8012-4cdc-a0b5-1b25345de7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-24214618-e371-41f0-afb4-4acee4e664a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-628ad037-1939-499f-8d34-58ff47b0df78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52693292-172.17.0.18-1597374073068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-9c35e0b5-ac71-42f1-8b26-635ad96b5579,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-d6597e44-0faa-47b0-8e79-29d5c3607fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-9f5f95ab-43f9-4105-9326-709412ce6bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-6712d5be-8d4b-4ccc-b99d-1acd16f2bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-30650384-dc84-4101-a480-51e2893c1ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-e6de93ee-8012-4cdc-a0b5-1b25345de7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-24214618-e371-41f0-afb4-4acee4e664a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-628ad037-1939-499f-8d34-58ff47b0df78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.interval
component: hdfs:NameNode
v1: 30000
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566826636-172.17.0.18-1597374679087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-561f30fc-31d5-4c85-b211-7940fc26f9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-ee8f6141-d3df-499c-a678-17f44dd52865,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-80597f1e-7e4b-4065-a6ae-478551aecedb,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-f47680e5-f4da-4af6-acf5-3bfe7fc05021,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-70801908-20e2-42a3-8420-843120b3c066,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-6c4b505d-94eb-470f-abec-d3f78a9aa1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-173dbda5-5f33-4ec3-b7a7-9d4ec8b71a31,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-16d6c07d-0fe2-4b0a-b085-c75aeaf75723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566826636-172.17.0.18-1597374679087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-561f30fc-31d5-4c85-b211-7940fc26f9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-ee8f6141-d3df-499c-a678-17f44dd52865,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-80597f1e-7e4b-4065-a6ae-478551aecedb,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-f47680e5-f4da-4af6-acf5-3bfe7fc05021,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-70801908-20e2-42a3-8420-843120b3c066,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-6c4b505d-94eb-470f-abec-d3f78a9aa1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-173dbda5-5f33-4ec3-b7a7-9d4ec8b71a31,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-16d6c07d-0fe2-4b0a-b085-c75aeaf75723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5533
