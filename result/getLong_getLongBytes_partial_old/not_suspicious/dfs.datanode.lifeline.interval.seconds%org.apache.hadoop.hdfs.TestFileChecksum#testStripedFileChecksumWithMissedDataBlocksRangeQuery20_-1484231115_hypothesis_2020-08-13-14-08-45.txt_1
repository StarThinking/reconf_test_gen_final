reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33359646-172.17.0.7-1597327778123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40118,DS-131583f0-2a13-4166-85d4-61c83dafd344,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-5aaba05a-ce84-4aaa-8934-fc8f2763dc50,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-187b2ef9-0649-4c91-8bf7-6065d6e0b154,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-30634655-2795-48ec-ab76-0be5d406246c,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-e9ad155c-8bc8-44f6-985b-445b305a09b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-71046aef-e11b-42ed-8b8d-b009a3c8f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-3d43b77c-9a08-4710-8192-6bb6823c78f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-b85f020a-4d84-4b77-a18b-c9611d1bf821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33359646-172.17.0.7-1597327778123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40118,DS-131583f0-2a13-4166-85d4-61c83dafd344,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-5aaba05a-ce84-4aaa-8934-fc8f2763dc50,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-187b2ef9-0649-4c91-8bf7-6065d6e0b154,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-30634655-2795-48ec-ab76-0be5d406246c,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-e9ad155c-8bc8-44f6-985b-445b305a09b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-71046aef-e11b-42ed-8b8d-b009a3c8f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-3d43b77c-9a08-4710-8192-6bb6823c78f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-b85f020a-4d84-4b77-a18b-c9611d1bf821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230938357-172.17.0.7-1597328082716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-0babfc45-2ba1-475c-82c4-78aa5b05b3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-46772b4c-a8f6-4ecf-8f56-402eb21951bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-feaf7991-a454-4621-9f93-31145a9d0bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-56fb350d-6f1a-4684-9775-5092941eade8,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-69d791bf-aa1c-4ff6-a660-31e8ee90d4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-91630747-e999-4e67-9b79-59e43a1db94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-b89c668e-0071-47d2-9cd6-4bec1dea64c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-5b945091-f444-4a50-9f29-6deda672293c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230938357-172.17.0.7-1597328082716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-0babfc45-2ba1-475c-82c4-78aa5b05b3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-46772b4c-a8f6-4ecf-8f56-402eb21951bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-feaf7991-a454-4621-9f93-31145a9d0bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-56fb350d-6f1a-4684-9775-5092941eade8,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-69d791bf-aa1c-4ff6-a660-31e8ee90d4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-91630747-e999-4e67-9b79-59e43a1db94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-b89c668e-0071-47d2-9cd6-4bec1dea64c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-5b945091-f444-4a50-9f29-6deda672293c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269085520-172.17.0.7-1597328690702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-326b5228-9712-47c0-99f0-7dbdfef259ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-68f06d70-2539-4076-be88-014d1ddb0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-13d0bc0e-d95c-4c6c-9ad8-1ec62bf57bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-368b3ab2-e8ed-48cd-939a-c975b3cf835b,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-a2646937-1e9c-4c5b-8a9f-f645c4f58fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-f3ab8558-1839-4813-adea-5587c7a736e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-d0aec248-9379-4b17-9903-e0f263f2d814,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-a74ae69c-03ca-4704-a135-4ecaddf0a1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269085520-172.17.0.7-1597328690702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44053,DS-326b5228-9712-47c0-99f0-7dbdfef259ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-68f06d70-2539-4076-be88-014d1ddb0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-13d0bc0e-d95c-4c6c-9ad8-1ec62bf57bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-368b3ab2-e8ed-48cd-939a-c975b3cf835b,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-a2646937-1e9c-4c5b-8a9f-f645c4f58fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-f3ab8558-1839-4813-adea-5587c7a736e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-d0aec248-9379-4b17-9903-e0f263f2d814,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-a74ae69c-03ca-4704-a135-4ecaddf0a1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553817638-172.17.0.7-1597328959147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41248,DS-49e05c2b-e68b-48b9-b87b-6db16949dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f631c9c0-2799-455a-a505-c2b302e257c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-af2bb640-2bd7-45f5-8af6-62de64737c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-dc951f12-30e4-425d-9259-8b8f453fd64d,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-5a5d4cc2-ed26-40d4-964b-d21723563568,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-832b0a14-465b-47e3-abc8-2f79e9cf8d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-6890c9e6-6eab-4826-8fed-3a829e9a0c03,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-d5b4393f-5f37-4fc5-a5bb-4f0a388dc7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553817638-172.17.0.7-1597328959147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41248,DS-49e05c2b-e68b-48b9-b87b-6db16949dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f631c9c0-2799-455a-a505-c2b302e257c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-af2bb640-2bd7-45f5-8af6-62de64737c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-dc951f12-30e4-425d-9259-8b8f453fd64d,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-5a5d4cc2-ed26-40d4-964b-d21723563568,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-832b0a14-465b-47e3-abc8-2f79e9cf8d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-6890c9e6-6eab-4826-8fed-3a829e9a0c03,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-d5b4393f-5f37-4fc5-a5bb-4f0a388dc7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104239647-172.17.0.7-1597329666286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-b39095b0-44f3-4e15-aeb3-f48ba3022cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-e069b465-9b6a-4d0e-adf6-c7146c5a02d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-7c3205bf-63b0-4abb-b4c4-f50e1eb442a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-f74a5e1d-a263-46d6-be76-2777e5be43d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-98257e04-4e8a-49ed-998d-e001791ab53f,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-b390615d-0030-4383-80fe-d2fcf7232b61,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-d127cfff-0324-4327-bd8a-b31437892e44,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-3d900a61-acc5-4947-9457-a3bda9d61218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104239647-172.17.0.7-1597329666286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-b39095b0-44f3-4e15-aeb3-f48ba3022cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-e069b465-9b6a-4d0e-adf6-c7146c5a02d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-7c3205bf-63b0-4abb-b4c4-f50e1eb442a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-f74a5e1d-a263-46d6-be76-2777e5be43d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-98257e04-4e8a-49ed-998d-e001791ab53f,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-b390615d-0030-4383-80fe-d2fcf7232b61,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-d127cfff-0324-4327-bd8a-b31437892e44,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-3d900a61-acc5-4947-9457-a3bda9d61218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476168710-172.17.0.7-1597329741229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-884fa94b-7776-4353-8cf5-6040b36ed1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-92f9bd86-36ce-4d0d-8a1d-94741903e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-3e0a7469-c2d1-4303-aff6-da3a1d68826d,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-3710543d-c5d7-4b04-b4ad-0e1e3abaf8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-eff20d77-b5c8-41e0-a072-b3587ea24f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-3104a320-4733-47f4-a0f6-efadb14f12a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-dcceadbd-3cae-4477-955a-c588f0ffaf37,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-5c244fbf-7563-436e-967a-7d54848090dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476168710-172.17.0.7-1597329741229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-884fa94b-7776-4353-8cf5-6040b36ed1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-92f9bd86-36ce-4d0d-8a1d-94741903e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-3e0a7469-c2d1-4303-aff6-da3a1d68826d,DISK], DatanodeInfoWithStorage[127.0.0.1:34804,DS-3710543d-c5d7-4b04-b4ad-0e1e3abaf8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-eff20d77-b5c8-41e0-a072-b3587ea24f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-3104a320-4733-47f4-a0f6-efadb14f12a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-dcceadbd-3cae-4477-955a-c588f0ffaf37,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-5c244fbf-7563-436e-967a-7d54848090dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480715634-172.17.0.7-1597329778537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35358,DS-b47c2b73-8b50-446e-8d56-c47d188127c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-1be95a58-f11d-4f7a-b071-489554b0e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-bd96bc89-3b4b-41ae-ae46-9d7df2bd9347,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-c5ab2db4-2c7c-4a58-bf01-9c42e8495c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-df55a42e-b3bf-4a70-b1b8-66c6d2656a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-e653c6ac-6996-4ef1-b2e0-f90306774f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-36c0746d-07a0-4804-80e8-7f3a99cd1007,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-0c6f0135-5a86-4ae3-99b1-a073728e8826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480715634-172.17.0.7-1597329778537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35358,DS-b47c2b73-8b50-446e-8d56-c47d188127c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-1be95a58-f11d-4f7a-b071-489554b0e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-bd96bc89-3b4b-41ae-ae46-9d7df2bd9347,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-c5ab2db4-2c7c-4a58-bf01-9c42e8495c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-df55a42e-b3bf-4a70-b1b8-66c6d2656a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-e653c6ac-6996-4ef1-b2e0-f90306774f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-36c0746d-07a0-4804-80e8-7f3a99cd1007,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-0c6f0135-5a86-4ae3-99b1-a073728e8826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272412235-172.17.0.7-1597330183054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-25261763-f0c5-42e5-8aaa-cb8fde9a5e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-0336136b-76e5-4fc2-80c9-84f785b9949e,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-1768518f-b392-4f0f-8a27-11cd231c0e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-fabc30da-1e74-42c3-9274-45fb0387a970,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e0ac71e7-6a7c-416c-a5a6-30c33d0c335b,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-b42af342-fef8-4c98-8501-6f2a75c9df12,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-0a9229c9-b5fb-4d05-ab1a-5bea8513bf66,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-f1a09075-fa98-42df-8a5b-eecbf16dbf69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272412235-172.17.0.7-1597330183054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36532,DS-25261763-f0c5-42e5-8aaa-cb8fde9a5e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-0336136b-76e5-4fc2-80c9-84f785b9949e,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-1768518f-b392-4f0f-8a27-11cd231c0e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-fabc30da-1e74-42c3-9274-45fb0387a970,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e0ac71e7-6a7c-416c-a5a6-30c33d0c335b,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-b42af342-fef8-4c98-8501-6f2a75c9df12,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-0a9229c9-b5fb-4d05-ab1a-5bea8513bf66,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-f1a09075-fa98-42df-8a5b-eecbf16dbf69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249279557-172.17.0.7-1597330475456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-6d12a716-94f3-4407-82da-c6bebf558090,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-31a203c6-0863-4349-b2ba-d863732880ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-02c7003c-afc7-4582-b5ae-c6ed3487df48,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-23eda2ce-42b0-4778-84ff-265bb2e4ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-f2f175c0-0940-4d0e-abdc-f52c46dc9701,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-8887cd95-612d-4ce5-ba31-9ed34c88c676,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-7633eef0-755f-43ba-9a5f-d3fe381ace4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-3fcfd550-0c62-43f8-86ae-b966e3bd5c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-249279557-172.17.0.7-1597330475456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-6d12a716-94f3-4407-82da-c6bebf558090,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-31a203c6-0863-4349-b2ba-d863732880ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-02c7003c-afc7-4582-b5ae-c6ed3487df48,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-23eda2ce-42b0-4778-84ff-265bb2e4ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-f2f175c0-0940-4d0e-abdc-f52c46dc9701,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-8887cd95-612d-4ce5-ba31-9ed34c88c676,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-7633eef0-755f-43ba-9a5f-d3fe381ace4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-3fcfd550-0c62-43f8-86ae-b966e3bd5c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545907579-172.17.0.7-1597330739927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38704,DS-fa9f023a-2335-4a01-a703-d36eae68c5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-7edd2a17-4bf7-4cac-bed2-958c22345c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-af76a031-aea6-467b-900d-abbf36e7561c,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-26ac410e-9f2d-4afc-80ac-d0a1d8c1ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-7deb7c25-f962-485e-b61f-7a0608e11b52,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-815acc50-7bc2-4ccf-b33a-9222c5ea602f,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-4ca2a10e-2755-48c1-8c31-6021d96a145a,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-cdafff2f-bcff-4e33-92e4-28621bed5980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545907579-172.17.0.7-1597330739927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38704,DS-fa9f023a-2335-4a01-a703-d36eae68c5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-7edd2a17-4bf7-4cac-bed2-958c22345c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-af76a031-aea6-467b-900d-abbf36e7561c,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-26ac410e-9f2d-4afc-80ac-d0a1d8c1ada3,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-7deb7c25-f962-485e-b61f-7a0608e11b52,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-815acc50-7bc2-4ccf-b33a-9222c5ea602f,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-4ca2a10e-2755-48c1-8c31-6021d96a145a,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-cdafff2f-bcff-4e33-92e4-28621bed5980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619970055-172.17.0.7-1597331959749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37964,DS-b49ec76c-f8d7-491d-939e-1949963c049d,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-83726e52-0094-4c67-b241-9ebad824835b,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-19b5eddc-1e34-4a1f-ab05-5ad33f032904,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-07f0c466-0692-4e0d-967e-babab58e1790,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-548a99ae-bf3b-4394-8184-c41a19d09c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-729cb404-92db-4e58-97b4-cb3342c6c831,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-b22d3f77-1143-4186-9fa0-87453736eb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-c5b07a9b-432c-4a20-a15f-ff8cabf3c069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619970055-172.17.0.7-1597331959749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37964,DS-b49ec76c-f8d7-491d-939e-1949963c049d,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-83726e52-0094-4c67-b241-9ebad824835b,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-19b5eddc-1e34-4a1f-ab05-5ad33f032904,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-07f0c466-0692-4e0d-967e-babab58e1790,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-548a99ae-bf3b-4394-8184-c41a19d09c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-729cb404-92db-4e58-97b4-cb3342c6c831,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-b22d3f77-1143-4186-9fa0-87453736eb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-c5b07a9b-432c-4a20-a15f-ff8cabf3c069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365023798-172.17.0.7-1597332003094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33716,DS-1b7e6297-8327-413f-8c55-df299b3d2795,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-7a58b4ba-9bff-40ef-9a46-dd96a7b14f24,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-52bf7e3b-bee6-4f55-ad24-a6144b318c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-7f9d55d1-55a0-4ee4-a958-dd2fd8e203b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-bdeebd0b-7caf-42ca-84e7-91065468991d,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-18ea39a1-ccad-4674-9109-3aea7f350709,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-a33d2c26-624a-4914-b657-a652c9870213,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-b64740cd-bc0b-4caf-9e52-dcf42acfb59a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365023798-172.17.0.7-1597332003094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33716,DS-1b7e6297-8327-413f-8c55-df299b3d2795,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-7a58b4ba-9bff-40ef-9a46-dd96a7b14f24,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-52bf7e3b-bee6-4f55-ad24-a6144b318c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-7f9d55d1-55a0-4ee4-a958-dd2fd8e203b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-bdeebd0b-7caf-42ca-84e7-91065468991d,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-18ea39a1-ccad-4674-9109-3aea7f350709,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-a33d2c26-624a-4914-b657-a652c9870213,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-b64740cd-bc0b-4caf-9e52-dcf42acfb59a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145270982-172.17.0.7-1597332190520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38396,DS-b0843caf-dc56-4121-8581-c695b735d682,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-3b5c6a5f-54aa-45fd-b6b8-278075eedd50,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-56856a80-baba-491a-a844-c4887a632d05,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-7896b1b5-f8d0-4284-83b0-1699de8f498b,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-d1b7dc7e-66e7-472d-a63f-002b4be52e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-4f8c7255-cc67-4318-a4e8-0ff768e27c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-f6747129-6981-4988-934e-3c5a6214c749,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-c205eba0-9ea1-45cd-958c-74c41ca40661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145270982-172.17.0.7-1597332190520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38396,DS-b0843caf-dc56-4121-8581-c695b735d682,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-3b5c6a5f-54aa-45fd-b6b8-278075eedd50,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-56856a80-baba-491a-a844-c4887a632d05,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-7896b1b5-f8d0-4284-83b0-1699de8f498b,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-d1b7dc7e-66e7-472d-a63f-002b4be52e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-4f8c7255-cc67-4318-a4e8-0ff768e27c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-f6747129-6981-4988-934e-3c5a6214c749,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-c205eba0-9ea1-45cd-958c-74c41ca40661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628021628-172.17.0.7-1597332553364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-055f2b1a-1caf-4847-bd18-0c74556d91d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-333837a0-7412-42fb-9f54-157a437a89b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-033d0ca8-b592-4108-bf8e-466f2c41d9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-c81278fa-737a-4d36-9fac-489bab2ec7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-2e32f21c-5d67-4262-b681-b3cb2cfbcc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-643ea032-4d77-48f9-9192-9a79d8a915eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-e170a9ea-9d89-4585-aa6c-9e4f11e988d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-88a7c48c-a68d-4d39-87a6-d99aa3060502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628021628-172.17.0.7-1597332553364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43637,DS-055f2b1a-1caf-4847-bd18-0c74556d91d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-333837a0-7412-42fb-9f54-157a437a89b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-033d0ca8-b592-4108-bf8e-466f2c41d9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-c81278fa-737a-4d36-9fac-489bab2ec7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-2e32f21c-5d67-4262-b681-b3cb2cfbcc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-643ea032-4d77-48f9-9192-9a79d8a915eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-e170a9ea-9d89-4585-aa6c-9e4f11e988d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-88a7c48c-a68d-4d39-87a6-d99aa3060502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421652180-172.17.0.7-1597333152369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-27b7bbdb-6d1b-416b-8341-e9074b856768,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-362a0bde-a172-43bb-ab53-e5a98e42b954,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-27343c8e-6c54-46ca-abc5-e54210089527,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-e44a2f7b-d85e-4322-91d6-4c4e48d2457e,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-a172e2ba-42b6-4e47-9ea1-1810de918fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-364408f2-655c-4211-a520-a44797079d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-112de6c6-76e9-4a56-925a-bb021f1d71a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-ffb0f1c4-cacd-4fe0-a77f-0a6c07b21ad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421652180-172.17.0.7-1597333152369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-27b7bbdb-6d1b-416b-8341-e9074b856768,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-362a0bde-a172-43bb-ab53-e5a98e42b954,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-27343c8e-6c54-46ca-abc5-e54210089527,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-e44a2f7b-d85e-4322-91d6-4c4e48d2457e,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-a172e2ba-42b6-4e47-9ea1-1810de918fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-364408f2-655c-4211-a520-a44797079d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-112de6c6-76e9-4a56-925a-bb021f1d71a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-ffb0f1c4-cacd-4fe0-a77f-0a6c07b21ad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701144028-172.17.0.7-1597333303038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38363,DS-fe93adee-4d3a-4ea9-9741-af728e19e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-442f1d9e-d59e-4732-a84b-d3f1d5ea2a96,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-9d65d91b-59cb-4b20-a3bc-b0369d2cf342,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-b4262ce1-8a73-416a-a5a6-22fabbf81fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-753cb750-9d98-4adb-888a-093e2692ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-64ca13ff-8991-4abb-8b23-c687c097b2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-749a92e6-fdd8-4abb-904b-21452e56f5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d1406016-906a-4d7e-8e8d-6b46c053c0d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701144028-172.17.0.7-1597333303038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38363,DS-fe93adee-4d3a-4ea9-9741-af728e19e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-442f1d9e-d59e-4732-a84b-d3f1d5ea2a96,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-9d65d91b-59cb-4b20-a3bc-b0369d2cf342,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-b4262ce1-8a73-416a-a5a6-22fabbf81fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-753cb750-9d98-4adb-888a-093e2692ddec,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-64ca13ff-8991-4abb-8b23-c687c097b2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-749a92e6-fdd8-4abb-904b-21452e56f5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-d1406016-906a-4d7e-8e8d-6b46c053c0d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5598
