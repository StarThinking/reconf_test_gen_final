reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621559631-172.17.0.14-1597282572592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44392,DS-ef55aab0-ff3f-424b-ad0b-42de05ad2ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-93e84f2b-0d07-4871-b5ea-bf46bb1efb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-46c2dbe7-9648-45f6-b89d-5bd421e217cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-b1304708-b058-4c82-9775-b49701459dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-1e1c7d24-443d-4243-a629-1d3bd7233cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-c867344b-66c2-436a-bac6-5e546e447070,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-f1fcdbb8-0fe6-4109-82e7-ee539de47846,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-0568cbeb-350c-43b5-9caf-0bd941ce7e48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621559631-172.17.0.14-1597282572592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44392,DS-ef55aab0-ff3f-424b-ad0b-42de05ad2ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-93e84f2b-0d07-4871-b5ea-bf46bb1efb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-46c2dbe7-9648-45f6-b89d-5bd421e217cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-b1304708-b058-4c82-9775-b49701459dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-1e1c7d24-443d-4243-a629-1d3bd7233cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-c867344b-66c2-436a-bac6-5e546e447070,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-f1fcdbb8-0fe6-4109-82e7-ee539de47846,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-0568cbeb-350c-43b5-9caf-0bd941ce7e48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452103922-172.17.0.14-1597282753903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35423,DS-b10b1927-6fba-4695-b74f-22d55d1014eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-2e741acd-7347-48ee-b894-2377f52bb22c,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-b4638d62-bc38-49b1-b882-bf087494b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-490321a1-6a3d-42bb-b5ba-f635b37aea04,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-64ed7bb6-d902-41bf-9d5e-67bcdd053dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-445ab2f0-043b-4611-8b92-cc70ed95322c,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-8a4a5421-697e-4c6c-853e-fa491dd79d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-d21f8f51-509d-4ad8-86f2-13535b0e8a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-452103922-172.17.0.14-1597282753903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35423,DS-b10b1927-6fba-4695-b74f-22d55d1014eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-2e741acd-7347-48ee-b894-2377f52bb22c,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-b4638d62-bc38-49b1-b882-bf087494b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-490321a1-6a3d-42bb-b5ba-f635b37aea04,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-64ed7bb6-d902-41bf-9d5e-67bcdd053dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-445ab2f0-043b-4611-8b92-cc70ed95322c,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-8a4a5421-697e-4c6c-853e-fa491dd79d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-d21f8f51-509d-4ad8-86f2-13535b0e8a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698850836-172.17.0.14-1597282868964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36329,DS-e07dd630-8d21-43f4-85ab-373fee1ea420,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-058247fc-eb35-4de7-9c73-51a4492c1b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-88cc7b94-2971-4cc3-9943-b3c512e71201,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-072619fd-1769-4442-8cc4-0841a6b84b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-0ec89469-74a9-4653-a85b-782b4227cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-9d844e49-ba1e-42f6-8c59-7b6aed8febe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-65869e27-234f-47c3-90ea-24c36ef1215b,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-9c2d8e58-3889-4a69-9aae-8432c3a5797b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698850836-172.17.0.14-1597282868964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36329,DS-e07dd630-8d21-43f4-85ab-373fee1ea420,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-058247fc-eb35-4de7-9c73-51a4492c1b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-88cc7b94-2971-4cc3-9943-b3c512e71201,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-072619fd-1769-4442-8cc4-0841a6b84b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-0ec89469-74a9-4653-a85b-782b4227cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-9d844e49-ba1e-42f6-8c59-7b6aed8febe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-65869e27-234f-47c3-90ea-24c36ef1215b,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-9c2d8e58-3889-4a69-9aae-8432c3a5797b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494909594-172.17.0.14-1597283014161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42708,DS-0beb9e99-2867-4101-9592-206eed0f24cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-0b275166-5e04-4a55-b9a6-f9b2095f6f68,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-f4a7df8c-b24c-4581-aa3a-17b5455dc647,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-bba2026d-c852-4e5e-8f0b-84dd8e118c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-ab6c149c-8373-4613-b3a0-abacda90273f,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-ac71bbae-aaa6-46cb-b302-ee848b65b8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-41a86957-de8a-4d61-9573-6ba779158f30,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-dce09781-f988-456c-acd8-54772e449939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494909594-172.17.0.14-1597283014161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42708,DS-0beb9e99-2867-4101-9592-206eed0f24cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-0b275166-5e04-4a55-b9a6-f9b2095f6f68,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-f4a7df8c-b24c-4581-aa3a-17b5455dc647,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-bba2026d-c852-4e5e-8f0b-84dd8e118c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-ab6c149c-8373-4613-b3a0-abacda90273f,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-ac71bbae-aaa6-46cb-b302-ee848b65b8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-41a86957-de8a-4d61-9573-6ba779158f30,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-dce09781-f988-456c-acd8-54772e449939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137212284-172.17.0.14-1597283518701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34099,DS-4801b8cc-fb07-46f1-867b-114cf4ffad68,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-f2028f25-96ff-44e7-a5cf-5293b2b8d742,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-ea6c5deb-75b1-4cea-b7b8-b2612ceb7ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-d4e487be-c576-444b-8de1-44c3e3b8529a,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-3db301c9-f5cb-44ed-a6e4-516414a47bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-a8279929-53e3-48c4-902b-4bd8189913bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-7eb87cd6-7525-4b5d-8b6e-10acca6e2dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-54f2a94d-c875-46aa-8ff0-4e91d1885ce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137212284-172.17.0.14-1597283518701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34099,DS-4801b8cc-fb07-46f1-867b-114cf4ffad68,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-f2028f25-96ff-44e7-a5cf-5293b2b8d742,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-ea6c5deb-75b1-4cea-b7b8-b2612ceb7ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-d4e487be-c576-444b-8de1-44c3e3b8529a,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-3db301c9-f5cb-44ed-a6e4-516414a47bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-a8279929-53e3-48c4-902b-4bd8189913bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-7eb87cd6-7525-4b5d-8b6e-10acca6e2dba,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-54f2a94d-c875-46aa-8ff0-4e91d1885ce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443942399-172.17.0.14-1597283937631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34005,DS-58e00923-538a-4844-929b-0b9a2aec4812,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-7d59e9fc-34f7-41bd-9a71-f35737c3d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-0508fbda-37a1-401e-bc03-da67d0e9a297,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-f3484fdf-aef8-4bf1-b251-a65b8e8044a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-4b112dd2-6e40-43bb-a6d6-76b56b445f76,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-4fd18148-5684-48c5-83b4-7a8cb84c52ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-3fde2bf8-a45c-407e-bacc-d9fd8f170b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-17f91c75-5d4e-4ed1-820d-7fed7cfbebcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1443942399-172.17.0.14-1597283937631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34005,DS-58e00923-538a-4844-929b-0b9a2aec4812,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-7d59e9fc-34f7-41bd-9a71-f35737c3d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-0508fbda-37a1-401e-bc03-da67d0e9a297,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-f3484fdf-aef8-4bf1-b251-a65b8e8044a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-4b112dd2-6e40-43bb-a6d6-76b56b445f76,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-4fd18148-5684-48c5-83b4-7a8cb84c52ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-3fde2bf8-a45c-407e-bacc-d9fd8f170b38,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-17f91c75-5d4e-4ed1-820d-7fed7cfbebcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500844726-172.17.0.14-1597285083259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44555,DS-516da682-8293-4d96-9327-1aa11bdb06c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-3f97c694-d79b-4982-b81f-948e3d7bf921,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-3f51984e-942c-4fc6-8772-0f3dbd22493e,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-ebed6b74-0987-43d6-b449-1a7a0a348f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-7a440ca3-b3ae-48fa-80eb-26657b3e7a89,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-8e664e38-06ab-466b-ba87-869aded3d42c,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-aab718a7-ea12-44c8-8c7d-4c25f44ee5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-4eb58780-32ee-4b20-b00b-200511a057ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500844726-172.17.0.14-1597285083259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44555,DS-516da682-8293-4d96-9327-1aa11bdb06c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-3f97c694-d79b-4982-b81f-948e3d7bf921,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-3f51984e-942c-4fc6-8772-0f3dbd22493e,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-ebed6b74-0987-43d6-b449-1a7a0a348f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-7a440ca3-b3ae-48fa-80eb-26657b3e7a89,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-8e664e38-06ab-466b-ba87-869aded3d42c,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-aab718a7-ea12-44c8-8c7d-4c25f44ee5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-4eb58780-32ee-4b20-b00b-200511a057ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728025607-172.17.0.14-1597285301177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-53e3c39d-a8a7-4df5-9b97-a140dcc4511b,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-0e09988b-a4f3-473e-a24c-9e3434ea975d,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-fea4628c-3035-4cb3-b69d-5bc20aa701b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-d5bb1141-705f-43b1-86e9-bbc9e7e9764e,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-94ce6cb8-fc5b-4fac-853c-6a1721be3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-7ee95b53-1c0a-4415-bbbd-8dfeae5b9747,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-9424d6cd-2078-4926-a51c-ed859af4f372,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-d86fdcee-5386-4ffc-937c-b4382bf6e7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728025607-172.17.0.14-1597285301177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-53e3c39d-a8a7-4df5-9b97-a140dcc4511b,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-0e09988b-a4f3-473e-a24c-9e3434ea975d,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-fea4628c-3035-4cb3-b69d-5bc20aa701b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-d5bb1141-705f-43b1-86e9-bbc9e7e9764e,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-94ce6cb8-fc5b-4fac-853c-6a1721be3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-7ee95b53-1c0a-4415-bbbd-8dfeae5b9747,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-9424d6cd-2078-4926-a51c-ed859af4f372,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-d86fdcee-5386-4ffc-937c-b4382bf6e7cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983101196-172.17.0.14-1597285341706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39487,DS-4b90d737-c069-4aa4-a5b7-8f21a7a30fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-12ed1b7c-1abe-4bee-802c-73d8ebfd3f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-1b9b856d-0493-4454-a458-9d6691fb716b,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-c116baa1-7973-47f1-bfd9-cf384162d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-5e5b4fce-2def-4ed7-a248-bd3045dae808,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-2b7d7411-db5a-4c43-9de2-ae8e7eda5fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-c51a7534-bee9-4545-b864-1d5eba75034d,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-5fe0cf4b-1bda-4353-9ccc-fad983187845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983101196-172.17.0.14-1597285341706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39487,DS-4b90d737-c069-4aa4-a5b7-8f21a7a30fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-12ed1b7c-1abe-4bee-802c-73d8ebfd3f62,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-1b9b856d-0493-4454-a458-9d6691fb716b,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-c116baa1-7973-47f1-bfd9-cf384162d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-5e5b4fce-2def-4ed7-a248-bd3045dae808,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-2b7d7411-db5a-4c43-9de2-ae8e7eda5fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-c51a7534-bee9-4545-b864-1d5eba75034d,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-5fe0cf4b-1bda-4353-9ccc-fad983187845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906110451-172.17.0.14-1597285585782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-8c9a7888-d672-4daf-a332-9d40a9facec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-a6edb8a1-4ea3-428b-96b8-6847b0b9bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-a5cc57ef-89b3-4628-8315-331c537d3e78,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-bd958ee4-6f9d-444b-a797-6dde9e4c0cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-f66dd819-a25b-4448-a803-0cf1a1ca016d,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-bfc99088-004b-4399-bedb-54a2b5d7f1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-32e53996-9007-4dd4-b5fa-06dd38e93714,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-41f3f69b-02c8-455e-9e3a-dff5dc2bb48e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906110451-172.17.0.14-1597285585782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-8c9a7888-d672-4daf-a332-9d40a9facec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-a6edb8a1-4ea3-428b-96b8-6847b0b9bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-a5cc57ef-89b3-4628-8315-331c537d3e78,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-bd958ee4-6f9d-444b-a797-6dde9e4c0cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-f66dd819-a25b-4448-a803-0cf1a1ca016d,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-bfc99088-004b-4399-bedb-54a2b5d7f1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-32e53996-9007-4dd4-b5fa-06dd38e93714,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-41f3f69b-02c8-455e-9e3a-dff5dc2bb48e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803223624-172.17.0.14-1597285803095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38553,DS-2fa1a4d2-a2bd-42a5-b1d4-f69a8448f776,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-9d43a8e8-6651-426e-ab28-6f6c19bde24d,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-74636c19-ac79-405a-9488-1e28d62c1ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-681f6d14-823c-4315-b226-6771771c64e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-8d47377e-5d93-40a6-99c4-d161b037b46d,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-ebaabc5c-4853-408a-9161-6ae77a2896f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-231153b8-089e-4f24-9221-ecf5c6c84171,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-63a60f81-1ce2-4b7d-9e86-341fe6b24c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803223624-172.17.0.14-1597285803095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38553,DS-2fa1a4d2-a2bd-42a5-b1d4-f69a8448f776,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-9d43a8e8-6651-426e-ab28-6f6c19bde24d,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-74636c19-ac79-405a-9488-1e28d62c1ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-681f6d14-823c-4315-b226-6771771c64e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-8d47377e-5d93-40a6-99c4-d161b037b46d,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-ebaabc5c-4853-408a-9161-6ae77a2896f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-231153b8-089e-4f24-9221-ecf5c6c84171,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-63a60f81-1ce2-4b7d-9e86-341fe6b24c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952795418-172.17.0.14-1597286012896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-941d6854-6a7c-4b63-9307-c2d425c014b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-d4eb934d-f70c-4a1c-9b96-73818751bc97,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-0ae46652-1e1b-4a2d-a0a5-4ad3c63cedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-b1a56987-8aba-47b9-8fda-fa8e71adedff,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-a30ffe38-49cc-4bed-a1e6-658b6e33d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-d4e8274d-cc83-4c40-96cb-119b8a3ecda5,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-6eaac94e-70be-43a5-9f85-2ea9194161c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-2d50e817-c589-46c1-8b2f-b08adff18c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952795418-172.17.0.14-1597286012896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-941d6854-6a7c-4b63-9307-c2d425c014b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-d4eb934d-f70c-4a1c-9b96-73818751bc97,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-0ae46652-1e1b-4a2d-a0a5-4ad3c63cedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-b1a56987-8aba-47b9-8fda-fa8e71adedff,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-a30ffe38-49cc-4bed-a1e6-658b6e33d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-d4e8274d-cc83-4c40-96cb-119b8a3ecda5,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-6eaac94e-70be-43a5-9f85-2ea9194161c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-2d50e817-c589-46c1-8b2f-b08adff18c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931074890-172.17.0.14-1597286156550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42101,DS-6b9eced9-5df0-45b8-8dc9-6dc8d353ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-6f5b70dc-76aa-48d1-bee8-b9222d8609df,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-445436fa-b75a-4050-995e-ace4da0be373,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-00ec61c1-9a03-4c5e-b367-1eaddbbce01b,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-f551763f-73c7-40e1-933e-e98fc531a392,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-68b6a83a-32ca-40cc-964f-64af6c7adf00,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-cb937dae-3181-4bd0-8233-8d69f4be6775,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-411d6136-6ea1-44b0-8598-9ab1f49f9b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931074890-172.17.0.14-1597286156550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42101,DS-6b9eced9-5df0-45b8-8dc9-6dc8d353ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-6f5b70dc-76aa-48d1-bee8-b9222d8609df,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-445436fa-b75a-4050-995e-ace4da0be373,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-00ec61c1-9a03-4c5e-b367-1eaddbbce01b,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-f551763f-73c7-40e1-933e-e98fc531a392,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-68b6a83a-32ca-40cc-964f-64af6c7adf00,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-cb937dae-3181-4bd0-8233-8d69f4be6775,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-411d6136-6ea1-44b0-8598-9ab1f49f9b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909806243-172.17.0.14-1597286233173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33267,DS-deaccf8b-4289-44ba-bbea-029f99d60700,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-fa4edaf9-a03c-4cb5-ac18-ab59c9e6fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-f75f2438-3247-4406-bebd-a21a3bcb1807,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-57c1a7fd-7df8-49b4-9af4-1da667a93744,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-b0b91c30-d43d-4476-9dd0-a42c6a1c9b46,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-f7b634c0-984e-4bb6-a4a4-5f1f0afa4ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-64f27d2b-61a2-4ea3-84ed-384a48b03618,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-5fa1845c-ecb0-4fd0-b769-62af667d8cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909806243-172.17.0.14-1597286233173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33267,DS-deaccf8b-4289-44ba-bbea-029f99d60700,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-fa4edaf9-a03c-4cb5-ac18-ab59c9e6fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-f75f2438-3247-4406-bebd-a21a3bcb1807,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-57c1a7fd-7df8-49b4-9af4-1da667a93744,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-b0b91c30-d43d-4476-9dd0-a42c6a1c9b46,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-f7b634c0-984e-4bb6-a4a4-5f1f0afa4ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-64f27d2b-61a2-4ea3-84ed-384a48b03618,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-5fa1845c-ecb0-4fd0-b769-62af667d8cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46972394-172.17.0.14-1597286345902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-04de22ef-406c-45ef-b080-79c594289336,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-c3c5d75b-3463-4814-af54-f76107fcca32,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-d783f570-0f72-4083-8048-19acdc7c171d,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-6bda3194-4812-4134-bd5d-46a1c75b5acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-fa900ce4-37ea-405c-8e55-e4421bb0a9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-1f444d15-63fe-4143-84d5-ede3e1fb88ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-b61da89f-ebe9-413f-b1e6-d7ac0d634ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-6ae2525f-c356-496a-aa53-1a975a455f09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46972394-172.17.0.14-1597286345902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-04de22ef-406c-45ef-b080-79c594289336,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-c3c5d75b-3463-4814-af54-f76107fcca32,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-d783f570-0f72-4083-8048-19acdc7c171d,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-6bda3194-4812-4134-bd5d-46a1c75b5acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-fa900ce4-37ea-405c-8e55-e4421bb0a9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-1f444d15-63fe-4143-84d5-ede3e1fb88ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-b61da89f-ebe9-413f-b1e6-d7ac0d634ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-6ae2525f-c356-496a-aa53-1a975a455f09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 10m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10742752-172.17.0.14-1597287081113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-90bbaf9e-09c3-420f-b67c-58d08c72cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-b1f86b84-ba2e-47d2-9193-da09a43b5dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-d80e9cbb-d58d-42fc-979c-614efa1f38bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-e49cb3b7-7c57-4d83-bcce-4433f878123e,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-7a5718b0-e33f-45af-878a-a4c943b366dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-51cda230-0bc3-4c37-bd7d-52b71350e2df,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-8f4320da-6c43-46e6-9196-bbc3d3b4d097,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-879f4134-ce23-4a2d-a723-f438b8da7b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10742752-172.17.0.14-1597287081113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46735,DS-90bbaf9e-09c3-420f-b67c-58d08c72cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-b1f86b84-ba2e-47d2-9193-da09a43b5dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-d80e9cbb-d58d-42fc-979c-614efa1f38bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-e49cb3b7-7c57-4d83-bcce-4433f878123e,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-7a5718b0-e33f-45af-878a-a4c943b366dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-51cda230-0bc3-4c37-bd7d-52b71350e2df,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-8f4320da-6c43-46e6-9196-bbc3d3b4d097,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-879f4134-ce23-4a2d-a723-f438b8da7b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5552
