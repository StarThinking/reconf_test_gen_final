reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328000680-172.17.0.13-1597547572991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46841,DS-2f4945eb-fc7d-4b71-8764-5c6699c2a392,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-b6291881-5e5f-42eb-9ba0-d44ac30795a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-9904c2c0-fb02-459e-8025-9744f19783e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-c1142ecb-e3b2-4590-8652-b80dedbdafb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-cb58f7a6-c12c-417a-bcf2-550763d03bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-b7d537c7-3e71-4aaa-b832-99321f4d680d,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-49adf309-ae7e-4c08-b089-731d3ddebd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-66c89a56-28bd-4c4b-8981-66211531c628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328000680-172.17.0.13-1597547572991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46841,DS-2f4945eb-fc7d-4b71-8764-5c6699c2a392,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-b6291881-5e5f-42eb-9ba0-d44ac30795a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-9904c2c0-fb02-459e-8025-9744f19783e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-c1142ecb-e3b2-4590-8652-b80dedbdafb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-cb58f7a6-c12c-417a-bcf2-550763d03bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-b7d537c7-3e71-4aaa-b832-99321f4d680d,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-49adf309-ae7e-4c08-b089-731d3ddebd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-66c89a56-28bd-4c4b-8981-66211531c628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947618842-172.17.0.13-1597547685189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-9debc4df-3449-4cf5-a714-97cdf0687bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-492e67c7-80ce-442a-92d8-47d2a1984dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-066bf3b7-9c5f-4abe-8c5a-3edb066b8a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-53c69364-3646-4aa7-aea1-ba6d801345e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-de1f035b-7b05-4e3e-b5ca-c6898b90db27,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-01b0ceab-85e9-4c55-bba1-ef4db47f50d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-8fc86da3-54a1-46a0-9bd8-44bd27b09589,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-2f03ebd3-a732-4c54-b1d2-3367cfa7e2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947618842-172.17.0.13-1597547685189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-9debc4df-3449-4cf5-a714-97cdf0687bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-492e67c7-80ce-442a-92d8-47d2a1984dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-066bf3b7-9c5f-4abe-8c5a-3edb066b8a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-53c69364-3646-4aa7-aea1-ba6d801345e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-de1f035b-7b05-4e3e-b5ca-c6898b90db27,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-01b0ceab-85e9-4c55-bba1-ef4db47f50d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-8fc86da3-54a1-46a0-9bd8-44bd27b09589,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-2f03ebd3-a732-4c54-b1d2-3367cfa7e2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264406751-172.17.0.13-1597547920911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36951,DS-d6698563-0d1c-409b-9b21-7a179247d121,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-741696d8-a16f-4bef-a682-aa3df13318c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-0809c55a-4aaa-4c90-a96e-cce19d9e53b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-92817e21-a523-443c-b318-9f9cac2920f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-753b5c4d-6d37-48e8-a705-495f6466998d,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-df1afb2d-18fb-4218-91b2-5b8c50db8508,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-da53aabd-554c-4ac9-932d-75470c9fffd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-808dab45-de83-45c5-b330-ceb4233da8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264406751-172.17.0.13-1597547920911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36951,DS-d6698563-0d1c-409b-9b21-7a179247d121,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-741696d8-a16f-4bef-a682-aa3df13318c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-0809c55a-4aaa-4c90-a96e-cce19d9e53b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-92817e21-a523-443c-b318-9f9cac2920f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-753b5c4d-6d37-48e8-a705-495f6466998d,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-df1afb2d-18fb-4218-91b2-5b8c50db8508,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-da53aabd-554c-4ac9-932d-75470c9fffd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-808dab45-de83-45c5-b330-ceb4233da8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227079372-172.17.0.13-1597547967201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-3bba931c-a6e1-498c-9b55-158a19894f58,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-af690584-5103-4af7-8325-37d1c97ef957,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-4cf024ad-3a56-4cc0-aa10-88f7a81c0e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-d9c9913d-c188-4d07-a2dc-f96b0fca9036,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-c7b4dc41-5cb9-41a6-966c-5663187cc812,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-02fac361-150b-4c19-9ef2-b7decb8fdc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-cdd01b93-2771-4921-821d-ea8db9ae2df2,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-39d25d2a-1dd3-4d80-9bbd-bfd336f79f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227079372-172.17.0.13-1597547967201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-3bba931c-a6e1-498c-9b55-158a19894f58,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-af690584-5103-4af7-8325-37d1c97ef957,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-4cf024ad-3a56-4cc0-aa10-88f7a81c0e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-d9c9913d-c188-4d07-a2dc-f96b0fca9036,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-c7b4dc41-5cb9-41a6-966c-5663187cc812,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-02fac361-150b-4c19-9ef2-b7decb8fdc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-cdd01b93-2771-4921-821d-ea8db9ae2df2,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-39d25d2a-1dd3-4d80-9bbd-bfd336f79f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892554353-172.17.0.13-1597548007745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37530,DS-fa26ab0d-db9d-4b16-ae4c-ae0e28c11090,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-6edfd256-5209-493d-88b3-45014df43717,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-2eebb96d-0dc1-4734-b1f3-ffead1dd767a,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-06bd7e64-b9fa-42e1-bad2-bde7013661aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-cb1a2f0e-d718-4641-ad47-0807fca0d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-2d7c8a23-afb8-424a-ba6a-c1fd744778ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-3dc710f9-ddc8-4892-943c-565374e36c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-ef04782b-9a90-4022-8aba-06226dfc03dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892554353-172.17.0.13-1597548007745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37530,DS-fa26ab0d-db9d-4b16-ae4c-ae0e28c11090,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-6edfd256-5209-493d-88b3-45014df43717,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-2eebb96d-0dc1-4734-b1f3-ffead1dd767a,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-06bd7e64-b9fa-42e1-bad2-bde7013661aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-cb1a2f0e-d718-4641-ad47-0807fca0d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-2d7c8a23-afb8-424a-ba6a-c1fd744778ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-3dc710f9-ddc8-4892-943c-565374e36c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-ef04782b-9a90-4022-8aba-06226dfc03dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115235419-172.17.0.13-1597548345930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44442,DS-b3c4f0ce-280b-4323-9e58-2ab407ae91ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-26e94cad-db20-40a4-9b38-acdd0a68edd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-18ca0862-dc37-4d0b-9679-cb9c2cb2c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-45ec8e19-d9bf-4403-8bd6-423d5c7fb4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-6cb6a2f0-3c93-42be-903a-deff07cf75a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-3fb0093d-84d1-4976-ae6c-611551d59e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-42e87af4-6a03-48a6-9f7b-688ea2b0e636,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-bc505483-df12-41ba-b0a1-4306f00b8513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115235419-172.17.0.13-1597548345930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44442,DS-b3c4f0ce-280b-4323-9e58-2ab407ae91ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-26e94cad-db20-40a4-9b38-acdd0a68edd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-18ca0862-dc37-4d0b-9679-cb9c2cb2c6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-45ec8e19-d9bf-4403-8bd6-423d5c7fb4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-6cb6a2f0-3c93-42be-903a-deff07cf75a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-3fb0093d-84d1-4976-ae6c-611551d59e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-42e87af4-6a03-48a6-9f7b-688ea2b0e636,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-bc505483-df12-41ba-b0a1-4306f00b8513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198620739-172.17.0.13-1597549244909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-e41092f8-1617-49f3-8dab-ead660ca9813,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-f0448313-6bc8-4bd5-a986-b1eee6fee1db,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-69c14915-7072-4d00-850f-2dd9337891cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-dbe0157b-7e5b-44cb-b7c5-da1a5879abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-9b7a1e76-077a-49b2-bb04-c91f47bd44d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-9d66293d-92f7-4d74-b401-9748e86a2c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-6fb79ad7-ed20-4de0-a380-3a76c487e6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-7698a937-70fb-48c4-ba31-606b2cb8e2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198620739-172.17.0.13-1597549244909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-e41092f8-1617-49f3-8dab-ead660ca9813,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-f0448313-6bc8-4bd5-a986-b1eee6fee1db,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-69c14915-7072-4d00-850f-2dd9337891cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-dbe0157b-7e5b-44cb-b7c5-da1a5879abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-9b7a1e76-077a-49b2-bb04-c91f47bd44d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-9d66293d-92f7-4d74-b401-9748e86a2c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-6fb79ad7-ed20-4de0-a380-3a76c487e6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-7698a937-70fb-48c4-ba31-606b2cb8e2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147425003-172.17.0.13-1597549593421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-8da8d42f-e275-4327-bda1-964542cf8665,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-ee6d765c-62c7-4a48-b346-622d1fe89fea,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-c7459a5b-b4ef-4915-9eac-4576139b40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-9792379c-872d-46ce-8d13-01ba2a9beb33,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-4a0a24bf-7ddc-4356-9a88-b3ac969d76fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-7d371c0e-9bf4-4c54-8201-ec5ec85fbe88,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-f2dadb87-4d94-4c92-89ac-141793584cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-767c22fc-4fcf-4836-8b5e-c1ef9e0bb530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147425003-172.17.0.13-1597549593421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35633,DS-8da8d42f-e275-4327-bda1-964542cf8665,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-ee6d765c-62c7-4a48-b346-622d1fe89fea,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-c7459a5b-b4ef-4915-9eac-4576139b40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-9792379c-872d-46ce-8d13-01ba2a9beb33,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-4a0a24bf-7ddc-4356-9a88-b3ac969d76fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-7d371c0e-9bf4-4c54-8201-ec5ec85fbe88,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-f2dadb87-4d94-4c92-89ac-141793584cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-767c22fc-4fcf-4836-8b5e-c1ef9e0bb530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401412762-172.17.0.13-1597549641113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-1e12145f-afee-40ef-a5cf-0642aac259c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-91fbc133-3e87-4016-81f4-5df19d4a4dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-a97151a8-b389-46af-ab3c-032295b9cd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-7c9d2f6e-4c7d-4915-ae0c-191f5f9e2eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-eef14e7f-3db6-4db2-a926-aded071ee999,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-c0461eb1-b0bb-4cca-a1f7-e89d1a93db62,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-58c5a393-1424-4a39-accd-7309d4d8a361,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fc227ff1-895a-44fb-97f5-72aaa74be08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401412762-172.17.0.13-1597549641113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46883,DS-1e12145f-afee-40ef-a5cf-0642aac259c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-91fbc133-3e87-4016-81f4-5df19d4a4dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-a97151a8-b389-46af-ab3c-032295b9cd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-7c9d2f6e-4c7d-4915-ae0c-191f5f9e2eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-eef14e7f-3db6-4db2-a926-aded071ee999,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-c0461eb1-b0bb-4cca-a1f7-e89d1a93db62,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-58c5a393-1424-4a39-accd-7309d4d8a361,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fc227ff1-895a-44fb-97f5-72aaa74be08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079227159-172.17.0.13-1597550682286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37122,DS-c094ebb4-5c18-480b-b715-1fd63510f919,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-e0f24e90-a018-4a4d-97ef-b13cec8f715d,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-bf16c7dd-06a1-4339-ad66-29015efed83e,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-785717cd-f002-49cd-a64b-33bd0a75eaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-6621e020-d0b1-4689-84cf-e2a42dc0b0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4698a741-d4a4-43f1-853b-f5617b6686b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-098c7281-3a29-4f78-9a65-d729e75f5ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-078a8f60-0628-4877-954a-34b1624f0f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079227159-172.17.0.13-1597550682286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37122,DS-c094ebb4-5c18-480b-b715-1fd63510f919,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-e0f24e90-a018-4a4d-97ef-b13cec8f715d,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-bf16c7dd-06a1-4339-ad66-29015efed83e,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-785717cd-f002-49cd-a64b-33bd0a75eaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-6621e020-d0b1-4689-84cf-e2a42dc0b0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4698a741-d4a4-43f1-853b-f5617b6686b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-098c7281-3a29-4f78-9a65-d729e75f5ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-078a8f60-0628-4877-954a-34b1624f0f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104579629-172.17.0.13-1597550999184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45521,DS-3f432bab-004d-49b5-b063-019fbe2e01c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-62784c4b-dad5-49c1-b503-a2d3bca15c82,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-77cf0b6e-54a9-45b4-9877-9723bc0c14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-b4e5c7bd-6c9d-4966-835d-1dfa7bf912d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-6314c61c-c4c2-42d9-89f1-463e268c403f,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-5de8fb5a-28e6-48b5-9c7a-08ec35bd81d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-d1258bd1-9758-456f-8fb5-8bd815f60655,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-d2797195-cd60-4361-8c3a-fa85340ef01b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104579629-172.17.0.13-1597550999184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45521,DS-3f432bab-004d-49b5-b063-019fbe2e01c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-62784c4b-dad5-49c1-b503-a2d3bca15c82,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-77cf0b6e-54a9-45b4-9877-9723bc0c14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-b4e5c7bd-6c9d-4966-835d-1dfa7bf912d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-6314c61c-c4c2-42d9-89f1-463e268c403f,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-5de8fb5a-28e6-48b5-9c7a-08ec35bd81d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-d1258bd1-9758-456f-8fb5-8bd815f60655,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-d2797195-cd60-4361-8c3a-fa85340ef01b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798498548-172.17.0.13-1597551088209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34800,DS-41adeb00-5e80-4c66-81ea-4e7a3d00a574,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-ff79192b-638d-4530-bde7-a99194105853,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-61d76f11-b601-43dc-b3d1-103f598de936,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-f38bac0a-1025-4616-b2f3-85ac9c57644f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-082da612-ee02-4230-9ef1-ca4fe8f62255,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-ed906d9f-7302-4932-a1ac-6d45aa735d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-99172255-34ef-423e-910f-ef8bd358a9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-610efaab-d878-432b-a088-c692a51ff6f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798498548-172.17.0.13-1597551088209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34800,DS-41adeb00-5e80-4c66-81ea-4e7a3d00a574,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-ff79192b-638d-4530-bde7-a99194105853,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-61d76f11-b601-43dc-b3d1-103f598de936,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-f38bac0a-1025-4616-b2f3-85ac9c57644f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-082da612-ee02-4230-9ef1-ca4fe8f62255,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-ed906d9f-7302-4932-a1ac-6d45aa735d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-99172255-34ef-423e-910f-ef8bd358a9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-610efaab-d878-432b-a088-c692a51ff6f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236220927-172.17.0.13-1597551771200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35097,DS-ccc2c9df-01ea-4723-bba4-ffa2c722dcab,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-ec794377-3b45-439d-b789-f0ff1566364a,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-d976944d-1ec3-43f3-826c-a8d6b32e8af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-d07abbf9-25c5-48f5-9623-4b076136d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-a34a2540-675c-4443-94c2-6689a8ce2afa,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-215dc8fd-a5d5-4dbd-b217-720bcf07a41b,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-890ef640-6819-4ab5-8d24-003b61a4c960,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7bf2fb16-e8c9-4df9-b01e-05745141beaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236220927-172.17.0.13-1597551771200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35097,DS-ccc2c9df-01ea-4723-bba4-ffa2c722dcab,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-ec794377-3b45-439d-b789-f0ff1566364a,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-d976944d-1ec3-43f3-826c-a8d6b32e8af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-d07abbf9-25c5-48f5-9623-4b076136d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-a34a2540-675c-4443-94c2-6689a8ce2afa,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-215dc8fd-a5d5-4dbd-b217-720bcf07a41b,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-890ef640-6819-4ab5-8d24-003b61a4c960,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7bf2fb16-e8c9-4df9-b01e-05745141beaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270372761-172.17.0.13-1597552130403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35301,DS-8d2b0e68-8734-404d-9ebf-7c8f364bb35e,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-8781ca49-430d-4a93-9c39-8f425fdd1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-e43e0e42-6fa9-4510-80fa-61c21dc34839,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-2a692187-181b-4306-99ef-ac3e8a271679,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-e5d751ab-b81e-474e-ae8d-b8a580be052a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-a4a79316-7d51-48c5-b8a6-5a831c506ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-f6f37ba5-55b7-457a-ba6a-5dd276966d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-3781313e-0909-4f4d-b698-1242c5ead22f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270372761-172.17.0.13-1597552130403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35301,DS-8d2b0e68-8734-404d-9ebf-7c8f364bb35e,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-8781ca49-430d-4a93-9c39-8f425fdd1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-e43e0e42-6fa9-4510-80fa-61c21dc34839,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-2a692187-181b-4306-99ef-ac3e8a271679,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-e5d751ab-b81e-474e-ae8d-b8a580be052a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-a4a79316-7d51-48c5-b8a6-5a831c506ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-f6f37ba5-55b7-457a-ba6a-5dd276966d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-3781313e-0909-4f4d-b698-1242c5ead22f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982314763-172.17.0.13-1597552528666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41515,DS-ee32f842-c094-4cf4-92b4-401e62e307b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-3dac8a5e-b03a-4d22-a75e-cc4e65133298,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-8363a01a-44e5-4e38-b0dc-85a8c6ea5dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-60b73cb3-2504-4896-890a-5cb00aac31ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-89b56cd9-54ee-4899-8f05-314e0829eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-17878271-1bbc-4666-ac02-d3f214a39f65,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-d51efa75-0b9a-419a-a719-87a4c7f9c4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-d10d881a-6162-44d0-82e2-327eb032fd96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982314763-172.17.0.13-1597552528666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41515,DS-ee32f842-c094-4cf4-92b4-401e62e307b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-3dac8a5e-b03a-4d22-a75e-cc4e65133298,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-8363a01a-44e5-4e38-b0dc-85a8c6ea5dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-60b73cb3-2504-4896-890a-5cb00aac31ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-89b56cd9-54ee-4899-8f05-314e0829eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-17878271-1bbc-4666-ac02-d3f214a39f65,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-d51efa75-0b9a-419a-a719-87a4c7f9c4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-d10d881a-6162-44d0-82e2-327eb032fd96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642633923-172.17.0.13-1597552570518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45600,DS-02d617e9-c731-4677-aad6-613b70032f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-c6b77144-af07-4531-a12e-68de55051fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-261aec79-bd62-49d8-863d-90ae8cfed70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-a19cc248-6a43-472d-a5f0-dc38c4a27334,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-60e3c317-c28e-4944-82eb-9e0a3599af98,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-8cc92f53-ef6b-465a-88e2-6abdf15c0208,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-f63648ff-5782-4b79-8ad9-c6660a30fac9,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-cca090bf-8a54-4299-8e9a-82b713ef2e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642633923-172.17.0.13-1597552570518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45600,DS-02d617e9-c731-4677-aad6-613b70032f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-c6b77144-af07-4531-a12e-68de55051fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-261aec79-bd62-49d8-863d-90ae8cfed70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-a19cc248-6a43-472d-a5f0-dc38c4a27334,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-60e3c317-c28e-4944-82eb-9e0a3599af98,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-8cc92f53-ef6b-465a-88e2-6abdf15c0208,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-f63648ff-5782-4b79-8ad9-c6660a30fac9,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-cca090bf-8a54-4299-8e9a-82b713ef2e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007348043-172.17.0.13-1597553072423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34641,DS-e3def945-9157-4fa6-8169-d34ee00157c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-45ed459a-a6a8-4bda-9649-954a4f01e0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-8faedc2a-cda1-4c08-9d4a-bba81a8d7576,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-d651e670-ddc6-4318-84ab-8ca4f288a1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-6a9b4087-9688-4794-9fbe-57e48e438b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-6c8ea5a2-df38-4ced-8414-dc4f4d2618b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-b9fd4756-801f-4bdc-991d-5086d2f2fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-59aca73d-6478-486c-afb8-51e977dc5e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007348043-172.17.0.13-1597553072423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34641,DS-e3def945-9157-4fa6-8169-d34ee00157c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-45ed459a-a6a8-4bda-9649-954a4f01e0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-8faedc2a-cda1-4c08-9d4a-bba81a8d7576,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-d651e670-ddc6-4318-84ab-8ca4f288a1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-6a9b4087-9688-4794-9fbe-57e48e438b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-6c8ea5a2-df38-4ced-8414-dc4f4d2618b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-b9fd4756-801f-4bdc-991d-5086d2f2fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-59aca73d-6478-486c-afb8-51e977dc5e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5894
