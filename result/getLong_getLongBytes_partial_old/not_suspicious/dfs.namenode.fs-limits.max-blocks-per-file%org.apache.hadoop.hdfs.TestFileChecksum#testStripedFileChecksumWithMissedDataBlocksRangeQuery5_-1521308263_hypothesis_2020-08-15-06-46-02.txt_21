reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229892092-172.17.0.8-1597474308458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34749,DS-aafd1d8b-e17e-4f34-a79b-6dfd43a2dbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-436c86be-2fe0-448e-98cc-b98093108214,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-8f199c94-1326-479e-911b-ac799d3a7640,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-678e2b4c-b3a1-4c58-ae29-ec69e96faf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-a5275eac-1a3c-4b46-b32d-aeef04533803,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-45eb2402-d751-4343-96e3-506363465e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-73075648-13e2-4025-b0ef-1eafa29e452d,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-0cbb44cb-99d6-4e26-965c-1d453e474dfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229892092-172.17.0.8-1597474308458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34749,DS-aafd1d8b-e17e-4f34-a79b-6dfd43a2dbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-436c86be-2fe0-448e-98cc-b98093108214,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-8f199c94-1326-479e-911b-ac799d3a7640,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-678e2b4c-b3a1-4c58-ae29-ec69e96faf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-a5275eac-1a3c-4b46-b32d-aeef04533803,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-45eb2402-d751-4343-96e3-506363465e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-73075648-13e2-4025-b0ef-1eafa29e452d,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-0cbb44cb-99d6-4e26-965c-1d453e474dfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344924894-172.17.0.8-1597474347141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41225,DS-61e49e89-9e84-447d-8365-df38d76abf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-8db6693b-f323-4304-b75b-b6c7274140e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-c28018b0-eda4-4a71-b6a0-4ebc4512e85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-36897ae7-c50c-4e1d-a5ae-d178d7aead1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-076557d7-3ed1-42de-a641-44212769e9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-fc004635-0be8-411b-b164-d5545604b44b,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-e7eb621c-d1ac-4bcb-bedd-6e57c654cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-0c659cce-ca3e-4f41-bc96-bc92937fd663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344924894-172.17.0.8-1597474347141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41225,DS-61e49e89-9e84-447d-8365-df38d76abf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-8db6693b-f323-4304-b75b-b6c7274140e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-c28018b0-eda4-4a71-b6a0-4ebc4512e85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-36897ae7-c50c-4e1d-a5ae-d178d7aead1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-076557d7-3ed1-42de-a641-44212769e9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-fc004635-0be8-411b-b164-d5545604b44b,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-e7eb621c-d1ac-4bcb-bedd-6e57c654cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-0c659cce-ca3e-4f41-bc96-bc92937fd663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862291404-172.17.0.8-1597474694062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38994,DS-29075ed7-42f5-4ef7-8ebd-c5bea784aeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-2984ffef-3306-4b7d-a16b-3b79cc4dd0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-c9ce628c-4256-4266-b01d-0ef185fbfc85,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-b0ea3dda-f0e7-4a1c-a6ea-95ac3a88f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-c507a83e-5193-48a6-80c7-46754796d1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-12ae5edb-6803-4fc1-969f-6659f7cf957d,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-42a8432f-8d51-4d57-9f05-abc0ca2145eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-e7ccaa45-71c0-4b8a-989f-eec018ab6e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862291404-172.17.0.8-1597474694062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38994,DS-29075ed7-42f5-4ef7-8ebd-c5bea784aeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-2984ffef-3306-4b7d-a16b-3b79cc4dd0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-c9ce628c-4256-4266-b01d-0ef185fbfc85,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-b0ea3dda-f0e7-4a1c-a6ea-95ac3a88f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-c507a83e-5193-48a6-80c7-46754796d1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-12ae5edb-6803-4fc1-969f-6659f7cf957d,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-42a8432f-8d51-4d57-9f05-abc0ca2145eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-e7ccaa45-71c0-4b8a-989f-eec018ab6e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783341912-172.17.0.8-1597475616976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45910,DS-c5889b59-a9e0-4eb2-80b3-6a651c1ad38e,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-0ac112f3-2056-4987-a4ba-1c55d03baf46,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-414437c8-058a-4fb0-9a73-fdf6155a9408,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-0e8e379d-cccf-415f-8b44-52a6278b6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-d5c4ee37-231f-4eae-b50d-975610dbe7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-2ea46aee-37b2-4463-836f-cab2912fd73d,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-a8faf8e1-0808-4b24-88a0-9707d7301949,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-ff433d5f-a033-4f76-8492-0bd5ba8f76f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783341912-172.17.0.8-1597475616976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45910,DS-c5889b59-a9e0-4eb2-80b3-6a651c1ad38e,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-0ac112f3-2056-4987-a4ba-1c55d03baf46,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-414437c8-058a-4fb0-9a73-fdf6155a9408,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-0e8e379d-cccf-415f-8b44-52a6278b6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-d5c4ee37-231f-4eae-b50d-975610dbe7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-2ea46aee-37b2-4463-836f-cab2912fd73d,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-a8faf8e1-0808-4b24-88a0-9707d7301949,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-ff433d5f-a033-4f76-8492-0bd5ba8f76f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148696267-172.17.0.8-1597475665780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36427,DS-a77570d5-4288-4db3-ab46-331e9871f168,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-c1d4f6c1-4699-4ad1-842c-b59e15ce42da,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-4d798557-b5f1-4adb-ab5d-c515f3c0b8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-7b8bfb78-82fa-4303-a73e-042e37e99134,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-696a9805-3c64-4822-97cd-6c1e9f6ee788,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-99915644-bd8d-486b-97cb-7e8b49cfabc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-41bb99fe-15e9-4713-b615-333ef38059e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-8a1dec7e-cdd6-433f-94ce-eca4de37bfce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148696267-172.17.0.8-1597475665780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36427,DS-a77570d5-4288-4db3-ab46-331e9871f168,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-c1d4f6c1-4699-4ad1-842c-b59e15ce42da,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-4d798557-b5f1-4adb-ab5d-c515f3c0b8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-7b8bfb78-82fa-4303-a73e-042e37e99134,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-696a9805-3c64-4822-97cd-6c1e9f6ee788,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-99915644-bd8d-486b-97cb-7e8b49cfabc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-41bb99fe-15e9-4713-b615-333ef38059e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-8a1dec7e-cdd6-433f-94ce-eca4de37bfce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190155994-172.17.0.8-1597475925985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-54a0adcc-b51a-41ec-b6a4-cd94677ea164,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-d577baeb-0f52-4fee-b6c4-4185593999f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-959d0102-b105-4caf-bbc7-51dc00a2f066,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-c66fdc5e-d238-4602-b81c-896d06aa6687,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-7efda886-f399-48f2-8ac1-4d772545122b,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-535e2b0e-adbc-4617-8337-0ab910f72a20,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-f720f720-9252-4a2a-8ab9-6bf20a49bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-4ce82ef8-e1de-46ce-b6ca-759106358f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190155994-172.17.0.8-1597475925985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33364,DS-54a0adcc-b51a-41ec-b6a4-cd94677ea164,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-d577baeb-0f52-4fee-b6c4-4185593999f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-959d0102-b105-4caf-bbc7-51dc00a2f066,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-c66fdc5e-d238-4602-b81c-896d06aa6687,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-7efda886-f399-48f2-8ac1-4d772545122b,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-535e2b0e-adbc-4617-8337-0ab910f72a20,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-f720f720-9252-4a2a-8ab9-6bf20a49bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-4ce82ef8-e1de-46ce-b6ca-759106358f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901276925-172.17.0.8-1597475966045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-1aae2cb7-8b12-4a5f-9866-9196530f4972,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-bec498d0-20f0-4e77-b967-748e2ffd3f42,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-4a85441e-bee2-4652-b205-c42e121e912b,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-7b11f4bc-848e-4c39-8dc8-e16a8ac70dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-0d3c8e78-e7ef-4d18-ace9-94ab29004de8,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-51e643fc-97d7-4336-9c7f-ff6107a98797,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-33f4bdbf-47b8-40b7-9c36-c5eaa0802d46,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-589631ef-2ffa-489b-8536-caa9e6030ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901276925-172.17.0.8-1597475966045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-1aae2cb7-8b12-4a5f-9866-9196530f4972,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-bec498d0-20f0-4e77-b967-748e2ffd3f42,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-4a85441e-bee2-4652-b205-c42e121e912b,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-7b11f4bc-848e-4c39-8dc8-e16a8ac70dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-0d3c8e78-e7ef-4d18-ace9-94ab29004de8,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-51e643fc-97d7-4336-9c7f-ff6107a98797,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-33f4bdbf-47b8-40b7-9c36-c5eaa0802d46,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-589631ef-2ffa-489b-8536-caa9e6030ec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849821823-172.17.0.8-1597476885929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40958,DS-26571503-e1dd-4a02-b09f-cba5cb7e7a41,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-37df677b-66eb-4f34-8a46-8d319e3cb617,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-9ed45f07-812d-47eb-8320-caddffe0e104,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-a867e673-6533-42be-9542-f150254e053b,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-a39f4ed2-c487-4c14-952f-f11393f92985,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-56aaf440-493b-4f97-aff5-637ed56e1448,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-991bd5f4-ca59-4876-b3ef-7f70ebe4ad58,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-c4c0ec9e-d11c-4074-8f7a-5a72727c0806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849821823-172.17.0.8-1597476885929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40958,DS-26571503-e1dd-4a02-b09f-cba5cb7e7a41,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-37df677b-66eb-4f34-8a46-8d319e3cb617,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-9ed45f07-812d-47eb-8320-caddffe0e104,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-a867e673-6533-42be-9542-f150254e053b,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-a39f4ed2-c487-4c14-952f-f11393f92985,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-56aaf440-493b-4f97-aff5-637ed56e1448,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-991bd5f4-ca59-4876-b3ef-7f70ebe4ad58,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-c4c0ec9e-d11c-4074-8f7a-5a72727c0806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730608211-172.17.0.8-1597477257918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35839,DS-f6d5c2fa-1892-48b3-afed-07f6e4cb5705,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-28108878-052e-4aa6-8e9a-4dcce375d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-dace5137-401f-4889-aaf9-410fb6515b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-c543e18b-4c7a-401e-9b00-ff425d9629de,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-a916c3ea-54bd-4195-b1cb-ddb1e61f0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-8466a68c-c675-44db-a188-98394f8791f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-d3e0ab4e-e1e6-4083-9a85-4096a99ad0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-a71aa5f4-45dc-4281-8e69-ba8aa15c13e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-730608211-172.17.0.8-1597477257918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35839,DS-f6d5c2fa-1892-48b3-afed-07f6e4cb5705,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-28108878-052e-4aa6-8e9a-4dcce375d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-dace5137-401f-4889-aaf9-410fb6515b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-c543e18b-4c7a-401e-9b00-ff425d9629de,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-a916c3ea-54bd-4195-b1cb-ddb1e61f0e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-8466a68c-c675-44db-a188-98394f8791f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-d3e0ab4e-e1e6-4083-9a85-4096a99ad0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-a71aa5f4-45dc-4281-8e69-ba8aa15c13e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897728163-172.17.0.8-1597477715485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-d0e81118-6ed1-4663-bd1b-e7575a66368e,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-bfb801d3-770c-4ac5-a50b-e12ea2658195,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-05bd2bcf-f62a-4b0e-9eb0-ee3bdbc7b89b,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-9e148830-3b9c-4e2e-b19f-0b1eda3670ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-034935ca-d535-4a41-ad31-30d2c22ad452,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-f4d95a48-1462-4acc-9881-33cfd303d4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-c90f0739-668e-4027-a527-7af485fad892,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-1977aa3d-3e73-41c4-a416-42f82cc7943f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897728163-172.17.0.8-1597477715485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-d0e81118-6ed1-4663-bd1b-e7575a66368e,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-bfb801d3-770c-4ac5-a50b-e12ea2658195,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-05bd2bcf-f62a-4b0e-9eb0-ee3bdbc7b89b,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-9e148830-3b9c-4e2e-b19f-0b1eda3670ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-034935ca-d535-4a41-ad31-30d2c22ad452,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-f4d95a48-1462-4acc-9881-33cfd303d4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-c90f0739-668e-4027-a527-7af485fad892,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-1977aa3d-3e73-41c4-a416-42f82cc7943f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092317656-172.17.0.8-1597478155454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-32dd99c5-14da-46bc-9ec6-1e9fa6b12f13,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-742384b4-5012-4406-a5c7-048e34f951b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-3bceee4a-b14b-4643-bbaf-f5431d2edf37,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-3b5abe73-f789-4ab8-a733-0b1973f412c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-f1f19cb0-a00c-434c-8963-31bbdd33365b,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-b3886cfb-6cfc-4eca-bdb0-35a16345ecde,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-3292ae26-2981-49f0-b3a0-a1e0da29221a,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-9d2546d6-207c-48e0-b203-d7d101900f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092317656-172.17.0.8-1597478155454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-32dd99c5-14da-46bc-9ec6-1e9fa6b12f13,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-742384b4-5012-4406-a5c7-048e34f951b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-3bceee4a-b14b-4643-bbaf-f5431d2edf37,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-3b5abe73-f789-4ab8-a733-0b1973f412c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-f1f19cb0-a00c-434c-8963-31bbdd33365b,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-b3886cfb-6cfc-4eca-bdb0-35a16345ecde,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-3292ae26-2981-49f0-b3a0-a1e0da29221a,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-9d2546d6-207c-48e0-b203-d7d101900f8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268097000-172.17.0.8-1597479428090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40028,DS-0f79a6c3-c230-4732-a904-f17765323974,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-1c3bce27-8e59-49d9-b094-bf062e9d485a,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-014fcf46-1377-4ec6-9836-4123177f5720,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-23d61989-37e3-454b-8f50-1e0068ecd59c,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-58a0a807-0907-4703-8d2a-9eb71bceef30,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-08f7174f-66c6-44a3-933f-135eb9bb6b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-1f424af2-b0e4-4288-b1ef-6e66159e2478,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-1ee9aa11-af2b-462e-a229-11b2df1190d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268097000-172.17.0.8-1597479428090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40028,DS-0f79a6c3-c230-4732-a904-f17765323974,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-1c3bce27-8e59-49d9-b094-bf062e9d485a,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-014fcf46-1377-4ec6-9836-4123177f5720,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-23d61989-37e3-454b-8f50-1e0068ecd59c,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-58a0a807-0907-4703-8d2a-9eb71bceef30,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-08f7174f-66c6-44a3-933f-135eb9bb6b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-1f424af2-b0e4-4288-b1ef-6e66159e2478,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-1ee9aa11-af2b-462e-a229-11b2df1190d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946981350-172.17.0.8-1597479946928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-5eaa57c3-60ed-40b0-94ba-c0ea861c5e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-af19334d-8aca-48f5-b351-482210757112,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-ef277d8a-cc2f-48f6-bffa-05728bc40146,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-4f2cd52e-f658-44cc-9638-5af3a002f824,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-870bf227-8a14-42c1-8e6c-672eb0f81545,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-0984edf2-d312-45e9-9095-be4584ab543a,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-c8dd0d3e-0437-46b4-ad1f-3cded6bc1816,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-cb50c105-f7ee-4b57-81fa-34a45ae175d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946981350-172.17.0.8-1597479946928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41929,DS-5eaa57c3-60ed-40b0-94ba-c0ea861c5e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-af19334d-8aca-48f5-b351-482210757112,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-ef277d8a-cc2f-48f6-bffa-05728bc40146,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-4f2cd52e-f658-44cc-9638-5af3a002f824,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-870bf227-8a14-42c1-8e6c-672eb0f81545,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-0984edf2-d312-45e9-9095-be4584ab543a,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-c8dd0d3e-0437-46b4-ad1f-3cded6bc1816,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-cb50c105-f7ee-4b57-81fa-34a45ae175d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255558137-172.17.0.8-1597480058317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45232,DS-2837ed34-9f27-483e-ab7e-a116be660b80,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-56107a15-f6d6-4907-aac7-addf9e8798d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-54b7a25f-b8a4-4b26-b0bd-bb241cc36543,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-35092510-88fd-4e44-a1a2-3e9df398fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-e6151968-8fbb-4c57-9cc8-3b4b809463f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-fd82cecb-88ed-495a-a8c7-b97507339d42,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-bac4d453-4e02-48f8-9a43-f68db9b5148f,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-020dfd2b-2ff7-46d4-aab8-9ef0f1bdd634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255558137-172.17.0.8-1597480058317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45232,DS-2837ed34-9f27-483e-ab7e-a116be660b80,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-56107a15-f6d6-4907-aac7-addf9e8798d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-54b7a25f-b8a4-4b26-b0bd-bb241cc36543,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-35092510-88fd-4e44-a1a2-3e9df398fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-e6151968-8fbb-4c57-9cc8-3b4b809463f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-fd82cecb-88ed-495a-a8c7-b97507339d42,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-bac4d453-4e02-48f8-9a43-f68db9b5148f,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-020dfd2b-2ff7-46d4-aab8-9ef0f1bdd634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399520254-172.17.0.8-1597480577563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-85901025-3f63-4e22-bc2b-56b3cb4c0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-1e9a8aa0-9f7d-4b99-9a3a-c33f23512bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-5b74714d-5f7f-4884-9fad-3cd3a5f4e57b,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-57e3b1ae-aa16-4810-9f03-d36f9d84c8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-533b69d8-925a-4ff9-a73c-14374810ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-6b17ca79-7274-4047-8144-b971edc37241,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-b1417809-9452-4a16-aed9-e1e5e93fdcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-e498e12e-e8e8-4b14-b201-010d2858029e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399520254-172.17.0.8-1597480577563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-85901025-3f63-4e22-bc2b-56b3cb4c0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-1e9a8aa0-9f7d-4b99-9a3a-c33f23512bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-5b74714d-5f7f-4884-9fad-3cd3a5f4e57b,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-57e3b1ae-aa16-4810-9f03-d36f9d84c8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-533b69d8-925a-4ff9-a73c-14374810ac22,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-6b17ca79-7274-4047-8144-b971edc37241,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-b1417809-9452-4a16-aed9-e1e5e93fdcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-e498e12e-e8e8-4b14-b201-010d2858029e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791862175-172.17.0.8-1597480772328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37145,DS-a13a0187-b56c-46a0-8e6a-ee5a582a3e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-ba34e3b4-02ff-4909-980d-69813d19c823,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-3c84b661-98d2-4346-83ca-8aaf750f6513,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-dbfa6e49-0d0c-486a-b6ea-01a7f19bfdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-52c02bfe-219d-44ae-934f-15af2731efe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-5f5fab13-868d-4ce6-9005-d4873698b6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-316c2714-defb-4d0d-806a-46a8610eef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-12c55b46-09a1-4ce1-a2cd-3612a706a2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791862175-172.17.0.8-1597480772328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37145,DS-a13a0187-b56c-46a0-8e6a-ee5a582a3e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-ba34e3b4-02ff-4909-980d-69813d19c823,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-3c84b661-98d2-4346-83ca-8aaf750f6513,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-dbfa6e49-0d0c-486a-b6ea-01a7f19bfdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-52c02bfe-219d-44ae-934f-15af2731efe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-5f5fab13-868d-4ce6-9005-d4873698b6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-316c2714-defb-4d0d-806a-46a8610eef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-12c55b46-09a1-4ce1-a2cd-3612a706a2d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6890
