reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679309261-172.17.0.12-1597382456609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-ec4e83d9-70e1-446c-aa1d-240dd480fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-e60ca6ee-1aa6-4c5e-8524-ed26fc197f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-6d968e43-74fd-4f1b-9936-676049eb29f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-d012fc5e-3724-4ba8-bfad-f0b63a75a664,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-a95b711e-9188-4876-8d87-cbdb7425de2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-d8e85c82-5f6b-40ca-9bf5-36627a758b11,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-9bec3e67-dc3f-4c65-b595-4415480d179a,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-2deb9fdd-d08b-43be-bd5f-9605c3999d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679309261-172.17.0.12-1597382456609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-ec4e83d9-70e1-446c-aa1d-240dd480fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-e60ca6ee-1aa6-4c5e-8524-ed26fc197f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-6d968e43-74fd-4f1b-9936-676049eb29f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-d012fc5e-3724-4ba8-bfad-f0b63a75a664,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-a95b711e-9188-4876-8d87-cbdb7425de2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-d8e85c82-5f6b-40ca-9bf5-36627a758b11,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-9bec3e67-dc3f-4c65-b595-4415480d179a,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-2deb9fdd-d08b-43be-bd5f-9605c3999d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104935638-172.17.0.12-1597383335244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-7490e66f-9495-4ae1-959f-23de998e16b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-97ca5ce3-188c-4b1b-abee-35822ca98e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-a2bc92c1-b73c-426f-95a0-bb12b1825458,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-b53551fc-6280-4058-b37b-376306b6c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-81284308-59e9-46e3-8a2e-3daeea2521d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-d7dfa101-5ef0-47db-858e-353260d7b938,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-cd33ad15-8bba-48db-8000-df4ee8bd8764,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-c935d71d-b934-46fe-91a2-8e5884e46433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104935638-172.17.0.12-1597383335244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-7490e66f-9495-4ae1-959f-23de998e16b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-97ca5ce3-188c-4b1b-abee-35822ca98e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-a2bc92c1-b73c-426f-95a0-bb12b1825458,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-b53551fc-6280-4058-b37b-376306b6c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-81284308-59e9-46e3-8a2e-3daeea2521d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-d7dfa101-5ef0-47db-858e-353260d7b938,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-cd33ad15-8bba-48db-8000-df4ee8bd8764,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-c935d71d-b934-46fe-91a2-8e5884e46433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194436690-172.17.0.12-1597383431367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33729,DS-4fec3db5-1cce-4aea-a690-4b6757308915,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-b31cbf26-d6e9-46a5-9d0a-74ed3e502777,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-7be54d4f-9729-4ea0-885f-aba1de7e9533,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-0675e374-d466-47fe-976a-01b736d9a42e,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-6bc8eef6-bb40-4e0e-abd6-2e99e7ffdb14,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-7258ae54-5d86-4b87-aa20-8974e9ea3379,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-fdc5b384-244f-4842-8dce-6f0a8fb4699d,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-45d2bfd7-8e08-4323-9b8c-21147d6c8f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194436690-172.17.0.12-1597383431367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33729,DS-4fec3db5-1cce-4aea-a690-4b6757308915,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-b31cbf26-d6e9-46a5-9d0a-74ed3e502777,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-7be54d4f-9729-4ea0-885f-aba1de7e9533,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-0675e374-d466-47fe-976a-01b736d9a42e,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-6bc8eef6-bb40-4e0e-abd6-2e99e7ffdb14,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-7258ae54-5d86-4b87-aa20-8974e9ea3379,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-fdc5b384-244f-4842-8dce-6f0a8fb4699d,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-45d2bfd7-8e08-4323-9b8c-21147d6c8f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749127954-172.17.0.12-1597383953885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44404,DS-11658579-3d8c-4ac0-8045-d48dfb6b69aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-557efe89-b75c-4aea-949a-eadd2f668c35,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-30783b8e-2eef-46f1-a20b-ff4252be71e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-c47d503c-f8fb-437f-80b4-9cb7768edffe,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-949f1c4e-66d0-46b9-a8bb-495ce34ca7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-e9a90248-f8d6-4531-8c24-44fb11f7f82c,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-e3ca173c-aca8-4822-9658-81791b0aae61,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-aa1b78bb-b031-4544-b520-ee52bfc9f575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749127954-172.17.0.12-1597383953885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44404,DS-11658579-3d8c-4ac0-8045-d48dfb6b69aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-557efe89-b75c-4aea-949a-eadd2f668c35,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-30783b8e-2eef-46f1-a20b-ff4252be71e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-c47d503c-f8fb-437f-80b4-9cb7768edffe,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-949f1c4e-66d0-46b9-a8bb-495ce34ca7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-e9a90248-f8d6-4531-8c24-44fb11f7f82c,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-e3ca173c-aca8-4822-9658-81791b0aae61,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-aa1b78bb-b031-4544-b520-ee52bfc9f575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874573849-172.17.0.12-1597384183914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-9d5e947c-ba18-4e63-9a13-fa8c13a7880a,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-4b0b477a-366d-4ff2-b260-d438e0eb3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-c2b15b1e-7bd4-43c9-bb7e-15ec25fcae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-c3156326-fdb6-4ccc-a439-032764018193,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-1e575aef-75a3-4218-ad24-b066d8cdc570,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-677bf9ff-2d02-48ee-bee5-34fbb216da36,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-090d42c3-e17b-43c6-9dc4-aa90ba6d5f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-cfb0accb-e3fc-4370-9f5e-b2f2c0d4c8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874573849-172.17.0.12-1597384183914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45604,DS-9d5e947c-ba18-4e63-9a13-fa8c13a7880a,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-4b0b477a-366d-4ff2-b260-d438e0eb3bda,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-c2b15b1e-7bd4-43c9-bb7e-15ec25fcae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-c3156326-fdb6-4ccc-a439-032764018193,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-1e575aef-75a3-4218-ad24-b066d8cdc570,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-677bf9ff-2d02-48ee-bee5-34fbb216da36,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-090d42c3-e17b-43c6-9dc4-aa90ba6d5f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-cfb0accb-e3fc-4370-9f5e-b2f2c0d4c8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527287749-172.17.0.12-1597384580244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35353,DS-07121e98-da45-4cad-972a-08443a0bdf07,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-76719d5b-291a-4c7e-8e2c-0a7574a83eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-412ffd39-ba0e-4f00-82fe-d9b49d0b3e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-caae29ed-9fc7-4c00-967e-5ee972366b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-4a002ad0-cb5d-4691-8ed5-64c5a8e519ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-8bb0367b-1162-4b6d-953e-390328051b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-62764a86-e19b-404e-8122-0ffade0833b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-5adec9e6-a63f-44fa-a387-4aed196ed746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-527287749-172.17.0.12-1597384580244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35353,DS-07121e98-da45-4cad-972a-08443a0bdf07,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-76719d5b-291a-4c7e-8e2c-0a7574a83eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-412ffd39-ba0e-4f00-82fe-d9b49d0b3e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-caae29ed-9fc7-4c00-967e-5ee972366b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-4a002ad0-cb5d-4691-8ed5-64c5a8e519ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-8bb0367b-1162-4b6d-953e-390328051b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-62764a86-e19b-404e-8122-0ffade0833b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-5adec9e6-a63f-44fa-a387-4aed196ed746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983855026-172.17.0.12-1597384867849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33251,DS-5d54850d-7b5e-4e70-980c-4195530eeeed,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-d63185d5-7dd2-47fc-84ba-a9de958cd226,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-402102f9-7b53-4cea-9997-c7b6cb9d4eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ac935849-1963-47b6-a831-db6bb7325360,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-44dd4dd7-7634-4164-9c6f-275fde8c37cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-fb14fdfb-6474-41d8-90f9-3fef8c9196d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-2750a4d1-19a9-499b-a284-d46ffa97f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-3e370f75-3bb8-41dd-b93a-7675f8b1440b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983855026-172.17.0.12-1597384867849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33251,DS-5d54850d-7b5e-4e70-980c-4195530eeeed,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-d63185d5-7dd2-47fc-84ba-a9de958cd226,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-402102f9-7b53-4cea-9997-c7b6cb9d4eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ac935849-1963-47b6-a831-db6bb7325360,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-44dd4dd7-7634-4164-9c6f-275fde8c37cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-fb14fdfb-6474-41d8-90f9-3fef8c9196d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-2750a4d1-19a9-499b-a284-d46ffa97f20f,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-3e370f75-3bb8-41dd-b93a-7675f8b1440b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428765613-172.17.0.12-1597385514281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-97b15c36-f65d-4b65-84b4-e5355c956c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-7b55b018-be22-4e81-9150-7a5fc4e413cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-c4065340-4118-4339-a098-ebc04ce541cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-42e0fcde-8926-4f78-b992-12a0021acf38,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-ad27317e-a962-48e2-88c4-04617ba856ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-ecdda7df-aee0-404e-aadb-ec429670e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-aca711e3-49c5-4ecc-b0d6-b5d695cff951,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-ea4ccd14-572b-4887-bf07-232453e5d048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428765613-172.17.0.12-1597385514281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-97b15c36-f65d-4b65-84b4-e5355c956c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-7b55b018-be22-4e81-9150-7a5fc4e413cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-c4065340-4118-4339-a098-ebc04ce541cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-42e0fcde-8926-4f78-b992-12a0021acf38,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-ad27317e-a962-48e2-88c4-04617ba856ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-ecdda7df-aee0-404e-aadb-ec429670e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-aca711e3-49c5-4ecc-b0d6-b5d695cff951,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-ea4ccd14-572b-4887-bf07-232453e5d048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425846926-172.17.0.12-1597385845938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34409,DS-bfa7c75c-43ad-4bc0-abd9-5f2b85b1ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-18eb6b3c-6946-45e5-9ab8-73138509969d,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-a2bda562-65e7-4432-bb16-e226f2929d33,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-d0d4972d-958c-4afd-acfa-62e0c3a355c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-99b359a1-118f-423f-9a28-50a66bcf3f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-363cb97e-bace-48cf-a8bc-6318a2733c33,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-3d3a6079-f574-4422-b414-5ba30d1622bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-61d2195c-0adf-405d-b8f8-50c7de4311ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425846926-172.17.0.12-1597385845938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34409,DS-bfa7c75c-43ad-4bc0-abd9-5f2b85b1ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-18eb6b3c-6946-45e5-9ab8-73138509969d,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-a2bda562-65e7-4432-bb16-e226f2929d33,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-d0d4972d-958c-4afd-acfa-62e0c3a355c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-99b359a1-118f-423f-9a28-50a66bcf3f77,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-363cb97e-bace-48cf-a8bc-6318a2733c33,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-3d3a6079-f574-4422-b414-5ba30d1622bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-61d2195c-0adf-405d-b8f8-50c7de4311ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334580457-172.17.0.12-1597386598269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-f14f53c2-3bd2-4f2e-b7da-f1165fa3fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-19fbc9ed-6594-4887-a0f3-cb7d54fcd04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-67ed263f-9d0f-4da9-949f-7cf823cc7a29,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-461eedca-1153-4a58-a35f-d1f8e62510bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-46b58d7a-455d-41c7-a104-8b0b7bc0421e,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-53e67e04-7a9f-4080-a4a2-b4edbf39af87,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-51238638-40db-4f66-a4ae-84d7d3476de1,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-3efdc6d0-ebba-4ff0-843f-2044adc7f7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334580457-172.17.0.12-1597386598269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-f14f53c2-3bd2-4f2e-b7da-f1165fa3fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-19fbc9ed-6594-4887-a0f3-cb7d54fcd04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-67ed263f-9d0f-4da9-949f-7cf823cc7a29,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-461eedca-1153-4a58-a35f-d1f8e62510bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-46b58d7a-455d-41c7-a104-8b0b7bc0421e,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-53e67e04-7a9f-4080-a4a2-b4edbf39af87,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-51238638-40db-4f66-a4ae-84d7d3476de1,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-3efdc6d0-ebba-4ff0-843f-2044adc7f7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236733351-172.17.0.12-1597386745428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-59b944f7-c5cb-4f68-94ce-8ca611cc1d09,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-020072a8-ff79-460d-914b-e55fad4a504a,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-e0de3fac-a389-4db7-a969-56a5e8cca828,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-0c471db0-0888-4b96-a144-bb18512f3b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-18fcdbdb-1987-4f0e-99a5-fa3a368968e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-1d959ec5-249f-41e6-a27d-ad2286f78834,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-8e86d319-1823-466c-99b6-6fea1d656e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-0f32d423-45ec-452d-b835-ce0aa9a3f281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236733351-172.17.0.12-1597386745428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-59b944f7-c5cb-4f68-94ce-8ca611cc1d09,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-020072a8-ff79-460d-914b-e55fad4a504a,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-e0de3fac-a389-4db7-a969-56a5e8cca828,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-0c471db0-0888-4b96-a144-bb18512f3b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-18fcdbdb-1987-4f0e-99a5-fa3a368968e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-1d959ec5-249f-41e6-a27d-ad2286f78834,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-8e86d319-1823-466c-99b6-6fea1d656e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-0f32d423-45ec-452d-b835-ce0aa9a3f281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721717792-172.17.0.12-1597387085449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33442,DS-28246cf7-e0df-48dc-a40a-591d3c3424a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-028eead0-2041-42ba-9065-f0e167733150,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-7a890be8-0e76-4828-88ba-9347a44c0ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-59aa828a-a94d-4631-8d01-bc7f7a3ecc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-6f5f8cdb-9d08-49c9-b6b3-5c460f8bc5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-839c8dfa-b888-414b-b90d-f553229ac17f,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-2e17d094-6186-4377-a9dc-e0ea5b4ac700,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-57d6104a-1f63-4454-b454-b5ed6d08c8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721717792-172.17.0.12-1597387085449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33442,DS-28246cf7-e0df-48dc-a40a-591d3c3424a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-028eead0-2041-42ba-9065-f0e167733150,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-7a890be8-0e76-4828-88ba-9347a44c0ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-59aa828a-a94d-4631-8d01-bc7f7a3ecc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-6f5f8cdb-9d08-49c9-b6b3-5c460f8bc5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-839c8dfa-b888-414b-b90d-f553229ac17f,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-2e17d094-6186-4377-a9dc-e0ea5b4ac700,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-57d6104a-1f63-4454-b454-b5ed6d08c8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80366255-172.17.0.12-1597387363070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38264,DS-2c4dbe33-83a2-4fa3-bd89-3d314b229abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-90e2b10e-ae63-42b0-8773-ab5a431b202e,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-fb623332-d0ee-42dd-93e5-5b94d0d3d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-06d311c3-80c3-41aa-9cfc-a409f4414106,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-58f31658-b0f4-443f-990c-91d22d89f8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-a1a60936-c9a5-4310-a8bd-0ad2af0c275f,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-b3d28211-2a8f-4406-847e-71556023410d,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-98b809ff-02ee-4690-8027-942c3c89cc92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80366255-172.17.0.12-1597387363070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38264,DS-2c4dbe33-83a2-4fa3-bd89-3d314b229abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-90e2b10e-ae63-42b0-8773-ab5a431b202e,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-fb623332-d0ee-42dd-93e5-5b94d0d3d4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-06d311c3-80c3-41aa-9cfc-a409f4414106,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-58f31658-b0f4-443f-990c-91d22d89f8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-a1a60936-c9a5-4310-a8bd-0ad2af0c275f,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-b3d28211-2a8f-4406-847e-71556023410d,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-98b809ff-02ee-4690-8027-942c3c89cc92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52964166-172.17.0.12-1597387416984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44113,DS-9358af8b-fbc2-4b27-b290-9614bd8c4103,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-e4ed6d9d-a929-4d11-b499-fab471b165c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-c49c1d73-11b5-4715-bfd3-aa7c26cda59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-3d91b71d-4a07-42c6-ad7f-151b8c6a3f96,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-5ad796d7-4865-4cf4-97a8-5a9da042feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-082f9fc1-570b-454b-af1b-ce1a694a4946,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-7c9533b9-4bdb-4955-90ed-8999c30da312,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-10ce5764-4448-4adc-ac92-ad3f22d6cef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52964166-172.17.0.12-1597387416984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44113,DS-9358af8b-fbc2-4b27-b290-9614bd8c4103,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-e4ed6d9d-a929-4d11-b499-fab471b165c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-c49c1d73-11b5-4715-bfd3-aa7c26cda59b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-3d91b71d-4a07-42c6-ad7f-151b8c6a3f96,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-5ad796d7-4865-4cf4-97a8-5a9da042feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-082f9fc1-570b-454b-af1b-ce1a694a4946,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-7c9533b9-4bdb-4955-90ed-8999c30da312,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-10ce5764-4448-4adc-ac92-ad3f22d6cef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156994987-172.17.0.12-1597387651905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41730,DS-134cd596-f667-47cf-958d-8216bf413d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-27f595d5-8c0b-42b7-9118-960a2125450e,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-64bd27df-b079-4ade-8900-9fdba222c555,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-1a342164-4277-401c-be89-cd1d0375f483,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-83e8d491-115c-4c0b-a3ff-be7c95219f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-363f9096-4917-44ba-a2c4-43c7d657ac54,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-787912f8-c3b4-4427-8375-4bafd7dc51da,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-eb636c3e-66fe-4d5f-a8cf-3bd3999c6cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156994987-172.17.0.12-1597387651905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41730,DS-134cd596-f667-47cf-958d-8216bf413d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-27f595d5-8c0b-42b7-9118-960a2125450e,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-64bd27df-b079-4ade-8900-9fdba222c555,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-1a342164-4277-401c-be89-cd1d0375f483,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-83e8d491-115c-4c0b-a3ff-be7c95219f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-363f9096-4917-44ba-a2c4-43c7d657ac54,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-787912f8-c3b4-4427-8375-4bafd7dc51da,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-eb636c3e-66fe-4d5f-a8cf-3bd3999c6cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907308737-172.17.0.12-1597388026644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39353,DS-0d03ec03-eac6-47cc-9a42-84d63d07dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-7127370b-400c-4521-92fb-8d5265fb1896,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-c72bab46-80b7-49a3-855c-1fc8b558f9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-6d2dd94c-5776-486e-91aa-49f781b47776,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-ed39a305-26c0-458c-b2b2-ce671dd98c97,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-0d5a62be-8fa7-462d-aa91-d7bf60cec1db,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-a7cd14f7-216b-4359-ac58-5ae9a7296931,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-b8aef1a1-d36e-4e58-b901-4daa87991d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907308737-172.17.0.12-1597388026644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39353,DS-0d03ec03-eac6-47cc-9a42-84d63d07dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-7127370b-400c-4521-92fb-8d5265fb1896,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-c72bab46-80b7-49a3-855c-1fc8b558f9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-6d2dd94c-5776-486e-91aa-49f781b47776,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-ed39a305-26c0-458c-b2b2-ce671dd98c97,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-0d5a62be-8fa7-462d-aa91-d7bf60cec1db,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-a7cd14f7-216b-4359-ac58-5ae9a7296931,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-b8aef1a1-d36e-4e58-b901-4daa87991d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957338746-172.17.0.12-1597388132063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40900,DS-ed36bf09-e4ca-4dea-b731-9b4b2d4bc890,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-465f2031-ca01-4f30-b687-a6e40f2e6d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-5417b487-8c51-4e50-9ed0-e0f7eb83ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-bc6347fb-dbd3-47e5-a3d9-5dbbb6f96235,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-aca51734-3761-4280-a96f-30c0c4b854df,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-cd2a495d-7aa9-4de6-8d69-afce1480bbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-b90a1dad-e2f0-408b-aded-93d06b26a897,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-3129ecd0-6939-4eba-99e3-80988c097d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957338746-172.17.0.12-1597388132063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40900,DS-ed36bf09-e4ca-4dea-b731-9b4b2d4bc890,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-465f2031-ca01-4f30-b687-a6e40f2e6d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-5417b487-8c51-4e50-9ed0-e0f7eb83ef73,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-bc6347fb-dbd3-47e5-a3d9-5dbbb6f96235,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-aca51734-3761-4280-a96f-30c0c4b854df,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-cd2a495d-7aa9-4de6-8d69-afce1480bbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-b90a1dad-e2f0-408b-aded-93d06b26a897,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-3129ecd0-6939-4eba-99e3-80988c097d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754022088-172.17.0.12-1597388364316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-5a48fac3-01e3-4122-98bb-84163f62e84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-948245e2-7bab-420f-8bf5-2a2ca0ce9498,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-960b44b3-e4c0-45bc-af19-dcf6689db268,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-132334bc-cb77-458d-ba4d-e85a5e298668,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-25bdd189-9201-44f8-8bb0-f338ab296e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-054dd663-9751-4dd1-ba3f-42607eea92bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-b4013974-e7f9-4ce2-ac7c-da28114238d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-e8d8e4fb-e849-49f5-a989-72d462becb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754022088-172.17.0.12-1597388364316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-5a48fac3-01e3-4122-98bb-84163f62e84c,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-948245e2-7bab-420f-8bf5-2a2ca0ce9498,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-960b44b3-e4c0-45bc-af19-dcf6689db268,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-132334bc-cb77-458d-ba4d-e85a5e298668,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-25bdd189-9201-44f8-8bb0-f338ab296e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-054dd663-9751-4dd1-ba3f-42607eea92bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-b4013974-e7f9-4ce2-ac7c-da28114238d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-e8d8e4fb-e849-49f5-a989-72d462becb9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6947
