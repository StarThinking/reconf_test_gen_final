reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266244941-172.17.0.9-1597519555734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38997,DS-cb0a86d9-17f2-4ef1-883e-6f82c899bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-71e1b66d-8e8c-4231-a85c-118a3e8426c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-6bffd030-e382-4ebc-a897-37428578543c,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-51f8857b-f526-44ed-8664-9f6c7059f75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-cd5e038a-d9b6-4975-8736-a9c059f62ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-9891eeb7-3cd8-4490-a778-ce7abd18eab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-fe32438e-42e7-4427-881c-c1e1f4173d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-4fdb6720-8b5b-47ea-9b1b-ab7f51f1ecfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266244941-172.17.0.9-1597519555734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38997,DS-cb0a86d9-17f2-4ef1-883e-6f82c899bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-71e1b66d-8e8c-4231-a85c-118a3e8426c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-6bffd030-e382-4ebc-a897-37428578543c,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-51f8857b-f526-44ed-8664-9f6c7059f75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-cd5e038a-d9b6-4975-8736-a9c059f62ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-9891eeb7-3cd8-4490-a778-ce7abd18eab5,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-fe32438e-42e7-4427-881c-c1e1f4173d63,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-4fdb6720-8b5b-47ea-9b1b-ab7f51f1ecfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171808377-172.17.0.9-1597519999676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33494,DS-a5553fb9-015d-436a-beac-bb8b9c83fe50,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-2811b3bc-b323-48d1-9b54-7df7e9ce3897,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-dd5f0b2f-b864-4684-b504-ab54330e95f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-be38f3b3-13a9-4313-afb5-5aeada2fb38b,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-821e1326-14d0-4eea-b882-38d28e6e888c,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-569bc584-6054-4221-b4e1-8ad8de5078ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-51416d24-f447-476a-84cf-90505ad39194,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-570afa34-9beb-4197-ad62-b4dcbfd90d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171808377-172.17.0.9-1597519999676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33494,DS-a5553fb9-015d-436a-beac-bb8b9c83fe50,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-2811b3bc-b323-48d1-9b54-7df7e9ce3897,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-dd5f0b2f-b864-4684-b504-ab54330e95f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-be38f3b3-13a9-4313-afb5-5aeada2fb38b,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-821e1326-14d0-4eea-b882-38d28e6e888c,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-569bc584-6054-4221-b4e1-8ad8de5078ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-51416d24-f447-476a-84cf-90505ad39194,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-570afa34-9beb-4197-ad62-b4dcbfd90d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195657552-172.17.0.9-1597520154099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-6c9cfa1b-12c2-471a-90e8-2bb6182d9e25,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-efabbd01-b019-4c3e-993c-cee5b1b95a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-8d449b1a-ff33-4fa7-bd50-40344032d154,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-92cbb868-fa57-4f63-8153-25718ecda7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-bb163f7a-2e5b-4644-8745-02a8252957a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-b0792a67-b285-48a5-bd93-edfb27d2a6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b032228d-5fe5-4d35-90d8-753e0286309f,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-1da646ad-3521-4162-bbbe-fe8350b728f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195657552-172.17.0.9-1597520154099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41231,DS-6c9cfa1b-12c2-471a-90e8-2bb6182d9e25,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-efabbd01-b019-4c3e-993c-cee5b1b95a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-8d449b1a-ff33-4fa7-bd50-40344032d154,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-92cbb868-fa57-4f63-8153-25718ecda7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-bb163f7a-2e5b-4644-8745-02a8252957a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-b0792a67-b285-48a5-bd93-edfb27d2a6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-b032228d-5fe5-4d35-90d8-753e0286309f,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-1da646ad-3521-4162-bbbe-fe8350b728f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409476470-172.17.0.9-1597520233324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-7e70a9c5-7854-494e-a4c1-9af8340f0e68,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-b94ce830-6cdb-4211-ab20-c6a48bdc96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-ac2d85b6-5691-46d6-8a48-cafb05bdd7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-baebadf9-e73f-4d8a-ba68-86f9c595521e,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-c2b88fa7-f196-414d-9a66-1b819f39d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-47fe7d7a-a43c-421b-b9d4-0db5b47e3e60,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-0085ef2f-554e-4305-923f-f94ff693e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-655c1fad-4d33-45ce-bbd6-19da1d4d069d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409476470-172.17.0.9-1597520233324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-7e70a9c5-7854-494e-a4c1-9af8340f0e68,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-b94ce830-6cdb-4211-ab20-c6a48bdc96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-ac2d85b6-5691-46d6-8a48-cafb05bdd7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-baebadf9-e73f-4d8a-ba68-86f9c595521e,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-c2b88fa7-f196-414d-9a66-1b819f39d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-47fe7d7a-a43c-421b-b9d4-0db5b47e3e60,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-0085ef2f-554e-4305-923f-f94ff693e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-655c1fad-4d33-45ce-bbd6-19da1d4d069d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731296937-172.17.0.9-1597520681194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34589,DS-e6b82f6d-00be-40ee-aff6-71891c49eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-fce3cc0b-d57d-4aa3-a935-7bc27d7d7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-a222495b-aecd-42fe-8b68-6ba5b3265b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-a2d0355e-a270-42ef-8b41-8cd387a046c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-a05472da-81c5-469b-b428-8a30af60092e,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-6932cc83-3c9b-4aea-adcb-1bb239bf1fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-6ef962c1-c2ac-4b6f-832c-fd4776ea3df5,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-8be77a4a-2444-44e3-a422-1750b19bdf60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731296937-172.17.0.9-1597520681194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34589,DS-e6b82f6d-00be-40ee-aff6-71891c49eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-fce3cc0b-d57d-4aa3-a935-7bc27d7d7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-a222495b-aecd-42fe-8b68-6ba5b3265b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-a2d0355e-a270-42ef-8b41-8cd387a046c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-a05472da-81c5-469b-b428-8a30af60092e,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-6932cc83-3c9b-4aea-adcb-1bb239bf1fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-6ef962c1-c2ac-4b6f-832c-fd4776ea3df5,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-8be77a4a-2444-44e3-a422-1750b19bdf60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547161486-172.17.0.9-1597520809807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-52798e3e-1336-446f-be70-477b8ded4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-bed406e6-d5f5-412a-9f76-a783d909e7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-63a90410-7986-4ad3-b72f-826e360715aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-b82aea5f-1cba-4900-881c-0c9253e8ca2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-81195051-df1d-4f7d-bcd4-91be2907e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-bea6b48e-eef3-4c28-b3fd-87261b8edebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-e9672009-3633-4d00-a282-1e675a9e1752,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-99e51e2b-2380-485d-b86f-ecbdc8c43130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547161486-172.17.0.9-1597520809807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-52798e3e-1336-446f-be70-477b8ded4fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-bed406e6-d5f5-412a-9f76-a783d909e7da,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-63a90410-7986-4ad3-b72f-826e360715aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-b82aea5f-1cba-4900-881c-0c9253e8ca2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-81195051-df1d-4f7d-bcd4-91be2907e6da,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-bea6b48e-eef3-4c28-b3fd-87261b8edebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-e9672009-3633-4d00-a282-1e675a9e1752,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-99e51e2b-2380-485d-b86f-ecbdc8c43130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1021698797-172.17.0.9-1597520892945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-a65cfd04-ff13-4014-bbce-4e48f78356af,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-a67e7630-467e-480f-bfb9-9a19dc99e452,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-a044131c-2991-4b30-a4ba-84f99805a3da,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-bc0c4a8e-06aa-40ab-93c8-c6fd37b0a8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-fc65bfca-da51-4f54-aa41-7739c89912a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-2b18ab79-e386-41c9-8025-09e82fa9318f,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-a43efb85-aac0-4fe3-81d4-a5dbdeddd559,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-4ba468af-e52f-4c1d-95f4-c90d418cc060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1021698797-172.17.0.9-1597520892945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-a65cfd04-ff13-4014-bbce-4e48f78356af,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-a67e7630-467e-480f-bfb9-9a19dc99e452,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-a044131c-2991-4b30-a4ba-84f99805a3da,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-bc0c4a8e-06aa-40ab-93c8-c6fd37b0a8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-fc65bfca-da51-4f54-aa41-7739c89912a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-2b18ab79-e386-41c9-8025-09e82fa9318f,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-a43efb85-aac0-4fe3-81d4-a5dbdeddd559,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-4ba468af-e52f-4c1d-95f4-c90d418cc060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973285896-172.17.0.9-1597521005440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-659b13f5-c25d-41bb-bcc2-f24da89209d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-27d06678-1018-407b-8fc0-59122a9da773,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-b4ce9319-03e7-4e0f-af85-b0c20566b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-41152866-e31c-4eaf-88c9-b9a1b9d484b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-b773cb68-6b26-4b7f-bc99-5990493709ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-04814105-7816-4628-8779-30dae0643ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-e360471c-889d-4bb7-8c7f-3c773c12eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-ca4dba05-2a10-48a3-bf48-49d2c9984cad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1973285896-172.17.0.9-1597521005440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-659b13f5-c25d-41bb-bcc2-f24da89209d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-27d06678-1018-407b-8fc0-59122a9da773,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-b4ce9319-03e7-4e0f-af85-b0c20566b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-41152866-e31c-4eaf-88c9-b9a1b9d484b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-b773cb68-6b26-4b7f-bc99-5990493709ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-04814105-7816-4628-8779-30dae0643ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-e360471c-889d-4bb7-8c7f-3c773c12eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-ca4dba05-2a10-48a3-bf48-49d2c9984cad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002175829-172.17.0.9-1597521343573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-d97b462e-7a8c-4329-aedd-f97a7d809426,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-b3853312-b93f-47cd-95a8-f4440e806f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-0a3965f7-e100-4742-835e-0a4492395927,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-82721b56-cc1c-4d4a-8c69-421838ea8019,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-7a72f055-6aff-425e-9bc8-ad8086bcf9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-66555aac-1642-47fc-a00e-1bff67e6d934,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-6e726f96-3d52-443a-b2ec-f845f2d02a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-4bd44911-c83f-480d-8aea-96101c5b80e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002175829-172.17.0.9-1597521343573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-d97b462e-7a8c-4329-aedd-f97a7d809426,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-b3853312-b93f-47cd-95a8-f4440e806f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-0a3965f7-e100-4742-835e-0a4492395927,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-82721b56-cc1c-4d4a-8c69-421838ea8019,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-7a72f055-6aff-425e-9bc8-ad8086bcf9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-66555aac-1642-47fc-a00e-1bff67e6d934,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-6e726f96-3d52-443a-b2ec-f845f2d02a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-4bd44911-c83f-480d-8aea-96101c5b80e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499269565-172.17.0.9-1597522190324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36477,DS-3188d5c2-05a8-4199-b217-a14d55ef97e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-bd00eb85-8e8b-4d75-b718-e71b94cb6bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-701183c3-6439-49a7-ba24-4262295380bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-9eed5a7d-b990-4790-b88b-5e54f6d37b03,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-51fbaf92-95c4-4adc-9152-714eefa013ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-e96109cb-1c3e-4585-a81e-e7cc155e0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-3cce4c3e-e8b8-4387-9570-072d11e16065,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-fe5b0a61-bcd9-4686-accc-8f2e8d89d049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499269565-172.17.0.9-1597522190324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36477,DS-3188d5c2-05a8-4199-b217-a14d55ef97e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-bd00eb85-8e8b-4d75-b718-e71b94cb6bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-701183c3-6439-49a7-ba24-4262295380bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-9eed5a7d-b990-4790-b88b-5e54f6d37b03,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-51fbaf92-95c4-4adc-9152-714eefa013ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-e96109cb-1c3e-4585-a81e-e7cc155e0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-3cce4c3e-e8b8-4387-9570-072d11e16065,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-fe5b0a61-bcd9-4686-accc-8f2e8d89d049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256065840-172.17.0.9-1597522303602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42766,DS-c7476faf-b199-4bb8-b807-df737bf50706,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-3c58cf3a-1d01-41a9-aa5f-54e0c013a8de,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-f833f790-56c3-4180-9c2f-e7e81cecd2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-85c277c0-b59a-42d5-80a9-a5a0795ac4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-6c9501ab-e2f8-4d0e-9fbd-99685408d43d,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-3b2b71ae-539d-48e2-83f5-8f063be4a301,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-08c73bb7-6d4e-437e-bf2c-f28bf81a6e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-f4a2caa6-96e5-4016-971c-351c4564bd56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256065840-172.17.0.9-1597522303602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42766,DS-c7476faf-b199-4bb8-b807-df737bf50706,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-3c58cf3a-1d01-41a9-aa5f-54e0c013a8de,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-f833f790-56c3-4180-9c2f-e7e81cecd2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-85c277c0-b59a-42d5-80a9-a5a0795ac4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-6c9501ab-e2f8-4d0e-9fbd-99685408d43d,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-3b2b71ae-539d-48e2-83f5-8f063be4a301,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-08c73bb7-6d4e-437e-bf2c-f28bf81a6e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-f4a2caa6-96e5-4016-971c-351c4564bd56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245551543-172.17.0.9-1597522545048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-6f32f05d-0eaf-4766-a960-8a56ff5fe3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-62e5e2fc-dafa-4420-87fb-916f31262da8,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-ec26c2e4-a087-4c0b-b8bf-5f8a03c97fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-4ed7d828-89f3-4b99-ab1a-412d8d4d7959,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-3a623777-7fbf-4088-81bd-ac3dc56a7b72,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-2a9f2331-e0f9-434c-9625-1529e750c180,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f17643ca-f6f9-4ae0-8eaf-11cb0ece5a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-19fdffa9-1e29-498e-ac63-dfdc9fb9cb6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245551543-172.17.0.9-1597522545048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-6f32f05d-0eaf-4766-a960-8a56ff5fe3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-62e5e2fc-dafa-4420-87fb-916f31262da8,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-ec26c2e4-a087-4c0b-b8bf-5f8a03c97fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-4ed7d828-89f3-4b99-ab1a-412d8d4d7959,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-3a623777-7fbf-4088-81bd-ac3dc56a7b72,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-2a9f2331-e0f9-434c-9625-1529e750c180,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-f17643ca-f6f9-4ae0-8eaf-11cb0ece5a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-19fdffa9-1e29-498e-ac63-dfdc9fb9cb6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365880899-172.17.0.9-1597523125135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41628,DS-b037f021-353d-483f-bf93-c506ff215d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-e07766bd-41d4-441a-b227-e19c1d09c673,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-266d0387-026d-42a8-b9e0-896b6597dc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-c3169865-e6a9-42c1-91a0-23d104ab2103,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-69cb693d-40f6-414d-8988-e11a488a283d,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-125e6e0f-eddc-4042-84de-cbb66fc6ccff,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-a49e5eb5-a75c-470d-a693-19bda2574f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-aad589ec-7090-4fdf-9bfb-d7977e262e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365880899-172.17.0.9-1597523125135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41628,DS-b037f021-353d-483f-bf93-c506ff215d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-e07766bd-41d4-441a-b227-e19c1d09c673,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-266d0387-026d-42a8-b9e0-896b6597dc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-c3169865-e6a9-42c1-91a0-23d104ab2103,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-69cb693d-40f6-414d-8988-e11a488a283d,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-125e6e0f-eddc-4042-84de-cbb66fc6ccff,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-a49e5eb5-a75c-470d-a693-19bda2574f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-aad589ec-7090-4fdf-9bfb-d7977e262e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942403663-172.17.0.9-1597523226052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34111,DS-2278b73f-5763-400b-a2e0-c432994423f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-5853df64-94fd-4775-8834-5bf3028dc439,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-79ff9800-a6b6-4508-8744-17f88948fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-dacfcd5b-8af8-43da-9978-1f96549c759d,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-1e3c3cb1-8531-4b08-936e-9d7f25fd1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-30d68227-267f-4b43-9606-7dd01bc4bbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-87272f74-8e89-49aa-9a77-fd59a751fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-a440ac37-990c-4dbf-a524-6e3a7b3ee558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1942403663-172.17.0.9-1597523226052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34111,DS-2278b73f-5763-400b-a2e0-c432994423f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-5853df64-94fd-4775-8834-5bf3028dc439,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-79ff9800-a6b6-4508-8744-17f88948fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-dacfcd5b-8af8-43da-9978-1f96549c759d,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-1e3c3cb1-8531-4b08-936e-9d7f25fd1f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-30d68227-267f-4b43-9606-7dd01bc4bbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-87272f74-8e89-49aa-9a77-fd59a751fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-a440ac37-990c-4dbf-a524-6e3a7b3ee558,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522914223-172.17.0.9-1597523539966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-4f96a359-d27e-44b1-ada3-e0e803e307a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-51b75f38-e718-4d7a-88be-45e3ebd46211,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-1bba3969-14e6-49d5-ba77-b7f79686889a,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-76a78851-1d32-44df-8c62-8447f58e903c,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-609197a4-670f-4c47-b4eb-b105b1fbb97c,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-3a3f20cd-2a5a-411b-9bfd-3b82af60e9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-ec737c4f-bdff-4881-9050-e42c9fa4655a,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-8dbd37cc-ead9-4183-9754-b03ae9e9fdb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522914223-172.17.0.9-1597523539966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-4f96a359-d27e-44b1-ada3-e0e803e307a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-51b75f38-e718-4d7a-88be-45e3ebd46211,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-1bba3969-14e6-49d5-ba77-b7f79686889a,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-76a78851-1d32-44df-8c62-8447f58e903c,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-609197a4-670f-4c47-b4eb-b105b1fbb97c,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-3a3f20cd-2a5a-411b-9bfd-3b82af60e9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-ec737c4f-bdff-4881-9050-e42c9fa4655a,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-8dbd37cc-ead9-4183-9754-b03ae9e9fdb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972163569-172.17.0.9-1597523618203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45754,DS-bb99d0a8-5d9f-4d89-be48-d4c8da2d53ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-ae3d5930-cf2f-451a-b7d8-41d1a5837b21,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-41597987-19b6-42ff-bfc8-4ee3b7715661,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-bfa3ec35-6f4e-452e-b5f1-a7a48f7bfdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-dbdd54f6-40f9-4897-b9fe-1f77625a7530,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-906c755c-f1ba-4cc2-8afc-ad1659cb585c,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-100390f7-361c-4b0d-b464-32d57bbe9d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-88a2e92a-067e-4f0a-8f87-df18a00cbbf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972163569-172.17.0.9-1597523618203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45754,DS-bb99d0a8-5d9f-4d89-be48-d4c8da2d53ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-ae3d5930-cf2f-451a-b7d8-41d1a5837b21,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-41597987-19b6-42ff-bfc8-4ee3b7715661,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-bfa3ec35-6f4e-452e-b5f1-a7a48f7bfdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-dbdd54f6-40f9-4897-b9fe-1f77625a7530,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-906c755c-f1ba-4cc2-8afc-ad1659cb585c,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-100390f7-361c-4b0d-b464-32d57bbe9d69,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-88a2e92a-067e-4f0a-8f87-df18a00cbbf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283000575-172.17.0.9-1597523655253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-96807ca5-2187-41ac-a349-3a562c1a34c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-8f23d735-ec9e-4fbb-90a5-10939d6c36e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-45c6ce84-2d9f-4d7f-89b3-9ec87060d57b,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-3edd2dda-2e80-4517-ba18-7c7ef8cea292,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-a093b927-e39c-4348-ac0c-33124cf13238,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-1ed014df-d2c0-4995-9184-fff6b5be1e19,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-f371f41c-9424-407b-a926-3c8c9986570a,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-ec51cb70-14f8-44cc-9c05-4dd75436f373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-283000575-172.17.0.9-1597523655253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-96807ca5-2187-41ac-a349-3a562c1a34c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-8f23d735-ec9e-4fbb-90a5-10939d6c36e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-45c6ce84-2d9f-4d7f-89b3-9ec87060d57b,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-3edd2dda-2e80-4517-ba18-7c7ef8cea292,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-a093b927-e39c-4348-ac0c-33124cf13238,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-1ed014df-d2c0-4995-9184-fff6b5be1e19,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-f371f41c-9424-407b-a926-3c8c9986570a,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-ec51cb70-14f8-44cc-9c05-4dd75436f373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590689591-172.17.0.9-1597523873063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-f5b487bb-5a72-4664-adda-3df84d469f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-15c91425-3d28-4f35-abf9-bdb16d7c47f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-0f3b4556-96b9-4d4e-8336-86288702e40f,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-4e17f71c-5c9b-49f6-b54b-42c13ad6b129,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-22d9280b-9585-43a6-83d5-ffc9d48e3209,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-5590022b-af38-4652-8d0e-99ef3457b644,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-1a0adfbf-e783-45a3-beb2-a2925b778b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-c32f7dfc-b6b8-4789-9f9a-055fc65204f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590689591-172.17.0.9-1597523873063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-f5b487bb-5a72-4664-adda-3df84d469f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-15c91425-3d28-4f35-abf9-bdb16d7c47f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-0f3b4556-96b9-4d4e-8336-86288702e40f,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-4e17f71c-5c9b-49f6-b54b-42c13ad6b129,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-22d9280b-9585-43a6-83d5-ffc9d48e3209,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-5590022b-af38-4652-8d0e-99ef3457b644,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-1a0adfbf-e783-45a3-beb2-a2925b778b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-c32f7dfc-b6b8-4789-9f9a-055fc65204f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751188921-172.17.0.9-1597524305330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-a8f75644-2fac-488c-987b-49bd6636ac62,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-9d09502a-cb4d-405c-ab57-2a4630d330e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-57fa6a57-9434-4181-ad28-9da07ff9bf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-566fb212-ddac-400c-8fd2-9f702eb94ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-9607047d-d59f-4922-81e1-e4dc835bbce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-5d8af710-72c8-4c1d-9f0f-fc6a1103f480,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-9b7af4f5-ace0-4558-88d9-d61eb36a05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-91ba40bd-8c7f-4fd8-a1ec-bdd5e0571ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751188921-172.17.0.9-1597524305330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46670,DS-a8f75644-2fac-488c-987b-49bd6636ac62,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-9d09502a-cb4d-405c-ab57-2a4630d330e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-57fa6a57-9434-4181-ad28-9da07ff9bf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-566fb212-ddac-400c-8fd2-9f702eb94ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-9607047d-d59f-4922-81e1-e4dc835bbce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-5d8af710-72c8-4c1d-9f0f-fc6a1103f480,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-9b7af4f5-ace0-4558-88d9-d61eb36a05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-91ba40bd-8c7f-4fd8-a1ec-bdd5e0571ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850858257-172.17.0.9-1597524439900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-56f822f4-d8d8-4ddd-9f73-a1b4ac94421c,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-6f9ae948-abe0-4774-9f46-71fff2e5dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-6ca26c71-6330-4ca2-9640-7297fd7f9f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-47da0a95-734b-4682-835e-581fbe0414ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-4837f8db-e5e7-4e7d-b320-72184c084152,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-c5adc30a-f933-4d6c-b1be-3196468ff9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-84bef4ee-d2cd-453e-96ea-8f9d586340cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-5bdc5483-e18b-41a9-8e06-9d6ac7ce9325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850858257-172.17.0.9-1597524439900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34200,DS-56f822f4-d8d8-4ddd-9f73-a1b4ac94421c,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-6f9ae948-abe0-4774-9f46-71fff2e5dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-6ca26c71-6330-4ca2-9640-7297fd7f9f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-47da0a95-734b-4682-835e-581fbe0414ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-4837f8db-e5e7-4e7d-b320-72184c084152,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-c5adc30a-f933-4d6c-b1be-3196468ff9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-84bef4ee-d2cd-453e-96ea-8f9d586340cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-5bdc5483-e18b-41a9-8e06-9d6ac7ce9325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478092038-172.17.0.9-1597524512785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46063,DS-d4b4edaa-e7e5-4d8a-ac2c-28e06d3f2768,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-db0293aa-6a80-4c2d-be22-de4221780703,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-e39dd76e-6228-4a16-8295-76703d878dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-95b20fd5-a888-4d89-9a4c-f4eb6d99f64a,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-ac0d3439-8ff9-4883-8392-5d9055e75d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-79d418cc-d736-47f4-b162-fe7bcccefd05,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-b78a89b9-8514-434d-991f-f43f4f8e6937,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-df66a500-e9a3-4e7b-9afe-9d35a2dc7b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478092038-172.17.0.9-1597524512785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46063,DS-d4b4edaa-e7e5-4d8a-ac2c-28e06d3f2768,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-db0293aa-6a80-4c2d-be22-de4221780703,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-e39dd76e-6228-4a16-8295-76703d878dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-95b20fd5-a888-4d89-9a4c-f4eb6d99f64a,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-ac0d3439-8ff9-4883-8392-5d9055e75d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-79d418cc-d736-47f4-b162-fe7bcccefd05,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-b78a89b9-8514-434d-991f-f43f4f8e6937,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-df66a500-e9a3-4e7b-9afe-9d35a2dc7b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240394883-172.17.0.9-1597524591745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-b4b1ca25-5099-4061-8406-4cab722cd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-5f3b729e-1378-4426-8e4a-e75f02cf27c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-caf14fc5-ecd7-4112-9e00-6672fb891454,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-987f0967-c8cc-4fae-8fbf-00f246fb5e19,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-b0127945-1407-455a-b5ee-31dc14db2f06,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-2ad9c021-7e39-4c5d-9a98-00c8665939e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-bbd8ef0b-1564-4912-a9a0-aa1871eb7231,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-45e12303-0d02-4896-ab00-e42c768e6043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240394883-172.17.0.9-1597524591745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-b4b1ca25-5099-4061-8406-4cab722cd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-5f3b729e-1378-4426-8e4a-e75f02cf27c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-caf14fc5-ecd7-4112-9e00-6672fb891454,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-987f0967-c8cc-4fae-8fbf-00f246fb5e19,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-b0127945-1407-455a-b5ee-31dc14db2f06,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-2ad9c021-7e39-4c5d-9a98-00c8665939e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-bbd8ef0b-1564-4912-a9a0-aa1871eb7231,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-45e12303-0d02-4896-ab00-e42c768e6043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611147353-172.17.0.9-1597524783716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-4101a72b-d903-490a-993c-a933398d7cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-099c366c-443a-45a4-9118-3b59d984ec72,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-1f704607-d6c6-4b38-8790-9e023fa663fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-66c552c2-a23e-4456-97ba-15fe61f370d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-64b8ddf6-d5e9-424f-8a31-321fbca361af,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-e90ad02d-ca4a-4cad-9baf-01158de24554,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-6cd24b2b-6094-4d81-b943-ecc4e35d8e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-ab395ff3-48ce-4182-9604-6a3feac2391a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611147353-172.17.0.9-1597524783716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-4101a72b-d903-490a-993c-a933398d7cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-099c366c-443a-45a4-9118-3b59d984ec72,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-1f704607-d6c6-4b38-8790-9e023fa663fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-66c552c2-a23e-4456-97ba-15fe61f370d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-64b8ddf6-d5e9-424f-8a31-321fbca361af,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-e90ad02d-ca4a-4cad-9baf-01158de24554,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-6cd24b2b-6094-4d81-b943-ecc4e35d8e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-ab395ff3-48ce-4182-9604-6a3feac2391a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5632
