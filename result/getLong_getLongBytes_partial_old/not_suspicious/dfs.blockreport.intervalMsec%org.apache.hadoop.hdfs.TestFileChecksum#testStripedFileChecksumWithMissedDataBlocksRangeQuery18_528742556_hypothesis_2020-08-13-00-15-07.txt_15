reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616661266-172.17.0.2-1597278547009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-3434039f-bc72-45f4-8613-7cb7d098fabd,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-8424f824-cc7b-4ad2-acc6-d590512a2065,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-7c27f0a9-1f46-44fa-b37c-16652e5d94da,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-c283ed3b-5e5b-430d-9696-5945f8cc3def,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-a84564c3-235d-442f-a3cb-c5e1eae22bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-f089ee7d-ee8f-4caa-9ebf-9667534ce777,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-acd6f537-377d-423a-be65-7e90e0047883,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-792febd1-bfc3-4d9e-868b-c35c3425fc72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616661266-172.17.0.2-1597278547009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-3434039f-bc72-45f4-8613-7cb7d098fabd,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-8424f824-cc7b-4ad2-acc6-d590512a2065,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-7c27f0a9-1f46-44fa-b37c-16652e5d94da,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-c283ed3b-5e5b-430d-9696-5945f8cc3def,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-a84564c3-235d-442f-a3cb-c5e1eae22bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-f089ee7d-ee8f-4caa-9ebf-9667534ce777,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-acd6f537-377d-423a-be65-7e90e0047883,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-792febd1-bfc3-4d9e-868b-c35c3425fc72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1364982963-172.17.0.2-1597278690273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-29413525-da5c-4455-a295-245210d9896a,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-6fc33911-73ef-4bfe-88b9-b8058645e943,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-1401301e-3a2d-4f71-9a18-3f9cee9645b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-a3e84c71-bc28-4d75-ae58-192b602aadc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-6d998171-2ae0-4b16-8348-2a30231053ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-4152a275-97a1-47e3-ae89-2382bab6cbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-c9fa1f0b-0a6e-498d-9c05-8214cab66e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-8f6780c8-1dd0-44ba-9200-0876d574eead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1364982963-172.17.0.2-1597278690273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-29413525-da5c-4455-a295-245210d9896a,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-6fc33911-73ef-4bfe-88b9-b8058645e943,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-1401301e-3a2d-4f71-9a18-3f9cee9645b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-a3e84c71-bc28-4d75-ae58-192b602aadc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-6d998171-2ae0-4b16-8348-2a30231053ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-4152a275-97a1-47e3-ae89-2382bab6cbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-c9fa1f0b-0a6e-498d-9c05-8214cab66e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-8f6780c8-1dd0-44ba-9200-0876d574eead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720157930-172.17.0.2-1597278775140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-55bb5bf1-937d-402b-9716-015baac22f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-e8080328-a797-42b0-b07a-c73dfc77d711,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-6e9bb83b-3d4b-4152-9988-9787f5f52ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-f2fcac70-e97f-4611-a55c-228eb91e2076,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-e2eec633-4751-40e9-8971-1512bbc125de,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-d1a42bb9-4d57-4fe1-8498-f6fd054820ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-b91471b6-432c-4aba-a0ca-0dc4b3801513,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-eb26a5c3-85d8-4f82-9e0a-2c9a35b7c3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720157930-172.17.0.2-1597278775140:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-55bb5bf1-937d-402b-9716-015baac22f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-e8080328-a797-42b0-b07a-c73dfc77d711,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-6e9bb83b-3d4b-4152-9988-9787f5f52ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-f2fcac70-e97f-4611-a55c-228eb91e2076,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-e2eec633-4751-40e9-8971-1512bbc125de,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-d1a42bb9-4d57-4fe1-8498-f6fd054820ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-b91471b6-432c-4aba-a0ca-0dc4b3801513,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-eb26a5c3-85d8-4f82-9e0a-2c9a35b7c3bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043150513-172.17.0.2-1597279640114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-b4d0d8b9-a525-48d6-94a1-d6bd2d3857f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-0b075fd5-6a7c-420a-babf-e3e0ff700ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-30697110-8368-4ed4-991e-e4efde30592a,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-c31d03db-6b6f-4965-94c8-4394cb20ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-1ace2400-c660-4992-9cb3-511a4614a859,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-6618d69d-07e2-4b3d-bf26-0d9050b8f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-34d08ff6-71f6-4ff8-82d5-f7e12e57180a,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-90d804e9-dc7d-49c9-bedd-dcf190ad6b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043150513-172.17.0.2-1597279640114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-b4d0d8b9-a525-48d6-94a1-d6bd2d3857f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32928,DS-0b075fd5-6a7c-420a-babf-e3e0ff700ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-30697110-8368-4ed4-991e-e4efde30592a,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-c31d03db-6b6f-4965-94c8-4394cb20ff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-1ace2400-c660-4992-9cb3-511a4614a859,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-6618d69d-07e2-4b3d-bf26-0d9050b8f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-34d08ff6-71f6-4ff8-82d5-f7e12e57180a,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-90d804e9-dc7d-49c9-bedd-dcf190ad6b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365158251-172.17.0.2-1597280035130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42442,DS-0927419d-f627-428e-9ccb-7d437e19e48e,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-d7460e80-46f6-4fb5-bf77-c4d9f481738e,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-405187ec-d8c0-446c-a597-de5d66db7936,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-73b152c3-29d0-4d5a-bc9f-baae7439e236,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-047c3814-8098-47e1-8705-c0c4ed684905,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-beabf52f-32f1-47f9-bfeb-e9ef83a5d6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-b9a4c22a-5042-4b56-9542-06e055c65f24,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-7f387a58-8791-4021-ac70-d39f48595166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365158251-172.17.0.2-1597280035130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42442,DS-0927419d-f627-428e-9ccb-7d437e19e48e,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-d7460e80-46f6-4fb5-bf77-c4d9f481738e,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-405187ec-d8c0-446c-a597-de5d66db7936,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-73b152c3-29d0-4d5a-bc9f-baae7439e236,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-047c3814-8098-47e1-8705-c0c4ed684905,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-beabf52f-32f1-47f9-bfeb-e9ef83a5d6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-b9a4c22a-5042-4b56-9542-06e055c65f24,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-7f387a58-8791-4021-ac70-d39f48595166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266709925-172.17.0.2-1597280232529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41342,DS-2a973548-4b5d-497f-b3a4-156be42ed00a,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-a2147a85-99fb-4d0a-a37f-ee5fce5276df,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d1369372-3ce5-4984-87f1-63dd80225905,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-a66ea21a-49b2-49bf-994e-7160efa47bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-c983dca9-fc6d-4550-9e35-0240089467cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-d2f7b520-626c-40f2-bdff-3d18ae2a8190,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-0323302e-8c6f-4a5e-8244-eee9b95eaea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-765d1e02-0b00-428f-ba87-1d3aa7c5ddf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266709925-172.17.0.2-1597280232529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41342,DS-2a973548-4b5d-497f-b3a4-156be42ed00a,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-a2147a85-99fb-4d0a-a37f-ee5fce5276df,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-d1369372-3ce5-4984-87f1-63dd80225905,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-a66ea21a-49b2-49bf-994e-7160efa47bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-c983dca9-fc6d-4550-9e35-0240089467cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-d2f7b520-626c-40f2-bdff-3d18ae2a8190,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-0323302e-8c6f-4a5e-8244-eee9b95eaea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-765d1e02-0b00-428f-ba87-1d3aa7c5ddf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294200252-172.17.0.2-1597280362875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-8484c402-84a0-4989-95fe-a25920e900c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-0e0c5fe3-2b3e-4ce9-857e-2bf6992f00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-0abffac1-fe29-44a7-a57e-bfb04d505457,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-8c294807-0368-4844-8b4a-52c3a85c51a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-9e10a56b-331e-45c3-997c-d40a700bbf47,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-9184ad7f-75e0-4eb0-9f89-22b9601e7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-e87c539b-7458-4525-9f1f-43541b2510b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-3f26b9c4-e617-4436-b366-e5898dc67e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294200252-172.17.0.2-1597280362875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-8484c402-84a0-4989-95fe-a25920e900c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-0e0c5fe3-2b3e-4ce9-857e-2bf6992f00fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-0abffac1-fe29-44a7-a57e-bfb04d505457,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-8c294807-0368-4844-8b4a-52c3a85c51a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-9e10a56b-331e-45c3-997c-d40a700bbf47,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-9184ad7f-75e0-4eb0-9f89-22b9601e7e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-e87c539b-7458-4525-9f1f-43541b2510b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-3f26b9c4-e617-4436-b366-e5898dc67e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108040273-172.17.0.2-1597281184105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-504e8e72-c2b9-4d3d-8e8a-d8a78952ca21,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-81d04478-5cae-4be0-b421-e09bf3cbbd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-3533bc49-1795-4ad8-8166-8e709011713d,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-f5b678a1-da1f-41ab-8547-447c2bf50213,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-a10df68f-d664-40cb-b1f5-394fd593f77f,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-707703bc-f5a5-41c7-adbb-2e9c98d4328e,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-89d25dd0-0c81-4974-9847-3e9907129612,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-7353e084-0d75-4b1e-8ef1-a9d1e1df57b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108040273-172.17.0.2-1597281184105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-504e8e72-c2b9-4d3d-8e8a-d8a78952ca21,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-81d04478-5cae-4be0-b421-e09bf3cbbd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-3533bc49-1795-4ad8-8166-8e709011713d,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-f5b678a1-da1f-41ab-8547-447c2bf50213,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-a10df68f-d664-40cb-b1f5-394fd593f77f,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-707703bc-f5a5-41c7-adbb-2e9c98d4328e,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-89d25dd0-0c81-4974-9847-3e9907129612,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-7353e084-0d75-4b1e-8ef1-a9d1e1df57b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573919775-172.17.0.2-1597281458476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-b3557146-a948-4e8a-850d-0fc70c398b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-e61a6840-0bcd-46e8-907c-20d014b0014f,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-18dd0ead-eb4b-477d-b458-6b0a08f38ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-631f658c-8abe-4eec-bff7-63bbe8cde758,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-d94e3aec-a9e7-4bef-b607-1a86f519e7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-f6e53b93-efd9-4166-8ace-c1c3d0c8f993,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-341d43a8-9165-4b2c-b504-eb195ca599ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-22a7dd2e-a403-41c6-b164-10f8e41860df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573919775-172.17.0.2-1597281458476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-b3557146-a948-4e8a-850d-0fc70c398b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-e61a6840-0bcd-46e8-907c-20d014b0014f,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-18dd0ead-eb4b-477d-b458-6b0a08f38ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-631f658c-8abe-4eec-bff7-63bbe8cde758,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-d94e3aec-a9e7-4bef-b607-1a86f519e7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-f6e53b93-efd9-4166-8ace-c1c3d0c8f993,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-341d43a8-9165-4b2c-b504-eb195ca599ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-22a7dd2e-a403-41c6-b164-10f8e41860df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272610531-172.17.0.2-1597281931359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43747,DS-671ad062-4062-40dc-8da4-425fb145c386,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-b0a5445f-7419-4df3-89e9-3b27fbc92e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-41590092-1c9d-4eb5-acc7-b42341b4bd72,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-819ddf84-7458-4aeb-ba72-4bed6b605b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-8c06e10d-9e78-4a58-8eb2-79c409ccb64e,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-a6507031-8123-4b92-a209-28212d4c55c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-725daf9b-bcf5-4329-96b9-167f5c74d521,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-49801569-4c65-43f3-b36b-295d4097debe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272610531-172.17.0.2-1597281931359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43747,DS-671ad062-4062-40dc-8da4-425fb145c386,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-b0a5445f-7419-4df3-89e9-3b27fbc92e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-41590092-1c9d-4eb5-acc7-b42341b4bd72,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-819ddf84-7458-4aeb-ba72-4bed6b605b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-8c06e10d-9e78-4a58-8eb2-79c409ccb64e,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-a6507031-8123-4b92-a209-28212d4c55c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-725daf9b-bcf5-4329-96b9-167f5c74d521,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-49801569-4c65-43f3-b36b-295d4097debe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581496471-172.17.0.2-1597281983354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-a5f8ae70-ad41-41bd-a83f-11399f38fb45,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-afa0ef3c-9540-4cc7-8217-0eddc28f249b,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-0b00126d-a585-4478-8e42-645b04df0a35,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-1e4fd91c-ab2c-4e90-bcdb-6827ebe56d00,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-15cfa98d-bd28-4ca9-86af-77de568c8fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-2b658b64-dc24-4bf1-8189-43b003c8f89a,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-235ac1df-0bd9-41f6-a195-718a1cc5c86d,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-749ca60d-18f0-48a2-869b-ef12daa5a8c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581496471-172.17.0.2-1597281983354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-a5f8ae70-ad41-41bd-a83f-11399f38fb45,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-afa0ef3c-9540-4cc7-8217-0eddc28f249b,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-0b00126d-a585-4478-8e42-645b04df0a35,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-1e4fd91c-ab2c-4e90-bcdb-6827ebe56d00,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-15cfa98d-bd28-4ca9-86af-77de568c8fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-2b658b64-dc24-4bf1-8189-43b003c8f89a,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-235ac1df-0bd9-41f6-a195-718a1cc5c86d,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-749ca60d-18f0-48a2-869b-ef12daa5a8c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914099966-172.17.0.2-1597282379437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-2fc69b38-d40e-484f-820e-8a856842ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-025ca14f-d4db-407f-85e6-dc2a61d7462b,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-9b2b56c5-1a61-4591-b39b-0baa9518b8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-8ef55b3b-c63d-4bf6-ae98-ffdddff94227,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-a464ffa9-2ab6-4554-9f3c-94cd36d02b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-86338754-ef7e-44f5-914d-53108ec33367,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-ab229344-d033-45bc-9784-5fac708e4d61,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-96ab771a-aef2-4639-920d-62ca37f1ffab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914099966-172.17.0.2-1597282379437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-2fc69b38-d40e-484f-820e-8a856842ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-025ca14f-d4db-407f-85e6-dc2a61d7462b,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-9b2b56c5-1a61-4591-b39b-0baa9518b8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-8ef55b3b-c63d-4bf6-ae98-ffdddff94227,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-a464ffa9-2ab6-4554-9f3c-94cd36d02b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-86338754-ef7e-44f5-914d-53108ec33367,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-ab229344-d033-45bc-9784-5fac708e4d61,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-96ab771a-aef2-4639-920d-62ca37f1ffab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67378474-172.17.0.2-1597282706850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-87ec521d-f598-4f07-85da-aab13a32491a,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-3ad5ca72-fc20-49f3-8e92-bf475b2859cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-6411d876-e9d1-46ef-94ec-2a75a43e5416,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-88e6a721-f7db-4adf-b697-9392d04baf42,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-af290aee-4f08-44ec-b350-80486ffb7b42,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-78bfcfc8-8f45-44ce-a27c-a457bc0e1ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-258168d5-c7c8-4ef2-8936-7c88768b757d,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-13da5364-17cf-4058-b6e0-3aae4043f716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67378474-172.17.0.2-1597282706850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-87ec521d-f598-4f07-85da-aab13a32491a,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-3ad5ca72-fc20-49f3-8e92-bf475b2859cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-6411d876-e9d1-46ef-94ec-2a75a43e5416,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-88e6a721-f7db-4adf-b697-9392d04baf42,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-af290aee-4f08-44ec-b350-80486ffb7b42,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-78bfcfc8-8f45-44ce-a27c-a457bc0e1ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-258168d5-c7c8-4ef2-8936-7c88768b757d,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-13da5364-17cf-4058-b6e0-3aae4043f716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734234496-172.17.0.2-1597283065130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34304,DS-633deee6-0106-4f1f-bad0-0f27c7c53797,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-7e2b0d3a-597c-4ea2-89da-9ed15e2c4887,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-d546b3b1-76f9-4cf3-9a85-dcc864847302,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-b3b2d38a-f568-40df-bbaa-58bd836704fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-85a8f643-899a-4624-9736-a39b3031c613,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-c4449c8e-e590-473d-86e9-c25ad11f557d,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-10455f65-e54b-42f3-965d-89247b8533ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-21530430-0755-41e0-b5c3-8185c2ff1e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-734234496-172.17.0.2-1597283065130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34304,DS-633deee6-0106-4f1f-bad0-0f27c7c53797,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-7e2b0d3a-597c-4ea2-89da-9ed15e2c4887,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-d546b3b1-76f9-4cf3-9a85-dcc864847302,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-b3b2d38a-f568-40df-bbaa-58bd836704fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-85a8f643-899a-4624-9736-a39b3031c613,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-c4449c8e-e590-473d-86e9-c25ad11f557d,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-10455f65-e54b-42f3-965d-89247b8533ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-21530430-0755-41e0-b5c3-8185c2ff1e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312730962-172.17.0.2-1597283491433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-c1df5fec-80f9-425f-b9ee-5945578cac40,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-9ada6412-e79d-489a-8066-72c6f38d9973,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f19e61fc-9ca6-4557-a802-d89cd0f929bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-9e0a4e12-4838-46ee-be77-131fec4dc457,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-9b357810-5baf-43ba-a730-8a991d2ac793,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-cdd0093b-3191-485b-b95b-fd4261b20072,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-acb4a3e5-7454-40e8-bf35-690c91f5fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-a462de2f-de95-491a-a22e-9a4daa4ae395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312730962-172.17.0.2-1597283491433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-c1df5fec-80f9-425f-b9ee-5945578cac40,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-9ada6412-e79d-489a-8066-72c6f38d9973,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f19e61fc-9ca6-4557-a802-d89cd0f929bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-9e0a4e12-4838-46ee-be77-131fec4dc457,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-9b357810-5baf-43ba-a730-8a991d2ac793,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-cdd0093b-3191-485b-b95b-fd4261b20072,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-acb4a3e5-7454-40e8-bf35-690c91f5fd02,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-a462de2f-de95-491a-a22e-9a4daa4ae395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567500004-172.17.0.2-1597283725037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39826,DS-855df36c-47ff-4277-8637-0a26763365e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-d23c1d22-15a7-45e4-bc7d-820c06ad17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-6f5ed676-e47e-4442-8145-37b17df63f55,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-14ae2d50-3f19-453a-b182-d26cdb1b9db1,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-01682f63-0c2e-4565-acd3-831d69bc3877,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-786ff69c-492a-4100-a0e1-eaf42420057a,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-a23c6efe-12db-46fb-8ea7-a27f73604d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-e5dcb36a-ab32-4ccc-84bb-820d9ad269b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567500004-172.17.0.2-1597283725037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39826,DS-855df36c-47ff-4277-8637-0a26763365e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-d23c1d22-15a7-45e4-bc7d-820c06ad17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-6f5ed676-e47e-4442-8145-37b17df63f55,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-14ae2d50-3f19-453a-b182-d26cdb1b9db1,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-01682f63-0c2e-4565-acd3-831d69bc3877,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-786ff69c-492a-4100-a0e1-eaf42420057a,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-a23c6efe-12db-46fb-8ea7-a27f73604d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-e5dcb36a-ab32-4ccc-84bb-820d9ad269b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192459954-172.17.0.2-1597283814619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44146,DS-4381c05e-609b-496f-93d6-1875d3c97aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-604b4f87-8876-4dee-891e-61be40a2ec92,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-9c3056b7-5e8a-4dd3-add3-b7c3310eaca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-d190537e-74df-469d-8cfa-96fb18535491,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-9c92b345-f38e-4c43-a00c-e39ad964e468,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-5b303fda-a576-4d56-a56d-344eba363e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-a7c06591-bc4e-4ec8-8a88-0151d1fdb418,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-7a4fe6ea-d1e7-4862-a301-79cd9768a8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192459954-172.17.0.2-1597283814619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44146,DS-4381c05e-609b-496f-93d6-1875d3c97aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-604b4f87-8876-4dee-891e-61be40a2ec92,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-9c3056b7-5e8a-4dd3-add3-b7c3310eaca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-d190537e-74df-469d-8cfa-96fb18535491,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-9c92b345-f38e-4c43-a00c-e39ad964e468,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-5b303fda-a576-4d56-a56d-344eba363e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-a7c06591-bc4e-4ec8-8a88-0151d1fdb418,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-7a4fe6ea-d1e7-4862-a301-79cd9768a8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369518962-172.17.0.2-1597283965818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38387,DS-cc0d64b0-dff0-49db-8055-0fddaef0cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-26583631-ebbf-45fe-baa7-26c1821bec98,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-c5c31c34-c086-4c14-914a-e29390ff6867,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-c9868184-d8f3-4187-abac-89897d1be748,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-3a949cff-23b4-4c80-8d9c-c2638a6356bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-bc5e369b-6056-4321-9af9-8c8bef0c5aff,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-9aa86bd4-094f-484b-9c7c-b21edf16b799,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-817d35db-b846-41c1-b2b4-f018faf42acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369518962-172.17.0.2-1597283965818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38387,DS-cc0d64b0-dff0-49db-8055-0fddaef0cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-26583631-ebbf-45fe-baa7-26c1821bec98,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-c5c31c34-c086-4c14-914a-e29390ff6867,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-c9868184-d8f3-4187-abac-89897d1be748,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-3a949cff-23b4-4c80-8d9c-c2638a6356bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-bc5e369b-6056-4321-9af9-8c8bef0c5aff,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-9aa86bd4-094f-484b-9c7c-b21edf16b799,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-817d35db-b846-41c1-b2b4-f018faf42acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789184636-172.17.0.2-1597284098023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43428,DS-e58fc22c-c418-4ed3-8346-fea5972f7fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-2cb57191-1bb0-49a6-8e93-242381b7afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-8135236a-88a1-401c-96da-b6cd9b7d3cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-cfd7c6fa-0c8c-487d-84eb-c13f427cc694,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-8b09badd-6441-4513-9c63-c55d8ac9efaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-0f3da165-5ca9-496c-89a9-16d1af60b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-3559c76c-8a69-4a29-a097-730bc983e8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-d8020255-36d5-47a6-8751-1f5946b298a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789184636-172.17.0.2-1597284098023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43428,DS-e58fc22c-c418-4ed3-8346-fea5972f7fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-2cb57191-1bb0-49a6-8e93-242381b7afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-8135236a-88a1-401c-96da-b6cd9b7d3cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-cfd7c6fa-0c8c-487d-84eb-c13f427cc694,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-8b09badd-6441-4513-9c63-c55d8ac9efaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-0f3da165-5ca9-496c-89a9-16d1af60b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-3559c76c-8a69-4a29-a097-730bc983e8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-d8020255-36d5-47a6-8751-1f5946b298a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590667219-172.17.0.2-1597284135137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46410,DS-89afb79f-6f6a-4bf4-bdb1-8b1dcd5e2214,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-4ebf362b-3759-40de-95dd-cfe40f8a6f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-00b508d2-9e63-443b-9aaf-02b2e240fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-7ff0e9c9-ba02-44be-9746-3de0b4dd63dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-1923b22c-6b70-4825-8283-9be3ba126d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-c334a743-8606-4759-b93c-f5a3ff00698b,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-c41912f0-4320-4f8c-89d4-9f040946d016,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-fc3704ce-220b-4353-995e-c8c20ee9611f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590667219-172.17.0.2-1597284135137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46410,DS-89afb79f-6f6a-4bf4-bdb1-8b1dcd5e2214,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-4ebf362b-3759-40de-95dd-cfe40f8a6f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-00b508d2-9e63-443b-9aaf-02b2e240fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-7ff0e9c9-ba02-44be-9746-3de0b4dd63dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-1923b22c-6b70-4825-8283-9be3ba126d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-c334a743-8606-4759-b93c-f5a3ff00698b,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-c41912f0-4320-4f8c-89d4-9f040946d016,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-fc3704ce-220b-4353-995e-c8c20ee9611f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592098657-172.17.0.2-1597284178549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-b7677ec4-405d-4fc4-af31-fff2a1599a54,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-5bee85a9-507f-428b-9fde-353d2b8bf2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-3c873c52-99b4-403c-a893-0f040c31c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-0eaa9001-21f3-41de-9874-b4b0a6a7c504,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-5f6f5f66-cdf8-49a4-a5b0-608acf3bed06,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-bdefa4ef-78d9-4035-959f-0c962ddcdd32,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-c5b4794f-8311-4704-bfd1-76b074ba1884,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-1b890af0-2a38-43eb-9a39-fc77caead392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592098657-172.17.0.2-1597284178549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-b7677ec4-405d-4fc4-af31-fff2a1599a54,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-5bee85a9-507f-428b-9fde-353d2b8bf2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-3c873c52-99b4-403c-a893-0f040c31c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-0eaa9001-21f3-41de-9874-b4b0a6a7c504,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-5f6f5f66-cdf8-49a4-a5b0-608acf3bed06,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-bdefa4ef-78d9-4035-959f-0c962ddcdd32,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-c5b4794f-8311-4704-bfd1-76b074ba1884,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-1b890af0-2a38-43eb-9a39-fc77caead392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 7045
