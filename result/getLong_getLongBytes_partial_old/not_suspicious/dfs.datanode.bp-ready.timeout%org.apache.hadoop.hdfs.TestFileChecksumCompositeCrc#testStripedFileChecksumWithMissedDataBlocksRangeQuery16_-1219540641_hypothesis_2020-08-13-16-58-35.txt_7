reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771943926-172.17.0.3-1597339817819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39491,DS-88b4ef48-e24e-4e6a-b9a9-5ec96bb2d551,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-e53622ee-ba27-4fcc-a4ae-92b55d9e5154,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-ad8e0ddd-d37d-4c46-931f-a8a5b4361904,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-4cef6f63-8d1e-4aab-ac2b-b8097ae9e96e,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-acf7f5cb-e580-4d12-af2d-d6cc4dbe4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-0c7a7f29-0da1-4fb0-8178-8d430dd33d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-13e0cf1b-ad8c-4ffd-baeb-164f15683d25,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-677ed3dd-4828-4436-98b2-aad3192a9546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771943926-172.17.0.3-1597339817819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39491,DS-88b4ef48-e24e-4e6a-b9a9-5ec96bb2d551,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-e53622ee-ba27-4fcc-a4ae-92b55d9e5154,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-ad8e0ddd-d37d-4c46-931f-a8a5b4361904,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-4cef6f63-8d1e-4aab-ac2b-b8097ae9e96e,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-acf7f5cb-e580-4d12-af2d-d6cc4dbe4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-0c7a7f29-0da1-4fb0-8178-8d430dd33d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-13e0cf1b-ad8c-4ffd-baeb-164f15683d25,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-677ed3dd-4828-4436-98b2-aad3192a9546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815756963-172.17.0.3-1597340121275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35401,DS-5f49e537-f646-422e-9995-7be34a69df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-abadc856-ea8f-484d-ae26-726a70fb91b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-ac401755-849e-40c8-801a-82ce1bff3013,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-2ded1158-c6ce-4e00-bf01-cb543541db47,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-2e80713a-29a0-4e8c-b341-6bdd3bd7c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ca9970f2-0e9f-4ea1-a8fe-000ae6dbccb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-e4616231-4eae-4985-b886-07f34b09a858,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-9da17170-6f4a-4b8f-b39f-28f4fde8d9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815756963-172.17.0.3-1597340121275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35401,DS-5f49e537-f646-422e-9995-7be34a69df4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-abadc856-ea8f-484d-ae26-726a70fb91b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-ac401755-849e-40c8-801a-82ce1bff3013,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-2ded1158-c6ce-4e00-bf01-cb543541db47,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-2e80713a-29a0-4e8c-b341-6bdd3bd7c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ca9970f2-0e9f-4ea1-a8fe-000ae6dbccb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-e4616231-4eae-4985-b886-07f34b09a858,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-9da17170-6f4a-4b8f-b39f-28f4fde8d9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912031843-172.17.0.3-1597341100906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41999,DS-1f081536-d776-4068-851a-97e1c371e678,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-2197d4db-91ef-417e-91b6-3884042e8333,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-2509f882-a33b-47f3-bba9-4f9558c833a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-43a7e024-f385-4a7d-908a-e7e8155415a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-bf519216-bd2f-4551-9e60-66225468a1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-5e0c69d7-4187-4d3b-81da-7cbcd23e170a,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-0fad0c6e-51f0-4ebb-a535-20ea45b8dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-65d52661-8702-4cbb-baab-7e6cc450f5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912031843-172.17.0.3-1597341100906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41999,DS-1f081536-d776-4068-851a-97e1c371e678,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-2197d4db-91ef-417e-91b6-3884042e8333,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-2509f882-a33b-47f3-bba9-4f9558c833a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-43a7e024-f385-4a7d-908a-e7e8155415a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-bf519216-bd2f-4551-9e60-66225468a1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-5e0c69d7-4187-4d3b-81da-7cbcd23e170a,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-0fad0c6e-51f0-4ebb-a535-20ea45b8dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-65d52661-8702-4cbb-baab-7e6cc450f5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634694914-172.17.0.3-1597341142942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-4e424d76-c159-4768-89f4-ad0a2e9c0d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-af593512-58e3-48b4-8a13-f1e194fc5640,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-9a3c6a23-55c3-4df9-97b3-9d8a59b37e20,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-6802cd93-b6e7-46ae-a6ea-5560ddc17976,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-eb7adf6c-6987-46ae-8f6e-55279e84c35e,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-5a4ee35c-1d31-4166-8ce2-597668af5ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-0afda012-988d-4987-8579-e2d2b07443c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-5d083cf7-030f-4846-ab45-c1d898884c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-634694914-172.17.0.3-1597341142942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37221,DS-4e424d76-c159-4768-89f4-ad0a2e9c0d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-af593512-58e3-48b4-8a13-f1e194fc5640,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-9a3c6a23-55c3-4df9-97b3-9d8a59b37e20,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-6802cd93-b6e7-46ae-a6ea-5560ddc17976,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-eb7adf6c-6987-46ae-8f6e-55279e84c35e,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-5a4ee35c-1d31-4166-8ce2-597668af5ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-0afda012-988d-4987-8579-e2d2b07443c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-5d083cf7-030f-4846-ab45-c1d898884c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768927142-172.17.0.3-1597341681549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36823,DS-03ff5a62-702d-475f-87d7-5a9774589cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-db55d96f-7bdb-497e-80ad-77199f9c7f58,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-d53d6150-16ca-4ef0-8b51-e39946e34d86,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-c794ffb4-2d1e-4001-a654-6adf58876cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-308cf564-d131-4b91-a205-da4bca57733c,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-ec038623-f526-4ec8-af9d-4c4118147d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-4c8a50bb-5440-4cf5-b944-b16d92f5dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-94280343-f89e-4db4-b9cb-13bacf19328d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768927142-172.17.0.3-1597341681549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36823,DS-03ff5a62-702d-475f-87d7-5a9774589cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-db55d96f-7bdb-497e-80ad-77199f9c7f58,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-d53d6150-16ca-4ef0-8b51-e39946e34d86,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-c794ffb4-2d1e-4001-a654-6adf58876cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-308cf564-d131-4b91-a205-da4bca57733c,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-ec038623-f526-4ec8-af9d-4c4118147d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-4c8a50bb-5440-4cf5-b944-b16d92f5dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-94280343-f89e-4db4-b9cb-13bacf19328d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849504932-172.17.0.3-1597341941060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39013,DS-99a09df7-594e-4237-bf9d-47c38c1e2dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-4a1f55f4-a628-4291-9520-74a51dc499f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-41fcd95e-46cb-4d52-b530-fe3c6070b315,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-1da20878-d974-4edf-8d98-dc427166abba,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-909462b5-fa62-466b-901d-58e92e52dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-2bfb7da9-74b8-4c2b-82fd-895dab6a6821,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-bdee2b49-ae69-4c60-99e9-8d0e64467362,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-df999125-8168-4afc-a5cb-8bf03e9bcdb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849504932-172.17.0.3-1597341941060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39013,DS-99a09df7-594e-4237-bf9d-47c38c1e2dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-4a1f55f4-a628-4291-9520-74a51dc499f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-41fcd95e-46cb-4d52-b530-fe3c6070b315,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-1da20878-d974-4edf-8d98-dc427166abba,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-909462b5-fa62-466b-901d-58e92e52dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-2bfb7da9-74b8-4c2b-82fd-895dab6a6821,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-bdee2b49-ae69-4c60-99e9-8d0e64467362,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-df999125-8168-4afc-a5cb-8bf03e9bcdb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870133541-172.17.0.3-1597342046592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-61194b0a-0e16-4dd4-bacb-0732b6c56215,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-03feb152-d65b-4545-9dad-c9bcd5b06d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-0f283ed9-6326-402a-acf7-d475976b4c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-81b22b01-4284-41c0-b50b-9bdaf5eb173a,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-c592aa82-6966-4774-a905-08200ef95c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-7e8adfe3-1fe0-4979-bc5a-d94427e5facd,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-b7c1730d-360a-4a8c-9dd0-6b3df0497476,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-20c1a1fc-6c31-4252-8e57-ba6235d32379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870133541-172.17.0.3-1597342046592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-61194b0a-0e16-4dd4-bacb-0732b6c56215,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-03feb152-d65b-4545-9dad-c9bcd5b06d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-0f283ed9-6326-402a-acf7-d475976b4c15,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-81b22b01-4284-41c0-b50b-9bdaf5eb173a,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-c592aa82-6966-4774-a905-08200ef95c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-7e8adfe3-1fe0-4979-bc5a-d94427e5facd,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-b7c1730d-360a-4a8c-9dd0-6b3df0497476,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-20c1a1fc-6c31-4252-8e57-ba6235d32379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064517337-172.17.0.3-1597342539302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-e3950a61-f7e0-4fda-bbcb-2db38030c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-39136d4a-080c-482c-8c2d-6a712588b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-18f57cc0-0ce1-4b51-a7f2-03a67aee3c34,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-c36cfe93-d267-4223-ad1f-d2fae39c003d,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-ec236422-e9c7-491a-b072-ae42c902f9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-eaaaa10d-5370-43dc-a9e9-c0105f4f7dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-153d0900-fd37-4c3d-9bb2-874ed9f60b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-75665b29-de58-40a6-b3e2-31ee7e9e73ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064517337-172.17.0.3-1597342539302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-e3950a61-f7e0-4fda-bbcb-2db38030c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-39136d4a-080c-482c-8c2d-6a712588b4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-18f57cc0-0ce1-4b51-a7f2-03a67aee3c34,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-c36cfe93-d267-4223-ad1f-d2fae39c003d,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-ec236422-e9c7-491a-b072-ae42c902f9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-eaaaa10d-5370-43dc-a9e9-c0105f4f7dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-153d0900-fd37-4c3d-9bb2-874ed9f60b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-75665b29-de58-40a6-b3e2-31ee7e9e73ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601054024-172.17.0.3-1597342962279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-6c210d5d-d6f0-427d-935b-5eb3762cc793,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-89d37ce6-19d6-4063-8ce5-7d8b9eb8000a,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-2aaf1944-741d-45db-b50c-bdc5029fea71,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-72da8ee9-657d-44ae-bf53-8d129ca7774d,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-4ed78baf-8a50-4381-b200-59409a070044,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-d7aff599-31c2-4a62-ad44-cbba9fb2b11c,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-d46f4a3b-4d1c-43cb-9b47-df9c3a689890,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-bfd1f9ef-d81c-460a-b8f5-448c84888e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601054024-172.17.0.3-1597342962279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-6c210d5d-d6f0-427d-935b-5eb3762cc793,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-89d37ce6-19d6-4063-8ce5-7d8b9eb8000a,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-2aaf1944-741d-45db-b50c-bdc5029fea71,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-72da8ee9-657d-44ae-bf53-8d129ca7774d,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-4ed78baf-8a50-4381-b200-59409a070044,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-d7aff599-31c2-4a62-ad44-cbba9fb2b11c,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-d46f4a3b-4d1c-43cb-9b47-df9c3a689890,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-bfd1f9ef-d81c-460a-b8f5-448c84888e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990244500-172.17.0.3-1597343179038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32979,DS-cac01576-a511-4f77-ada7-d1f38d052b70,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-ac3ad0c5-dfcd-4da7-8597-55a3fec39ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-ea785739-6e07-4fdd-a23e-2cd41038076b,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-42bf372f-0493-45a7-bd56-ce1d15af8b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-eee2ff79-1771-4782-8127-18927944cab4,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-7d23cd35-c2bb-4a7c-b45a-8460563c31dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-4d760522-bacb-488d-91d3-c3ee8cd1ac82,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-26de7eb1-30e2-4d23-a5f7-65b894bae0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990244500-172.17.0.3-1597343179038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32979,DS-cac01576-a511-4f77-ada7-d1f38d052b70,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-ac3ad0c5-dfcd-4da7-8597-55a3fec39ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-ea785739-6e07-4fdd-a23e-2cd41038076b,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-42bf372f-0493-45a7-bd56-ce1d15af8b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-eee2ff79-1771-4782-8127-18927944cab4,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-7d23cd35-c2bb-4a7c-b45a-8460563c31dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-4d760522-bacb-488d-91d3-c3ee8cd1ac82,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-26de7eb1-30e2-4d23-a5f7-65b894bae0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5568
