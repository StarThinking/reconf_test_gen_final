reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149754440-172.17.0.3-1597395825986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-85ef8a80-e404-4fde-9d4f-c81800187bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-bfac90e3-5ece-4a3e-bf81-77f4c6fe721e,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-38e47564-d0e1-43d3-8662-58a9ed54130f,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-d47f212f-9914-47bd-81cf-7cb525f2cb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-0601416b-9b9a-4df8-83fe-7ea5c96862a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-d0fdf332-a5e7-42f8-8ea2-83ad969946a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-1a462564-fa77-4833-bca7-e7950fd88d13,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-ffd777aa-3553-408d-8653-a1f58fca2507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149754440-172.17.0.3-1597395825986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-85ef8a80-e404-4fde-9d4f-c81800187bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-bfac90e3-5ece-4a3e-bf81-77f4c6fe721e,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-38e47564-d0e1-43d3-8662-58a9ed54130f,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-d47f212f-9914-47bd-81cf-7cb525f2cb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-0601416b-9b9a-4df8-83fe-7ea5c96862a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-d0fdf332-a5e7-42f8-8ea2-83ad969946a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-1a462564-fa77-4833-bca7-e7950fd88d13,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-ffd777aa-3553-408d-8653-a1f58fca2507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208487874-172.17.0.3-1597395872147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35316,DS-088684f7-06ed-4ab4-af82-01eee5d34e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-cbd6c11f-2052-4c27-99b8-7dde22271cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-064bee63-ef85-4b09-8f09-63aeadf3c648,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-15e6dbf9-1226-4108-990a-e0ffccfffdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-fe524922-a711-42c4-9f25-710afed20759,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-2259be76-e5a5-4c68-9d7a-4564bd7666ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-528bca37-de8a-4bc3-bf94-b85cd6407707,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-efe030c3-ba98-4106-aaf3-8ec15ca29d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208487874-172.17.0.3-1597395872147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35316,DS-088684f7-06ed-4ab4-af82-01eee5d34e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-cbd6c11f-2052-4c27-99b8-7dde22271cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-064bee63-ef85-4b09-8f09-63aeadf3c648,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-15e6dbf9-1226-4108-990a-e0ffccfffdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-fe524922-a711-42c4-9f25-710afed20759,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-2259be76-e5a5-4c68-9d7a-4564bd7666ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-528bca37-de8a-4bc3-bf94-b85cd6407707,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-efe030c3-ba98-4106-aaf3-8ec15ca29d74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004937233-172.17.0.3-1597395983796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34784,DS-9aa7e4b7-d7dc-49d1-b309-f430a3ad8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-f3fb8329-039c-45fc-8fcf-9e8a0d477bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-9a872d83-3643-4385-a434-c04a174bc1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-9c01cbb2-9804-439b-beec-58c0f81b551a,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-72327b74-f97b-4cd7-84d6-2dca9b042b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-0dbf02e5-8ef5-4c4b-b67c-ecb229267f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-60deff16-1716-42c8-941a-02468e9d2414,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-9cbe03d2-6e0a-43fe-9027-607938062cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004937233-172.17.0.3-1597395983796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34784,DS-9aa7e4b7-d7dc-49d1-b309-f430a3ad8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-f3fb8329-039c-45fc-8fcf-9e8a0d477bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-9a872d83-3643-4385-a434-c04a174bc1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-9c01cbb2-9804-439b-beec-58c0f81b551a,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-72327b74-f97b-4cd7-84d6-2dca9b042b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-0dbf02e5-8ef5-4c4b-b67c-ecb229267f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-60deff16-1716-42c8-941a-02468e9d2414,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-9cbe03d2-6e0a-43fe-9027-607938062cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461863964-172.17.0.3-1597396171439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45843,DS-12f4308c-aa8d-4d1c-9d6d-fd4e68099b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-6ff4d403-c6e7-40c7-a55b-e2c583e42887,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-5788bef1-9a26-4114-ae94-848cd2072454,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-d54a9b32-9155-4bbf-b9ea-d8085dcb6292,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-9259ca97-e2a0-4551-b9fd-43dc3dfaa047,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-d457b1df-08aa-4619-b9c9-338956d79dca,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-85020d96-5bb0-48d3-88a3-a2ff1a7439de,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-c5b1ecc4-7aed-4be7-b447-b4ebae493e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461863964-172.17.0.3-1597396171439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45843,DS-12f4308c-aa8d-4d1c-9d6d-fd4e68099b22,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-6ff4d403-c6e7-40c7-a55b-e2c583e42887,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-5788bef1-9a26-4114-ae94-848cd2072454,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-d54a9b32-9155-4bbf-b9ea-d8085dcb6292,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-9259ca97-e2a0-4551-b9fd-43dc3dfaa047,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-d457b1df-08aa-4619-b9c9-338956d79dca,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-85020d96-5bb0-48d3-88a3-a2ff1a7439de,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-c5b1ecc4-7aed-4be7-b447-b4ebae493e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475408587-172.17.0.3-1597396534686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39559,DS-13abf7cd-7d32-4580-9fc3-52df5e93565f,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-70afec98-de81-40dc-aafb-8688f1680e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-315582df-702c-473b-bd2a-ad4f84e95f01,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-f9f876fe-1ddf-4eda-876b-918422cb3f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-04ec7cd3-f582-46ee-bbc4-1f3674d09d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-cee12c75-3421-414f-9f11-cd14e3a76c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-b266db51-f667-4e1f-ad33-0603d8f6b970,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-567bc53d-765e-4135-8d1b-a71a722b9e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475408587-172.17.0.3-1597396534686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39559,DS-13abf7cd-7d32-4580-9fc3-52df5e93565f,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-70afec98-de81-40dc-aafb-8688f1680e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-315582df-702c-473b-bd2a-ad4f84e95f01,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-f9f876fe-1ddf-4eda-876b-918422cb3f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-04ec7cd3-f582-46ee-bbc4-1f3674d09d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-cee12c75-3421-414f-9f11-cd14e3a76c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-b266db51-f667-4e1f-ad33-0603d8f6b970,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-567bc53d-765e-4135-8d1b-a71a722b9e62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586761979-172.17.0.3-1597396930263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35598,DS-557fb742-fd75-4c36-8828-04d314248fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-794e9df7-22f2-4cf9-8273-53cb0d6cd73a,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-36109c32-b9ef-44a0-aa0c-e3ae32bd2c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-07e6d7c5-894d-423f-8305-97f9eef18edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-26774660-d576-4dd9-aefd-a71d10861bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-a4dfd420-e9b3-4b7c-a951-41419aadeb54,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-ad003f10-38df-4a89-93db-361941f0d09a,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-70599654-9817-416e-b92c-0c624f3dd9a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586761979-172.17.0.3-1597396930263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35598,DS-557fb742-fd75-4c36-8828-04d314248fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-794e9df7-22f2-4cf9-8273-53cb0d6cd73a,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-36109c32-b9ef-44a0-aa0c-e3ae32bd2c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-07e6d7c5-894d-423f-8305-97f9eef18edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-26774660-d576-4dd9-aefd-a71d10861bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-a4dfd420-e9b3-4b7c-a951-41419aadeb54,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-ad003f10-38df-4a89-93db-361941f0d09a,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-70599654-9817-416e-b92c-0c624f3dd9a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253088078-172.17.0.3-1597397272468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42813,DS-eb18264e-ec9d-4065-855f-633459da9a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b3172b20-95a8-489c-b7a1-9a283968670f,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-ad9c4853-3c2e-4120-9eb1-8e152949e9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-8591c139-efe3-477b-92fe-eca882782f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-44e606ba-42fc-4855-8978-4aed826d4565,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-8e03e6c4-6c7a-4cb7-a0b1-ee0a6ede2ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-b6f66af2-418e-4192-aff3-59b36223f60e,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-bdc66ef5-4b95-4edf-9795-f17b82c90ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253088078-172.17.0.3-1597397272468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42813,DS-eb18264e-ec9d-4065-855f-633459da9a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-b3172b20-95a8-489c-b7a1-9a283968670f,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-ad9c4853-3c2e-4120-9eb1-8e152949e9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-8591c139-efe3-477b-92fe-eca882782f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-44e606ba-42fc-4855-8978-4aed826d4565,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-8e03e6c4-6c7a-4cb7-a0b1-ee0a6ede2ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-b6f66af2-418e-4192-aff3-59b36223f60e,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-bdc66ef5-4b95-4edf-9795-f17b82c90ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040991048-172.17.0.3-1597397517040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38373,DS-0eb97968-6717-4326-b9d5-f6ccf1e32690,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-c70c1ce4-c2ab-4be4-a851-eac7a975258d,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-5f76aa88-fa4d-4a76-9e2c-98382a57188c,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-1734bfd1-8908-4a2c-bf1f-8219d1b52925,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-44047395-5959-4233-9a4b-87ad81e9f69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-a364d343-e35c-411a-a3f8-ef3396a733e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-b5a83bfc-c9e6-47c8-8356-e20d09052be6,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-989c8551-d7bc-413e-8261-3c66b21f6daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040991048-172.17.0.3-1597397517040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38373,DS-0eb97968-6717-4326-b9d5-f6ccf1e32690,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-c70c1ce4-c2ab-4be4-a851-eac7a975258d,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-5f76aa88-fa4d-4a76-9e2c-98382a57188c,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-1734bfd1-8908-4a2c-bf1f-8219d1b52925,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-44047395-5959-4233-9a4b-87ad81e9f69c,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-a364d343-e35c-411a-a3f8-ef3396a733e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-b5a83bfc-c9e6-47c8-8356-e20d09052be6,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-989c8551-d7bc-413e-8261-3c66b21f6daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857822481-172.17.0.3-1597397584795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-c312d798-9d1c-4b0a-b640-bebc6d313594,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-7ae77e26-3b3c-4aa4-af35-8c6f80156f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-249b2c49-0a15-4651-a581-d279657c6c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-ae86870e-f88b-439e-9adb-263eaacc3b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-12b84f87-8c35-436f-a7e0-0d845ac26369,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-6c48a194-fec3-487b-a818-dc7ac020fa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-0c89d016-fc84-42c6-be92-d140405235fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-4d678749-a588-4c4f-86f4-ae92f0e8ede5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857822481-172.17.0.3-1597397584795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-c312d798-9d1c-4b0a-b640-bebc6d313594,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-7ae77e26-3b3c-4aa4-af35-8c6f80156f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-249b2c49-0a15-4651-a581-d279657c6c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-ae86870e-f88b-439e-9adb-263eaacc3b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-12b84f87-8c35-436f-a7e0-0d845ac26369,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-6c48a194-fec3-487b-a818-dc7ac020fa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-0c89d016-fc84-42c6-be92-d140405235fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-4d678749-a588-4c4f-86f4-ae92f0e8ede5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649832912-172.17.0.3-1597398041114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-f8ed6c2e-6b10-458d-ac67-71632ce6eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-ccfb296d-6a31-4352-b122-85976418f52b,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-64aa88d1-8bad-4937-8518-d128a8a85006,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-58529cf1-0ff8-44e4-81b0-31d3a0b30b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-e856d821-8f06-4bd0-88c0-5086bbe9b1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-6fb70258-c0f6-4d61-9506-c25d295f9f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-d88e6a7a-3951-4260-8448-9f5d568ec793,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-7a1dd9e5-789c-4254-a1a0-708e3358fccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649832912-172.17.0.3-1597398041114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-f8ed6c2e-6b10-458d-ac67-71632ce6eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-ccfb296d-6a31-4352-b122-85976418f52b,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-64aa88d1-8bad-4937-8518-d128a8a85006,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-58529cf1-0ff8-44e4-81b0-31d3a0b30b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-e856d821-8f06-4bd0-88c0-5086bbe9b1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-6fb70258-c0f6-4d61-9506-c25d295f9f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-d88e6a7a-3951-4260-8448-9f5d568ec793,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-7a1dd9e5-789c-4254-a1a0-708e3358fccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197645173-172.17.0.3-1597398416964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-4a63ce4b-a9be-4d9c-bd7b-b3a52c286a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-600c353d-23d8-4df0-8513-10e2ae8430ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-a1efb786-1449-494e-97df-a275fd435fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-443174c3-616a-403a-be6a-05c086509b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-90eece3f-4cbc-4fe9-a700-8161fdb78236,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-2e43af1c-8220-4ff1-9ae7-7534b8ca1276,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-a2d6a8cc-7434-42b6-93b0-36f160c7f24c,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-9a959ea2-4ee8-4fa5-9283-896069c6f6f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197645173-172.17.0.3-1597398416964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-4a63ce4b-a9be-4d9c-bd7b-b3a52c286a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-600c353d-23d8-4df0-8513-10e2ae8430ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-a1efb786-1449-494e-97df-a275fd435fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-443174c3-616a-403a-be6a-05c086509b43,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-90eece3f-4cbc-4fe9-a700-8161fdb78236,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-2e43af1c-8220-4ff1-9ae7-7534b8ca1276,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-a2d6a8cc-7434-42b6-93b0-36f160c7f24c,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-9a959ea2-4ee8-4fa5-9283-896069c6f6f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796983614-172.17.0.3-1597398634547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-12c20cbd-131f-4497-b97b-65394cc837d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-33029e61-7765-4cf3-92ce-b928db75bdde,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-64c47f5d-c145-4588-9c47-b55838a2bfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-ce415cf4-8da6-4132-b554-20cccce922ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-b2a9583d-ce04-4852-92b7-de2d19fb0c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-607fa5ff-7a83-4ef8-8112-a2e7dc54bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-1c418cf7-6242-4484-bbc2-f31617350b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-9c8804e3-378f-4770-8429-fe286e91bfe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796983614-172.17.0.3-1597398634547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36345,DS-12c20cbd-131f-4497-b97b-65394cc837d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-33029e61-7765-4cf3-92ce-b928db75bdde,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-64c47f5d-c145-4588-9c47-b55838a2bfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-ce415cf4-8da6-4132-b554-20cccce922ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-b2a9583d-ce04-4852-92b7-de2d19fb0c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-607fa5ff-7a83-4ef8-8112-a2e7dc54bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-1c418cf7-6242-4484-bbc2-f31617350b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-9c8804e3-378f-4770-8429-fe286e91bfe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423791183-172.17.0.3-1597398944769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39793,DS-78b79cc3-2c7b-4a26-a117-0a70125f15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-b69be417-edd4-408f-901b-0a87c95f3525,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-e712cf50-9334-4c77-a91b-0935e083aea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-e350ca0c-0bba-4047-ad87-bb5f8191fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-d17bdebb-6aec-4461-a55f-e6a41c0e8436,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-07575792-ed1d-41fb-87e3-f7bd423e24a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-7dd615cf-1b98-4723-adcb-d36f5c85c36e,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-d688af4e-c512-461b-b72a-ea1b6e15d31d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423791183-172.17.0.3-1597398944769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39793,DS-78b79cc3-2c7b-4a26-a117-0a70125f15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-b69be417-edd4-408f-901b-0a87c95f3525,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-e712cf50-9334-4c77-a91b-0935e083aea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-e350ca0c-0bba-4047-ad87-bb5f8191fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-d17bdebb-6aec-4461-a55f-e6a41c0e8436,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-07575792-ed1d-41fb-87e3-f7bd423e24a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-7dd615cf-1b98-4723-adcb-d36f5c85c36e,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-d688af4e-c512-461b-b72a-ea1b6e15d31d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027744879-172.17.0.3-1597399086386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-7e693db6-b453-4f97-85bd-48233b73d844,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-8d67007e-4921-479b-adc8-8a66077b0747,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-d7e01691-fb66-425c-b1fc-b3105904fbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-c60e5a11-c94c-4efa-bc52-88b917cc0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-446f28e9-734d-4f87-b53c-9816076aceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-a2b84981-721c-4688-970f-41560c23a305,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-f84ac02c-4ddb-4df2-a2fb-cba44d1a9d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-3169c7bb-94c6-4a29-829f-865d8e25e9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027744879-172.17.0.3-1597399086386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40983,DS-7e693db6-b453-4f97-85bd-48233b73d844,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-8d67007e-4921-479b-adc8-8a66077b0747,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-d7e01691-fb66-425c-b1fc-b3105904fbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-c60e5a11-c94c-4efa-bc52-88b917cc0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-446f28e9-734d-4f87-b53c-9816076aceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-a2b84981-721c-4688-970f-41560c23a305,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-f84ac02c-4ddb-4df2-a2fb-cba44d1a9d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-3169c7bb-94c6-4a29-829f-865d8e25e9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871047948-172.17.0.3-1597399513788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-538cef18-4fa1-4b0d-9943-5037805868d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-3da47836-6f2f-4256-8bf4-bdc0eda4008c,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-08b013c0-de90-4493-b9c2-61d92f0d1a84,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-5e37f5f9-d1c3-4a8e-a170-64ced136009d,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-d0def8ef-c7b1-4d4d-b4ee-f4beb88f6fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-57e99d4d-4119-4cfb-b5d9-13d5eca63e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-215a7e00-a4f7-4250-bbf1-cb5208874bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-10914217-ae8f-4efb-b5af-2caecbf37897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871047948-172.17.0.3-1597399513788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-538cef18-4fa1-4b0d-9943-5037805868d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-3da47836-6f2f-4256-8bf4-bdc0eda4008c,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-08b013c0-de90-4493-b9c2-61d92f0d1a84,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-5e37f5f9-d1c3-4a8e-a170-64ced136009d,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-d0def8ef-c7b1-4d4d-b4ee-f4beb88f6fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-57e99d4d-4119-4cfb-b5d9-13d5eca63e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-215a7e00-a4f7-4250-bbf1-cb5208874bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-10914217-ae8f-4efb-b5af-2caecbf37897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577362092-172.17.0.3-1597399620795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-07903ab8-02e8-48cf-8270-b28b1ba99753,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-ee1194ee-5047-4858-bb5c-6e765a7224df,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-5ce7a82f-7bca-4da1-af4f-4c478df5d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-84256002-dff0-425c-90ce-3f9ef21a2498,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-a7c614b3-4a26-44cb-afb1-f551693676f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-0533f78c-f86a-47e8-ba87-af153e822a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-80d61d50-988e-48d1-ac79-27631db55b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-7e50d9db-a237-4f18-ae52-69d9e7f62286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577362092-172.17.0.3-1597399620795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-07903ab8-02e8-48cf-8270-b28b1ba99753,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-ee1194ee-5047-4858-bb5c-6e765a7224df,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-5ce7a82f-7bca-4da1-af4f-4c478df5d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-84256002-dff0-425c-90ce-3f9ef21a2498,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-a7c614b3-4a26-44cb-afb1-f551693676f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-0533f78c-f86a-47e8-ba87-af153e822a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-80d61d50-988e-48d1-ac79-27631db55b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-7e50d9db-a237-4f18-ae52-69d9e7f62286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285158377-172.17.0.3-1597400293430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-1f1bae07-286d-419d-955f-b4cc96bc42f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-d2ca191b-b263-4715-bf30-37901e2311ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-0cf27563-314e-4a8a-9960-4dbafad3cf13,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-0378c919-14bd-4fe6-a154-96796a41d2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-ff81f2db-2151-48be-8460-65ad78967adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-4a6168b4-47a7-4f8b-a165-ab0bdb84dc24,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-bfdf4690-e0fd-4d57-b0ac-b727038095bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-a6bd47ac-1a6d-4b90-a3f6-ef34b318a25f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285158377-172.17.0.3-1597400293430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41366,DS-1f1bae07-286d-419d-955f-b4cc96bc42f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-d2ca191b-b263-4715-bf30-37901e2311ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-0cf27563-314e-4a8a-9960-4dbafad3cf13,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-0378c919-14bd-4fe6-a154-96796a41d2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-ff81f2db-2151-48be-8460-65ad78967adf,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-4a6168b4-47a7-4f8b-a165-ab0bdb84dc24,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-bfdf4690-e0fd-4d57-b0ac-b727038095bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-a6bd47ac-1a6d-4b90-a3f6-ef34b318a25f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607705843-172.17.0.3-1597400325443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-8c161cdd-a66b-42f2-9935-c9668e5d27cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-6571a8bd-bbeb-4fb0-aaae-3cd191b983c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-c17db205-c6f0-49ec-b56f-4a38a9bf9b15,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-72e8f67f-2d15-4ac0-bf5e-b5c9f8271926,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-b880fb14-8d70-4ece-be79-b1534c3b3447,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-a06dac28-e07e-4ad4-be7b-5fb629f8bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-3a54bcd6-596a-4ebc-88d1-623b4e3d2911,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-7641609d-6042-44d5-a9de-a79a4cbdc598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607705843-172.17.0.3-1597400325443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-8c161cdd-a66b-42f2-9935-c9668e5d27cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-6571a8bd-bbeb-4fb0-aaae-3cd191b983c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-c17db205-c6f0-49ec-b56f-4a38a9bf9b15,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-72e8f67f-2d15-4ac0-bf5e-b5c9f8271926,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-b880fb14-8d70-4ece-be79-b1534c3b3447,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-a06dac28-e07e-4ad4-be7b-5fb629f8bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-3a54bcd6-596a-4ebc-88d1-623b4e3d2911,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-7641609d-6042-44d5-a9de-a79a4cbdc598,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5377
