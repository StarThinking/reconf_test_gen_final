reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728440456-172.17.0.5-1597325279530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-c8a896c3-060d-43d8-823a-1b023776d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-7cc02832-f1c7-4b8d-b125-aeb8c67118f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-119efb44-6f6a-4564-accd-264ca43b21be,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-fb42cd44-bfe4-45af-ae1e-569ad9e4191b,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-411dfd09-290a-45e9-b69b-f223600cbce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-f4409bc2-7a83-4a57-9179-d81449d53d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-c2005b3d-9af0-468a-a232-ed471e2d3df9,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-07d57589-e2c6-4e1b-b9d0-089dd35e5193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728440456-172.17.0.5-1597325279530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43795,DS-c8a896c3-060d-43d8-823a-1b023776d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-7cc02832-f1c7-4b8d-b125-aeb8c67118f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-119efb44-6f6a-4564-accd-264ca43b21be,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-fb42cd44-bfe4-45af-ae1e-569ad9e4191b,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-411dfd09-290a-45e9-b69b-f223600cbce8,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-f4409bc2-7a83-4a57-9179-d81449d53d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-c2005b3d-9af0-468a-a232-ed471e2d3df9,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-07d57589-e2c6-4e1b-b9d0-089dd35e5193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596219169-172.17.0.5-1597325989725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-a6f7a6de-b1cd-4525-924e-0d3806f8049d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-92637758-1745-4b99-89cd-39054f0b0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-41521b20-7a04-40dd-8ec1-1d88e1e7969d,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-ee7a6575-4c9e-4827-b961-120076c1c1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-5a821fea-e8d4-4ba3-866c-f0a72514277e,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-977c1b59-f902-4834-9fd5-de99f3e4463b,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-e1c96c37-5442-40a6-9ad9-ca1fec4f625e,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-8bbc8534-24ea-445d-a573-d93ae0547bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596219169-172.17.0.5-1597325989725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-a6f7a6de-b1cd-4525-924e-0d3806f8049d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-92637758-1745-4b99-89cd-39054f0b0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-41521b20-7a04-40dd-8ec1-1d88e1e7969d,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-ee7a6575-4c9e-4827-b961-120076c1c1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-5a821fea-e8d4-4ba3-866c-f0a72514277e,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-977c1b59-f902-4834-9fd5-de99f3e4463b,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-e1c96c37-5442-40a6-9ad9-ca1fec4f625e,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-8bbc8534-24ea-445d-a573-d93ae0547bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392161107-172.17.0.5-1597326412394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-7eeebb9d-d12a-4f1c-8152-4ad34d389a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-262769c0-e4b3-4213-87e4-4801d017279a,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-e3ed1fde-10a8-42d3-9de7-a07526bc0d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-1338572b-c293-4ddb-a59c-9b6a26aaea93,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-1cb58dd7-9c9d-4701-8b54-2c672c5edbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-6f6cf618-4176-490d-ba80-9143ba282a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-c021f2b7-87b5-45be-bbd7-04fabd2c0b08,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-8d8f4ef8-4543-4e66-8be9-b2f1c012b884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392161107-172.17.0.5-1597326412394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-7eeebb9d-d12a-4f1c-8152-4ad34d389a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-262769c0-e4b3-4213-87e4-4801d017279a,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-e3ed1fde-10a8-42d3-9de7-a07526bc0d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-1338572b-c293-4ddb-a59c-9b6a26aaea93,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-1cb58dd7-9c9d-4701-8b54-2c672c5edbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-6f6cf618-4176-490d-ba80-9143ba282a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-c021f2b7-87b5-45be-bbd7-04fabd2c0b08,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-8d8f4ef8-4543-4e66-8be9-b2f1c012b884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462921638-172.17.0.5-1597326532874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41139,DS-7c6eb899-3871-48a6-8a6d-3985d013ca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-7c8bfe32-3062-44ff-825c-77df66fea56f,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-55086af9-1a48-4ba1-837a-d60df3df2574,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-852a6829-fef6-4de0-9384-46214f2d2340,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-6bb063b4-5892-473c-a5dd-ff9f36aa2b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-0b3a7bc4-150f-45ae-966a-beaa7e3df926,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-0b45d06c-e0da-4028-b8de-3d73291a4c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-82bcc6f6-2944-4554-8a55-35fa4bc8cee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462921638-172.17.0.5-1597326532874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41139,DS-7c6eb899-3871-48a6-8a6d-3985d013ca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-7c8bfe32-3062-44ff-825c-77df66fea56f,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-55086af9-1a48-4ba1-837a-d60df3df2574,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-852a6829-fef6-4de0-9384-46214f2d2340,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-6bb063b4-5892-473c-a5dd-ff9f36aa2b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-0b3a7bc4-150f-45ae-966a-beaa7e3df926,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-0b45d06c-e0da-4028-b8de-3d73291a4c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-82bcc6f6-2944-4554-8a55-35fa4bc8cee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759369857-172.17.0.5-1597326652572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35267,DS-10519249-2bb4-42e1-aa88-f133fc0594bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-c3d5e136-a8ee-432d-9aa1-039565b5c2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-b06e4336-1105-42ab-86f1-c96d6f56c75c,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-c06b0c28-d606-4e43-b86a-01c2f958914f,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-236277fb-2bd5-49a4-bdc0-5d635055bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-aadece4b-b029-4736-9e3a-4eb9559c6fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-dc8b7f4d-4f93-4c59-8f4c-a4597b30e3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-a5ef5ba2-d2fe-4f6e-8fe1-db87f870ec80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759369857-172.17.0.5-1597326652572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35267,DS-10519249-2bb4-42e1-aa88-f133fc0594bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-c3d5e136-a8ee-432d-9aa1-039565b5c2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-b06e4336-1105-42ab-86f1-c96d6f56c75c,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-c06b0c28-d606-4e43-b86a-01c2f958914f,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-236277fb-2bd5-49a4-bdc0-5d635055bc30,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-aadece4b-b029-4736-9e3a-4eb9559c6fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-dc8b7f4d-4f93-4c59-8f4c-a4597b30e3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-a5ef5ba2-d2fe-4f6e-8fe1-db87f870ec80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58032745-172.17.0.5-1597326730401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36170,DS-a5d997a2-c554-4847-8dc8-bb546c6857f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-21883732-84e2-4f03-8873-2142234fe85e,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-f180ef27-d5a3-40f1-b5ae-0bc041174ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-a1530cf1-b713-4f2d-bda0-e6d9ea9ee9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-74f5fe22-2096-452f-aea0-d9236859876b,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-2d279001-84dd-4217-89fd-5067a699986f,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-4f22a77f-af7d-4ca9-91ab-32b27497e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-ccd3e694-e494-42af-884e-c97a9da11164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58032745-172.17.0.5-1597326730401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36170,DS-a5d997a2-c554-4847-8dc8-bb546c6857f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-21883732-84e2-4f03-8873-2142234fe85e,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-f180ef27-d5a3-40f1-b5ae-0bc041174ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-a1530cf1-b713-4f2d-bda0-e6d9ea9ee9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-74f5fe22-2096-452f-aea0-d9236859876b,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-2d279001-84dd-4217-89fd-5067a699986f,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-4f22a77f-af7d-4ca9-91ab-32b27497e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-ccd3e694-e494-42af-884e-c97a9da11164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237939365-172.17.0.5-1597327051384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-25f7054a-8e6a-47f4-98f4-802a1624e329,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-2a9cec3a-dfd3-4ed1-81b6-486e5e2d9348,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-0489aa9f-a653-43c7-bfe2-92edcdac7478,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-9102c828-78e0-4a1e-a425-41f31d40a1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-b3df7e40-a3c4-4510-a4b1-b1906812e58a,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-db848327-a292-4b76-a02c-4488784fe7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-8cb45ccf-a91a-45c0-8385-d31e6897bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-7b17fb57-7ee0-4a41-9189-11b2a12e136b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237939365-172.17.0.5-1597327051384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-25f7054a-8e6a-47f4-98f4-802a1624e329,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-2a9cec3a-dfd3-4ed1-81b6-486e5e2d9348,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-0489aa9f-a653-43c7-bfe2-92edcdac7478,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-9102c828-78e0-4a1e-a425-41f31d40a1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-b3df7e40-a3c4-4510-a4b1-b1906812e58a,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-db848327-a292-4b76-a02c-4488784fe7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-8cb45ccf-a91a-45c0-8385-d31e6897bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-7b17fb57-7ee0-4a41-9189-11b2a12e136b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839789413-172.17.0.5-1597327751769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43158,DS-160f7233-6f40-4415-beec-5e70ceac372f,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-6d7ffb92-73a4-4a37-9a0b-0275b210e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-39bc63ae-09b3-476f-80d5-9f10f59b2922,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-c36d5f14-a63d-46a0-809b-19275f1c2307,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-ec711747-ac88-49c5-b696-bcbbfca5b81f,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-30444afb-7eef-4275-b705-c0648eeab6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-d9df84cb-6117-4f05-8e33-7edd3eb48077,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-543693df-50bf-400d-ba8d-8b36f3abd0a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839789413-172.17.0.5-1597327751769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43158,DS-160f7233-6f40-4415-beec-5e70ceac372f,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-6d7ffb92-73a4-4a37-9a0b-0275b210e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-39bc63ae-09b3-476f-80d5-9f10f59b2922,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-c36d5f14-a63d-46a0-809b-19275f1c2307,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-ec711747-ac88-49c5-b696-bcbbfca5b81f,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-30444afb-7eef-4275-b705-c0648eeab6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-d9df84cb-6117-4f05-8e33-7edd3eb48077,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-543693df-50bf-400d-ba8d-8b36f3abd0a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752895236-172.17.0.5-1597327787456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-f80ba6ea-9d91-425e-91d0-29ba9bd94fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-c388044f-4912-4a2d-96d3-13c5af89c481,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-ff9edf6d-5e21-4dbc-b299-4ccae6bcfa47,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-f475a84d-835d-44d0-bec7-8bec0ba58258,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-77d46cd0-e3b4-4888-9698-b818c7007e83,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-cbf5c189-1ac8-44e7-bdf9-f3ab11bf62b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-7a28dc9f-276e-4aca-9758-69818d9f2758,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-d60e494e-3e20-47e2-a083-81b6402191a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752895236-172.17.0.5-1597327787456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37138,DS-f80ba6ea-9d91-425e-91d0-29ba9bd94fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-c388044f-4912-4a2d-96d3-13c5af89c481,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-ff9edf6d-5e21-4dbc-b299-4ccae6bcfa47,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-f475a84d-835d-44d0-bec7-8bec0ba58258,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-77d46cd0-e3b4-4888-9698-b818c7007e83,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-cbf5c189-1ac8-44e7-bdf9-f3ab11bf62b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-7a28dc9f-276e-4aca-9758-69818d9f2758,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-d60e494e-3e20-47e2-a083-81b6402191a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727404656-172.17.0.5-1597327892153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-aa0221e5-47c7-40e2-819a-fdc3bad2f435,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-05557872-a61a-4129-be2d-062cfccc1438,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-67862ac2-b1c6-4f9b-9fc6-87fadb68ab20,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-4ca5e79a-2420-4a53-8fb9-1d15e46d04c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-72f89688-4e95-4db4-9abc-51b677c2cf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-64d59b9b-9af8-46b6-b535-3f4ff414064a,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-ea76aa88-3745-4795-add5-94606aea43ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-c4736465-bb1a-45cf-9580-8b9c8acbe57d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1727404656-172.17.0.5-1597327892153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-aa0221e5-47c7-40e2-819a-fdc3bad2f435,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-05557872-a61a-4129-be2d-062cfccc1438,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-67862ac2-b1c6-4f9b-9fc6-87fadb68ab20,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-4ca5e79a-2420-4a53-8fb9-1d15e46d04c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-72f89688-4e95-4db4-9abc-51b677c2cf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-64d59b9b-9af8-46b6-b535-3f4ff414064a,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-ea76aa88-3745-4795-add5-94606aea43ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-c4736465-bb1a-45cf-9580-8b9c8acbe57d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916097674-172.17.0.5-1597328701288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-1a433aa8-00e8-408f-805f-8f44e77ad285,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-291b0672-230a-45a6-a402-b3b89d4c5c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-e08e4c96-5694-433b-8768-f96843f79980,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-dea3dcea-0b54-4794-bde4-d8e41dfd82d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-ca649c6b-2986-4e68-8dbc-dedc2aaa990f,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-e3293a21-7627-48df-8b8c-f5db17ebb757,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-2f2eb17d-4bc4-45fc-985a-b59849a56ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-01d1d162-355c-461b-addb-884d8e849450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916097674-172.17.0.5-1597328701288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-1a433aa8-00e8-408f-805f-8f44e77ad285,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-291b0672-230a-45a6-a402-b3b89d4c5c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-e08e4c96-5694-433b-8768-f96843f79980,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-dea3dcea-0b54-4794-bde4-d8e41dfd82d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-ca649c6b-2986-4e68-8dbc-dedc2aaa990f,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-e3293a21-7627-48df-8b8c-f5db17ebb757,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-2f2eb17d-4bc4-45fc-985a-b59849a56ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-01d1d162-355c-461b-addb-884d8e849450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105480260-172.17.0.5-1597329235024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36024,DS-1dad9f87-72ae-4f9a-a996-ad0c95dbe2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-57d53cc5-9032-4ca5-a922-822a506db91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-7136fa3e-cc21-4d0f-85e0-aee1a240f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-6824e8f1-2919-4520-83b5-66121d8b33df,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-ccd226bf-7670-48c4-a3b5-c12aeb37bcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-f32224b4-4026-4ae0-a523-fd9a0e966163,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-a1643cbf-ad03-458d-a140-294991305252,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-6c6d76e1-3098-4389-aff8-c25585842821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105480260-172.17.0.5-1597329235024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36024,DS-1dad9f87-72ae-4f9a-a996-ad0c95dbe2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-57d53cc5-9032-4ca5-a922-822a506db91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-7136fa3e-cc21-4d0f-85e0-aee1a240f58e,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-6824e8f1-2919-4520-83b5-66121d8b33df,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-ccd226bf-7670-48c4-a3b5-c12aeb37bcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-f32224b4-4026-4ae0-a523-fd9a0e966163,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-a1643cbf-ad03-458d-a140-294991305252,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-6c6d76e1-3098-4389-aff8-c25585842821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406208767-172.17.0.5-1597329422009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-60457034-2e27-4635-ad38-6629cdd0dccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-73f03d5b-46b1-4fbb-a4b4-89710affc030,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-26b1b8d6-d404-4fb4-a11f-fe77f5ba442a,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-5ba50821-279a-4251-aa51-b17f20008d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-e0b17e21-449e-402b-9dd0-1af76fe07070,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-ddceb8f1-9802-45ab-a7f6-40085d591cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-764b47a8-9ccd-4f53-bd14-ea8e9e7e5e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-9d1b5534-8880-4ba0-b98b-cdf149975677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406208767-172.17.0.5-1597329422009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-60457034-2e27-4635-ad38-6629cdd0dccc,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-73f03d5b-46b1-4fbb-a4b4-89710affc030,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-26b1b8d6-d404-4fb4-a11f-fe77f5ba442a,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-5ba50821-279a-4251-aa51-b17f20008d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-e0b17e21-449e-402b-9dd0-1af76fe07070,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-ddceb8f1-9802-45ab-a7f6-40085d591cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-764b47a8-9ccd-4f53-bd14-ea8e9e7e5e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-9d1b5534-8880-4ba0-b98b-cdf149975677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614990764-172.17.0.5-1597329459134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-6c731a49-e0d2-4568-b5b5-20287aa1f293,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-f48fa9c5-78e7-4491-b0df-8140841d6595,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-9d42f29d-a71c-4738-bb3b-e7f245af8870,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-735fa036-29ce-4f1d-abdb-e304f723249a,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-c3d4b443-2527-453c-a7f5-2ebe36e8605c,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-88530359-f508-4809-9037-40410cfb5731,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-1c0baab8-b835-41fd-abad-48d7be627da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-efa44e7d-b067-495b-95c1-64b2f6063fd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614990764-172.17.0.5-1597329459134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-6c731a49-e0d2-4568-b5b5-20287aa1f293,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-f48fa9c5-78e7-4491-b0df-8140841d6595,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-9d42f29d-a71c-4738-bb3b-e7f245af8870,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-735fa036-29ce-4f1d-abdb-e304f723249a,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-c3d4b443-2527-453c-a7f5-2ebe36e8605c,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-88530359-f508-4809-9037-40410cfb5731,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-1c0baab8-b835-41fd-abad-48d7be627da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-efa44e7d-b067-495b-95c1-64b2f6063fd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311461124-172.17.0.5-1597329610052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39506,DS-8a7619e8-70e4-49e3-bed1-54692b4d13f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-5b062f03-e718-4d39-ab73-410269a35ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-7277da2e-7caf-4b58-86b4-9e588ec69b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-8f92b197-3394-4e29-abb3-cdf315c17ced,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-01dcb674-55e6-43d6-b7fa-c2f4ead4b5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-4585a6f0-dacf-40e5-9716-8f3b7402a211,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-2d9c152b-ffe8-4ec7-9354-b07590dca0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-c74eff6e-8dc6-4246-8e8d-df434b1c1caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311461124-172.17.0.5-1597329610052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39506,DS-8a7619e8-70e4-49e3-bed1-54692b4d13f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-5b062f03-e718-4d39-ab73-410269a35ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-7277da2e-7caf-4b58-86b4-9e588ec69b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-8f92b197-3394-4e29-abb3-cdf315c17ced,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-01dcb674-55e6-43d6-b7fa-c2f4ead4b5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-4585a6f0-dacf-40e5-9716-8f3b7402a211,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-2d9c152b-ffe8-4ec7-9354-b07590dca0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-c74eff6e-8dc6-4246-8e8d-df434b1c1caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266654561-172.17.0.5-1597329687672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41022,DS-d934dc37-3234-432c-906e-5bc4f37f0848,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-e08becf2-1a72-418d-b55b-5eafd90f9e11,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-a2903598-7e89-4af7-b00c-b666a2f9ecdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-673892e6-de5f-49a4-9c91-15696f5fa1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-2b8bb87e-1a12-492a-8ad0-a2f184cb6bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-39a1a446-c71d-4f68-89e2-7d93c3e55795,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-fe2f5948-b4c2-4dc8-a323-bb833449b619,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-fd3584db-dce2-42d6-9eb4-52b2daa69af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266654561-172.17.0.5-1597329687672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41022,DS-d934dc37-3234-432c-906e-5bc4f37f0848,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-e08becf2-1a72-418d-b55b-5eafd90f9e11,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-a2903598-7e89-4af7-b00c-b666a2f9ecdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-673892e6-de5f-49a4-9c91-15696f5fa1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-2b8bb87e-1a12-492a-8ad0-a2f184cb6bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-39a1a446-c71d-4f68-89e2-7d93c3e55795,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-fe2f5948-b4c2-4dc8-a323-bb833449b619,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-fd3584db-dce2-42d6-9eb4-52b2daa69af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515935888-172.17.0.5-1597330125080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-496c775a-3d38-4cbf-9a67-ec40e7d5577b,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-1c9846bd-6302-4e4b-9c84-6f6af342936b,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-f2ebf83c-5b5f-49d0-9c8e-5a266e581d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-4478d488-7a73-483f-bb70-a0cc5b8cad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-e3e8f74e-22e7-40f6-807e-f6ccc6a6baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-505e011a-770d-4ab1-97e3-69df5f37e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-c4a46f35-cf03-4279-8576-5daaeaa8d11e,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-e528a060-96c4-466d-a9f3-56f1f0992193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1515935888-172.17.0.5-1597330125080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-496c775a-3d38-4cbf-9a67-ec40e7d5577b,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-1c9846bd-6302-4e4b-9c84-6f6af342936b,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-f2ebf83c-5b5f-49d0-9c8e-5a266e581d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-4478d488-7a73-483f-bb70-a0cc5b8cad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-e3e8f74e-22e7-40f6-807e-f6ccc6a6baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-505e011a-770d-4ab1-97e3-69df5f37e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-c4a46f35-cf03-4279-8576-5daaeaa8d11e,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-e528a060-96c4-466d-a9f3-56f1f0992193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5768
