reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308710130-172.17.0.20-1597330485895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-e1a011f2-63d8-441e-8a47-61542f9afd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-8a0a3c89-dfb3-4159-b4df-452b3940d1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-d7f9d2c4-c8e5-4a1a-bcc1-ec2632e3ff63,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-be179a67-c40e-4b01-80a2-5046d02c9f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-27571e47-99d4-4538-afcb-602bf6a2b077,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-a94b1fa7-9cfa-44cb-b887-91a4f2d44ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-7ac32a3a-5b70-400b-ba8e-0ebd7c01a480,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-6bb07da8-5735-4fc6-a8d6-ea640be0d2a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308710130-172.17.0.20-1597330485895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-e1a011f2-63d8-441e-8a47-61542f9afd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-8a0a3c89-dfb3-4159-b4df-452b3940d1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-d7f9d2c4-c8e5-4a1a-bcc1-ec2632e3ff63,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-be179a67-c40e-4b01-80a2-5046d02c9f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-27571e47-99d4-4538-afcb-602bf6a2b077,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-a94b1fa7-9cfa-44cb-b887-91a4f2d44ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-7ac32a3a-5b70-400b-ba8e-0ebd7c01a480,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-6bb07da8-5735-4fc6-a8d6-ea640be0d2a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307569174-172.17.0.20-1597330522856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-ad9b7be2-5128-4f8e-8191-0ede94a0b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-0cfb216e-bdbf-43ed-856c-70cae062d402,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-e795add3-8d6e-4a14-868f-4ad915ca3364,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-d39ce3ae-c929-4399-8d9f-fe9b9cfbf908,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-3ddbd2db-aa84-4127-90f9-72a6fc4125dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-8cf0bc39-a0f7-4cbd-a640-dfb7343ed37e,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-a2b8d3d2-7824-4850-99d6-64fdbd3a9827,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-fed10336-b958-495a-b783-cbc952d88d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307569174-172.17.0.20-1597330522856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-ad9b7be2-5128-4f8e-8191-0ede94a0b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-0cfb216e-bdbf-43ed-856c-70cae062d402,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-e795add3-8d6e-4a14-868f-4ad915ca3364,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-d39ce3ae-c929-4399-8d9f-fe9b9cfbf908,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-3ddbd2db-aa84-4127-90f9-72a6fc4125dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-8cf0bc39-a0f7-4cbd-a640-dfb7343ed37e,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-a2b8d3d2-7824-4850-99d6-64fdbd3a9827,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-fed10336-b958-495a-b783-cbc952d88d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1357274126-172.17.0.20-1597330714992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43561,DS-c7fe4371-a037-47af-a847-92ea06d2ae19,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-67cd2d6a-2e13-4405-b78d-38eb66b9ae27,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-a09e7b95-f532-4902-be4a-ec9a5e8b5ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-6c3e50af-6a0b-47eb-8911-5caec72ad870,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-6775afa0-2308-4332-bf8b-ff6a9a8b486d,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-0c5508c5-0e7f-4080-8873-4c5a93f7bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-65510a3b-df4c-46c6-ae5f-2a97e77c12f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-cd1465ac-5b32-4358-a0f7-9a36770b6012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1357274126-172.17.0.20-1597330714992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43561,DS-c7fe4371-a037-47af-a847-92ea06d2ae19,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-67cd2d6a-2e13-4405-b78d-38eb66b9ae27,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-a09e7b95-f532-4902-be4a-ec9a5e8b5ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-6c3e50af-6a0b-47eb-8911-5caec72ad870,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-6775afa0-2308-4332-bf8b-ff6a9a8b486d,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-0c5508c5-0e7f-4080-8873-4c5a93f7bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-65510a3b-df4c-46c6-ae5f-2a97e77c12f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-cd1465ac-5b32-4358-a0f7-9a36770b6012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960859539-172.17.0.20-1597331241330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41686,DS-d57b025d-0721-427c-b4c6-aeecd59db5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-0ca7f3f9-eb7e-4115-8065-31b4f44d7233,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-eecc7b27-be6f-49f5-babd-d4150e6df6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-2eaa3d9b-1232-4866-b6d2-399e423ec69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-3931e0ad-71b0-41e3-8e8e-295b32dbe79e,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-6364c173-8069-4224-aada-5df2b8447c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-8b57ffdf-a881-40d0-a365-9c9575d34f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-4da2d096-3242-41a2-84c0-0f3ca6572392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960859539-172.17.0.20-1597331241330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41686,DS-d57b025d-0721-427c-b4c6-aeecd59db5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-0ca7f3f9-eb7e-4115-8065-31b4f44d7233,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-eecc7b27-be6f-49f5-babd-d4150e6df6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-2eaa3d9b-1232-4866-b6d2-399e423ec69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-3931e0ad-71b0-41e3-8e8e-295b32dbe79e,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-6364c173-8069-4224-aada-5df2b8447c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-8b57ffdf-a881-40d0-a365-9c9575d34f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-4da2d096-3242-41a2-84c0-0f3ca6572392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636307638-172.17.0.20-1597331591283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-f0551b88-2261-4afa-8a9b-1a932b3d9b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-7100c151-df77-401b-88df-289b143b040e,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-36e52617-ceae-4114-bbd1-69296a2528c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-2cbd2e78-b732-4f27-b89c-9cfcdf6b378c,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-4befb02c-dee2-4b03-869f-4986124a2e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-bc1bd7bc-db3b-4c14-9bbf-9026f507860f,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-228cf59c-b181-490c-9523-a4c147722084,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-6187614d-eb6f-4685-b94b-c348c0c87b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636307638-172.17.0.20-1597331591283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-f0551b88-2261-4afa-8a9b-1a932b3d9b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-7100c151-df77-401b-88df-289b143b040e,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-36e52617-ceae-4114-bbd1-69296a2528c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-2cbd2e78-b732-4f27-b89c-9cfcdf6b378c,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-4befb02c-dee2-4b03-869f-4986124a2e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-bc1bd7bc-db3b-4c14-9bbf-9026f507860f,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-228cf59c-b181-490c-9523-a4c147722084,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-6187614d-eb6f-4685-b94b-c348c0c87b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216558942-172.17.0.20-1597331929208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33573,DS-25b8ba92-fd01-49f5-80b5-1c34c35c77ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-e434005c-d919-4300-b38e-44af358d64b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-b1539456-c8c8-4534-883e-d6faee012c20,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-dbee4cbf-4d4d-4c6f-ac5a-c423e59c7a48,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-d40153cb-c022-4aec-b0b7-7ebda3a3c970,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-6da87cff-56eb-4174-ad23-4bee520c268d,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-ca45ab6f-4dec-487a-ad47-b315378e26fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-029f76ef-54d0-496b-94b4-eb83feb4affa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216558942-172.17.0.20-1597331929208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33573,DS-25b8ba92-fd01-49f5-80b5-1c34c35c77ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-e434005c-d919-4300-b38e-44af358d64b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-b1539456-c8c8-4534-883e-d6faee012c20,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-dbee4cbf-4d4d-4c6f-ac5a-c423e59c7a48,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-d40153cb-c022-4aec-b0b7-7ebda3a3c970,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-6da87cff-56eb-4174-ad23-4bee520c268d,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-ca45ab6f-4dec-487a-ad47-b315378e26fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-029f76ef-54d0-496b-94b4-eb83feb4affa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457322099-172.17.0.20-1597331967493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33867,DS-a043858b-dfdc-4520-8aab-686e5c7499db,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-4b83f05e-45db-4d73-9bd6-2d5cbbe4e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-c5bf18d4-bbc9-4323-82d1-e2364485a925,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-0036adeb-4616-470d-acba-feae939eecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-977b79ee-5a56-4871-a282-cb704ddea1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-1f875370-16ef-4825-ad56-c2846b7efac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-80e43575-ce54-4fbb-b5b4-f8b8809e89dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-a60a28df-c29b-4397-88bc-0149ecfb10c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457322099-172.17.0.20-1597331967493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33867,DS-a043858b-dfdc-4520-8aab-686e5c7499db,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-4b83f05e-45db-4d73-9bd6-2d5cbbe4e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-c5bf18d4-bbc9-4323-82d1-e2364485a925,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-0036adeb-4616-470d-acba-feae939eecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-977b79ee-5a56-4871-a282-cb704ddea1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-1f875370-16ef-4825-ad56-c2846b7efac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-80e43575-ce54-4fbb-b5b4-f8b8809e89dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-a60a28df-c29b-4397-88bc-0149ecfb10c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434742745-172.17.0.20-1597332076188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-ace33d48-e16a-4b9d-831d-e5f77cf9324e,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-3f431f8b-05f6-4129-8b4e-29a6fb19b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-b516c432-be01-4689-bb8b-ab430e026779,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-4bd7cc65-fa70-45ee-ac19-ef74447afbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-7b5a712d-2ee3-4bb9-bc70-219f805c33e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-b866dd26-176a-4dc9-b6f8-ee3dbf7ac454,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-5a78be29-3563-460a-b1c9-8ddb44b35bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-4bfb0331-afcc-4390-bf2d-b3a71d73b001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434742745-172.17.0.20-1597332076188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-ace33d48-e16a-4b9d-831d-e5f77cf9324e,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-3f431f8b-05f6-4129-8b4e-29a6fb19b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-b516c432-be01-4689-bb8b-ab430e026779,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-4bd7cc65-fa70-45ee-ac19-ef74447afbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-7b5a712d-2ee3-4bb9-bc70-219f805c33e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-b866dd26-176a-4dc9-b6f8-ee3dbf7ac454,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-5a78be29-3563-460a-b1c9-8ddb44b35bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-4bfb0331-afcc-4390-bf2d-b3a71d73b001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41622176-172.17.0.20-1597332252786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45507,DS-3d30d8e4-ce8e-44eb-b1c5-deb4302fef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-6c5ae4ec-eb58-48f0-bea9-280a13f15be4,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-2e1618ab-5559-4eb9-9b3d-b6893d5280ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-eba88ce5-8898-4a85-bc42-48654eeb0be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-588c544b-0d42-4359-bde5-e9c31c104c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-d6bbc657-46c6-45ba-b96b-5a463d6f1c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-c29d6689-cea4-49bb-866d-e27af82c14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-e5560e75-5bb8-408a-855a-a5ef6f0744c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41622176-172.17.0.20-1597332252786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45507,DS-3d30d8e4-ce8e-44eb-b1c5-deb4302fef6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-6c5ae4ec-eb58-48f0-bea9-280a13f15be4,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-2e1618ab-5559-4eb9-9b3d-b6893d5280ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-eba88ce5-8898-4a85-bc42-48654eeb0be6,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-588c544b-0d42-4359-bde5-e9c31c104c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-d6bbc657-46c6-45ba-b96b-5a463d6f1c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-c29d6689-cea4-49bb-866d-e27af82c14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-e5560e75-5bb8-408a-855a-a5ef6f0744c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731626057-172.17.0.20-1597333163003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38414,DS-279ed170-dbac-48b8-8f53-93c6bd69d523,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-2e289b19-94f9-4b90-9579-2d72a2cf6e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-dd7e4107-6613-4aac-af40-1228d41e1d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-0e8575ab-3d8d-474a-bb75-3e862e024a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-112f0f2c-ca1c-4167-a779-4d0be9e2f6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-1e5926e2-58e5-48dc-aeb9-af343dc156a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-2d9124b0-adbc-4d88-b9cd-8561d647d00b,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-1aaff2e7-499e-4630-a513-a8d43a33969d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731626057-172.17.0.20-1597333163003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38414,DS-279ed170-dbac-48b8-8f53-93c6bd69d523,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-2e289b19-94f9-4b90-9579-2d72a2cf6e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-dd7e4107-6613-4aac-af40-1228d41e1d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-0e8575ab-3d8d-474a-bb75-3e862e024a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-112f0f2c-ca1c-4167-a779-4d0be9e2f6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-1e5926e2-58e5-48dc-aeb9-af343dc156a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-2d9124b0-adbc-4d88-b9cd-8561d647d00b,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-1aaff2e7-499e-4630-a513-a8d43a33969d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819569548-172.17.0.20-1597333816730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-e420d2d6-9786-4d9e-b0f5-889fa41cb413,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-0ced6ade-bf15-462f-8a5a-02adfb3db1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-7c65b1cb-2945-4d29-969c-2e1ab1784e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-18f0908b-cbd3-4f6b-bd86-ca012313e331,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-4a08ef28-c0e9-4636-aaec-44cf894f68de,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-d040d0e2-1e85-4443-ba46-e670c931928e,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-9e8fdf63-83e8-4c14-b8df-e3dab87ae051,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-ee19ddbe-84d7-4863-b3af-27d00b802bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819569548-172.17.0.20-1597333816730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-e420d2d6-9786-4d9e-b0f5-889fa41cb413,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-0ced6ade-bf15-462f-8a5a-02adfb3db1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-7c65b1cb-2945-4d29-969c-2e1ab1784e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-18f0908b-cbd3-4f6b-bd86-ca012313e331,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-4a08ef28-c0e9-4636-aaec-44cf894f68de,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-d040d0e2-1e85-4443-ba46-e670c931928e,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-9e8fdf63-83e8-4c14-b8df-e3dab87ae051,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-ee19ddbe-84d7-4863-b3af-27d00b802bdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753732359-172.17.0.20-1597334450856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-2720ee18-2054-4a99-82ca-5f49471378d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-cee5586b-2e4e-42c6-9db6-150122638a56,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-8b2a914e-90e2-4454-97df-d9353a7f6d45,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-8a20e156-5334-4398-a0d9-4c51aee28fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-1009adda-5aae-4de2-8c67-9837f70b8800,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-ac0b0d37-cd86-42ec-ba6f-b9b60a858948,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-15e1da84-beee-4b2f-91f1-e1ce11ebf8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-abe09bd2-144a-49b9-a7a4-3844b7e9b860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753732359-172.17.0.20-1597334450856:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-2720ee18-2054-4a99-82ca-5f49471378d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-cee5586b-2e4e-42c6-9db6-150122638a56,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-8b2a914e-90e2-4454-97df-d9353a7f6d45,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-8a20e156-5334-4398-a0d9-4c51aee28fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-1009adda-5aae-4de2-8c67-9837f70b8800,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-ac0b0d37-cd86-42ec-ba6f-b9b60a858948,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-15e1da84-beee-4b2f-91f1-e1ce11ebf8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-abe09bd2-144a-49b9-a7a4-3844b7e9b860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521467167-172.17.0.20-1597334827584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-b7cc3872-26bc-4b9f-add9-eab16024b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-d5ff6986-4d0a-4e52-8c4f-1a35345d2cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-e9823e97-64cd-4b2a-962a-eb37733f3a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-8992defa-5d47-4f0b-9345-c0ae41bf9dee,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-429c30c9-0738-4fd8-80ee-90e36d10b09e,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-0c13ad62-b1f9-4b7a-a660-452f937681d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-42b95835-9afd-4a39-8d7d-70a2b4e989b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-7c322a3b-6006-4f16-bfaf-8e2d310ce0c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521467167-172.17.0.20-1597334827584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-b7cc3872-26bc-4b9f-add9-eab16024b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-d5ff6986-4d0a-4e52-8c4f-1a35345d2cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-e9823e97-64cd-4b2a-962a-eb37733f3a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-8992defa-5d47-4f0b-9345-c0ae41bf9dee,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-429c30c9-0738-4fd8-80ee-90e36d10b09e,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-0c13ad62-b1f9-4b7a-a660-452f937681d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-42b95835-9afd-4a39-8d7d-70a2b4e989b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-7c322a3b-6006-4f16-bfaf-8e2d310ce0c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218319322-172.17.0.20-1597335022530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-cad34576-5a44-4832-a89d-d2defdb26926,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-d60bdc23-0ebd-4a1c-85a6-8caa3b7ecd78,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-80f5274a-4e30-4ab5-b776-a305c95514fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-8bfb1d84-2571-4e35-9467-ad60e191242d,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-bac6a9e7-5009-42f6-99c5-5b354126a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-3bfe6aba-122d-4be3-8b83-a3c5b3f24156,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-460abe3d-478a-45e5-93eb-5bd9fc710851,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-c13480c4-82f2-4144-adf7-802e8cf80a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218319322-172.17.0.20-1597335022530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-cad34576-5a44-4832-a89d-d2defdb26926,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-d60bdc23-0ebd-4a1c-85a6-8caa3b7ecd78,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-80f5274a-4e30-4ab5-b776-a305c95514fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-8bfb1d84-2571-4e35-9467-ad60e191242d,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-bac6a9e7-5009-42f6-99c5-5b354126a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-3bfe6aba-122d-4be3-8b83-a3c5b3f24156,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-460abe3d-478a-45e5-93eb-5bd9fc710851,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-c13480c4-82f2-4144-adf7-802e8cf80a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86596231-172.17.0.20-1597335360251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-1e466b7f-d353-4ea5-bf60-7c2788559000,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-8d7a73f9-7458-467e-a850-92b5585215be,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-bd3150e6-750a-42de-a4ee-1326bb261924,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-759b8870-600b-47b1-9cc6-c2a4722edafd,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-ce354742-0a9c-4272-8e74-a0709d889bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-7325cef7-b497-4965-8744-3e296c05df52,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-0423503e-f3d8-4409-8c49-7f1673418464,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-5e865869-370c-4ede-a0cf-80efabd7d2c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86596231-172.17.0.20-1597335360251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-1e466b7f-d353-4ea5-bf60-7c2788559000,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-8d7a73f9-7458-467e-a850-92b5585215be,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-bd3150e6-750a-42de-a4ee-1326bb261924,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-759b8870-600b-47b1-9cc6-c2a4722edafd,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-ce354742-0a9c-4272-8e74-a0709d889bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-7325cef7-b497-4965-8744-3e296c05df52,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-0423503e-f3d8-4409-8c49-7f1673418464,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-5e865869-370c-4ede-a0cf-80efabd7d2c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666974273-172.17.0.20-1597335545993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40977,DS-20d5f593-abb7-4c9e-8907-5dc8287cd812,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-10cbc00a-8043-410d-905e-69757df69ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-ae0f82b2-2f72-4943-a386-6f9171116334,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-05c60c85-8ed1-4a61-a131-97348aab30b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-5a4eab4b-21b0-453a-aef1-fd478d235aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-df05c3c3-0639-4ca5-a3bf-73e70d57965e,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-52198dc6-7c2d-4a19-a25e-bce93f0747ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-8d729d28-c937-4b36-8114-7f6f3ed6f236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666974273-172.17.0.20-1597335545993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40977,DS-20d5f593-abb7-4c9e-8907-5dc8287cd812,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-10cbc00a-8043-410d-905e-69757df69ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-ae0f82b2-2f72-4943-a386-6f9171116334,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-05c60c85-8ed1-4a61-a131-97348aab30b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-5a4eab4b-21b0-453a-aef1-fd478d235aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-df05c3c3-0639-4ca5-a3bf-73e70d57965e,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-52198dc6-7c2d-4a19-a25e-bce93f0747ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-8d729d28-c937-4b36-8114-7f6f3ed6f236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491593613-172.17.0.20-1597335727137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-d9f5c443-e91f-4c66-931f-736d684cb317,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-e111e00f-73c0-45fe-bae9-2beb028102fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-d660ae1a-c312-492a-b9dc-942780783d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-cd8e8579-a1fb-408c-af7a-2cb689df623f,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-7fe48432-0ebd-44cf-9bc7-74c83ee80966,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-aa00cd05-b48d-4e04-88a4-563d3e3249fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-1d0e24ca-09cf-4101-8dc2-2c51fe82cc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-f885315c-2216-4abf-aed7-1c9e1c82289d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491593613-172.17.0.20-1597335727137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-d9f5c443-e91f-4c66-931f-736d684cb317,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-e111e00f-73c0-45fe-bae9-2beb028102fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-d660ae1a-c312-492a-b9dc-942780783d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-cd8e8579-a1fb-408c-af7a-2cb689df623f,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-7fe48432-0ebd-44cf-9bc7-74c83ee80966,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-aa00cd05-b48d-4e04-88a4-563d3e3249fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-1d0e24ca-09cf-4101-8dc2-2c51fe82cc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-f885315c-2216-4abf-aed7-1c9e1c82289d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345401972-172.17.0.20-1597335754299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-936fa20e-1f4a-4944-8c74-8f8a1b1cb6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-4a5812a6-9688-4d59-a447-c428b690bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-7e85a8fa-0e62-4049-a22e-f65352b4570a,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-bf1e5883-c189-4040-8e44-e8795a20b3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-a8b47cf1-6d04-4a6d-9eed-b99f06dd51c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-31e0c029-5349-4645-b2e2-5940124551b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-eb675182-8393-4807-91e1-d0d5beeeb635,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-56405ee2-fc91-4e74-b8cc-d1f724861876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1345401972-172.17.0.20-1597335754299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37266,DS-936fa20e-1f4a-4944-8c74-8f8a1b1cb6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-4a5812a6-9688-4d59-a447-c428b690bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-7e85a8fa-0e62-4049-a22e-f65352b4570a,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-bf1e5883-c189-4040-8e44-e8795a20b3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-a8b47cf1-6d04-4a6d-9eed-b99f06dd51c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-31e0c029-5349-4645-b2e2-5940124551b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-eb675182-8393-4807-91e1-d0d5beeeb635,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-56405ee2-fc91-4e74-b8cc-d1f724861876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115260768-172.17.0.20-1597335825868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34882,DS-57d7889b-dc08-40a0-989d-3dbdebd0f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4e8a7a19-bf77-41fe-b4d8-41621ca416b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-27d55301-b89f-4e2d-a1fa-97447ed8bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-b7094083-5930-4dc3-a2f9-238da979f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-dde340ec-92d0-4d02-ad0c-02ed28ab0a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-eca51f04-d8c2-4a27-b341-5d10c04586e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-3fe59fe7-5852-4a0e-a1dd-031c4a96c714,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-e2f9c1d5-58ee-4b48-949d-31e45a6aee3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115260768-172.17.0.20-1597335825868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34882,DS-57d7889b-dc08-40a0-989d-3dbdebd0f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-4e8a7a19-bf77-41fe-b4d8-41621ca416b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-27d55301-b89f-4e2d-a1fa-97447ed8bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-b7094083-5930-4dc3-a2f9-238da979f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-dde340ec-92d0-4d02-ad0c-02ed28ab0a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-eca51f04-d8c2-4a27-b341-5d10c04586e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-3fe59fe7-5852-4a0e-a1dd-031c4a96c714,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-e2f9c1d5-58ee-4b48-949d-31e45a6aee3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5524
