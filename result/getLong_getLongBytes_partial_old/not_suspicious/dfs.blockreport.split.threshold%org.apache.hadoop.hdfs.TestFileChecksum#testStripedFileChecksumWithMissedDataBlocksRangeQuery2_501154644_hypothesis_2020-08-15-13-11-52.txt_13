reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599267262-172.17.0.17-1597497170605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-a7810c3a-9063-4ecc-902a-099f913d4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-0d50fcde-da88-4e45-8548-367c90df34c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-6b8b9191-ddcd-4471-b8db-a7a8adadebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-b3b833f7-dc25-4e79-ab8b-25c31a962d98,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-54cace2e-4394-4d82-9b2a-5bb9ceac6e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-ef180633-9b08-40fc-aa42-f12de442f531,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-3d5ab60c-ec84-40dd-987c-9391214b83f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-337f9442-3fcf-4650-8864-7ca529e2db8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599267262-172.17.0.17-1597497170605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-a7810c3a-9063-4ecc-902a-099f913d4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-0d50fcde-da88-4e45-8548-367c90df34c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-6b8b9191-ddcd-4471-b8db-a7a8adadebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-b3b833f7-dc25-4e79-ab8b-25c31a962d98,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-54cace2e-4394-4d82-9b2a-5bb9ceac6e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-ef180633-9b08-40fc-aa42-f12de442f531,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-3d5ab60c-ec84-40dd-987c-9391214b83f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-337f9442-3fcf-4650-8864-7ca529e2db8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893513394-172.17.0.17-1597497540354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35654,DS-af40f4fa-ebe6-4e50-93c6-70a635945f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-c4f792ca-8049-4798-8257-2101e6437845,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-18e541c1-d905-434a-a968-9e7ebd3e712d,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-41091ed6-0fa4-47f6-a8fb-81c6788c4be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-9d18f662-25a1-408a-a208-866f6a68fa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-ec0d97ce-1bd6-4a53-83f8-f968e237a547,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-76c7d7cd-f34c-4aa9-888f-04b81b7cff99,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-1057b5ee-8044-4155-8c9d-9b5bbcb76507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893513394-172.17.0.17-1597497540354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35654,DS-af40f4fa-ebe6-4e50-93c6-70a635945f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-c4f792ca-8049-4798-8257-2101e6437845,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-18e541c1-d905-434a-a968-9e7ebd3e712d,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-41091ed6-0fa4-47f6-a8fb-81c6788c4be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-9d18f662-25a1-408a-a208-866f6a68fa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-ec0d97ce-1bd6-4a53-83f8-f968e237a547,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-76c7d7cd-f34c-4aa9-888f-04b81b7cff99,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-1057b5ee-8044-4155-8c9d-9b5bbcb76507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244270597-172.17.0.17-1597497572624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-5a3d4b2f-f638-4388-8036-359d88a2751b,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-a7d5f419-836a-4cd1-a366-4b3da510a340,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-65bec976-1f27-43dd-84f1-8f464538fd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-a7be8bcf-da45-4bc4-9afe-6dbe6630c412,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-93dd9015-e7e7-4ca6-9df6-b6eef40637df,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-0d4ff0a3-a6db-4713-ba68-0a10163cdbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-3c62ff48-b5fd-4b85-a5d2-55c4c41c8368,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-44585fc7-3d96-4ed5-a630-5b9d42de13f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244270597-172.17.0.17-1597497572624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-5a3d4b2f-f638-4388-8036-359d88a2751b,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-a7d5f419-836a-4cd1-a366-4b3da510a340,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-65bec976-1f27-43dd-84f1-8f464538fd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-a7be8bcf-da45-4bc4-9afe-6dbe6630c412,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-93dd9015-e7e7-4ca6-9df6-b6eef40637df,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-0d4ff0a3-a6db-4713-ba68-0a10163cdbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-3c62ff48-b5fd-4b85-a5d2-55c4c41c8368,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-44585fc7-3d96-4ed5-a630-5b9d42de13f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773564344-172.17.0.17-1597497642782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46084,DS-46ed577e-c0c0-4e28-8fcd-6b8e8c9e104a,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-8fb05c12-448d-478d-8906-198a47cf1e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-7a203279-4489-4ac3-9bd3-ff0abb95394e,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-265df8aa-81bf-411e-952b-54f799f89a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-cfe889dd-b7b0-4458-85c8-7030932f5990,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-0a0ca69e-9b78-49ba-80d0-e67cc55e480a,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-da5cc1bc-1984-4009-8f15-5a1424a7271c,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-d6051f42-b7de-49f0-80d6-56f05c9c5704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773564344-172.17.0.17-1597497642782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46084,DS-46ed577e-c0c0-4e28-8fcd-6b8e8c9e104a,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-8fb05c12-448d-478d-8906-198a47cf1e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-7a203279-4489-4ac3-9bd3-ff0abb95394e,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-265df8aa-81bf-411e-952b-54f799f89a60,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-cfe889dd-b7b0-4458-85c8-7030932f5990,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-0a0ca69e-9b78-49ba-80d0-e67cc55e480a,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-da5cc1bc-1984-4009-8f15-5a1424a7271c,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-d6051f42-b7de-49f0-80d6-56f05c9c5704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270342681-172.17.0.17-1597498041713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-7d31c1b4-59f8-4417-afdf-d5eebb653e15,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-9e06a3ee-a465-4369-a37f-5d241cecb8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-13131c24-fda7-4129-8541-5ee56a96efa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-d14d19ba-c02f-4f5c-ad68-1fd79c249c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-2c8dc797-736c-4081-97e2-21fde796dd99,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-507a675c-343c-46e2-8867-1b556de9bc74,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-8da0610e-9f80-4ec2-b9fe-cc056fac0377,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-7dd70404-6bf3-401b-8353-61ba03d281f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270342681-172.17.0.17-1597498041713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39085,DS-7d31c1b4-59f8-4417-afdf-d5eebb653e15,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-9e06a3ee-a465-4369-a37f-5d241cecb8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-13131c24-fda7-4129-8541-5ee56a96efa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-d14d19ba-c02f-4f5c-ad68-1fd79c249c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-2c8dc797-736c-4081-97e2-21fde796dd99,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-507a675c-343c-46e2-8867-1b556de9bc74,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-8da0610e-9f80-4ec2-b9fe-cc056fac0377,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-7dd70404-6bf3-401b-8353-61ba03d281f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056944994-172.17.0.17-1597498084897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37371,DS-2dd91b7f-206f-4217-ac3e-2d43a88f5112,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-ddd98f39-901e-439a-bd67-23d408aa2eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-9cd78fc8-afb2-49a3-a412-bbd59180aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-7b13f20e-8a9e-4f85-9e99-26f866c612f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-1de27f2b-71e9-45ae-9d2c-fb33f703fa47,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-362f3456-e696-4440-99e4-e01e6ae66b33,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-01c3c6bc-e3d4-4408-8cb4-525d4f505302,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-be1cc7ec-bfcf-4032-856f-613d237cf5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056944994-172.17.0.17-1597498084897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37371,DS-2dd91b7f-206f-4217-ac3e-2d43a88f5112,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-ddd98f39-901e-439a-bd67-23d408aa2eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-9cd78fc8-afb2-49a3-a412-bbd59180aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-7b13f20e-8a9e-4f85-9e99-26f866c612f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-1de27f2b-71e9-45ae-9d2c-fb33f703fa47,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-362f3456-e696-4440-99e4-e01e6ae66b33,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-01c3c6bc-e3d4-4408-8cb4-525d4f505302,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-be1cc7ec-bfcf-4032-856f-613d237cf5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525739254-172.17.0.17-1597498695840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-6fe8949f-cdae-4c69-a230-022ab7f7b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-29ab0170-1d34-402a-afde-5aeac524dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-6193b8e0-17c0-4c4d-891e-d2c901aa16e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-a41dfc95-d9eb-430e-aecb-7e089298ff06,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-eb608f62-eb23-4b87-9e96-a976d5302a58,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-bbc42ad4-6f8a-4cb2-ae33-6744d09c9458,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-3a016966-c221-47a3-bfd3-05c8dcf8ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-4143d861-19fe-4fba-9662-9febfd517638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525739254-172.17.0.17-1597498695840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-6fe8949f-cdae-4c69-a230-022ab7f7b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-29ab0170-1d34-402a-afde-5aeac524dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-6193b8e0-17c0-4c4d-891e-d2c901aa16e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-a41dfc95-d9eb-430e-aecb-7e089298ff06,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-eb608f62-eb23-4b87-9e96-a976d5302a58,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-bbc42ad4-6f8a-4cb2-ae33-6744d09c9458,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-3a016966-c221-47a3-bfd3-05c8dcf8ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-4143d861-19fe-4fba-9662-9febfd517638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961177721-172.17.0.17-1597498736466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38259,DS-cc1e8ae0-2679-4538-bcd4-a010c1d5e5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-f2045776-6dc1-4565-bcb5-464d84560a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-8b27f096-7bae-4b95-a783-c10ab778ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-07ac4781-5c36-417d-a740-f76431bd7c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-9f34f01c-a744-4578-942c-11dac0dcf45a,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-38b41011-eb23-47be-a22c-321cc373824d,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-5aaae98c-1bd2-4929-b70c-b8a4c28cf7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-c7aff3f1-a815-48b1-8c1e-ef773b0a1e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961177721-172.17.0.17-1597498736466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38259,DS-cc1e8ae0-2679-4538-bcd4-a010c1d5e5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-f2045776-6dc1-4565-bcb5-464d84560a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-8b27f096-7bae-4b95-a783-c10ab778ff9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-07ac4781-5c36-417d-a740-f76431bd7c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-9f34f01c-a744-4578-942c-11dac0dcf45a,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-38b41011-eb23-47be-a22c-321cc373824d,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-5aaae98c-1bd2-4929-b70c-b8a4c28cf7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-c7aff3f1-a815-48b1-8c1e-ef773b0a1e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968082733-172.17.0.17-1597498817635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39052,DS-15ac9465-455e-4d1d-b4dd-8266018ce382,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-0c9ddfc7-2853-4fcc-9383-e4084625cb30,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-726b4344-ed46-4cf5-9287-36542aefb380,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-a80fb902-cb46-4710-80ad-9b22f7040b00,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-eb824f36-ee40-477a-904d-a59fe7bbdb61,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-a865efa5-a35e-41d9-be55-bd483df89648,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-a745e39f-c10e-4128-a1a4-067a87319e20,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-3a64f80b-8b6e-489e-8ab3-a21655b46a58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968082733-172.17.0.17-1597498817635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39052,DS-15ac9465-455e-4d1d-b4dd-8266018ce382,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-0c9ddfc7-2853-4fcc-9383-e4084625cb30,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-726b4344-ed46-4cf5-9287-36542aefb380,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-a80fb902-cb46-4710-80ad-9b22f7040b00,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-eb824f36-ee40-477a-904d-a59fe7bbdb61,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-a865efa5-a35e-41d9-be55-bd483df89648,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-a745e39f-c10e-4128-a1a4-067a87319e20,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-3a64f80b-8b6e-489e-8ab3-a21655b46a58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442681350-172.17.0.17-1597498962711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-ff5024dd-449d-4d37-a1bb-8d768ead4cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-6b33478d-10bb-43b4-9b57-a7b32efd8363,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-a1ebacf5-edd4-4474-8833-40e865f95576,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-9f87ce8d-43f1-46c9-9997-a9e46f2b29fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-0b71c0d2-2eb2-4624-b789-cbebef0a76f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-b141f9b9-c0c4-4253-8b2a-e347bc775f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-73064797-8322-452b-b0a7-ca2de2584b91,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-c4c5c07f-4cbc-4ed8-9461-a44fac283668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442681350-172.17.0.17-1597498962711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-ff5024dd-449d-4d37-a1bb-8d768ead4cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-6b33478d-10bb-43b4-9b57-a7b32efd8363,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-a1ebacf5-edd4-4474-8833-40e865f95576,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-9f87ce8d-43f1-46c9-9997-a9e46f2b29fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-0b71c0d2-2eb2-4624-b789-cbebef0a76f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-b141f9b9-c0c4-4253-8b2a-e347bc775f76,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-73064797-8322-452b-b0a7-ca2de2584b91,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-c4c5c07f-4cbc-4ed8-9461-a44fac283668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473975854-172.17.0.17-1597499447885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-29e89d46-cf8e-4233-9df4-24be161cd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-6075ca30-8dd7-4009-87e2-5e3ab8021d49,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-d897a29c-d5a4-4b52-8841-aca998b38d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-c4792dc5-288e-4030-a733-7b40c6df7173,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-95026e85-6c7d-46d7-816d-f82f46bba611,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-0ead2480-088a-4fd6-9f4f-a0ee9fc419f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-46ee7924-513c-432f-a494-47f9ee91b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-ebd0607f-3d2d-4b11-bc9d-176e3204a56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473975854-172.17.0.17-1597499447885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-29e89d46-cf8e-4233-9df4-24be161cd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-6075ca30-8dd7-4009-87e2-5e3ab8021d49,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-d897a29c-d5a4-4b52-8841-aca998b38d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-c4792dc5-288e-4030-a733-7b40c6df7173,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-95026e85-6c7d-46d7-816d-f82f46bba611,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-0ead2480-088a-4fd6-9f4f-a0ee9fc419f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-46ee7924-513c-432f-a494-47f9ee91b9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-ebd0607f-3d2d-4b11-bc9d-176e3204a56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112777893-172.17.0.17-1597499580781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41196,DS-25dad469-7f26-4f1c-907b-fc04468f5267,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-73e5c7c4-0d37-4ca0-9817-f8f00aae46fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-c54d8e73-c038-4c63-8c60-ef16154c9925,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-70489d08-057d-441a-b59e-b8fa23f4d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-8e94b0b1-554e-4f59-bcc9-325468081a37,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-70e2eeed-5f69-40cd-a117-5bac39cb60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-f6592973-9a62-4370-9e21-cf922184bda8,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-7270f91d-14e0-49c9-9350-0e610adde64c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112777893-172.17.0.17-1597499580781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41196,DS-25dad469-7f26-4f1c-907b-fc04468f5267,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-73e5c7c4-0d37-4ca0-9817-f8f00aae46fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-c54d8e73-c038-4c63-8c60-ef16154c9925,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-70489d08-057d-441a-b59e-b8fa23f4d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-8e94b0b1-554e-4f59-bcc9-325468081a37,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-70e2eeed-5f69-40cd-a117-5bac39cb60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-f6592973-9a62-4370-9e21-cf922184bda8,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-7270f91d-14e0-49c9-9350-0e610adde64c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300371447-172.17.0.17-1597499910085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-308572f2-ed8f-4983-8f85-2c569845772d,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-baf57d1b-1a06-4dff-94a7-1e17d9d670eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-278dd1ab-b45d-4587-a7cd-91a10f296ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-1e69ca7b-c334-49ab-9c7f-a79b3be2a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-b27f7caa-0b1c-4ed0-a01f-dbe9c14c4315,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-a6b0fc01-8ba1-4e12-8449-e5bca58ccbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-77af8e9f-8267-4b6e-92b4-943869f8d9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-90049caf-faba-4716-80ce-21d241eadd44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300371447-172.17.0.17-1597499910085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-308572f2-ed8f-4983-8f85-2c569845772d,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-baf57d1b-1a06-4dff-94a7-1e17d9d670eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-278dd1ab-b45d-4587-a7cd-91a10f296ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-1e69ca7b-c334-49ab-9c7f-a79b3be2a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-b27f7caa-0b1c-4ed0-a01f-dbe9c14c4315,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-a6b0fc01-8ba1-4e12-8449-e5bca58ccbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-77af8e9f-8267-4b6e-92b4-943869f8d9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-90049caf-faba-4716-80ce-21d241eadd44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775219242-172.17.0.17-1597500369936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-f4b2f895-9f61-4e84-95e0-be94e87a999e,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-29dbc622-168c-48c2-92ac-a92b63c08508,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-c2a69c4e-8ebb-472a-9128-db435e45cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-9b79f077-0f73-4ea6-a579-e51ef511f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-cb2acbc6-5f5a-44eb-b105-f9d9a1a92c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-a3a4bfcb-5aac-4cd5-a9f3-609e07085f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-ff31f6de-292d-4a41-94f7-8d812c1e5e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-d19d6d99-8bc8-4946-95d9-bf5aa015af24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775219242-172.17.0.17-1597500369936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34057,DS-f4b2f895-9f61-4e84-95e0-be94e87a999e,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-29dbc622-168c-48c2-92ac-a92b63c08508,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-c2a69c4e-8ebb-472a-9128-db435e45cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-9b79f077-0f73-4ea6-a579-e51ef511f3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-cb2acbc6-5f5a-44eb-b105-f9d9a1a92c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-a3a4bfcb-5aac-4cd5-a9f3-609e07085f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-ff31f6de-292d-4a41-94f7-8d812c1e5e81,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-d19d6d99-8bc8-4946-95d9-bf5aa015af24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817956990-172.17.0.17-1597500562784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-84cff65d-9f3d-447b-a770-9ab640a5ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-efb5ecf0-4aa6-4018-8de0-cf962966d1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-72c89877-da32-48fd-b883-8917caae3a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-4abaab51-f5f1-4a96-bb75-6ad7c890448d,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-8b0ec384-a9bf-46a3-8856-545fcacdb4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-b635bc9f-f99e-4c22-b0bd-89d5bdbbab74,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-d909bc57-8246-4cfa-8e7e-ad39459b388c,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4b7d5df3-4d28-49ce-b7a3-4bd6293aeebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817956990-172.17.0.17-1597500562784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-84cff65d-9f3d-447b-a770-9ab640a5ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-efb5ecf0-4aa6-4018-8de0-cf962966d1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-72c89877-da32-48fd-b883-8917caae3a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-4abaab51-f5f1-4a96-bb75-6ad7c890448d,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-8b0ec384-a9bf-46a3-8856-545fcacdb4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-b635bc9f-f99e-4c22-b0bd-89d5bdbbab74,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-d909bc57-8246-4cfa-8e7e-ad39459b388c,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-4b7d5df3-4d28-49ce-b7a3-4bd6293aeebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349332675-172.17.0.17-1597501068516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-1efe128e-f6b1-4404-ad64-61b8d7df5ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-a5d13243-ab86-444c-9887-3b28a5c8bf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-7efb190f-4827-418e-b84d-c8cc14d5960a,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-bfff06ce-71a3-4960-b6c6-e18fce0fb2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-46b74560-1ebb-4695-a184-91c0734d93a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-4441459f-4747-473b-b7b8-552ffecac516,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-b48816f5-05aa-4b72-8e89-8c7572398901,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-c4babb7b-f58f-40dd-8b11-073ddd595cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349332675-172.17.0.17-1597501068516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-1efe128e-f6b1-4404-ad64-61b8d7df5ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-a5d13243-ab86-444c-9887-3b28a5c8bf33,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-7efb190f-4827-418e-b84d-c8cc14d5960a,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-bfff06ce-71a3-4960-b6c6-e18fce0fb2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-46b74560-1ebb-4695-a184-91c0734d93a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-4441459f-4747-473b-b7b8-552ffecac516,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-b48816f5-05aa-4b72-8e89-8c7572398901,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-c4babb7b-f58f-40dd-8b11-073ddd595cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313498560-172.17.0.17-1597501148647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-0bf9c6a1-0acc-4406-b7a2-cf4aef351c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-2b01e1d2-129e-4a4d-b62e-2f4665d1ae22,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-5ecc0ee8-493b-44f0-8935-3ba1a9d74c76,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-f2fc4c90-cd06-4fa9-ab95-557dd5feaa70,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-bec2ef1b-cfba-4aee-82b5-1180589b1d39,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-ac855cc0-7166-4e9e-acac-320f8d550c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-c85c5ade-aac0-4f0b-a2e6-47095e2534a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-0df7cfaa-2a72-44f1-960c-3743f0b69e91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313498560-172.17.0.17-1597501148647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-0bf9c6a1-0acc-4406-b7a2-cf4aef351c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-2b01e1d2-129e-4a4d-b62e-2f4665d1ae22,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-5ecc0ee8-493b-44f0-8935-3ba1a9d74c76,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-f2fc4c90-cd06-4fa9-ab95-557dd5feaa70,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-bec2ef1b-cfba-4aee-82b5-1180589b1d39,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-ac855cc0-7166-4e9e-acac-320f8d550c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-c85c5ade-aac0-4f0b-a2e6-47095e2534a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-0df7cfaa-2a72-44f1-960c-3743f0b69e91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334925933-172.17.0.17-1597501312861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42687,DS-c68f1437-803f-4b03-9f55-f486e678d689,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-d8fcef8b-38a0-4915-a6ef-4f51b4bbe0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-0d7ea5b6-f965-401a-91fa-1b9dc7ef743c,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-f4a7d25a-b96f-44c6-a56d-e5a05ef07efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-7825961c-713f-4401-90df-a291fbce0a42,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-802856e1-4a49-4e3c-a84a-7e55e818f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-0aa8874b-a9c5-4dbb-9656-56b908413df6,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-34f0ade9-2d98-4a75-9e3d-041333992c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334925933-172.17.0.17-1597501312861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42687,DS-c68f1437-803f-4b03-9f55-f486e678d689,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-d8fcef8b-38a0-4915-a6ef-4f51b4bbe0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-0d7ea5b6-f965-401a-91fa-1b9dc7ef743c,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-f4a7d25a-b96f-44c6-a56d-e5a05ef07efb,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-7825961c-713f-4401-90df-a291fbce0a42,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-802856e1-4a49-4e3c-a84a-7e55e818f8db,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-0aa8874b-a9c5-4dbb-9656-56b908413df6,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-34f0ade9-2d98-4a75-9e3d-041333992c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962363324-172.17.0.17-1597501996869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-d0e85742-3000-47c2-9251-f03aea76a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-4320a71c-55ab-4302-9c85-a71df56a4ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-43bc4e14-6c34-4757-ac77-d2e6ccbcde48,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-19037a2c-9924-4ba9-a101-7b3aaf9b96ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-322099d8-88c8-4b5b-b901-5e95974fe029,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-5697b4cd-2617-4113-89ac-3d6fd964198e,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-f5bb5cab-b6ae-4580-a74e-336b22784afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-52372da9-7610-42bf-80c2-f5bbefd07673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962363324-172.17.0.17-1597501996869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-d0e85742-3000-47c2-9251-f03aea76a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-4320a71c-55ab-4302-9c85-a71df56a4ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-43bc4e14-6c34-4757-ac77-d2e6ccbcde48,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-19037a2c-9924-4ba9-a101-7b3aaf9b96ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-322099d8-88c8-4b5b-b901-5e95974fe029,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-5697b4cd-2617-4113-89ac-3d6fd964198e,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-f5bb5cab-b6ae-4580-a74e-336b22784afb,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-52372da9-7610-42bf-80c2-f5bbefd07673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5458
