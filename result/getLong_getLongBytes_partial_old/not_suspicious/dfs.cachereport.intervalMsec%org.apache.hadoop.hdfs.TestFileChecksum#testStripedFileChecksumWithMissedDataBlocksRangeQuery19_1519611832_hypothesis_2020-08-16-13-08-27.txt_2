reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244877361-172.17.0.5-1597583324659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-0861bbf1-4723-4c7f-bcb2-959235eada4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-298a3a33-3329-4385-b899-1fd6479a9e40,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-c88b7808-6b7f-423a-b9f7-98b75beac828,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-ff09f262-3a05-448c-b512-2f415d3c4934,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-1c3129bf-52a7-4842-97b7-3f0681af608d,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-ba17e00b-0049-4a59-9841-4093ed885089,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-70ad2775-0188-4801-b0fe-558aaa142954,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-07507abc-f0c9-44fe-af9b-1e965432e4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244877361-172.17.0.5-1597583324659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-0861bbf1-4723-4c7f-bcb2-959235eada4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-298a3a33-3329-4385-b899-1fd6479a9e40,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-c88b7808-6b7f-423a-b9f7-98b75beac828,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-ff09f262-3a05-448c-b512-2f415d3c4934,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-1c3129bf-52a7-4842-97b7-3f0681af608d,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-ba17e00b-0049-4a59-9841-4093ed885089,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-70ad2775-0188-4801-b0fe-558aaa142954,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-07507abc-f0c9-44fe-af9b-1e965432e4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193361411-172.17.0.5-1597583641069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37412,DS-f0a73d18-fec2-4c8a-a7b8-0cdb08dce3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-0856775d-4ad2-44c3-986b-75f8e04a5b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-d8dc7e8a-4eb0-4a80-8203-6fa8256db166,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-2e644707-6f8b-43cf-9a2f-2f0cd3179389,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-70117dee-b179-4175-b593-93c7a6594fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-247679ee-cdc5-4ec6-a995-6d8e85007e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-e903afc9-74c9-4354-81c2-e5e2136fba89,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-9d35f444-10a9-4255-acdb-7d7e97bed4ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193361411-172.17.0.5-1597583641069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37412,DS-f0a73d18-fec2-4c8a-a7b8-0cdb08dce3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-0856775d-4ad2-44c3-986b-75f8e04a5b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-d8dc7e8a-4eb0-4a80-8203-6fa8256db166,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-2e644707-6f8b-43cf-9a2f-2f0cd3179389,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-70117dee-b179-4175-b593-93c7a6594fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-247679ee-cdc5-4ec6-a995-6d8e85007e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-e903afc9-74c9-4354-81c2-e5e2136fba89,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-9d35f444-10a9-4255-acdb-7d7e97bed4ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144707838-172.17.0.5-1597583804709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-3ac62e92-4ee3-4f33-890f-868538a87685,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-94dde793-2cc8-43e9-bff4-f5412efa57f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-2bd7abdf-c30d-44fa-aed3-cb0c7ab01e15,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-e8400004-49ce-487c-8ebf-e3987b18adba,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-71996079-9904-49ed-b848-7b5336990d31,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-c0caf704-1e69-48d4-bf3f-ebd1fb33edb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-0a4b4dd5-fbd1-4a87-8950-5da31ef6f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-33b18b17-7e27-44ad-b8f9-aaf51b8cb043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144707838-172.17.0.5-1597583804709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44216,DS-3ac62e92-4ee3-4f33-890f-868538a87685,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-94dde793-2cc8-43e9-bff4-f5412efa57f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-2bd7abdf-c30d-44fa-aed3-cb0c7ab01e15,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-e8400004-49ce-487c-8ebf-e3987b18adba,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-71996079-9904-49ed-b848-7b5336990d31,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-c0caf704-1e69-48d4-bf3f-ebd1fb33edb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-0a4b4dd5-fbd1-4a87-8950-5da31ef6f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-33b18b17-7e27-44ad-b8f9-aaf51b8cb043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46300004-172.17.0.5-1597584052364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34707,DS-e42db6d9-9aeb-4a6e-a91b-ae6d85d3c8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-cc8a21f7-00e0-4fcf-9c3e-cd773f9f7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-5546b12f-4b2c-4287-b786-96f458f8f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-e50a3aa8-db6f-48f1-a81a-d55065a67c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-97bd83ea-284c-4aca-87ae-46fd7cbbc27f,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-355cd34c-3209-4d44-9336-449542c0efd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-d24dc28d-5495-434f-8d8c-20329a6573a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-2f1367f2-29af-4dfd-aa29-d35956a16abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46300004-172.17.0.5-1597584052364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34707,DS-e42db6d9-9aeb-4a6e-a91b-ae6d85d3c8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-cc8a21f7-00e0-4fcf-9c3e-cd773f9f7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-5546b12f-4b2c-4287-b786-96f458f8f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-e50a3aa8-db6f-48f1-a81a-d55065a67c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-97bd83ea-284c-4aca-87ae-46fd7cbbc27f,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-355cd34c-3209-4d44-9336-449542c0efd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-d24dc28d-5495-434f-8d8c-20329a6573a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-2f1367f2-29af-4dfd-aa29-d35956a16abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822968019-172.17.0.5-1597584133670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-826dfb42-577e-43d2-b2fe-b74d8b602c13,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-09c42c62-488a-46f2-b165-19139ed9a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-2083591c-ea47-44c5-b9f5-a9be7a56d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-f447020d-e078-4444-a89d-66ae4d517da5,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-5aff9ae7-40c9-40de-9bc8-6a7fa10348f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-bbba4c46-e425-426f-92fb-444ea197923e,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-8e69fdc3-7db2-4bc4-ab2b-c1aee7bb06e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-ca7009c7-c78b-4c01-9dda-42e845c29926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822968019-172.17.0.5-1597584133670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-826dfb42-577e-43d2-b2fe-b74d8b602c13,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-09c42c62-488a-46f2-b165-19139ed9a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-2083591c-ea47-44c5-b9f5-a9be7a56d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-f447020d-e078-4444-a89d-66ae4d517da5,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-5aff9ae7-40c9-40de-9bc8-6a7fa10348f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-bbba4c46-e425-426f-92fb-444ea197923e,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-8e69fdc3-7db2-4bc4-ab2b-c1aee7bb06e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-ca7009c7-c78b-4c01-9dda-42e845c29926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890463048-172.17.0.5-1597584250725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-e5b637a4-b799-4c4b-99e3-816e2f0e3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-2f47ea50-ccf8-418b-bfe2-a725a36941f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-a9de354b-604f-4f3a-bbed-bfbadb7fa1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-0a6d2b8e-965d-4ccf-afd4-e7ad90230858,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-3e572ed8-9eec-4bc4-8ab5-33b286bf0ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-b7a9c6f5-ce4b-4315-9743-4d5003d172f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-351531d3-d961-4cd2-b58f-f993db347140,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-98a3fa72-40d7-4389-a140-2326fa256d26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890463048-172.17.0.5-1597584250725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-e5b637a4-b799-4c4b-99e3-816e2f0e3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-2f47ea50-ccf8-418b-bfe2-a725a36941f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-a9de354b-604f-4f3a-bbed-bfbadb7fa1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-0a6d2b8e-965d-4ccf-afd4-e7ad90230858,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-3e572ed8-9eec-4bc4-8ab5-33b286bf0ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-b7a9c6f5-ce4b-4315-9743-4d5003d172f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-351531d3-d961-4cd2-b58f-f993db347140,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-98a3fa72-40d7-4389-a140-2326fa256d26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997551900-172.17.0.5-1597584288235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46168,DS-377f0b05-84c9-4307-99c9-a03b65f53d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-b36ea4f5-2b4a-4f7f-86e0-61bf52e88818,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-c1b3a71f-149a-4ea9-96af-934709070eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-e128b3a7-2908-4880-bcbc-33bda4e3328c,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-ee914d40-1da0-44f8-b09b-a0beb2bc8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-2d7f87fa-e96d-4e21-95d0-28a7ce4b7add,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-50078b9a-73ac-402c-a054-9993e00df7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-e3b2c291-d04a-46b4-9878-d9a8a4f91a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997551900-172.17.0.5-1597584288235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46168,DS-377f0b05-84c9-4307-99c9-a03b65f53d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-b36ea4f5-2b4a-4f7f-86e0-61bf52e88818,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-c1b3a71f-149a-4ea9-96af-934709070eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-e128b3a7-2908-4880-bcbc-33bda4e3328c,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-ee914d40-1da0-44f8-b09b-a0beb2bc8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-2d7f87fa-e96d-4e21-95d0-28a7ce4b7add,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-50078b9a-73ac-402c-a054-9993e00df7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-e3b2c291-d04a-46b4-9878-d9a8a4f91a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413733657-172.17.0.5-1597584596158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-7ad0ac21-8c03-478c-a8f4-c56990fda6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-f3ed8b78-9898-4413-ba2b-5f7b0ae30297,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-ffbd8952-fbc9-49f0-b59f-708d9f906dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-7dc50f18-7f0d-4bdb-9163-2b3bddbc0a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-3817a14f-b343-46f9-9fd4-e2f4067ee368,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-667ef0fe-27c1-4c56-b19e-e3dc2faa1112,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-ede7405e-a823-44e0-ab3f-b15c3036bb31,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-3f64d2d5-c9ef-4b55-b2af-5e58d8b90a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413733657-172.17.0.5-1597584596158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35357,DS-7ad0ac21-8c03-478c-a8f4-c56990fda6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-f3ed8b78-9898-4413-ba2b-5f7b0ae30297,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-ffbd8952-fbc9-49f0-b59f-708d9f906dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-7dc50f18-7f0d-4bdb-9163-2b3bddbc0a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-3817a14f-b343-46f9-9fd4-e2f4067ee368,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-667ef0fe-27c1-4c56-b19e-e3dc2faa1112,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-ede7405e-a823-44e0-ab3f-b15c3036bb31,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-3f64d2d5-c9ef-4b55-b2af-5e58d8b90a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093672900-172.17.0.5-1597584715423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-d83a4067-a9cc-4361-bc38-ef32c859db15,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-12612e85-db86-4cdc-9dab-982b42e44c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-bfcaae11-afa5-48d9-af88-dba7cfe146e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-d79a36bf-a746-45d4-8072-2d3695bcca21,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-9e39b7f6-59ac-4755-8d37-932485838fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-53fbfb65-fa0c-4b74-a7f6-90553ad61e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-6bb52038-792b-457b-9c66-3787a637c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-c126a6b9-15fa-4eb0-b47e-742436ee1a9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093672900-172.17.0.5-1597584715423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-d83a4067-a9cc-4361-bc38-ef32c859db15,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-12612e85-db86-4cdc-9dab-982b42e44c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-bfcaae11-afa5-48d9-af88-dba7cfe146e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-d79a36bf-a746-45d4-8072-2d3695bcca21,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-9e39b7f6-59ac-4755-8d37-932485838fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-53fbfb65-fa0c-4b74-a7f6-90553ad61e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-6bb52038-792b-457b-9c66-3787a637c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-c126a6b9-15fa-4eb0-b47e-742436ee1a9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272109835-172.17.0.5-1597584991086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-3e9ec5c4-e2d0-418f-b55b-d8f13d567b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-2d822549-0f93-48dd-ba8e-635aecfb87fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-0eaa74e1-452b-46df-8644-30153ec4f815,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-2c206afc-76a0-46f1-9a1d-8553f5d351de,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-e500ae74-a1aa-4c9b-809b-d167ac965be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-01371064-7e02-450a-96a3-4e365442c7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-8383ccef-d5af-436f-b7b1-563a3c35ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-a110d39a-6c2f-4cee-94c5-43399295c265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272109835-172.17.0.5-1597584991086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-3e9ec5c4-e2d0-418f-b55b-d8f13d567b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-2d822549-0f93-48dd-ba8e-635aecfb87fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-0eaa74e1-452b-46df-8644-30153ec4f815,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-2c206afc-76a0-46f1-9a1d-8553f5d351de,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-e500ae74-a1aa-4c9b-809b-d167ac965be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-01371064-7e02-450a-96a3-4e365442c7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-8383ccef-d5af-436f-b7b1-563a3c35ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-a110d39a-6c2f-4cee-94c5-43399295c265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522121836-172.17.0.5-1597585558860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-8567f435-e6e4-4030-98da-c6d58703e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-98cd3318-f2a7-4310-a4c5-e24a56f43dae,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-d1dd401e-eefc-4ff6-8773-22f2658f2d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-eba6386e-2a6d-4c50-be30-f6896f0df39f,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-3fa741eb-ce9c-41ac-a9aa-4433a345c4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-042640b7-2c88-4a15-9be4-ddcd2c45d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-b66cefa9-62d7-43d0-9dee-107bf751b59a,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-7b78315e-2adb-4025-be5f-911faf0d8c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522121836-172.17.0.5-1597585558860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35867,DS-8567f435-e6e4-4030-98da-c6d58703e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-98cd3318-f2a7-4310-a4c5-e24a56f43dae,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-d1dd401e-eefc-4ff6-8773-22f2658f2d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-eba6386e-2a6d-4c50-be30-f6896f0df39f,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-3fa741eb-ce9c-41ac-a9aa-4433a345c4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-042640b7-2c88-4a15-9be4-ddcd2c45d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-b66cefa9-62d7-43d0-9dee-107bf751b59a,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-7b78315e-2adb-4025-be5f-911faf0d8c5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788934777-172.17.0.5-1597585634870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38778,DS-f512a7d6-5d73-49de-aa81-6041a79b5a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-05c22724-7f2f-4b85-bada-273997c882ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-86af5ce1-8aac-42ca-a515-3e60ca115373,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-fdbe017c-bcb8-4d8c-a825-5b68a6d78fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-ab50db32-d598-4a42-b1f1-44c6021e8a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-275d81fc-5828-4794-86bb-358961866664,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-2613a9bc-e40b-40f2-9b5c-e43b8645830e,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-b1cf15c0-b9ba-4116-b9fd-892848dbb174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788934777-172.17.0.5-1597585634870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38778,DS-f512a7d6-5d73-49de-aa81-6041a79b5a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-05c22724-7f2f-4b85-bada-273997c882ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-86af5ce1-8aac-42ca-a515-3e60ca115373,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-fdbe017c-bcb8-4d8c-a825-5b68a6d78fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-ab50db32-d598-4a42-b1f1-44c6021e8a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-275d81fc-5828-4794-86bb-358961866664,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-2613a9bc-e40b-40f2-9b5c-e43b8645830e,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-b1cf15c0-b9ba-4116-b9fd-892848dbb174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738506989-172.17.0.5-1597585937986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-3beea682-27ad-4c5e-8fb9-792976ea6bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-484865c0-1dba-4d21-93ad-cad98e97cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-46e28f42-a45a-4655-8b5f-bcb89a5cc01e,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-3bca1d42-3f33-43e8-b8a6-45d364891891,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-93d5e0a0-6d4b-4e10-8713-382ec2b65568,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-187b82ea-90c7-43e6-a113-cdf8d0be823d,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-67faec88-99cf-4a2c-88c6-914d529b74d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-c5722654-598d-4ecd-8a03-1f9d47f39d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738506989-172.17.0.5-1597585937986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-3beea682-27ad-4c5e-8fb9-792976ea6bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-484865c0-1dba-4d21-93ad-cad98e97cb10,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-46e28f42-a45a-4655-8b5f-bcb89a5cc01e,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-3bca1d42-3f33-43e8-b8a6-45d364891891,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-93d5e0a0-6d4b-4e10-8713-382ec2b65568,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-187b82ea-90c7-43e6-a113-cdf8d0be823d,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-67faec88-99cf-4a2c-88c6-914d529b74d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-c5722654-598d-4ecd-8a03-1f9d47f39d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309405116-172.17.0.5-1597586002861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-87923fb9-7461-48d9-af7f-36e1bf40375d,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-cfa5e268-3bb5-433c-8f4f-a00abb872e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-dcf42a6c-9b07-4cdc-9c27-0d05ef8f4643,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-2b8b789d-730d-42c3-9b77-0b53601aa7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-2514c747-c06c-412c-a379-789e92d0b034,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-f2b76ba0-87d4-4439-92b6-6b6c6e910b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-32c23a2d-386d-4047-a7ab-a8a38d3e87c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-e8050917-caec-4f7b-b4eb-36cfd6dab0a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309405116-172.17.0.5-1597586002861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-87923fb9-7461-48d9-af7f-36e1bf40375d,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-cfa5e268-3bb5-433c-8f4f-a00abb872e81,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-dcf42a6c-9b07-4cdc-9c27-0d05ef8f4643,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-2b8b789d-730d-42c3-9b77-0b53601aa7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-2514c747-c06c-412c-a379-789e92d0b034,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-f2b76ba0-87d4-4439-92b6-6b6c6e910b12,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-32c23a2d-386d-4047-a7ab-a8a38d3e87c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-e8050917-caec-4f7b-b4eb-36cfd6dab0a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265459709-172.17.0.5-1597586221911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-c839a8f6-a5e4-483d-8ac1-e1f9fd74a1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-e0d0cf91-b89c-49ce-987f-7716406e385e,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-17f98e85-8ed1-43a6-8088-2e429fe6915c,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-c1387961-4706-498c-8cd2-c362e2c5e937,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-7c06ec38-0134-4914-95c2-3b880a9bad9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-51f7a087-cdd7-4fe7-a78e-d653122496f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-304c590b-d5f8-4061-994a-412faa8b4c97,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-7bcb1832-eb8f-4026-afc3-75f6842b2839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265459709-172.17.0.5-1597586221911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-c839a8f6-a5e4-483d-8ac1-e1f9fd74a1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-e0d0cf91-b89c-49ce-987f-7716406e385e,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-17f98e85-8ed1-43a6-8088-2e429fe6915c,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-c1387961-4706-498c-8cd2-c362e2c5e937,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-7c06ec38-0134-4914-95c2-3b880a9bad9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-51f7a087-cdd7-4fe7-a78e-d653122496f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-304c590b-d5f8-4061-994a-412faa8b4c97,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-7bcb1832-eb8f-4026-afc3-75f6842b2839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98325245-172.17.0.5-1597586623494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-37f75fba-84b9-4c13-bab5-d833ccebe88c,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-6825e1d1-265e-4abc-92ee-3d9f3e56570d,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-bab80470-97e3-402c-bac2-cbdbf432d9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-20d4c24f-e667-462e-97ec-d39fc640be26,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-8f2ddca0-06e4-47d1-bda8-03aa5794e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-06c21e10-8d7d-4455-8ee6-3ac9b800ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-bf7edb58-dba8-4128-8e56-cdd8782262d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-4fe9cfa9-3b74-4d3e-8c83-6665be5b6fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98325245-172.17.0.5-1597586623494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38165,DS-37f75fba-84b9-4c13-bab5-d833ccebe88c,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-6825e1d1-265e-4abc-92ee-3d9f3e56570d,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-bab80470-97e3-402c-bac2-cbdbf432d9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-20d4c24f-e667-462e-97ec-d39fc640be26,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-8f2ddca0-06e4-47d1-bda8-03aa5794e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-06c21e10-8d7d-4455-8ee6-3ac9b800ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-bf7edb58-dba8-4128-8e56-cdd8782262d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-4fe9cfa9-3b74-4d3e-8c83-6665be5b6fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830762767-172.17.0.5-1597586665221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-4aee27c6-709e-46fd-bc42-64dbba6f02b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-afdee313-b088-404c-803d-0dadcbcb3eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-1ae7a8d5-8ae0-4118-9228-ea27f7136b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-708d1c3d-21e4-4219-9ee6-2fa3b7313e29,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-75d9420b-1b38-4d37-aaa0-5797c35e5aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-dae26f86-01f9-4544-aed2-1098aeca6e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-066e9cd7-642b-4fd2-8e24-7462f453bb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-9b36ca0a-3e3f-4bd7-abde-590b166aedac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830762767-172.17.0.5-1597586665221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-4aee27c6-709e-46fd-bc42-64dbba6f02b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-afdee313-b088-404c-803d-0dadcbcb3eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-1ae7a8d5-8ae0-4118-9228-ea27f7136b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-708d1c3d-21e4-4219-9ee6-2fa3b7313e29,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-75d9420b-1b38-4d37-aaa0-5797c35e5aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-dae26f86-01f9-4544-aed2-1098aeca6e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-066e9cd7-642b-4fd2-8e24-7462f453bb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-9b36ca0a-3e3f-4bd7-abde-590b166aedac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291046154-172.17.0.5-1597587370424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36720,DS-0031053c-44cc-43a1-9479-81e0c5bb2588,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-6e38ae82-0957-40d1-ac45-aa3dda9d4901,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-18961a2a-e757-4497-9f51-5906b7a48203,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-16b153c8-ab40-46f5-bff6-300cb82001b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-60d9c526-fb6c-463d-a42c-bb30885dd972,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-c71f7688-f927-4558-86aa-2b4d2c5b5605,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-332bdf93-960d-47db-aecb-cac7116723e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-80e5cb5c-c83d-4aaf-b729-1e695e6983d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291046154-172.17.0.5-1597587370424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36720,DS-0031053c-44cc-43a1-9479-81e0c5bb2588,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-6e38ae82-0957-40d1-ac45-aa3dda9d4901,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-18961a2a-e757-4497-9f51-5906b7a48203,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-16b153c8-ab40-46f5-bff6-300cb82001b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-60d9c526-fb6c-463d-a42c-bb30885dd972,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-c71f7688-f927-4558-86aa-2b4d2c5b5605,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-332bdf93-960d-47db-aecb-cac7116723e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-80e5cb5c-c83d-4aaf-b729-1e695e6983d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908504392-172.17.0.5-1597587479219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-6225039d-1c74-4268-9ac7-73e814dffdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-951996f8-083a-4359-9de3-0c92959e2b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-76fbd9ba-0f0d-4604-a81c-bc3e09314856,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-d405bbf3-82e3-44b8-97fd-54bfc05f24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-535ffb57-c9d2-40c8-9443-7b7ed6613ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-fcdb06bc-f736-4c29-9772-a3ec02a262cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-801cecd4-b5c8-4862-9c82-9a4bcebe812e,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-7828a612-51af-4334-a89b-cdf2a8b4528b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908504392-172.17.0.5-1597587479219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-6225039d-1c74-4268-9ac7-73e814dffdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-951996f8-083a-4359-9de3-0c92959e2b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-76fbd9ba-0f0d-4604-a81c-bc3e09314856,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-d405bbf3-82e3-44b8-97fd-54bfc05f24fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-535ffb57-c9d2-40c8-9443-7b7ed6613ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-fcdb06bc-f736-4c29-9772-a3ec02a262cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-801cecd4-b5c8-4862-9c82-9a4bcebe812e,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-7828a612-51af-4334-a89b-cdf2a8b4528b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989049969-172.17.0.5-1597587786308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46542,DS-a1c5b47c-0206-404d-b953-7a8486e3d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-f0132887-3482-4cc1-bf63-f66c9afae556,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-67bf8292-0b78-4cbf-bcc6-93f7f5fa2c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-b1f04c7f-1f09-4f1d-86f0-001801c3e263,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-04288a01-a759-4c96-acd2-71117f89b935,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-73945ee0-668a-4d67-945a-95f987d06dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-8763c835-4a66-442a-8bb9-fa33f11c3d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-189895ff-7061-4d54-8f1f-38028a56644d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989049969-172.17.0.5-1597587786308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46542,DS-a1c5b47c-0206-404d-b953-7a8486e3d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-f0132887-3482-4cc1-bf63-f66c9afae556,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-67bf8292-0b78-4cbf-bcc6-93f7f5fa2c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-b1f04c7f-1f09-4f1d-86f0-001801c3e263,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-04288a01-a759-4c96-acd2-71117f89b935,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-73945ee0-668a-4d67-945a-95f987d06dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-8763c835-4a66-442a-8bb9-fa33f11c3d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-189895ff-7061-4d54-8f1f-38028a56644d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553235615-172.17.0.5-1597588397164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-7d650bfb-a9fc-427d-971c-7bae5f095371,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-0456944b-d95b-4192-a21f-cc8109ba9aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-4b3c5ada-67db-47c4-b4f7-59e37e333ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-7f6fb734-0637-4a2b-87fb-c54630f86bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-bbabdee2-be52-49c3-83ac-6daabf6403b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-b590e9cc-2b47-4239-87c0-bd5606d7ca7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-0532affe-3ef6-4692-9ad2-9de4afa5f613,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-31a66701-304a-4123-b5ae-225e13069152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553235615-172.17.0.5-1597588397164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-7d650bfb-a9fc-427d-971c-7bae5f095371,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-0456944b-d95b-4192-a21f-cc8109ba9aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-4b3c5ada-67db-47c4-b4f7-59e37e333ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-7f6fb734-0637-4a2b-87fb-c54630f86bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-bbabdee2-be52-49c3-83ac-6daabf6403b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-b590e9cc-2b47-4239-87c0-bd5606d7ca7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-0532affe-3ef6-4692-9ad2-9de4afa5f613,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-31a66701-304a-4123-b5ae-225e13069152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5729
