reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028602649-172.17.0.8-1597347857079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46178,DS-44d224e2-4d71-402a-902c-32699bc5571a,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-2644308b-29e3-4e7f-b82b-cd8628f9489a,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-76870ffc-52eb-4608-8fcb-b441f5862a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-cce0de49-7b07-4699-8591-4ca479f81cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-dc0991de-75ee-4874-9605-ed03b09620f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-d0fd857a-bac6-4460-93d6-17876273fd59,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-f29f453d-0aa1-4e71-9498-98e0eeefe866,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-a093b0b1-9745-48ab-8f6c-950be7128657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028602649-172.17.0.8-1597347857079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46178,DS-44d224e2-4d71-402a-902c-32699bc5571a,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-2644308b-29e3-4e7f-b82b-cd8628f9489a,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-76870ffc-52eb-4608-8fcb-b441f5862a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-cce0de49-7b07-4699-8591-4ca479f81cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-dc0991de-75ee-4874-9605-ed03b09620f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-d0fd857a-bac6-4460-93d6-17876273fd59,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-f29f453d-0aa1-4e71-9498-98e0eeefe866,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-a093b0b1-9745-48ab-8f6c-950be7128657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674382854-172.17.0.8-1597348129730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-0524c2c9-ed07-4270-8848-01841018f9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-d3942385-7b6f-4323-a50f-7faf2c031026,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-7ce8509c-fa46-4984-89c4-9f606397fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-c115d017-a146-4dc3-8ce5-a3501236e846,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-60102145-5beb-4b37-bd1a-3263e910a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-56f87e1e-080d-4949-b5ff-e01e0956642a,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-4e0be3b1-da66-49fd-872f-202c5c431e56,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-9ec3366d-f9af-4524-b5f5-be1b1b25cb3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674382854-172.17.0.8-1597348129730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41152,DS-0524c2c9-ed07-4270-8848-01841018f9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-d3942385-7b6f-4323-a50f-7faf2c031026,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-7ce8509c-fa46-4984-89c4-9f606397fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-c115d017-a146-4dc3-8ce5-a3501236e846,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-60102145-5beb-4b37-bd1a-3263e910a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-56f87e1e-080d-4949-b5ff-e01e0956642a,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-4e0be3b1-da66-49fd-872f-202c5c431e56,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-9ec3366d-f9af-4524-b5f5-be1b1b25cb3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575034123-172.17.0.8-1597348273253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34956,DS-b894b825-ee7d-4311-8504-1a934aae6fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-42ba2bf8-1fb6-4a13-9028-c445b94bbfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-ab484d91-704c-4985-a257-f3a6e5075c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-f1b0e809-d47d-4066-8728-7160f61cf773,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-88ef041a-0ff1-404a-8c4b-a18692286a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-a318b8d3-5461-47bb-ad25-480106e44703,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-8c103719-d46e-4ac2-b0e5-ad75cf1f95ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-24f4ad56-10d7-46b7-aa56-754c597544e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575034123-172.17.0.8-1597348273253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34956,DS-b894b825-ee7d-4311-8504-1a934aae6fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-42ba2bf8-1fb6-4a13-9028-c445b94bbfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-ab484d91-704c-4985-a257-f3a6e5075c28,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-f1b0e809-d47d-4066-8728-7160f61cf773,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-88ef041a-0ff1-404a-8c4b-a18692286a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-a318b8d3-5461-47bb-ad25-480106e44703,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-8c103719-d46e-4ac2-b0e5-ad75cf1f95ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-24f4ad56-10d7-46b7-aa56-754c597544e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125765385-172.17.0.8-1597348675838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41786,DS-37040be4-4e14-4fab-8a05-bffff10dabb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-4ac33de5-cbbc-41e6-84c8-23dd3afaf54d,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-177cb792-91f7-40a5-868c-48d494bfc5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-66bd4a9e-0376-49cb-9366-148aa92f334a,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-4406867b-8f5d-485c-85ba-791f7e0defc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-ad7cd6d8-2018-4ee8-8bdc-a0bc4f658768,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-fe9dfb78-7197-4101-85e8-3ee2fe2a376d,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-0130f8f9-b7a1-4b5b-ba0c-63d4297d5087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125765385-172.17.0.8-1597348675838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41786,DS-37040be4-4e14-4fab-8a05-bffff10dabb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-4ac33de5-cbbc-41e6-84c8-23dd3afaf54d,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-177cb792-91f7-40a5-868c-48d494bfc5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-66bd4a9e-0376-49cb-9366-148aa92f334a,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-4406867b-8f5d-485c-85ba-791f7e0defc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-ad7cd6d8-2018-4ee8-8bdc-a0bc4f658768,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-fe9dfb78-7197-4101-85e8-3ee2fe2a376d,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-0130f8f9-b7a1-4b5b-ba0c-63d4297d5087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353084507-172.17.0.8-1597348749861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42829,DS-5178c51b-c343-4cbf-bdab-ea2ef323cd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-fea9c6db-0bc6-43f0-a07d-d256fc5ccc47,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-6ceee8fe-826f-4ef9-a8b4-e957faa99a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-c081e57f-91c6-4b13-9b49-bb7db6fb7504,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-2fb2d1c5-a718-4b66-97d9-964c79a39b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-076be12b-18af-485e-b48e-806c8c875294,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-9338b222-4380-4512-ac14-2682563dcfee,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-39beb333-ab07-458a-aeaa-5fb72a791301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353084507-172.17.0.8-1597348749861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42829,DS-5178c51b-c343-4cbf-bdab-ea2ef323cd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-fea9c6db-0bc6-43f0-a07d-d256fc5ccc47,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-6ceee8fe-826f-4ef9-a8b4-e957faa99a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-c081e57f-91c6-4b13-9b49-bb7db6fb7504,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-2fb2d1c5-a718-4b66-97d9-964c79a39b10,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-076be12b-18af-485e-b48e-806c8c875294,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-9338b222-4380-4512-ac14-2682563dcfee,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-39beb333-ab07-458a-aeaa-5fb72a791301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50996158-172.17.0.8-1597349283637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39053,DS-264705b2-85b2-4b43-8e92-d3fa386812f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-7cd65c32-cf9c-45a9-a851-1d678caeb30a,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-3de66564-227c-41d6-a790-6e0e69ca7210,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-75dcfad8-0937-4fc7-a6f8-3c0b0f49dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-dbfdfd99-03e9-4b02-b969-f15fee1321ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-3af936e2-19d6-46a0-92e9-44fe00392254,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-3c7532a3-6af7-4bcc-8352-ec4bb903e718,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-a08d3bd9-0799-43e2-ac50-906dc8c067c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50996158-172.17.0.8-1597349283637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39053,DS-264705b2-85b2-4b43-8e92-d3fa386812f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-7cd65c32-cf9c-45a9-a851-1d678caeb30a,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-3de66564-227c-41d6-a790-6e0e69ca7210,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-75dcfad8-0937-4fc7-a6f8-3c0b0f49dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-dbfdfd99-03e9-4b02-b969-f15fee1321ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-3af936e2-19d6-46a0-92e9-44fe00392254,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-3c7532a3-6af7-4bcc-8352-ec4bb903e718,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-a08d3bd9-0799-43e2-ac50-906dc8c067c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424760014-172.17.0.8-1597349566692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-a0a51f05-a6d9-4880-8cbf-66f775efe785,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-3c003bbb-1347-4d74-b042-dfc15947168c,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-52576dfb-b52b-4ffa-890a-4733297c4761,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-9b770c81-1a5a-4092-a251-fa4ea4dd39ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-5b4e28f9-bc71-4197-add6-fb579fbac0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-4414cb5b-d6f0-42ac-82a9-f71015bc950c,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-f26730c7-ea26-43d7-8ce1-fb38e516201b,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-051c7bb5-3a09-4a35-8d68-eb645370e137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424760014-172.17.0.8-1597349566692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-a0a51f05-a6d9-4880-8cbf-66f775efe785,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-3c003bbb-1347-4d74-b042-dfc15947168c,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-52576dfb-b52b-4ffa-890a-4733297c4761,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-9b770c81-1a5a-4092-a251-fa4ea4dd39ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-5b4e28f9-bc71-4197-add6-fb579fbac0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-4414cb5b-d6f0-42ac-82a9-f71015bc950c,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-f26730c7-ea26-43d7-8ce1-fb38e516201b,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-051c7bb5-3a09-4a35-8d68-eb645370e137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669946983-172.17.0.8-1597350092542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32998,DS-16c50662-dfe2-4ba7-82a0-3152db1dcb94,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-d80d9590-2ebb-4b14-9d8d-39786dfbc97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-8f091703-fc22-4886-9a23-57df10117e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-9aad23ff-17ce-4a99-8c57-828781f13ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-202e0a34-2393-4cc6-9e1d-684422468ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-56b3e44b-fc20-46b6-b22c-62d6a2186340,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-5bf9de6e-bb7e-4ba0-a845-a987cf2dd66e,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-1f489ad8-32c5-4b84-940f-6234cd15ef8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669946983-172.17.0.8-1597350092542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32998,DS-16c50662-dfe2-4ba7-82a0-3152db1dcb94,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-d80d9590-2ebb-4b14-9d8d-39786dfbc97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-8f091703-fc22-4886-9a23-57df10117e30,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-9aad23ff-17ce-4a99-8c57-828781f13ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-202e0a34-2393-4cc6-9e1d-684422468ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-56b3e44b-fc20-46b6-b22c-62d6a2186340,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-5bf9de6e-bb7e-4ba0-a845-a987cf2dd66e,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-1f489ad8-32c5-4b84-940f-6234cd15ef8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004837055-172.17.0.8-1597350770903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-425ab8e1-5897-4e83-b120-0a824468e4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-32159621-6fd8-4f89-8cd0-4802edfcc4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-6018aa41-7b2a-4511-a948-1628a6edce1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-ac1645af-15f7-41f0-bdc2-b7da3732a543,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-10a1be6c-55a5-4f8f-abf4-ccf68ef6b053,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-48c3ace6-8a00-4da7-9df5-591fff4ad146,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-5db1d2da-e8a1-4c86-b304-d84676879787,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-b9446384-c5f5-41ea-be2d-7182e45776cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2004837055-172.17.0.8-1597350770903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33167,DS-425ab8e1-5897-4e83-b120-0a824468e4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-32159621-6fd8-4f89-8cd0-4802edfcc4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-6018aa41-7b2a-4511-a948-1628a6edce1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-ac1645af-15f7-41f0-bdc2-b7da3732a543,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-10a1be6c-55a5-4f8f-abf4-ccf68ef6b053,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-48c3ace6-8a00-4da7-9df5-591fff4ad146,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-5db1d2da-e8a1-4c86-b304-d84676879787,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-b9446384-c5f5-41ea-be2d-7182e45776cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222226317-172.17.0.8-1597351362821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44705,DS-c24ff64f-7997-4ea4-b0e4-760a3e019b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-e6a9242c-e72f-486d-87b8-aa170e415988,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-f6efc2ff-2101-4a1a-9595-56151ddcf4be,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-5ea6d33d-2190-4352-b275-f916da9d2cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-c4997b3c-4b23-4c93-a5bb-627a04bef600,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-0b7bc752-1f54-46fd-900a-ff31921464de,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-7e8b053d-7ccd-4152-8eb0-2e8155652991,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-800f6ba3-20a0-414c-b7f2-12f4875e98de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222226317-172.17.0.8-1597351362821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44705,DS-c24ff64f-7997-4ea4-b0e4-760a3e019b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-e6a9242c-e72f-486d-87b8-aa170e415988,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-f6efc2ff-2101-4a1a-9595-56151ddcf4be,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-5ea6d33d-2190-4352-b275-f916da9d2cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-c4997b3c-4b23-4c93-a5bb-627a04bef600,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-0b7bc752-1f54-46fd-900a-ff31921464de,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-7e8b053d-7ccd-4152-8eb0-2e8155652991,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-800f6ba3-20a0-414c-b7f2-12f4875e98de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487052498-172.17.0.8-1597352497237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46454,DS-bba24d29-1292-483b-bb2d-cd4099001f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-0bf90387-0b86-4de6-a64c-d63128c901fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-a060d740-2feb-4fa0-b9c2-5e314ced1664,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-91ea831e-4552-453d-a28d-d6d52d35cff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-78295a0b-b599-498d-931f-9152891fc9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-2521e9ef-95bd-4a61-aac2-e9f1e22f3f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-ae73013e-d34b-48b0-bb5e-0d3e3b45746b,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-d896de90-ab81-419d-9830-5030ce7b2c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487052498-172.17.0.8-1597352497237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46454,DS-bba24d29-1292-483b-bb2d-cd4099001f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-0bf90387-0b86-4de6-a64c-d63128c901fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-a060d740-2feb-4fa0-b9c2-5e314ced1664,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-91ea831e-4552-453d-a28d-d6d52d35cff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-78295a0b-b599-498d-931f-9152891fc9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-2521e9ef-95bd-4a61-aac2-e9f1e22f3f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-ae73013e-d34b-48b0-bb5e-0d3e3b45746b,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-d896de90-ab81-419d-9830-5030ce7b2c7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.accesstime.precision
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487730250-172.17.0.8-1597352710985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-22adbdf0-0cb4-4d3c-815f-3189c5737566,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-fc77c29d-6a93-4f7a-93f1-51c7c00f607d,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-1dfad042-9b79-4e06-bbb0-e850554254c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-f2a58c87-3e4e-43e6-b3d7-6f4ce0da136c,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-3ea14914-48ce-4da8-95b1-fbfb53d67fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-0f2a4941-d641-426e-9007-a74e46d73036,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-901874e4-b7b8-475b-82a1-4faefd1e57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-e14f2273-c817-4a18-a2fb-f5ebadda2f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487730250-172.17.0.8-1597352710985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38707,DS-22adbdf0-0cb4-4d3c-815f-3189c5737566,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-fc77c29d-6a93-4f7a-93f1-51c7c00f607d,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-1dfad042-9b79-4e06-bbb0-e850554254c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-f2a58c87-3e4e-43e6-b3d7-6f4ce0da136c,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-3ea14914-48ce-4da8-95b1-fbfb53d67fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-0f2a4941-d641-426e-9007-a74e46d73036,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-901874e4-b7b8-475b-82a1-4faefd1e57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-e14f2273-c817-4a18-a2fb-f5ebadda2f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5557
