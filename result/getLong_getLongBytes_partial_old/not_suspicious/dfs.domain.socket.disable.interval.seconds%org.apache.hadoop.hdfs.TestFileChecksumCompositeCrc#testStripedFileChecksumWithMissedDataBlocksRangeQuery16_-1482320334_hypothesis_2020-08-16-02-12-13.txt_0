reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554419658-172.17.0.7-1597543949558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-40ec97e3-32fc-4360-bc52-fe654a6240e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-195ca7be-1501-4644-bb16-87708a65d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-b2ff3bee-9150-4373-8a9c-ea8704da6d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-c6106827-417f-46b7-b0ba-e16bfb20f53c,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-3ad6ef71-8b08-41e0-bd6a-58e83d5a71cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-58185483-4f7c-4b39-8bc9-9d4e061abbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-48b3613b-8949-4143-8996-85991e288999,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-d600529e-5f6b-44b3-8124-8a1d0ac70cbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554419658-172.17.0.7-1597543949558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-40ec97e3-32fc-4360-bc52-fe654a6240e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-195ca7be-1501-4644-bb16-87708a65d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-b2ff3bee-9150-4373-8a9c-ea8704da6d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-c6106827-417f-46b7-b0ba-e16bfb20f53c,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-3ad6ef71-8b08-41e0-bd6a-58e83d5a71cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-58185483-4f7c-4b39-8bc9-9d4e061abbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-48b3613b-8949-4143-8996-85991e288999,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-d600529e-5f6b-44b3-8124-8a1d0ac70cbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598805690-172.17.0.7-1597544135937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46697,DS-6d1439df-e619-48a5-9562-c40c0d6bfdda,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-4e8bec14-c273-4524-ad65-1b75d9ea6ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-f4e042f8-0949-4ee9-936a-5a9573a0e5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-0ed82e20-145f-48bc-9286-687727745b98,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-2c87cc41-e7c7-4510-86cd-b9f84deb84cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-9c55ab5a-5bc5-40d6-9b1f-eff2d65bdb30,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-210755f4-d700-44f8-81ef-4bab135d44e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-b2243f12-642d-49fb-9a18-3201ee7c4cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598805690-172.17.0.7-1597544135937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46697,DS-6d1439df-e619-48a5-9562-c40c0d6bfdda,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-4e8bec14-c273-4524-ad65-1b75d9ea6ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-f4e042f8-0949-4ee9-936a-5a9573a0e5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-0ed82e20-145f-48bc-9286-687727745b98,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-2c87cc41-e7c7-4510-86cd-b9f84deb84cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-9c55ab5a-5bc5-40d6-9b1f-eff2d65bdb30,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-210755f4-d700-44f8-81ef-4bab135d44e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-b2243f12-642d-49fb-9a18-3201ee7c4cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853231726-172.17.0.7-1597544446679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35938,DS-8c5805f8-0e10-4511-a76f-dbc812a2cc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-91729880-4a28-4e8d-8a97-ed2b107ac55f,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-dc3983af-e335-42f1-ac39-4f86fa2fbb32,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-96757cac-18ae-492b-871d-46d0dcf3b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-59ad71f7-8e62-4892-ac0a-1b4b5dcc8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-0b6672b5-6995-467d-af2d-fb1a5b959ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-e8d7e918-5f49-493b-b003-613c0bb04ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-68c1dc02-2ed0-4212-a119-fb36e4aadad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853231726-172.17.0.7-1597544446679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35938,DS-8c5805f8-0e10-4511-a76f-dbc812a2cc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-91729880-4a28-4e8d-8a97-ed2b107ac55f,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-dc3983af-e335-42f1-ac39-4f86fa2fbb32,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-96757cac-18ae-492b-871d-46d0dcf3b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-59ad71f7-8e62-4892-ac0a-1b4b5dcc8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-0b6672b5-6995-467d-af2d-fb1a5b959ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:45243,DS-e8d7e918-5f49-493b-b003-613c0bb04ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-68c1dc02-2ed0-4212-a119-fb36e4aadad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562238017-172.17.0.7-1597544488035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-f177738c-d1f8-47f6-a124-0ad6be38da41,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-ab0daef5-08c2-46ea-b94c-4bb9a0a6e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-6ee32f19-98fe-46d0-87e0-0975acbd2ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-0be6fd20-9756-40ed-9c56-2a244734fd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-5d7d2e3f-a20c-455a-9038-f13d553ff722,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-8b503a3b-7645-4650-a949-dc807ca7647c,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-0f6b6976-669c-4c96-8665-d8896b47aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-c99fd838-c209-471e-9acf-cf77b25cdb2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562238017-172.17.0.7-1597544488035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-f177738c-d1f8-47f6-a124-0ad6be38da41,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-ab0daef5-08c2-46ea-b94c-4bb9a0a6e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-6ee32f19-98fe-46d0-87e0-0975acbd2ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-0be6fd20-9756-40ed-9c56-2a244734fd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-5d7d2e3f-a20c-455a-9038-f13d553ff722,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-8b503a3b-7645-4650-a949-dc807ca7647c,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-0f6b6976-669c-4c96-8665-d8896b47aadf,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-c99fd838-c209-471e-9acf-cf77b25cdb2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536217784-172.17.0.7-1597544722565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-01e18bfc-181b-4db1-a061-d1416018ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-fcb5fd9e-0da7-4a98-8495-46e69c7806cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-83bd8879-0412-4a59-ba90-e032e200b057,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-65d03623-e681-4a7b-83d3-9e01cf446f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-0a4fb1bc-8cda-4351-b514-cfa1cbc10f01,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-38b31b0f-bc04-44c4-beab-a3c358cb3d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-faa98a17-a383-451a-b43a-4880080447d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-bc4d8496-3560-4e8e-a34d-8b3ae2fd7554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536217784-172.17.0.7-1597544722565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-01e18bfc-181b-4db1-a061-d1416018ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-fcb5fd9e-0da7-4a98-8495-46e69c7806cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-83bd8879-0412-4a59-ba90-e032e200b057,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-65d03623-e681-4a7b-83d3-9e01cf446f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-0a4fb1bc-8cda-4351-b514-cfa1cbc10f01,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-38b31b0f-bc04-44c4-beab-a3c358cb3d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-faa98a17-a383-451a-b43a-4880080447d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-bc4d8496-3560-4e8e-a34d-8b3ae2fd7554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17872773-172.17.0.7-1597544828715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33253,DS-ba5e1826-a629-430f-b077-28f8dd6d3498,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-c4420353-8d1b-42c3-89e3-8b182a76ffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-01d4a899-9357-40ce-95ac-e10c50e10d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-9014e468-ec4c-4131-a61e-465dd2bb84b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-caa6e2ed-5edd-44d7-99d7-cadd13885bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-e0be43cd-f74d-45ce-9e50-ee76c3476930,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-221b9799-72ce-4a6d-8076-392813533ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-a491a188-2de4-4ed7-a4b0-d58856890f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-17872773-172.17.0.7-1597544828715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33253,DS-ba5e1826-a629-430f-b077-28f8dd6d3498,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-c4420353-8d1b-42c3-89e3-8b182a76ffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-01d4a899-9357-40ce-95ac-e10c50e10d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-9014e468-ec4c-4131-a61e-465dd2bb84b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-caa6e2ed-5edd-44d7-99d7-cadd13885bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-e0be43cd-f74d-45ce-9e50-ee76c3476930,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-221b9799-72ce-4a6d-8076-392813533ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-a491a188-2de4-4ed7-a4b0-d58856890f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657804060-172.17.0.7-1597545004512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34016,DS-93a1a1ee-7349-4c10-aafd-5349d405cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-02e4e3e1-20a0-4e5b-824a-9dab9ea37274,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-7c39b000-34b6-4e8f-993b-3df58a5960c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-0b8ed296-932b-4783-9c1b-73c864983522,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-b13b3822-83de-400a-b13b-2eaa9105c524,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-b20c9b5e-3171-436f-816d-7631885e0586,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-eb7ad155-41bf-46ab-8180-70199d61f20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-dfa7fee1-9f92-4243-ba66-fc42ae4fd0d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657804060-172.17.0.7-1597545004512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34016,DS-93a1a1ee-7349-4c10-aafd-5349d405cdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-02e4e3e1-20a0-4e5b-824a-9dab9ea37274,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-7c39b000-34b6-4e8f-993b-3df58a5960c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-0b8ed296-932b-4783-9c1b-73c864983522,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-b13b3822-83de-400a-b13b-2eaa9105c524,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-b20c9b5e-3171-436f-816d-7631885e0586,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-eb7ad155-41bf-46ab-8180-70199d61f20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-dfa7fee1-9f92-4243-ba66-fc42ae4fd0d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318212641-172.17.0.7-1597545425294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43034,DS-49f9f710-6e37-4797-bb7b-be3eea192d65,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-33acfb87-8f84-4dfa-bdad-6b8ee8e4f801,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-f1b2cadb-cc72-407d-ba8a-d701577cd609,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-7f3af409-28cf-4210-bfff-1b3efcc8734f,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-a25293f3-bf51-4392-a735-2ffd039f8e90,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-7d5c2e0b-b987-4ab6-a52f-7edd83432133,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-c410c04a-d15e-4b3d-a9aa-943d49b8244f,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-9b234bd4-a393-4010-b6de-3c458e689622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318212641-172.17.0.7-1597545425294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43034,DS-49f9f710-6e37-4797-bb7b-be3eea192d65,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-33acfb87-8f84-4dfa-bdad-6b8ee8e4f801,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-f1b2cadb-cc72-407d-ba8a-d701577cd609,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-7f3af409-28cf-4210-bfff-1b3efcc8734f,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-a25293f3-bf51-4392-a735-2ffd039f8e90,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-7d5c2e0b-b987-4ab6-a52f-7edd83432133,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-c410c04a-d15e-4b3d-a9aa-943d49b8244f,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-9b234bd4-a393-4010-b6de-3c458e689622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105840652-172.17.0.7-1597545506647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-4e58e29a-efd5-430d-8529-7e4882bfee42,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-90f963be-da91-4649-bb8a-37ff47984586,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-4a19a34f-dc2f-4add-a4ac-fb74710ea1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-74d60216-617f-46a6-8385-2e0c042ecda0,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-8b1e597e-f5a4-4166-8d5e-e263f0d713e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-5647e0e4-3a21-4e5c-8747-ccd1c8112add,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-6aceb1b6-c386-4437-9ce8-7fa4506faf70,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-075d7781-e781-4783-8d18-414a0c8c27a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105840652-172.17.0.7-1597545506647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-4e58e29a-efd5-430d-8529-7e4882bfee42,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-90f963be-da91-4649-bb8a-37ff47984586,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-4a19a34f-dc2f-4add-a4ac-fb74710ea1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-74d60216-617f-46a6-8385-2e0c042ecda0,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-8b1e597e-f5a4-4166-8d5e-e263f0d713e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-5647e0e4-3a21-4e5c-8747-ccd1c8112add,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-6aceb1b6-c386-4437-9ce8-7fa4506faf70,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-075d7781-e781-4783-8d18-414a0c8c27a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350525321-172.17.0.7-1597546388942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37967,DS-e89bd375-2833-4267-b4f2-fd34127da81c,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-cec9f230-b52d-449b-945f-d2bc16e5bf63,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-5b07e2e5-aa0d-4799-af0c-83e88cce9a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-d3e98a07-2143-4b7a-be52-f3d9bd3ee8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-43ea9642-f56a-474e-9723-ed678ac63da0,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-a1ad5c01-b2a1-4f2c-9309-60d2f2a544fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-7ce05939-484e-4719-b91f-164a2237e215,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-d0ff3780-08e5-41b4-82a6-751b712865d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350525321-172.17.0.7-1597546388942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37967,DS-e89bd375-2833-4267-b4f2-fd34127da81c,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-cec9f230-b52d-449b-945f-d2bc16e5bf63,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-5b07e2e5-aa0d-4799-af0c-83e88cce9a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-d3e98a07-2143-4b7a-be52-f3d9bd3ee8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-43ea9642-f56a-474e-9723-ed678ac63da0,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-a1ad5c01-b2a1-4f2c-9309-60d2f2a544fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-7ce05939-484e-4719-b91f-164a2237e215,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-d0ff3780-08e5-41b4-82a6-751b712865d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671851132-172.17.0.7-1597546560797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43789,DS-d11fb176-e584-4a6b-8c4a-bb506fbba38e,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-35130f02-c8e6-47a9-9234-31ea493c28ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-0f7199f4-9675-4bb9-919a-3aadbb3055b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-21d630c4-76e3-407a-a65a-25591463f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-e78f58c3-ca80-4f18-9334-a497e4261057,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-3085a1c6-a4b6-48ed-a4c6-10e3bcd450ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-584345e5-627d-4ccd-b982-f3df3b2034ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-c3783d84-4dca-4515-b8d5-ed36ad72a62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671851132-172.17.0.7-1597546560797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43789,DS-d11fb176-e584-4a6b-8c4a-bb506fbba38e,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-35130f02-c8e6-47a9-9234-31ea493c28ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-0f7199f4-9675-4bb9-919a-3aadbb3055b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-21d630c4-76e3-407a-a65a-25591463f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-e78f58c3-ca80-4f18-9334-a497e4261057,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-3085a1c6-a4b6-48ed-a4c6-10e3bcd450ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-584345e5-627d-4ccd-b982-f3df3b2034ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-c3783d84-4dca-4515-b8d5-ed36ad72a62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255473961-172.17.0.7-1597546621649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45167,DS-9405f916-67fd-4c7c-b9f0-a5558ba50c71,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-247b4e55-1c2e-4923-ad65-0abd7050ab93,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-98543b11-7c1a-4897-9c5e-eac8065de7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-2bc169fc-5ed9-44ca-81fc-b0bb1e2d0229,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-9fa63b81-1e37-49ec-8968-3c09cc1cf1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-47156501-a0e3-45b9-a4d0-01f1097178e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-1e80ff61-d1e6-4a3c-ba88-3276792eb9da,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-f33d2c1c-83b2-4287-8f64-dc8b275b5ffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255473961-172.17.0.7-1597546621649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45167,DS-9405f916-67fd-4c7c-b9f0-a5558ba50c71,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-247b4e55-1c2e-4923-ad65-0abd7050ab93,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-98543b11-7c1a-4897-9c5e-eac8065de7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-2bc169fc-5ed9-44ca-81fc-b0bb1e2d0229,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-9fa63b81-1e37-49ec-8968-3c09cc1cf1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-47156501-a0e3-45b9-a4d0-01f1097178e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-1e80ff61-d1e6-4a3c-ba88-3276792eb9da,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-f33d2c1c-83b2-4287-8f64-dc8b275b5ffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444680222-172.17.0.7-1597546721771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38028,DS-7fa7b55b-9bf6-47c0-8231-570d201f90f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-22bfe8aa-6e6a-4c8c-8ac2-324151e744aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-db7d1313-77f6-4b24-b8e1-f988639891d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-c80f6a12-70e0-472a-b092-e1469b18d4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-3e945604-ecce-4f04-8ab0-8113dc029058,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-50c42447-a574-4107-b3ac-f70953a403ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-275e6274-57ab-4f49-9da0-9c1663bb2330,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-806baf00-8b42-486d-9e21-5c79129efdb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444680222-172.17.0.7-1597546721771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38028,DS-7fa7b55b-9bf6-47c0-8231-570d201f90f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-22bfe8aa-6e6a-4c8c-8ac2-324151e744aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-db7d1313-77f6-4b24-b8e1-f988639891d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-c80f6a12-70e0-472a-b092-e1469b18d4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-3e945604-ecce-4f04-8ab0-8113dc029058,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-50c42447-a574-4107-b3ac-f70953a403ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-275e6274-57ab-4f49-9da0-9c1663bb2330,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-806baf00-8b42-486d-9e21-5c79129efdb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618841912-172.17.0.7-1597546830236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-6a76b903-d9c4-4011-80b4-584d0a03374b,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-765a3804-dfac-4e2b-8738-e25f02a13b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-d2b55e16-0033-4f33-b302-aeeff5d0b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-dfa5ccb8-bc92-4cc9-8ba1-74e02ecc1d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-49590f55-9d88-4c9f-969e-34dcf5268fba,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-7fd820cb-7448-42cc-b3a9-be4a29dd1317,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-f3cf0c6f-9872-418c-abd2-6ecd38919e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-b350d58c-ee85-4eca-a9d1-2e44b3507ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618841912-172.17.0.7-1597546830236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-6a76b903-d9c4-4011-80b4-584d0a03374b,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-765a3804-dfac-4e2b-8738-e25f02a13b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-d2b55e16-0033-4f33-b302-aeeff5d0b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-dfa5ccb8-bc92-4cc9-8ba1-74e02ecc1d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-49590f55-9d88-4c9f-969e-34dcf5268fba,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-7fd820cb-7448-42cc-b3a9-be4a29dd1317,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-f3cf0c6f-9872-418c-abd2-6ecd38919e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-b350d58c-ee85-4eca-a9d1-2e44b3507ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646997694-172.17.0.7-1597547379610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-02388ada-5432-4e43-aaa6-d6cf833e6b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-b3fe368e-42c9-45f2-b239-04e986282399,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-9cd757b4-a839-41ae-a906-23d497b720c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-3d926044-bc17-4dde-96ae-fa4eca85be3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-6833ee54-7bd0-4d11-b87e-7ed7fdcd903a,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-7e0bf0d0-5a40-46bb-80d1-c198fe66260c,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-1b269a6e-954d-42b2-b987-159965ce9013,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-8ff0841f-60df-473c-9d19-966b1d629271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646997694-172.17.0.7-1597547379610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45259,DS-02388ada-5432-4e43-aaa6-d6cf833e6b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-b3fe368e-42c9-45f2-b239-04e986282399,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-9cd757b4-a839-41ae-a906-23d497b720c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-3d926044-bc17-4dde-96ae-fa4eca85be3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-6833ee54-7bd0-4d11-b87e-7ed7fdcd903a,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-7e0bf0d0-5a40-46bb-80d1-c198fe66260c,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-1b269a6e-954d-42b2-b987-159965ce9013,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-8ff0841f-60df-473c-9d19-966b1d629271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257261279-172.17.0.7-1597547594015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39078,DS-dbc11086-1080-4940-b575-9067088ba49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-73a9ca11-3112-4267-b722-007bd31fc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-b50ed749-6a3d-4cdb-b6f6-41818578b939,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-509d4cb7-71fa-4de0-9f5d-fdcef8e3b638,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-ad63c3e9-86c7-48d0-8e13-ecd554db961a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-cd7c219e-affb-4cce-8b34-b801aa7fcdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-38cc7255-276d-4d93-a81d-1b2d7501ac71,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-0d72d616-7888-4e97-b2ef-eb90197fd850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257261279-172.17.0.7-1597547594015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39078,DS-dbc11086-1080-4940-b575-9067088ba49e,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-73a9ca11-3112-4267-b722-007bd31fc93e,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-b50ed749-6a3d-4cdb-b6f6-41818578b939,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-509d4cb7-71fa-4de0-9f5d-fdcef8e3b638,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-ad63c3e9-86c7-48d0-8e13-ecd554db961a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-cd7c219e-affb-4cce-8b34-b801aa7fcdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-38cc7255-276d-4d93-a81d-1b2d7501ac71,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-0d72d616-7888-4e97-b2ef-eb90197fd850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634967390-172.17.0.7-1597547760616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43045,DS-d9c2771a-50d7-4271-a849-9179283d6b78,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-a3acd868-30a8-4fb8-a237-c1dea50c5808,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-d70fafc2-1fb1-49ff-8652-ef0482aef686,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-83dec6e8-e836-449e-9046-e9f2bb134d70,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-80920ed2-5621-417f-b52a-276f1912030b,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-93d8838c-9585-44e0-adbc-fba3c37b3d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-a0a5fa6d-c816-4c0e-a39a-637792fde352,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-73bb802f-b417-49fc-816b-55744d940b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634967390-172.17.0.7-1597547760616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43045,DS-d9c2771a-50d7-4271-a849-9179283d6b78,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-a3acd868-30a8-4fb8-a237-c1dea50c5808,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-d70fafc2-1fb1-49ff-8652-ef0482aef686,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-83dec6e8-e836-449e-9046-e9f2bb134d70,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-80920ed2-5621-417f-b52a-276f1912030b,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-93d8838c-9585-44e0-adbc-fba3c37b3d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-a0a5fa6d-c816-4c0e-a39a-637792fde352,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-73bb802f-b417-49fc-816b-55744d940b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554317387-172.17.0.7-1597547970320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-d61a2a4d-8a31-4f80-95bd-084c742c3cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-332d81ba-dd0a-4daa-863f-62b76760af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-19eb32e7-c425-4a1f-bf09-ca2c08f94468,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-ae844cc1-cd54-479a-b150-582ef3822520,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-18ba68ac-1a73-432a-9a22-7655fb1447af,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-30987012-7f5d-4420-9f4f-250256476675,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-b6d26974-4a7e-4c6a-afc9-7ae30c718b14,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-113c3dae-a060-4175-a15f-d2789f6d3166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554317387-172.17.0.7-1597547970320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-d61a2a4d-8a31-4f80-95bd-084c742c3cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-332d81ba-dd0a-4daa-863f-62b76760af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-19eb32e7-c425-4a1f-bf09-ca2c08f94468,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-ae844cc1-cd54-479a-b150-582ef3822520,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-18ba68ac-1a73-432a-9a22-7655fb1447af,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-30987012-7f5d-4420-9f4f-250256476675,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-b6d26974-4a7e-4c6a-afc9-7ae30c718b14,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-113c3dae-a060-4175-a15f-d2789f6d3166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806363960-172.17.0.7-1597548186028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40294,DS-6c327c31-f70b-4518-8ed9-c61ca124a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-80949c54-bed0-4c95-a19d-d482a0f21e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-0d4fdb23-1410-4f31-9249-d5eb8d1674e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-0feaa606-1c96-4c1c-b101-baf557aab46c,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-3ddaaf2b-320e-408d-bd6b-fec568a186db,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-98d2bc1b-5ad6-4fbe-8a69-e739fc400cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-582de796-b591-4b6a-8549-2cb10c2cc82b,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-42cb58db-c088-4325-a26c-5f300b981c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806363960-172.17.0.7-1597548186028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40294,DS-6c327c31-f70b-4518-8ed9-c61ca124a2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-80949c54-bed0-4c95-a19d-d482a0f21e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-0d4fdb23-1410-4f31-9249-d5eb8d1674e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-0feaa606-1c96-4c1c-b101-baf557aab46c,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-3ddaaf2b-320e-408d-bd6b-fec568a186db,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-98d2bc1b-5ad6-4fbe-8a69-e739fc400cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-582de796-b591-4b6a-8549-2cb10c2cc82b,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-42cb58db-c088-4325-a26c-5f300b981c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126042168-172.17.0.7-1597548584866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41482,DS-28b0b5d7-35f3-449f-85a9-6d6631d7014e,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-547c8c23-529f-4b93-beb2-d0fde5c2fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-bffd4736-5bbd-4f7c-8e7e-e9bde71afd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-10605f54-a2b7-4ea2-9040-68301e3b6fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-404ca8ae-cd71-48ab-b40a-49454db5c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-067f6fa1-187d-4c1d-b1eb-0f5c4476cd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-5ab6b231-a739-4f16-8538-1100c2f2f663,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-524f648a-5f5b-4f06-a4e3-773cdb11323b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126042168-172.17.0.7-1597548584866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41482,DS-28b0b5d7-35f3-449f-85a9-6d6631d7014e,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-547c8c23-529f-4b93-beb2-d0fde5c2fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-bffd4736-5bbd-4f7c-8e7e-e9bde71afd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-10605f54-a2b7-4ea2-9040-68301e3b6fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-404ca8ae-cd71-48ab-b40a-49454db5c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-067f6fa1-187d-4c1d-b1eb-0f5c4476cd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-5ab6b231-a739-4f16-8538-1100c2f2f663,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-524f648a-5f5b-4f06-a4e3-773cdb11323b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529582319-172.17.0.7-1597548911279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40780,DS-9dc107e4-429f-4a58-aaf3-77977f0fe722,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-1275cd65-308f-41fb-80f7-9350c93fd646,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-8dd9db13-a127-428a-9e0a-eddc1fcbf987,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-4122e8c2-b7ef-4000-ba12-4026fd6d52eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-d5708f8d-97a9-4dc5-8480-d0a317410f34,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-9745982b-0632-408a-9423-cbf62eeb8a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0d64bb30-7da6-48b6-9959-55e6a54d4433,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-3ebbdcb6-df67-4afe-8f77-3dafd6a4ee12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529582319-172.17.0.7-1597548911279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40780,DS-9dc107e4-429f-4a58-aaf3-77977f0fe722,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-1275cd65-308f-41fb-80f7-9350c93fd646,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-8dd9db13-a127-428a-9e0a-eddc1fcbf987,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-4122e8c2-b7ef-4000-ba12-4026fd6d52eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-d5708f8d-97a9-4dc5-8480-d0a317410f34,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-9745982b-0632-408a-9423-cbf62eeb8a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-0d64bb30-7da6-48b6-9959-55e6a54d4433,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-3ebbdcb6-df67-4afe-8f77-3dafd6a4ee12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072146402-172.17.0.7-1597549231402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34139,DS-1593fe49-b616-4325-8c6c-bf443172e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-66b54bc3-5ccf-4924-bb13-0a1eda63707c,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-40c98dd0-9d8c-42da-8f17-daaa25216a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-6c6f478b-36ec-4e1d-b78e-bb215e269898,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-6e49b0a7-0e99-4982-a165-fd1c7c8db63b,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-42e598b1-81dd-4e5f-a303-b2d6b92f1d98,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-4bb44bcf-2f55-4445-b332-cc7be429000a,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-79f9bb27-fbcc-4798-b7bf-951b9872e85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072146402-172.17.0.7-1597549231402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34139,DS-1593fe49-b616-4325-8c6c-bf443172e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-66b54bc3-5ccf-4924-bb13-0a1eda63707c,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-40c98dd0-9d8c-42da-8f17-daaa25216a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-6c6f478b-36ec-4e1d-b78e-bb215e269898,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-6e49b0a7-0e99-4982-a165-fd1c7c8db63b,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-42e598b1-81dd-4e5f-a303-b2d6b92f1d98,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-4bb44bcf-2f55-4445-b332-cc7be429000a,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-79f9bb27-fbcc-4798-b7bf-951b9872e85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5351
