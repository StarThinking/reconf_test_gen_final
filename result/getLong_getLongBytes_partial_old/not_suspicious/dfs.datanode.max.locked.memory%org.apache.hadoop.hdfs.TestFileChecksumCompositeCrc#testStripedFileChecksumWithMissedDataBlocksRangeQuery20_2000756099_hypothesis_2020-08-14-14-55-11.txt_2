reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756255211-172.17.0.8-1597417065804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-052501b2-0c73-4f70-b742-b4f759fe0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-8749accc-dd36-4a56-b09e-751deb3a2e34,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-572aff90-b178-4f10-9609-3e1d3f2390f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-8260f477-6375-4fe5-94e8-52d2d59eee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-701e4d72-8c33-46fa-bd8c-12392bd29de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-7208645c-422c-49fc-ba5a-8860bacbeb51,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-514c5bbe-dc33-480c-8d61-609a80972b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-a1b6e3c8-6c39-4fd6-9a7c-ac4040277619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756255211-172.17.0.8-1597417065804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34434,DS-052501b2-0c73-4f70-b742-b4f759fe0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-8749accc-dd36-4a56-b09e-751deb3a2e34,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-572aff90-b178-4f10-9609-3e1d3f2390f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-8260f477-6375-4fe5-94e8-52d2d59eee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-701e4d72-8c33-46fa-bd8c-12392bd29de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-7208645c-422c-49fc-ba5a-8860bacbeb51,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-514c5bbe-dc33-480c-8d61-609a80972b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-a1b6e3c8-6c39-4fd6-9a7c-ac4040277619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612228819-172.17.0.8-1597417348855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34292,DS-9ff049d5-a073-4ef0-89df-2703281f5ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-c192b6e5-202f-443b-ad15-7f1e2d8b7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-dd7aa1c4-767d-445f-b18f-49e181c1e7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-99e622ba-e823-4505-9a56-743a2f2c890b,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-24f1acb2-27fd-45b5-beb1-dbf97d5bdc21,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-8b587825-d6d5-463f-95cf-869c70d35ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-a6e5eba3-29ba-4d41-bfc8-40e8bd5b64be,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-ce1b1602-56bd-4221-b0f3-ce89dfa5cf36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612228819-172.17.0.8-1597417348855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34292,DS-9ff049d5-a073-4ef0-89df-2703281f5ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-c192b6e5-202f-443b-ad15-7f1e2d8b7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-dd7aa1c4-767d-445f-b18f-49e181c1e7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-99e622ba-e823-4505-9a56-743a2f2c890b,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-24f1acb2-27fd-45b5-beb1-dbf97d5bdc21,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-8b587825-d6d5-463f-95cf-869c70d35ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-a6e5eba3-29ba-4d41-bfc8-40e8bd5b64be,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-ce1b1602-56bd-4221-b0f3-ce89dfa5cf36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919737484-172.17.0.8-1597417886086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-79a136ff-0828-4184-bc35-9c22a7ec872e,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-9fa1d13f-acc7-415d-b987-2af465bad3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-905f1243-eef4-4cbb-b4c8-341b6514b6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-6b189a22-961a-44f0-9b98-64f059e99638,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-9cafcc27-e570-4de7-a8dc-556f32a9d177,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-ae0a1c39-877d-4ff3-b115-5f0c6665a521,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-566d1662-6fb8-42ab-b6fc-d003ac9a742f,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-dc7e58ad-606b-423f-ade1-aa5276d08383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919737484-172.17.0.8-1597417886086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-79a136ff-0828-4184-bc35-9c22a7ec872e,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-9fa1d13f-acc7-415d-b987-2af465bad3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-905f1243-eef4-4cbb-b4c8-341b6514b6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-6b189a22-961a-44f0-9b98-64f059e99638,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-9cafcc27-e570-4de7-a8dc-556f32a9d177,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-ae0a1c39-877d-4ff3-b115-5f0c6665a521,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-566d1662-6fb8-42ab-b6fc-d003ac9a742f,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-dc7e58ad-606b-423f-ade1-aa5276d08383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802774825-172.17.0.8-1597418038125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46503,DS-b79eeebb-bb08-40bf-85b4-cca683b292ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-4f22a259-8cf7-457e-84ba-5bbf814c9098,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-607016fb-5dc2-437e-a95a-96ef65d8d2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-5ddaf682-9ced-4bc7-b273-8442128e20cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-cff081e7-2787-4d27-be01-3bb0b6b92491,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-c68c668e-17ff-4cf4-a66d-78a8e13283ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-929a1d6c-9b93-4c43-8a2d-80a0a501967b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-6a29b2ba-68bd-4a8e-8c28-a3f6788ce9ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802774825-172.17.0.8-1597418038125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46503,DS-b79eeebb-bb08-40bf-85b4-cca683b292ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-4f22a259-8cf7-457e-84ba-5bbf814c9098,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-607016fb-5dc2-437e-a95a-96ef65d8d2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-5ddaf682-9ced-4bc7-b273-8442128e20cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-cff081e7-2787-4d27-be01-3bb0b6b92491,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-c68c668e-17ff-4cf4-a66d-78a8e13283ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-929a1d6c-9b93-4c43-8a2d-80a0a501967b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-6a29b2ba-68bd-4a8e-8c28-a3f6788ce9ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219686333-172.17.0.8-1597418941422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-49b8b13f-40a7-4882-af8b-682e82dcb7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-156f6221-9cb5-4de9-aacb-cf4d9450e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-a3a8fe0c-69d9-47a9-be04-a0b41afb4852,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-3b64a932-f869-422c-8825-702794933523,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-9ce63879-ab35-46da-8ad2-c18a4f63a922,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-b3b3cb0b-9378-4b7c-b29b-775994aa2fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-4eb26b3f-880f-4225-b4d4-8da4f69d8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-ad637354-5503-4341-8940-3ce2d6294d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219686333-172.17.0.8-1597418941422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-49b8b13f-40a7-4882-af8b-682e82dcb7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-156f6221-9cb5-4de9-aacb-cf4d9450e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-a3a8fe0c-69d9-47a9-be04-a0b41afb4852,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-3b64a932-f869-422c-8825-702794933523,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-9ce63879-ab35-46da-8ad2-c18a4f63a922,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-b3b3cb0b-9378-4b7c-b29b-775994aa2fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-4eb26b3f-880f-4225-b4d4-8da4f69d8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-ad637354-5503-4341-8940-3ce2d6294d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700374949-172.17.0.8-1597419138752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-7c8c5207-3403-49ad-ad11-7e987c5fac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-31945c31-80cb-41d0-acbb-7998a615e823,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-77ac241d-df1a-45e3-80f3-bce7a3f0640b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-9fd65f7d-8fae-4a08-9fb2-101ed15787d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-049a7915-d672-4b53-a50f-bd5dde2a40a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-b26422fd-a562-4302-a61c-559e40528621,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-ecc26767-e9dc-406e-ade2-bc2bb2acc8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-27fe16a5-9811-4c66-af88-39fe4750b703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700374949-172.17.0.8-1597419138752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-7c8c5207-3403-49ad-ad11-7e987c5fac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-31945c31-80cb-41d0-acbb-7998a615e823,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-77ac241d-df1a-45e3-80f3-bce7a3f0640b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-9fd65f7d-8fae-4a08-9fb2-101ed15787d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-049a7915-d672-4b53-a50f-bd5dde2a40a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-b26422fd-a562-4302-a61c-559e40528621,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-ecc26767-e9dc-406e-ade2-bc2bb2acc8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-27fe16a5-9811-4c66-af88-39fe4750b703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000585960-172.17.0.8-1597419527181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-f6e6e4e7-a1ab-4bed-a686-001d37f59d84,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-71fcf0bc-e49f-4f58-87ad-42082209d1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-6d63b899-8dea-4fad-aa08-8d364e5a3f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-086aa03f-a54a-4315-a784-c0f0fe6d9e28,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-b9a24d76-c245-48c1-acb1-f268a4e6e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-0bac6150-dbb3-44ae-9aa7-4d6bcc38925b,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-6b13ee12-dac8-486e-9a5c-4d7edb593017,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-f45da4e7-d37e-401a-9d32-fa6833fda0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000585960-172.17.0.8-1597419527181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-f6e6e4e7-a1ab-4bed-a686-001d37f59d84,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-71fcf0bc-e49f-4f58-87ad-42082209d1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-6d63b899-8dea-4fad-aa08-8d364e5a3f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-086aa03f-a54a-4315-a784-c0f0fe6d9e28,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-b9a24d76-c245-48c1-acb1-f268a4e6e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-0bac6150-dbb3-44ae-9aa7-4d6bcc38925b,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-6b13ee12-dac8-486e-9a5c-4d7edb593017,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-f45da4e7-d37e-401a-9d32-fa6833fda0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264966049-172.17.0.8-1597419836773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43491,DS-d444e7cd-943f-4fdf-bb75-bb5717d90d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-d89fcc5d-3be7-4f61-b8c1-364c05f77911,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-6c396ce5-8bed-49eb-b2a0-8bf0de59d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-6490d74a-b840-4c53-9189-b1f6ac9b713a,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-2c0c82e2-cda0-4156-a54b-7eb978ba9821,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-a7a3a882-16e4-4e28-b059-4c897fd7656c,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-f6d76732-e048-44ca-af8a-147b053f7b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-e8d4484f-b67b-4602-a46f-8fb6c58be23b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264966049-172.17.0.8-1597419836773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43491,DS-d444e7cd-943f-4fdf-bb75-bb5717d90d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-d89fcc5d-3be7-4f61-b8c1-364c05f77911,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-6c396ce5-8bed-49eb-b2a0-8bf0de59d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-6490d74a-b840-4c53-9189-b1f6ac9b713a,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-2c0c82e2-cda0-4156-a54b-7eb978ba9821,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-a7a3a882-16e4-4e28-b059-4c897fd7656c,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-f6d76732-e048-44ca-af8a-147b053f7b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-e8d4484f-b67b-4602-a46f-8fb6c58be23b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645186605-172.17.0.8-1597420039908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43885,DS-6afe0531-ac58-4d9e-8b0c-8042a05aa44d,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-86ffffba-fc6d-4ea3-8b90-f297e5d35e56,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-1930f705-aee5-40ff-abdc-63322d2a6c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-c54447a8-29ff-4bc1-8ec2-9bf283fa940c,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-770756dc-7440-4723-96bf-fe2683a576a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-aa1c7249-6b69-46e8-bb5d-3ec44acbcb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-a8168db5-6629-444f-a51c-cbc35f938dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-409e1c10-17b4-4c9c-a214-3157ab7c1c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645186605-172.17.0.8-1597420039908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43885,DS-6afe0531-ac58-4d9e-8b0c-8042a05aa44d,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-86ffffba-fc6d-4ea3-8b90-f297e5d35e56,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-1930f705-aee5-40ff-abdc-63322d2a6c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-c54447a8-29ff-4bc1-8ec2-9bf283fa940c,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-770756dc-7440-4723-96bf-fe2683a576a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-aa1c7249-6b69-46e8-bb5d-3ec44acbcb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-a8168db5-6629-444f-a51c-cbc35f938dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-409e1c10-17b4-4c9c-a214-3157ab7c1c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392725310-172.17.0.8-1597420075777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-79b2b516-d877-471e-a0de-61db708dd9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-e3f9ec93-5e9f-42c7-b733-acd4a7ad6967,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-b616b6a8-aece-479c-a926-61b84d7176cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-995383be-f2de-4ec3-b92f-bbf327045e60,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-c0a76108-3dcb-4fec-9c2d-8bbd6bab20df,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-72cb4a36-55df-467e-af2d-7758ead023da,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-3cda6dc0-ef39-44db-b279-34ff077e9df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-62dc6ac0-b42e-456c-80cb-7258e40a17b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392725310-172.17.0.8-1597420075777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-79b2b516-d877-471e-a0de-61db708dd9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33729,DS-e3f9ec93-5e9f-42c7-b733-acd4a7ad6967,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-b616b6a8-aece-479c-a926-61b84d7176cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-995383be-f2de-4ec3-b92f-bbf327045e60,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-c0a76108-3dcb-4fec-9c2d-8bbd6bab20df,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-72cb4a36-55df-467e-af2d-7758ead023da,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-3cda6dc0-ef39-44db-b279-34ff077e9df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-62dc6ac0-b42e-456c-80cb-7258e40a17b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516420954-172.17.0.8-1597420763309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41382,DS-775b03c1-0fb4-4e46-8331-8d92ac644880,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-59b2d4df-f1d7-49f9-98bf-68567923a646,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-a470ccdc-3e52-4b28-b0e0-d0e3ed8b0f15,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-8c7acd91-f838-4b7f-8ec0-09cd0fa37d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-bd3ebbdb-106b-4490-add8-82393ec975ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-589d6160-e9a8-49ab-bf33-c1976661729d,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-ac0ca9c3-73d9-4f85-b43c-b839c3998252,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-c650de5a-28f7-487b-9996-b2980f4cce53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516420954-172.17.0.8-1597420763309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41382,DS-775b03c1-0fb4-4e46-8331-8d92ac644880,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-59b2d4df-f1d7-49f9-98bf-68567923a646,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-a470ccdc-3e52-4b28-b0e0-d0e3ed8b0f15,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-8c7acd91-f838-4b7f-8ec0-09cd0fa37d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-bd3ebbdb-106b-4490-add8-82393ec975ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-589d6160-e9a8-49ab-bf33-c1976661729d,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-ac0ca9c3-73d9-4f85-b43c-b839c3998252,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-c650de5a-28f7-487b-9996-b2980f4cce53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999173821-172.17.0.8-1597420804063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-6a69fa14-f5cd-44b7-be52-2a1bff3ebcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-fb2fdbbe-83d8-44b3-8abc-c126963c7630,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-616a043c-495f-49ad-91e5-264791e157bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-b8e70992-f53f-4407-9226-b0915ab8227b,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-42f28841-b6a9-4dd5-b64a-b0a69a95d280,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-78da0402-690e-4a03-b5a7-d92aac17029a,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-4a630d76-89f5-47b1-8a4b-a5a9095f16ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-af156079-6b51-4ca3-a353-72fdc24c7027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999173821-172.17.0.8-1597420804063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32925,DS-6a69fa14-f5cd-44b7-be52-2a1bff3ebcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-fb2fdbbe-83d8-44b3-8abc-c126963c7630,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-616a043c-495f-49ad-91e5-264791e157bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-b8e70992-f53f-4407-9226-b0915ab8227b,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-42f28841-b6a9-4dd5-b64a-b0a69a95d280,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-78da0402-690e-4a03-b5a7-d92aac17029a,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-4a630d76-89f5-47b1-8a4b-a5a9095f16ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-af156079-6b51-4ca3-a353-72fdc24c7027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464066621-172.17.0.8-1597420880234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-c69c5d5e-6aa3-4bc4-947e-6595a13e7933,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-df1aa21c-e8bd-46b8-a144-e58d90379ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-5b1c9876-1f89-4fb4-9807-90839ec7f6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-414431a7-96d6-4b2f-a6c1-b851492654a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-af6b10fa-78ea-4698-8b2f-4dc2862447d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-5c5b8427-aa89-4bbc-92f7-bd712b254e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-66638a91-c0bc-4813-981d-ed2c701645da,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-d544a2b4-cad1-457b-b794-0f6371f89583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464066621-172.17.0.8-1597420880234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-c69c5d5e-6aa3-4bc4-947e-6595a13e7933,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-df1aa21c-e8bd-46b8-a144-e58d90379ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-5b1c9876-1f89-4fb4-9807-90839ec7f6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-414431a7-96d6-4b2f-a6c1-b851492654a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-af6b10fa-78ea-4698-8b2f-4dc2862447d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-5c5b8427-aa89-4bbc-92f7-bd712b254e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-66638a91-c0bc-4813-981d-ed2c701645da,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-d544a2b4-cad1-457b-b794-0f6371f89583,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612702446-172.17.0.8-1597421098049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-bb7749ca-e918-47a6-b438-d893922e1527,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-b617e21c-8c87-4c92-8fda-fdf42712ef21,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-08a95d37-fe66-4ebc-bfdf-47cc0bba8532,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-8c712227-447c-47b0-a048-dcfc3d1117c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-de8a9794-a6f9-4dba-a535-770eb880b160,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-a648178c-56bc-4784-beda-ac75c0bb6deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-ee292327-9fae-415d-9e58-85899ddae9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-8993e06c-2b1a-434f-98a6-a91bca4250b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612702446-172.17.0.8-1597421098049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37452,DS-bb7749ca-e918-47a6-b438-d893922e1527,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-b617e21c-8c87-4c92-8fda-fdf42712ef21,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-08a95d37-fe66-4ebc-bfdf-47cc0bba8532,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-8c712227-447c-47b0-a048-dcfc3d1117c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-de8a9794-a6f9-4dba-a535-770eb880b160,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-a648178c-56bc-4784-beda-ac75c0bb6deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-ee292327-9fae-415d-9e58-85899ddae9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-8993e06c-2b1a-434f-98a6-a91bca4250b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421950845-172.17.0.8-1597421523365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42086,DS-693e1ac9-9c9a-4fa0-b604-8cf1174fcda6,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-266b6424-dffc-4795-99e4-b8bc6825d100,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-62e4e11b-3a77-4b88-8f42-7bb939fab3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-1cec8686-3d9e-4a44-9b24-5fffd01eb3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-0b8f16b2-adec-4b03-862e-bf2a13d7bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-ac418436-af19-4411-88bb-ccf897857cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-fff7b7e7-6cba-4f0c-abd8-95a70cb17db9,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-cf2a6556-c315-40ed-90d8-76686f614b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421950845-172.17.0.8-1597421523365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42086,DS-693e1ac9-9c9a-4fa0-b604-8cf1174fcda6,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-266b6424-dffc-4795-99e4-b8bc6825d100,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-62e4e11b-3a77-4b88-8f42-7bb939fab3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-1cec8686-3d9e-4a44-9b24-5fffd01eb3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-0b8f16b2-adec-4b03-862e-bf2a13d7bf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-ac418436-af19-4411-88bb-ccf897857cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-fff7b7e7-6cba-4f0c-abd8-95a70cb17db9,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-cf2a6556-c315-40ed-90d8-76686f614b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96055856-172.17.0.8-1597421666950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34901,DS-1b98a00f-022e-4bf1-b9dd-17d3a2980f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-bb1722ff-b58f-4f8d-945c-8437346d75a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-714ee922-6de8-489a-a4b4-9cd9120a8112,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-fdb5f881-9a93-46f5-9a5e-12e5fc407d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-3091fa24-b4cd-47d6-b7ba-b6a5b0da18bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-5b42bad7-69ac-419a-b876-675de2ff4999,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-f80729e2-7a7e-448f-8482-80f6009af624,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-1250d073-4c8d-491f-bf06-0f220c3fedee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96055856-172.17.0.8-1597421666950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34901,DS-1b98a00f-022e-4bf1-b9dd-17d3a2980f62,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-bb1722ff-b58f-4f8d-945c-8437346d75a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-714ee922-6de8-489a-a4b4-9cd9120a8112,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-fdb5f881-9a93-46f5-9a5e-12e5fc407d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-3091fa24-b4cd-47d6-b7ba-b6a5b0da18bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-5b42bad7-69ac-419a-b876-675de2ff4999,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-f80729e2-7a7e-448f-8482-80f6009af624,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-1250d073-4c8d-491f-bf06-0f220c3fedee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224593702-172.17.0.8-1597421832851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-f292bcda-142f-4cfd-8e39-364db982817b,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-164bf57f-e2e0-4e95-ad9b-a16a6ee00d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-5ad2b090-f94f-4916-838a-703db8841509,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-eced8e8b-a360-496f-9c74-085a11825e42,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-ea2615f7-7e51-4482-a9f6-c6fc2b4bb685,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-13dbf090-d9ad-441b-a1d8-fe96ae11cba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-2e5b5d30-b7db-44db-ac31-d8a1b51c8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-5a2fb1c6-1823-4a02-88b6-de9b38e20794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224593702-172.17.0.8-1597421832851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-f292bcda-142f-4cfd-8e39-364db982817b,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-164bf57f-e2e0-4e95-ad9b-a16a6ee00d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-5ad2b090-f94f-4916-838a-703db8841509,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-eced8e8b-a360-496f-9c74-085a11825e42,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-ea2615f7-7e51-4482-a9f6-c6fc2b4bb685,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-13dbf090-d9ad-441b-a1d8-fe96ae11cba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-2e5b5d30-b7db-44db-ac31-d8a1b51c8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-5a2fb1c6-1823-4a02-88b6-de9b38e20794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681839800-172.17.0.8-1597421964073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-8b3ae91e-0552-492d-a6f0-2f5269fb0d81,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-9aeee72a-5721-4ede-8603-33e7dd0ed391,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-d44c831f-6e41-4c29-919d-c08b25383e05,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-1302a115-d0c9-4917-9381-ed36a876ab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-951808bb-a99c-43bc-a332-f52c8403f97f,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-b85c5f0d-68b5-4816-bb7e-f31879c09c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-83604273-4ec7-4a92-8499-c219a1e1195a,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-c1025056-ab99-4f94-af62-91817c8745d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681839800-172.17.0.8-1597421964073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-8b3ae91e-0552-492d-a6f0-2f5269fb0d81,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-9aeee72a-5721-4ede-8603-33e7dd0ed391,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-d44c831f-6e41-4c29-919d-c08b25383e05,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-1302a115-d0c9-4917-9381-ed36a876ab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-951808bb-a99c-43bc-a332-f52c8403f97f,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-b85c5f0d-68b5-4816-bb7e-f31879c09c53,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-83604273-4ec7-4a92-8499-c219a1e1195a,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-c1025056-ab99-4f94-af62-91817c8745d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 16384
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488894546-172.17.0.8-1597421991928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40807,DS-118e39f5-6a0c-4ffd-91be-d2ef9e0d0972,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-ac70617b-78ba-4330-b135-8111abda1a21,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-a6d9864a-899e-4afa-9fc0-c4f01c09d1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-68708acf-df6b-4fef-9b16-9d8f69e5a5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-7fd42ee2-df15-4c03-9664-cec746f971ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-8ee586cd-d5b7-4515-ac94-5d26abc0d8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-8d456cf2-4882-4bd3-8bbb-1c44b18aac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-5a324811-ac5c-4ffd-811b-307c173539c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-488894546-172.17.0.8-1597421991928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40807,DS-118e39f5-6a0c-4ffd-91be-d2ef9e0d0972,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-ac70617b-78ba-4330-b135-8111abda1a21,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-a6d9864a-899e-4afa-9fc0-c4f01c09d1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-68708acf-df6b-4fef-9b16-9d8f69e5a5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-7fd42ee2-df15-4c03-9664-cec746f971ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-8ee586cd-d5b7-4515-ac94-5d26abc0d8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-8d456cf2-4882-4bd3-8bbb-1c44b18aac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-5a324811-ac5c-4ffd-811b-307c173539c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5285
