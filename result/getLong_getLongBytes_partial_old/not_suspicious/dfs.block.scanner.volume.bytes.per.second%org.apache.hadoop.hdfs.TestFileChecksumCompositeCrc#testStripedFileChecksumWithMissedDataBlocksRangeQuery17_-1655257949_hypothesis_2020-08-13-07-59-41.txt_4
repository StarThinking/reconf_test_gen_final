reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264984596-172.17.0.7-1597306708826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35569,DS-9fcf441d-e875-484a-a51b-7fff16b0e413,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-555a7798-aacc-44c5-9811-b57b1c5409e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-0df12f57-3e5c-4e61-80ea-59ad832aacc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-3b8176ae-a535-4b4c-b989-4d539421fd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-df12bcb7-0453-4145-a1ee-d6b7bc6eedca,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-ae2e5932-3c66-4c24-9969-2f3b485f937e,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-58a08682-c534-4d08-a587-3b9cfe5569d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-f16581a5-bcc6-4251-8339-cf45b1c8fbb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264984596-172.17.0.7-1597306708826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35569,DS-9fcf441d-e875-484a-a51b-7fff16b0e413,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-555a7798-aacc-44c5-9811-b57b1c5409e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-0df12f57-3e5c-4e61-80ea-59ad832aacc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-3b8176ae-a535-4b4c-b989-4d539421fd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-df12bcb7-0453-4145-a1ee-d6b7bc6eedca,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-ae2e5932-3c66-4c24-9969-2f3b485f937e,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-58a08682-c534-4d08-a587-3b9cfe5569d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-f16581a5-bcc6-4251-8339-cf45b1c8fbb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824964132-172.17.0.7-1597306939342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-38da18bb-454a-43e6-8ce0-882a4851900f,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-ae73daa7-ccac-4d19-ae6a-1fc3672c0237,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-e063aa43-f652-44d0-8aa0-8fb5867aae90,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-be6ed9ae-5649-4a2d-80d1-c5db3005fec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-44594493-02e1-4f77-a7e6-42b4b3a35a06,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-8652539f-3ecb-4bcd-95b7-a2bdd16574d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-d3109db0-d381-44d4-b3de-f2f139c5cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-7928db48-773f-4e12-8670-1917261f84da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824964132-172.17.0.7-1597306939342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43953,DS-38da18bb-454a-43e6-8ce0-882a4851900f,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-ae73daa7-ccac-4d19-ae6a-1fc3672c0237,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-e063aa43-f652-44d0-8aa0-8fb5867aae90,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-be6ed9ae-5649-4a2d-80d1-c5db3005fec8,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-44594493-02e1-4f77-a7e6-42b4b3a35a06,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-8652539f-3ecb-4bcd-95b7-a2bdd16574d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-d3109db0-d381-44d4-b3de-f2f139c5cc38,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-7928db48-773f-4e12-8670-1917261f84da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165479121-172.17.0.7-1597307311473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40050,DS-2e95104c-c656-47e8-821d-ddc9d8809700,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-416bd5da-e9a6-4939-825d-6097283f3e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-36208059-1f22-43a0-ac3c-7b149b2e54ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-f13c9753-b4f1-4cd0-be5f-a30742cff018,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-d663d08e-b6c9-4853-a7a3-b7f75cc5d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-73f3989c-4016-4556-af54-243192fef7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-1ecc0954-59f0-48d6-bcad-a17f1dbecb34,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-4d51b74f-d8ad-473c-abb1-32135c2104e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165479121-172.17.0.7-1597307311473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40050,DS-2e95104c-c656-47e8-821d-ddc9d8809700,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-416bd5da-e9a6-4939-825d-6097283f3e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-36208059-1f22-43a0-ac3c-7b149b2e54ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-f13c9753-b4f1-4cd0-be5f-a30742cff018,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-d663d08e-b6c9-4853-a7a3-b7f75cc5d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-73f3989c-4016-4556-af54-243192fef7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-1ecc0954-59f0-48d6-bcad-a17f1dbecb34,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-4d51b74f-d8ad-473c-abb1-32135c2104e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529346947-172.17.0.7-1597307384693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-38f07b9a-c19f-4884-bc86-680665f594a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-2aec02e5-5f16-42c2-8e7e-dfd25c34c255,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-0d511d8a-afeb-43a0-bf8b-ca3530d949b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-abea0f47-a8f3-4f76-b327-0976051adf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-36ec1318-d78a-4e8b-812a-5528c44cb1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-d50a6622-b3d8-48ea-a39e-275903c46b27,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-c64fad0c-aef5-4942-b0ec-08782ea8252c,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-54dd65af-299d-41d3-a919-99595315db3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529346947-172.17.0.7-1597307384693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-38f07b9a-c19f-4884-bc86-680665f594a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-2aec02e5-5f16-42c2-8e7e-dfd25c34c255,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-0d511d8a-afeb-43a0-bf8b-ca3530d949b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-abea0f47-a8f3-4f76-b327-0976051adf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-36ec1318-d78a-4e8b-812a-5528c44cb1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-d50a6622-b3d8-48ea-a39e-275903c46b27,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-c64fad0c-aef5-4942-b0ec-08782ea8252c,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-54dd65af-299d-41d3-a919-99595315db3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573125317-172.17.0.7-1597307986926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-0a1695b6-7f14-4341-b2f5-f53bf474f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-03103856-c22e-4f9a-8183-9b68da139ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-410c8a5c-c1f5-4c61-b036-58ec581aaed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-534db794-da75-48e6-a044-75b249e1119d,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-2c75e65b-9c1a-4e79-a2a7-1e48d04a3c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-27400e29-fbd7-40c1-8f63-39cf23b1d1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-0e968bcf-3311-481d-9d39-0bfadca42961,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-8f129219-075c-4d58-b85e-49fc913e4d42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573125317-172.17.0.7-1597307986926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-0a1695b6-7f14-4341-b2f5-f53bf474f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-03103856-c22e-4f9a-8183-9b68da139ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-410c8a5c-c1f5-4c61-b036-58ec581aaed1,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-534db794-da75-48e6-a044-75b249e1119d,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-2c75e65b-9c1a-4e79-a2a7-1e48d04a3c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-27400e29-fbd7-40c1-8f63-39cf23b1d1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-0e968bcf-3311-481d-9d39-0bfadca42961,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-8f129219-075c-4d58-b85e-49fc913e4d42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617363852-172.17.0.7-1597308028035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-a2908777-93a7-4fce-9231-ce026142f86a,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-d93baf97-1dc4-4a1d-8b40-6ff2eeec0ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-20e559d9-d4c6-427a-a763-d6a4e0b10adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-c937e4f3-528b-4d45-9426-b4f7dfef8f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-5edbd328-2c53-48db-b0c3-dabfe6855fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-1c7ac541-ad90-4434-b573-4f8b11968909,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-f7b0cf4b-7f00-401a-bec0-aea9aa0f34db,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-8d48519b-e157-4d4a-b9fc-ff2b5e313d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617363852-172.17.0.7-1597308028035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-a2908777-93a7-4fce-9231-ce026142f86a,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-d93baf97-1dc4-4a1d-8b40-6ff2eeec0ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-20e559d9-d4c6-427a-a763-d6a4e0b10adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-c937e4f3-528b-4d45-9426-b4f7dfef8f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-5edbd328-2c53-48db-b0c3-dabfe6855fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-1c7ac541-ad90-4434-b573-4f8b11968909,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-f7b0cf4b-7f00-401a-bec0-aea9aa0f34db,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-8d48519b-e157-4d4a-b9fc-ff2b5e313d67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234171927-172.17.0.7-1597308171838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34974,DS-9fee80d8-ba4f-4f23-9148-6dc60d26be64,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-385075f6-e1df-4a9d-99d5-feaebf0839d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-9b5ec164-7393-4453-9782-80fbf96d1c24,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-bb07c9ce-4322-4bf2-9004-beab3294b8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-5d2b9396-d220-436a-b4eb-a4225239244e,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-5ae44bae-4549-49b0-ae1b-75a5bc51a4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-04f50c69-5ffd-49c3-911d-5044dc4d42f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-95119b66-4f3b-40f7-843d-88ee925337cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234171927-172.17.0.7-1597308171838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34974,DS-9fee80d8-ba4f-4f23-9148-6dc60d26be64,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-385075f6-e1df-4a9d-99d5-feaebf0839d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-9b5ec164-7393-4453-9782-80fbf96d1c24,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-bb07c9ce-4322-4bf2-9004-beab3294b8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-5d2b9396-d220-436a-b4eb-a4225239244e,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-5ae44bae-4549-49b0-ae1b-75a5bc51a4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-04f50c69-5ffd-49c3-911d-5044dc4d42f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-95119b66-4f3b-40f7-843d-88ee925337cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727859843-172.17.0.7-1597308596223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-f08ebe83-255d-46f2-b9d6-350f8aa974e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-94aafe5f-3a16-4cf1-aaea-37fbe462fb64,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-8e4be87b-8dde-4d10-bd95-41a26ef2aa48,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-7203a360-f1cb-41ad-89d6-e225fc97b935,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-d4538f58-ff54-4f2d-9a1c-83b39026f64b,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-eb6cbfbb-17c7-4e2d-9c02-f8b20ffe453d,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-afa04f7a-875a-49e6-bf1f-87db9dd20c08,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-713b4b92-6d73-48b7-a0fb-2cc5201001e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727859843-172.17.0.7-1597308596223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-f08ebe83-255d-46f2-b9d6-350f8aa974e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-94aafe5f-3a16-4cf1-aaea-37fbe462fb64,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-8e4be87b-8dde-4d10-bd95-41a26ef2aa48,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-7203a360-f1cb-41ad-89d6-e225fc97b935,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-d4538f58-ff54-4f2d-9a1c-83b39026f64b,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-eb6cbfbb-17c7-4e2d-9c02-f8b20ffe453d,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-afa04f7a-875a-49e6-bf1f-87db9dd20c08,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-713b4b92-6d73-48b7-a0fb-2cc5201001e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-182967141-172.17.0.7-1597308752781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44101,DS-6ba9e4f6-a924-4f8b-8811-c05286030def,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-8db78ca7-561b-4c6f-8ac5-6e34eeea4216,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-4b88b292-ab74-4119-a501-e4a31195693b,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-226a26ce-f624-47c2-8bd7-775644aee897,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-7dc69583-64bc-43bd-97fa-b3a5d0dff82e,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-58c4f3bc-fe16-4ccb-b615-49fd9a7dc6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-79a8c137-1649-4613-9289-6ad33ce78487,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-da3897c7-2246-4575-888d-12edb65c6121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-182967141-172.17.0.7-1597308752781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44101,DS-6ba9e4f6-a924-4f8b-8811-c05286030def,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-8db78ca7-561b-4c6f-8ac5-6e34eeea4216,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-4b88b292-ab74-4119-a501-e4a31195693b,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-226a26ce-f624-47c2-8bd7-775644aee897,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-7dc69583-64bc-43bd-97fa-b3a5d0dff82e,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-58c4f3bc-fe16-4ccb-b615-49fd9a7dc6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-79a8c137-1649-4613-9289-6ad33ce78487,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-da3897c7-2246-4575-888d-12edb65c6121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044549572-172.17.0.7-1597308824035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46820,DS-e3558bd5-b8cf-4509-8b40-be9ab489ccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-e05d7b89-6f0a-4343-8807-d88f8ba3c993,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-71f42b27-3f40-43cb-a981-5f9335e68a13,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-357611b8-d5dc-4808-8444-90158eaac12f,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-e2d80bfc-39e4-4ddb-9790-e74a4bc39048,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-ed754409-63f0-4231-86c4-099ee9287255,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-0dbf2d4b-050c-4dbb-b85a-66c73dc4777f,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-c117137d-608f-4829-82ec-cd60286d6f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044549572-172.17.0.7-1597308824035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46820,DS-e3558bd5-b8cf-4509-8b40-be9ab489ccbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-e05d7b89-6f0a-4343-8807-d88f8ba3c993,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-71f42b27-3f40-43cb-a981-5f9335e68a13,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-357611b8-d5dc-4808-8444-90158eaac12f,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-e2d80bfc-39e4-4ddb-9790-e74a4bc39048,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-ed754409-63f0-4231-86c4-099ee9287255,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-0dbf2d4b-050c-4dbb-b85a-66c73dc4777f,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-c117137d-608f-4829-82ec-cd60286d6f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760341518-172.17.0.7-1597308971208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45864,DS-b2eea027-9c17-459b-bff8-c61192214da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-b9f2a137-0bb1-4bad-9132-8591194fefcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-5e9333e9-41fe-42ce-818a-63087f587607,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-d57d408f-9122-4a5a-b6aa-c46682fbadd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-e913d29b-5d3b-4080-b1bb-786e64f19034,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-891d12a6-c63e-405d-bdf6-061bbfd80099,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-7daa8516-6906-463d-ab4e-fd79e3cf96a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-4894b2df-1528-49b3-afe2-2ecb5c073f65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760341518-172.17.0.7-1597308971208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45864,DS-b2eea027-9c17-459b-bff8-c61192214da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-b9f2a137-0bb1-4bad-9132-8591194fefcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-5e9333e9-41fe-42ce-818a-63087f587607,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-d57d408f-9122-4a5a-b6aa-c46682fbadd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-e913d29b-5d3b-4080-b1bb-786e64f19034,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-891d12a6-c63e-405d-bdf6-061bbfd80099,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-7daa8516-6906-463d-ab4e-fd79e3cf96a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-4894b2df-1528-49b3-afe2-2ecb5c073f65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044169645-172.17.0.7-1597309257562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-75fa92f9-7bb6-4fb1-b58f-96bb95517011,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-02857753-0864-48c7-9a9c-f18a69bbd45f,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-d67bc8f1-ea1e-4c6d-a097-e12c1bee3caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-5498997d-1d04-40f5-851b-d6b487818bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-7bc3b17e-7990-4386-8d21-16c16cfc8659,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-af5eac1e-cf33-4334-8f02-88aadcbfa705,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-7c624473-857f-463e-a6c7-81ccbf78f12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-a9108d61-edb6-40e6-a313-1975a6a5dbed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044169645-172.17.0.7-1597309257562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-75fa92f9-7bb6-4fb1-b58f-96bb95517011,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-02857753-0864-48c7-9a9c-f18a69bbd45f,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-d67bc8f1-ea1e-4c6d-a097-e12c1bee3caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-5498997d-1d04-40f5-851b-d6b487818bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-7bc3b17e-7990-4386-8d21-16c16cfc8659,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-af5eac1e-cf33-4334-8f02-88aadcbfa705,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-7c624473-857f-463e-a6c7-81ccbf78f12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-a9108d61-edb6-40e6-a313-1975a6a5dbed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987559931-172.17.0.7-1597309325117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-84cfd269-845a-4a42-9b13-8e4dbf933249,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-67666363-101f-4bab-b63d-2f18077beec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-a638dfad-cf95-42a0-a0b6-08bb5b49a212,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-5052b9b9-7cc3-4de1-a100-c2acb35ebec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-75bc4149-7b07-4f3c-891d-67e84b0da4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-0374f487-adad-4c03-9700-d0d6e45387db,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-8539d960-08d3-4dce-9d86-aca40664f53b,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-913f3ae1-a052-492f-ad0d-812e64eb162e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987559931-172.17.0.7-1597309325117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34777,DS-84cfd269-845a-4a42-9b13-8e4dbf933249,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-67666363-101f-4bab-b63d-2f18077beec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-a638dfad-cf95-42a0-a0b6-08bb5b49a212,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-5052b9b9-7cc3-4de1-a100-c2acb35ebec5,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-75bc4149-7b07-4f3c-891d-67e84b0da4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-0374f487-adad-4c03-9700-d0d6e45387db,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-8539d960-08d3-4dce-9d86-aca40664f53b,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-913f3ae1-a052-492f-ad0d-812e64eb162e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716394682-172.17.0.7-1597309466674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35848,DS-66120eb9-2a34-42e3-aedb-747a0666759a,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-2e25b7e3-432e-49c1-a73b-f5b62f65ae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-4b5024ac-86af-4aa1-bb05-cd092abff0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-ea8f27d5-5fb2-43eb-98a6-6ecb6e3f8483,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-562299bb-1d46-4207-92ad-1467618fe6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-2b80f733-f647-477f-a08e-e173fbd8e37f,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-453bdf32-d80d-4461-961a-0b1d4a48c483,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-5764bd96-9eed-4dc8-91da-7348ce6b306b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716394682-172.17.0.7-1597309466674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35848,DS-66120eb9-2a34-42e3-aedb-747a0666759a,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-2e25b7e3-432e-49c1-a73b-f5b62f65ae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-4b5024ac-86af-4aa1-bb05-cd092abff0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-ea8f27d5-5fb2-43eb-98a6-6ecb6e3f8483,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-562299bb-1d46-4207-92ad-1467618fe6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-2b80f733-f647-477f-a08e-e173fbd8e37f,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-453bdf32-d80d-4461-961a-0b1d4a48c483,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-5764bd96-9eed-4dc8-91da-7348ce6b306b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912636729-172.17.0.7-1597309687943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-4e0124fa-753a-40bb-bed9-089c7b23b357,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-05fbe047-87d4-426e-8657-a8c3deb0b317,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-731a6906-e994-4ccd-a73e-067d82036178,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-23e82abe-a755-4d62-8190-1260264c2c91,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-060f4bc4-4628-4f72-8555-d8c4bbc8b658,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-4f65fbe5-8247-4d20-8d85-57121fd7e2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-a04f9de2-103a-46f0-8c9b-0d049fd2776e,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-e096142a-00bd-41e3-bcc7-679a4e98cc7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912636729-172.17.0.7-1597309687943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-4e0124fa-753a-40bb-bed9-089c7b23b357,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-05fbe047-87d4-426e-8657-a8c3deb0b317,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-731a6906-e994-4ccd-a73e-067d82036178,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-23e82abe-a755-4d62-8190-1260264c2c91,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-060f4bc4-4628-4f72-8555-d8c4bbc8b658,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-4f65fbe5-8247-4d20-8d85-57121fd7e2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-a04f9de2-103a-46f0-8c9b-0d049fd2776e,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-e096142a-00bd-41e3-bcc7-679a4e98cc7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290785384-172.17.0.7-1597309858533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-8114dc6f-5f75-417f-bf91-966243a8cff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-6b0c9f9b-0c2c-40d0-8858-45a06f3e336f,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-bb5fda3e-63f8-4405-9ca3-93e4a59f6b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-46418914-491e-4135-8fd6-326ce7bb408d,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-690293d2-73bb-44de-b172-9844c9e1a24e,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-ca3af68a-2735-4baa-9364-ee185d18c477,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-bb7cb813-ec0f-4fa1-9f44-1971bbcb8c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-f40a7534-e91f-4dad-9440-33cb98cf87a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290785384-172.17.0.7-1597309858533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-8114dc6f-5f75-417f-bf91-966243a8cff3,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-6b0c9f9b-0c2c-40d0-8858-45a06f3e336f,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-bb5fda3e-63f8-4405-9ca3-93e4a59f6b24,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-46418914-491e-4135-8fd6-326ce7bb408d,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-690293d2-73bb-44de-b172-9844c9e1a24e,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-ca3af68a-2735-4baa-9364-ee185d18c477,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-bb7cb813-ec0f-4fa1-9f44-1971bbcb8c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-f40a7534-e91f-4dad-9440-33cb98cf87a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006830900-172.17.0.7-1597310158951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-00b7b47a-0019-4444-b88c-998fb3a20f54,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-89110662-e448-464f-90d8-f8dd0f958abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-67870841-44b6-470f-93cc-7ed17ffeb0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-cbeda9a9-20af-46d9-98db-53221e10b835,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-924b32e9-1c21-44da-908c-0872f2a63b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-eb52c3b2-82dd-48bc-97de-b89ac75993e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-cfed2209-c88a-4933-940d-82371af3934b,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-72022a3b-e976-401e-9c94-ba59b385d609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006830900-172.17.0.7-1597310158951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43895,DS-00b7b47a-0019-4444-b88c-998fb3a20f54,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-89110662-e448-464f-90d8-f8dd0f958abb,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-67870841-44b6-470f-93cc-7ed17ffeb0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-cbeda9a9-20af-46d9-98db-53221e10b835,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-924b32e9-1c21-44da-908c-0872f2a63b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-eb52c3b2-82dd-48bc-97de-b89ac75993e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-cfed2209-c88a-4933-940d-82371af3934b,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-72022a3b-e976-401e-9c94-ba59b385d609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547392229-172.17.0.7-1597310591835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42206,DS-83ac1a92-c52b-4cb1-aba1-26b321d54484,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-1a1aa69f-b318-4dd6-8225-680a6c326219,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-aaa26f0b-e0a4-4d41-9d67-ba0f8f56414d,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-c5f76e07-a807-4b2b-b093-090c6098c099,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-20f93f62-2684-4041-b3bb-47eb3a78f483,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-c634aff5-5013-4f5d-b44e-9ff7bc646738,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-337d8c6a-0ae7-41cf-a832-51fb13f7feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-c863b7b2-1abd-4325-9d15-6f4f02f97240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547392229-172.17.0.7-1597310591835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42206,DS-83ac1a92-c52b-4cb1-aba1-26b321d54484,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-1a1aa69f-b318-4dd6-8225-680a6c326219,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-aaa26f0b-e0a4-4d41-9d67-ba0f8f56414d,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-c5f76e07-a807-4b2b-b093-090c6098c099,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-20f93f62-2684-4041-b3bb-47eb3a78f483,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-c634aff5-5013-4f5d-b44e-9ff7bc646738,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-337d8c6a-0ae7-41cf-a832-51fb13f7feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-c863b7b2-1abd-4325-9d15-6f4f02f97240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193931995-172.17.0.7-1597310627735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39176,DS-6f6a950e-e7de-4fdd-9795-be95be6f7ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-787ea50c-eee4-4c92-affd-20c00dc4a2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-4a9c817e-b8f3-4220-aba6-a4355d932ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-c4c4c108-7100-415e-b1bd-ae9724a2eb95,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-2d51cdef-fd9e-4cd2-89fd-a2c2fc567284,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-23eb28c1-cdc5-4c75-935b-9499d5cf9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-9fab1dbe-a1db-4b17-88d5-ed4d5b685bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-44207d19-5f7a-47bc-86b7-7307b59dd6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193931995-172.17.0.7-1597310627735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39176,DS-6f6a950e-e7de-4fdd-9795-be95be6f7ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-787ea50c-eee4-4c92-affd-20c00dc4a2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-4a9c817e-b8f3-4220-aba6-a4355d932ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-c4c4c108-7100-415e-b1bd-ae9724a2eb95,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-2d51cdef-fd9e-4cd2-89fd-a2c2fc567284,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-23eb28c1-cdc5-4c75-935b-9499d5cf9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-9fab1dbe-a1db-4b17-88d5-ed4d5b685bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-44207d19-5f7a-47bc-86b7-7307b59dd6a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5463
