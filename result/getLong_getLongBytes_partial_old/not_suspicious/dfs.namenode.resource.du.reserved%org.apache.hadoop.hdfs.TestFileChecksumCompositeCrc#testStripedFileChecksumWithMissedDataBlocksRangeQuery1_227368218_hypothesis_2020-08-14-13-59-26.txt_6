reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430220907-172.17.0.17-1597413725957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43602,DS-ef52a6a3-c793-4ad4-973a-d3c08fe3d8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-cb1e5918-0ecd-49cd-aa23-13f143368103,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-261c283a-4180-42cc-8339-32320550976b,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-26ab9bb9-9410-49c8-b079-4ff8aee06836,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-d63a5223-1f7f-4176-8054-a7b92b90534a,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-92527946-367a-4487-83bd-a27ed6658def,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-bc0ea16d-f28d-46a2-9787-fdf85001b496,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-65e5b3cb-149a-4791-be57-380374b3e003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430220907-172.17.0.17-1597413725957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43602,DS-ef52a6a3-c793-4ad4-973a-d3c08fe3d8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-cb1e5918-0ecd-49cd-aa23-13f143368103,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-261c283a-4180-42cc-8339-32320550976b,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-26ab9bb9-9410-49c8-b079-4ff8aee06836,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-d63a5223-1f7f-4176-8054-a7b92b90534a,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-92527946-367a-4487-83bd-a27ed6658def,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-bc0ea16d-f28d-46a2-9787-fdf85001b496,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-65e5b3cb-149a-4791-be57-380374b3e003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123667571-172.17.0.17-1597414587453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-3872c788-0d3b-4a5c-a901-4a66ce8846d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-12b20f91-5ac9-4b37-85f1-e4eba010380d,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-38e520af-3a9c-4018-8788-89515d25b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-8d2af731-9c5f-4d99-b99e-15e21caea974,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-ad29fc70-dc3f-4df5-a11c-a2555325e53c,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-68ca55ec-4ece-463e-99d3-65072601f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-8bc4cc6c-3556-4f42-8be3-2d3be8d2ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-773e5efd-f998-4110-9a6c-c53ebab27c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123667571-172.17.0.17-1597414587453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-3872c788-0d3b-4a5c-a901-4a66ce8846d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-12b20f91-5ac9-4b37-85f1-e4eba010380d,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-38e520af-3a9c-4018-8788-89515d25b1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-8d2af731-9c5f-4d99-b99e-15e21caea974,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-ad29fc70-dc3f-4df5-a11c-a2555325e53c,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-68ca55ec-4ece-463e-99d3-65072601f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-8bc4cc6c-3556-4f42-8be3-2d3be8d2ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-773e5efd-f998-4110-9a6c-c53ebab27c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144961662-172.17.0.17-1597415133617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40964,DS-7e5455d6-a5b0-481d-9ba7-ef6f8447a568,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-1e662323-b782-4027-b591-e32219258508,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-221c5053-b780-4c97-b000-a86ed35f5d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-54771937-5907-4eee-8068-4296ed450107,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-960ab0d4-e087-40ac-835b-2b926f28b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-a91ad484-1d30-46bd-890f-74198e51477e,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-b5959f9a-b432-488e-83aa-288c89393e70,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-eab38896-575e-427b-b949-7a849f46cd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144961662-172.17.0.17-1597415133617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40964,DS-7e5455d6-a5b0-481d-9ba7-ef6f8447a568,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-1e662323-b782-4027-b591-e32219258508,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-221c5053-b780-4c97-b000-a86ed35f5d28,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-54771937-5907-4eee-8068-4296ed450107,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-960ab0d4-e087-40ac-835b-2b926f28b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-a91ad484-1d30-46bd-890f-74198e51477e,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-b5959f9a-b432-488e-83aa-288c89393e70,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-eab38896-575e-427b-b949-7a849f46cd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093480153-172.17.0.17-1597415902416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-f005e06b-71ae-4029-a33a-866355048f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-c1260174-0b82-47e1-ae4a-24abc2295302,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-a49bc156-54ba-4ca4-b32e-653447eb1a51,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-e9527db2-6af9-43ec-a2f3-5345ca518f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-2c905bf4-2616-4b41-9119-38380aa799ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-7afa3934-4f39-4d33-8c21-1ca0fe5fd208,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-13097dbf-3b1b-4f03-b2ec-e07fcf13a0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-9eb2c11a-d9d0-47fd-b960-92a584bb734e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093480153-172.17.0.17-1597415902416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-f005e06b-71ae-4029-a33a-866355048f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-c1260174-0b82-47e1-ae4a-24abc2295302,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-a49bc156-54ba-4ca4-b32e-653447eb1a51,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-e9527db2-6af9-43ec-a2f3-5345ca518f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-2c905bf4-2616-4b41-9119-38380aa799ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-7afa3934-4f39-4d33-8c21-1ca0fe5fd208,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-13097dbf-3b1b-4f03-b2ec-e07fcf13a0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-9eb2c11a-d9d0-47fd-b960-92a584bb734e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115311065-172.17.0.17-1597415938226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-5dc42461-7b3a-4acf-940a-43e601c8abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-09b2310a-aece-40c2-af14-0ca940c404e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-50986db6-8248-4faa-b198-1b299eb2e8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-e77c62bf-4e4d-45be-8a75-2d12a219619f,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-b163363d-2b6a-44dc-9a8e-44bdef4245d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-1323d96a-04c6-4e5a-b69a-d1043aa25bea,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-f61e2b8e-b96d-4f15-8178-ae6731d798e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-873f5954-568f-48b9-88b6-e5c490a6b50b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115311065-172.17.0.17-1597415938226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-5dc42461-7b3a-4acf-940a-43e601c8abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-09b2310a-aece-40c2-af14-0ca940c404e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-50986db6-8248-4faa-b198-1b299eb2e8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-e77c62bf-4e4d-45be-8a75-2d12a219619f,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-b163363d-2b6a-44dc-9a8e-44bdef4245d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-1323d96a-04c6-4e5a-b69a-d1043aa25bea,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-f61e2b8e-b96d-4f15-8178-ae6731d798e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-873f5954-568f-48b9-88b6-e5c490a6b50b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816930319-172.17.0.17-1597416105403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37704,DS-f5ffbc16-a1f9-4da4-a941-37adc6d517d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-4991de9e-9a7b-4c3b-9d86-db2a03567bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-34b24e95-7722-4894-872d-73693043032a,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-120cf79c-62e2-4a3e-96e7-47e0d6c92fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-d7fa79fd-dbd0-4e18-8849-7a1f9349b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-9fb95e82-4b51-4e47-ab5d-f5f6dc02e261,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-511ffb96-2fba-439d-8620-7150ef6e705d,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-7e604558-0173-4d6b-94cc-2610d8f8db99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816930319-172.17.0.17-1597416105403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37704,DS-f5ffbc16-a1f9-4da4-a941-37adc6d517d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-4991de9e-9a7b-4c3b-9d86-db2a03567bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-34b24e95-7722-4894-872d-73693043032a,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-120cf79c-62e2-4a3e-96e7-47e0d6c92fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-d7fa79fd-dbd0-4e18-8849-7a1f9349b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-9fb95e82-4b51-4e47-ab5d-f5f6dc02e261,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-511ffb96-2fba-439d-8620-7150ef6e705d,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-7e604558-0173-4d6b-94cc-2610d8f8db99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353059331-172.17.0.17-1597416761356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45571,DS-b2280bed-66c2-47a6-b574-ef599f6a7fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-44473147-e8fe-4330-bbc2-650b15811a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-05be2e4e-845a-43ab-aa7e-d15c984c3f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-813cc5b8-bb5a-480c-9ae9-c84eed67c626,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-67bd3aa4-e399-4005-9e28-2c914600a5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-78a1cf23-4c4a-40ca-b59b-1a6417e68d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-0edbb9f0-1d07-48e5-9bc4-8b8918d31f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-7365309d-1797-4f74-88e4-57b4dfb01b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353059331-172.17.0.17-1597416761356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45571,DS-b2280bed-66c2-47a6-b574-ef599f6a7fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-44473147-e8fe-4330-bbc2-650b15811a26,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-05be2e4e-845a-43ab-aa7e-d15c984c3f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-813cc5b8-bb5a-480c-9ae9-c84eed67c626,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-67bd3aa4-e399-4005-9e28-2c914600a5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-78a1cf23-4c4a-40ca-b59b-1a6417e68d95,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-0edbb9f0-1d07-48e5-9bc4-8b8918d31f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-7365309d-1797-4f74-88e4-57b4dfb01b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561633199-172.17.0.17-1597416926473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-5a4c1099-a14f-4887-9e7a-ebb1e37d9f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-385de99e-29b0-4a6f-b888-6b45c9b625d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-5f1d6daf-f98b-4778-af81-247af597f466,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-af8da4e2-c248-47e0-96f2-0e1556d2da03,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-8deb2bc0-e930-416e-aa3f-c05145ffeb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-b07209c5-ac41-4bc0-bb97-8817fe4ea129,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-ca9bf075-afd7-4407-9209-108168618393,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-4f4ffcb9-5899-4c2b-8674-8fa96f70b08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561633199-172.17.0.17-1597416926473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-5a4c1099-a14f-4887-9e7a-ebb1e37d9f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-385de99e-29b0-4a6f-b888-6b45c9b625d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-5f1d6daf-f98b-4778-af81-247af597f466,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-af8da4e2-c248-47e0-96f2-0e1556d2da03,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-8deb2bc0-e930-416e-aa3f-c05145ffeb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-b07209c5-ac41-4bc0-bb97-8817fe4ea129,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-ca9bf075-afd7-4407-9209-108168618393,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-4f4ffcb9-5899-4c2b-8674-8fa96f70b08d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811439153-172.17.0.17-1597417350886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45847,DS-06ae55b6-83af-4f4c-91da-32d73d379056,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-2b478cb2-3a7d-4eff-8206-b715e9257dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-a50e8916-5b3d-4d0f-b289-0255ad3c0b74,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-12e6a694-433d-4b00-bd65-fd5d49e846f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-cb2dd488-c203-4af2-8bb5-4b1382ead198,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-a4627185-6a95-4da3-8cd5-fa9d58a694f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-2749626f-592f-41bd-98b7-a5f2c856bae5,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-8fd5d0d7-c333-48dd-be16-3009bb21d37a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811439153-172.17.0.17-1597417350886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45847,DS-06ae55b6-83af-4f4c-91da-32d73d379056,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-2b478cb2-3a7d-4eff-8206-b715e9257dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-a50e8916-5b3d-4d0f-b289-0255ad3c0b74,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-12e6a694-433d-4b00-bd65-fd5d49e846f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-cb2dd488-c203-4af2-8bb5-4b1382ead198,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-a4627185-6a95-4da3-8cd5-fa9d58a694f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-2749626f-592f-41bd-98b7-a5f2c856bae5,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-8fd5d0d7-c333-48dd-be16-3009bb21d37a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352270497-172.17.0.17-1597417425590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-b2abc21b-6490-43c7-88a6-2330a234b6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-4b7dc491-efba-4986-ac43-884e0b99344d,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-6a7ea106-8719-40f1-9e52-5d498cc23e29,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-ade11c75-e584-4a63-8850-d014227ef098,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-81dad93a-9f8c-44a5-a5b7-52a424f47f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-4f2e974d-d62b-4f7d-b273-49f1abbf14b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-de433d2d-de0b-4d47-bcc1-933951b90880,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-e0288cb2-68b5-4258-be3d-a92ffd2c5f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352270497-172.17.0.17-1597417425590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-b2abc21b-6490-43c7-88a6-2330a234b6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-4b7dc491-efba-4986-ac43-884e0b99344d,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-6a7ea106-8719-40f1-9e52-5d498cc23e29,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-ade11c75-e584-4a63-8850-d014227ef098,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-81dad93a-9f8c-44a5-a5b7-52a424f47f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-4f2e974d-d62b-4f7d-b273-49f1abbf14b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-de433d2d-de0b-4d47-bcc1-933951b90880,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-e0288cb2-68b5-4258-be3d-a92ffd2c5f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621477892-172.17.0.17-1597417846071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39335,DS-9d134068-bc7b-4660-aba0-3ce821cc1a07,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-da5409bd-8ba8-4bcb-9478-d75d9abc9712,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-1c576b56-12c7-4430-8d2f-52b39d9a96cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-8919a83a-63fd-4093-9288-879d450a8dce,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-13e1fef3-7cfe-4b25-b9fa-5454adb87201,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-4a109fa2-5d54-4fd4-992e-21f66b2cb8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-de7ceab4-f0ac-4416-bfbe-c409b9893b83,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-76e40946-bbc7-49c3-8373-93396538d32b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621477892-172.17.0.17-1597417846071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39335,DS-9d134068-bc7b-4660-aba0-3ce821cc1a07,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-da5409bd-8ba8-4bcb-9478-d75d9abc9712,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-1c576b56-12c7-4430-8d2f-52b39d9a96cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-8919a83a-63fd-4093-9288-879d450a8dce,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-13e1fef3-7cfe-4b25-b9fa-5454adb87201,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-4a109fa2-5d54-4fd4-992e-21f66b2cb8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-de7ceab4-f0ac-4416-bfbe-c409b9893b83,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-76e40946-bbc7-49c3-8373-93396538d32b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269243429-172.17.0.17-1597418063635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-fbdf639b-362c-4794-b873-df7b9f979b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-833e8509-0b61-4fa6-9df2-53e55befefbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-6fc298fc-4681-4b2c-bb53-844722c0a249,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-a1999027-d606-41c2-901e-65ab3e84f154,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-6907e599-8693-40ee-b455-236ba8d60d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-88eae03d-5477-4ac3-b8e8-2b67440288fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-fd5fd7e0-04f3-43e0-8612-2935c8c52ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-f5a658bd-e3eb-45ce-8625-b6922e36bddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269243429-172.17.0.17-1597418063635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-fbdf639b-362c-4794-b873-df7b9f979b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-833e8509-0b61-4fa6-9df2-53e55befefbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-6fc298fc-4681-4b2c-bb53-844722c0a249,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-a1999027-d606-41c2-901e-65ab3e84f154,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-6907e599-8693-40ee-b455-236ba8d60d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-88eae03d-5477-4ac3-b8e8-2b67440288fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-fd5fd7e0-04f3-43e0-8612-2935c8c52ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-f5a658bd-e3eb-45ce-8625-b6922e36bddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563963761-172.17.0.17-1597418345126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34175,DS-4f4ee325-b313-4822-8b87-093976d470fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-7cd9bca4-b31b-4457-9f26-c5c03560e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-233f0d4a-bab5-427f-8e79-960220a0ec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-09d80c41-26ae-44fc-b2f2-34611dc89041,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-366d7aa2-e37c-41b5-b84d-aa7d86984d67,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-a337d16a-103b-4e72-a01c-600b36d236ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-40b75d69-f0e2-4e3c-9858-0b3e42ca685c,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-eb436dbc-220f-4ae8-b577-974a296a470a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563963761-172.17.0.17-1597418345126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34175,DS-4f4ee325-b313-4822-8b87-093976d470fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-7cd9bca4-b31b-4457-9f26-c5c03560e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-233f0d4a-bab5-427f-8e79-960220a0ec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-09d80c41-26ae-44fc-b2f2-34611dc89041,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-366d7aa2-e37c-41b5-b84d-aa7d86984d67,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-a337d16a-103b-4e72-a01c-600b36d236ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-40b75d69-f0e2-4e3c-9858-0b3e42ca685c,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-eb436dbc-220f-4ae8-b577-974a296a470a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181138067-172.17.0.17-1597418422382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45078,DS-8ab35c7a-d237-4d71-860b-204a2b332ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-aa8b01ad-4f9f-4adc-8112-7500329d4725,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-97317cfd-b67c-433a-b0ac-33712e2470af,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-812fc55a-548c-4005-8181-3ca770a5ec59,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-88757132-8e3b-495d-adc6-29f5d05f42d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-7303bb2e-c3ad-41db-8330-995df437bbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-797dca48-041c-475a-9cc8-2c9eac2463be,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-a9c49ea3-3b90-4395-97a3-d0b5add20352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181138067-172.17.0.17-1597418422382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45078,DS-8ab35c7a-d237-4d71-860b-204a2b332ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-aa8b01ad-4f9f-4adc-8112-7500329d4725,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-97317cfd-b67c-433a-b0ac-33712e2470af,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-812fc55a-548c-4005-8181-3ca770a5ec59,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-88757132-8e3b-495d-adc6-29f5d05f42d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-7303bb2e-c3ad-41db-8330-995df437bbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-797dca48-041c-475a-9cc8-2c9eac2463be,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-a9c49ea3-3b90-4395-97a3-d0b5add20352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806870625-172.17.0.17-1597418784651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-9d14ba62-53c6-4341-9316-58320f49fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-34577cc7-4b4d-4936-9de7-640ddf50b642,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-1dbc7ebc-325b-4c12-b53e-86d37258c229,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-616f7ad2-16ac-44fd-9865-343accfa857c,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-454385c2-c206-4d1e-b661-93e52b13d0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-043e7b54-f352-4bf8-a47a-af921906da62,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-ac283fde-d24e-4763-bd6c-e41fcfdd5f44,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-37c1160c-cbb7-48f0-a4db-f62decf5fe44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806870625-172.17.0.17-1597418784651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33589,DS-9d14ba62-53c6-4341-9316-58320f49fad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-34577cc7-4b4d-4936-9de7-640ddf50b642,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-1dbc7ebc-325b-4c12-b53e-86d37258c229,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-616f7ad2-16ac-44fd-9865-343accfa857c,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-454385c2-c206-4d1e-b661-93e52b13d0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-043e7b54-f352-4bf8-a47a-af921906da62,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-ac283fde-d24e-4763-bd6c-e41fcfdd5f44,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-37c1160c-cbb7-48f0-a4db-f62decf5fe44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894778960-172.17.0.17-1597418826921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-3a2d6c48-e82f-459e-a213-1b141b1bd4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-beb80f8a-5e3c-4fa0-a50b-035364bbe4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-1ecd2f60-3bbb-4194-8143-7d1b0444f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-2605a838-589c-45b3-a88f-8aaf60f1eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-c3116ea8-2f63-4f88-816d-5cb1bc290c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-8e21db25-745f-4d52-b8a8-b3bffff3d50c,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-0d06e615-ae56-4bc9-8fbd-dbf035df0211,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-98775950-234c-4813-9948-5f7ab308935f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894778960-172.17.0.17-1597418826921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-3a2d6c48-e82f-459e-a213-1b141b1bd4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-beb80f8a-5e3c-4fa0-a50b-035364bbe4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-1ecd2f60-3bbb-4194-8143-7d1b0444f6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-2605a838-589c-45b3-a88f-8aaf60f1eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-c3116ea8-2f63-4f88-816d-5cb1bc290c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-8e21db25-745f-4d52-b8a8-b3bffff3d50c,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-0d06e615-ae56-4bc9-8fbd-dbf035df0211,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-98775950-234c-4813-9948-5f7ab308935f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6007
