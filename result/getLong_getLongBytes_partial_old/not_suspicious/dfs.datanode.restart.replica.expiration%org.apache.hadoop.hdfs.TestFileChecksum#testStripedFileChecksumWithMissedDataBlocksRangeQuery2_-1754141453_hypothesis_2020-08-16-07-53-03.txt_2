reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991383531-172.17.0.7-1597564894113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37641,DS-36981725-8f28-4dbe-9648-20b0df34bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-4aa3425d-9aa3-4fb7-bfbe-3108f46743b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-b1ae6a31-5cfc-49d7-9e54-a308d076733e,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-dcbfce0b-959b-46cd-8d81-db1520ed0ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-6302fad5-96d2-422b-9c15-c6bf701c38c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-6ca98d0d-58d8-4d8f-9fa0-19da041e4f38,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-dc76ba8c-bd8c-4c43-aa40-4798c4bc8737,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-86c3f577-191d-4c7c-a8eb-8becc304c64c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991383531-172.17.0.7-1597564894113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37641,DS-36981725-8f28-4dbe-9648-20b0df34bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-4aa3425d-9aa3-4fb7-bfbe-3108f46743b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-b1ae6a31-5cfc-49d7-9e54-a308d076733e,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-dcbfce0b-959b-46cd-8d81-db1520ed0ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-6302fad5-96d2-422b-9c15-c6bf701c38c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-6ca98d0d-58d8-4d8f-9fa0-19da041e4f38,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-dc76ba8c-bd8c-4c43-aa40-4798c4bc8737,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-86c3f577-191d-4c7c-a8eb-8becc304c64c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258975450-172.17.0.7-1597565114484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41717,DS-5d9cc40d-9397-4733-8621-48c826e6dd95,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-83663dc4-d27c-4937-8230-0536c73c7dca,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-1547c064-db53-457b-a748-1843b6209287,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-095c2b0b-ed3b-482d-9808-3f7359f7a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-3b2b5447-48a0-44f8-8208-f179e879e70d,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-1c7e27c8-0a95-4e69-8c11-0c92e1965ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-11dec8b5-fe25-441d-bbb3-8d59833b7b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-62537151-4b7d-4966-85d8-bd9f9e283324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258975450-172.17.0.7-1597565114484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41717,DS-5d9cc40d-9397-4733-8621-48c826e6dd95,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-83663dc4-d27c-4937-8230-0536c73c7dca,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-1547c064-db53-457b-a748-1843b6209287,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-095c2b0b-ed3b-482d-9808-3f7359f7a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-3b2b5447-48a0-44f8-8208-f179e879e70d,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-1c7e27c8-0a95-4e69-8c11-0c92e1965ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-11dec8b5-fe25-441d-bbb3-8d59833b7b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-62537151-4b7d-4966-85d8-bd9f9e283324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59016938-172.17.0.7-1597565190270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34481,DS-bfe6c92d-d059-48ef-a576-24eb23d6bd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-3d47d65e-4366-48fa-929e-e8dd16117c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-395df92d-a872-43e9-bbe7-b69ba489a155,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-db910a3f-c2c1-4455-8cf5-ed8c3580d8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-fe89d4d4-0d94-4a3c-8497-932e81090d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-35874e0d-10b4-45d7-b4ce-e66b3a056322,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-858e6f3a-e566-4371-b60c-900522a1e932,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-dc6b64eb-7716-48b8-9e99-e809128f5c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59016938-172.17.0.7-1597565190270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34481,DS-bfe6c92d-d059-48ef-a576-24eb23d6bd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-3d47d65e-4366-48fa-929e-e8dd16117c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-395df92d-a872-43e9-bbe7-b69ba489a155,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-db910a3f-c2c1-4455-8cf5-ed8c3580d8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-fe89d4d4-0d94-4a3c-8497-932e81090d00,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-35874e0d-10b4-45d7-b4ce-e66b3a056322,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-858e6f3a-e566-4371-b60c-900522a1e932,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-dc6b64eb-7716-48b8-9e99-e809128f5c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386740820-172.17.0.7-1597565903117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-674bf2c0-498c-45a6-9f80-be644e04d517,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-292bb040-d42b-43e4-810d-811509daa3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-db50e57a-b5c1-416d-b095-92a8302f048c,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-d69e74ca-23a4-4f8e-b73d-9aa00d54dd83,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-bed4b056-ca3c-4517-99a5-5d2227dbe9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-4465c8b7-70fb-4f75-86c3-916bc099974a,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-c438b258-dfa7-465d-9423-2dc2a10e7b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-8bc4ff9f-8a1b-418f-aa44-1f464f63c869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386740820-172.17.0.7-1597565903117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-674bf2c0-498c-45a6-9f80-be644e04d517,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-292bb040-d42b-43e4-810d-811509daa3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-db50e57a-b5c1-416d-b095-92a8302f048c,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-d69e74ca-23a4-4f8e-b73d-9aa00d54dd83,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-bed4b056-ca3c-4517-99a5-5d2227dbe9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-4465c8b7-70fb-4f75-86c3-916bc099974a,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-c438b258-dfa7-465d-9423-2dc2a10e7b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-8bc4ff9f-8a1b-418f-aa44-1f464f63c869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709957188-172.17.0.7-1597566248406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-9ba262bf-3f04-45a5-8eb9-706a29f07fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-17234ce1-ef9d-4507-89fc-7bd1e82cf3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-13c8c8ca-d277-4bd0-a30b-69c176a9ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-b77b27ab-3437-4cee-bf89-ce472fe6873f,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-382cf7f0-f783-4a3c-bbff-79a8bfd84b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-f795e73b-6330-441b-aca1-31db3122448b,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-ec423c97-640e-410b-8369-3faf06c54d30,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-fd17010a-f569-4919-bbb2-70816b5f9879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709957188-172.17.0.7-1597566248406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-9ba262bf-3f04-45a5-8eb9-706a29f07fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-17234ce1-ef9d-4507-89fc-7bd1e82cf3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-13c8c8ca-d277-4bd0-a30b-69c176a9ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-b77b27ab-3437-4cee-bf89-ce472fe6873f,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-382cf7f0-f783-4a3c-bbff-79a8bfd84b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-f795e73b-6330-441b-aca1-31db3122448b,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-ec423c97-640e-410b-8369-3faf06c54d30,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-fd17010a-f569-4919-bbb2-70816b5f9879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689889825-172.17.0.7-1597566623154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41024,DS-50a2b7b5-e87d-4214-99e4-677c988d9379,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-6f150bd7-fb7f-425b-bcc2-cfd2e639bcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-daf95be4-4052-4714-89e5-fdb0aa761643,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-afe1e93b-baa7-4eb2-be6b-fa06dd7fdd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-b777714d-881e-44ad-a853-c04d9774bf92,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-e6c1a5cd-638a-48e6-83a0-ecc7833e841f,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-0d155920-a3d5-49a9-8bf1-4674511c2890,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-e8bb11a4-c370-43ca-a9e3-ce36f71b32cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689889825-172.17.0.7-1597566623154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41024,DS-50a2b7b5-e87d-4214-99e4-677c988d9379,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-6f150bd7-fb7f-425b-bcc2-cfd2e639bcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-daf95be4-4052-4714-89e5-fdb0aa761643,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-afe1e93b-baa7-4eb2-be6b-fa06dd7fdd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-b777714d-881e-44ad-a853-c04d9774bf92,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-e6c1a5cd-638a-48e6-83a0-ecc7833e841f,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-0d155920-a3d5-49a9-8bf1-4674511c2890,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-e8bb11a4-c370-43ca-a9e3-ce36f71b32cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085709616-172.17.0.7-1597566780445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35394,DS-4e736098-bfe2-4c20-9403-c049c44ba9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b82f7beb-f500-4f47-9792-d8427e235634,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-1eaf8d2d-a989-44e3-bc11-ad35420cc2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-8cb4df5b-8b25-4d60-8491-c0af14c2c481,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-94c45f7c-d66a-4859-8eed-f9427ef128e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f1daf505-ea5d-4231-a07f-dc01a31cb6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-d24307a4-d237-4aba-a8c3-eb6674e9d1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-f9ac01ce-51f6-412a-a81f-89ef7dd18f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085709616-172.17.0.7-1597566780445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35394,DS-4e736098-bfe2-4c20-9403-c049c44ba9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-b82f7beb-f500-4f47-9792-d8427e235634,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-1eaf8d2d-a989-44e3-bc11-ad35420cc2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-8cb4df5b-8b25-4d60-8491-c0af14c2c481,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-94c45f7c-d66a-4859-8eed-f9427ef128e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-f1daf505-ea5d-4231-a07f-dc01a31cb6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-d24307a4-d237-4aba-a8c3-eb6674e9d1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-f9ac01ce-51f6-412a-a81f-89ef7dd18f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712157321-172.17.0.7-1597567329131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-d335dd2f-386b-469c-9347-024173af7d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-f355fa49-db5f-441d-af56-d902075a0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-dba19b0c-c95c-4f7f-af71-755a2d5a00ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-6cdc9177-23c7-4ae0-9d96-916033db1690,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-d535a8e4-5910-4f50-a893-882d61354634,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-cbfb4f77-2982-4aa3-b8a7-d5f666ea760c,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-727f8ae4-597e-41c1-a9e3-d699acdd8d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-de0794f3-6f36-4285-b984-5dd77506f791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712157321-172.17.0.7-1597567329131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-d335dd2f-386b-469c-9347-024173af7d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-f355fa49-db5f-441d-af56-d902075a0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-dba19b0c-c95c-4f7f-af71-755a2d5a00ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-6cdc9177-23c7-4ae0-9d96-916033db1690,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-d535a8e4-5910-4f50-a893-882d61354634,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-cbfb4f77-2982-4aa3-b8a7-d5f666ea760c,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-727f8ae4-597e-41c1-a9e3-d699acdd8d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-de0794f3-6f36-4285-b984-5dd77506f791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247805315-172.17.0.7-1597567520485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-41de8572-ef3f-412e-9864-f7a4e074272b,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-5c4b5016-e729-4350-a6be-d7fee8ea43b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-2e12d2f2-d91b-4986-8ad9-7e342ad5d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-506342ea-5761-463c-ba26-d5c8187b70b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-7b93199d-9d75-4faf-817a-2387e476ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-a1f742cf-81c3-4058-ad47-01342e2296f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-528af1c7-c220-4f86-8aaf-e07586971a60,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-678d5d9a-c558-4fab-9747-1856e2558dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247805315-172.17.0.7-1597567520485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42500,DS-41de8572-ef3f-412e-9864-f7a4e074272b,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-5c4b5016-e729-4350-a6be-d7fee8ea43b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-2e12d2f2-d91b-4986-8ad9-7e342ad5d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-506342ea-5761-463c-ba26-d5c8187b70b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-7b93199d-9d75-4faf-817a-2387e476ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-a1f742cf-81c3-4058-ad47-01342e2296f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-528af1c7-c220-4f86-8aaf-e07586971a60,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-678d5d9a-c558-4fab-9747-1856e2558dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141358946-172.17.0.7-1597567684434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38771,DS-94859f9b-44fd-4d10-b984-bc9d87bada80,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-b0d5e32b-9204-451b-ac69-46b7ee26d714,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-5d5311a0-19de-455a-abef-edd0342cbb56,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-463171aa-6946-4fee-bc28-0d9ed163cd60,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-198f632b-b2f5-4e9c-abde-e92a2d394a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-0d27c65f-4deb-4d8c-87b4-c11d7c6e50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-b2bd135e-0ee7-42f3-b662-b84c2e0af524,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-8a6506d1-334b-45b4-879d-34a05add527a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141358946-172.17.0.7-1597567684434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38771,DS-94859f9b-44fd-4d10-b984-bc9d87bada80,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-b0d5e32b-9204-451b-ac69-46b7ee26d714,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-5d5311a0-19de-455a-abef-edd0342cbb56,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-463171aa-6946-4fee-bc28-0d9ed163cd60,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-198f632b-b2f5-4e9c-abde-e92a2d394a84,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-0d27c65f-4deb-4d8c-87b4-c11d7c6e50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-b2bd135e-0ee7-42f3-b662-b84c2e0af524,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-8a6506d1-334b-45b4-879d-34a05add527a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723295273-172.17.0.7-1597569058330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-c4402f24-aa7a-457e-ad36-f47b728293e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-37c1c8ae-94d6-4a4f-9490-aa4525a26965,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-3fece23e-3f1f-4c3f-a396-7196e961efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-a2e80b84-4cff-41f8-85ef-e3cd275fb072,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-045eac2c-1849-47f1-b118-f977103c6467,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-3c19c48f-8561-4476-89bf-bb0c099e8498,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-3b649d8c-1012-4eed-8986-f846e94f905c,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-e0c21922-6c8d-4729-9979-34ee664303f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723295273-172.17.0.7-1597569058330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42249,DS-c4402f24-aa7a-457e-ad36-f47b728293e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-37c1c8ae-94d6-4a4f-9490-aa4525a26965,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-3fece23e-3f1f-4c3f-a396-7196e961efe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-a2e80b84-4cff-41f8-85ef-e3cd275fb072,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-045eac2c-1849-47f1-b118-f977103c6467,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-3c19c48f-8561-4476-89bf-bb0c099e8498,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-3b649d8c-1012-4eed-8986-f846e94f905c,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-e0c21922-6c8d-4729-9979-34ee664303f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5674
