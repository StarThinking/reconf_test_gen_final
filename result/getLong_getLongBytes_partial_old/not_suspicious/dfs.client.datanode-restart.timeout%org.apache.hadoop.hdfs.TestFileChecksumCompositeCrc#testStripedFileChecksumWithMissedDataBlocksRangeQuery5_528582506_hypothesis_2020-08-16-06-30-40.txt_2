reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608991679-172.17.0.4-1597559963026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-ef7939a1-c812-4d5d-9ef5-6acc32ca611b,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-9a14f4fa-18e1-482e-bd9e-bef23ec1bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-4481bc2a-341a-4a34-a660-c95d9071a608,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-61faf374-c48b-4b62-90dd-272ee24cf269,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-76836afa-aa70-4ae9-9933-7dd8b4f6deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-362625c5-6921-4521-9139-e46651edf19b,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-5f2a77e3-519c-4c7d-ad1b-39e7166f5382,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-feec90eb-8cd8-474d-b5c2-3dbbe2650424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608991679-172.17.0.4-1597559963026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-ef7939a1-c812-4d5d-9ef5-6acc32ca611b,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-9a14f4fa-18e1-482e-bd9e-bef23ec1bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-4481bc2a-341a-4a34-a660-c95d9071a608,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-61faf374-c48b-4b62-90dd-272ee24cf269,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-76836afa-aa70-4ae9-9933-7dd8b4f6deb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-362625c5-6921-4521-9139-e46651edf19b,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-5f2a77e3-519c-4c7d-ad1b-39e7166f5382,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-feec90eb-8cd8-474d-b5c2-3dbbe2650424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663644935-172.17.0.4-1597560189588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35831,DS-da13b9f4-2d6f-4ee2-a555-bc3192c87cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-a019c9f1-6c72-45fa-9d72-e5b96f22bd14,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-7cc2f398-c6c3-4e70-a8c1-aae69441e8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-5dd06912-f6ae-4b51-b519-3e5815f8e77b,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-28ee32e1-3483-4f27-b327-4ebb28ad222f,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-62f2b740-c9b8-4422-8583-900d5d0a5818,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-bb7c543c-d264-4c50-b4fd-75874df1a610,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-cfb00c6a-de5d-4f05-ac93-4ba3a8d9254b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663644935-172.17.0.4-1597560189588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35831,DS-da13b9f4-2d6f-4ee2-a555-bc3192c87cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-a019c9f1-6c72-45fa-9d72-e5b96f22bd14,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-7cc2f398-c6c3-4e70-a8c1-aae69441e8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-5dd06912-f6ae-4b51-b519-3e5815f8e77b,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-28ee32e1-3483-4f27-b327-4ebb28ad222f,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-62f2b740-c9b8-4422-8583-900d5d0a5818,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-bb7c543c-d264-4c50-b4fd-75874df1a610,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-cfb00c6a-de5d-4f05-ac93-4ba3a8d9254b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321460082-172.17.0.4-1597560265369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-8fa9baeb-22ce-49b0-92cd-03c786925a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-62cde2c9-50ba-40fd-ae13-58745c53410b,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-b788be4a-16cd-44b6-a02a-31fb1bb21666,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-d137edb6-b92d-43ea-8bf8-169db18535e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-0f6929da-4f6a-4a9b-8e04-965aec0979c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-ca019f62-c193-4983-970a-d34f039b0d06,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-edec75b5-d4fb-446a-825c-7de1135367ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-fcb84051-ac37-48ed-8cf8-627e9845f76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321460082-172.17.0.4-1597560265369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44717,DS-8fa9baeb-22ce-49b0-92cd-03c786925a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-62cde2c9-50ba-40fd-ae13-58745c53410b,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-b788be4a-16cd-44b6-a02a-31fb1bb21666,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-d137edb6-b92d-43ea-8bf8-169db18535e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-0f6929da-4f6a-4a9b-8e04-965aec0979c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-ca019f62-c193-4983-970a-d34f039b0d06,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-edec75b5-d4fb-446a-825c-7de1135367ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-fcb84051-ac37-48ed-8cf8-627e9845f76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681713077-172.17.0.4-1597560305119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44422,DS-82f7c7f6-545a-4988-9f07-e08b0637a432,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-b25e1290-448d-4bc8-bb78-684b90f882aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-009d70c8-7f1e-4514-a6d4-7bcc4b3d3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-de414cc8-7d25-4a58-bb58-0aaea39c50fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-18a3a20b-81f2-4df6-b247-47b42b9d6338,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-89b302fe-aa61-4a75-ae4b-62177eba6599,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-f4194b12-c996-439a-8b85-132a82faa4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-ca0b5de4-79c4-4af4-8b7e-6da935273c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681713077-172.17.0.4-1597560305119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44422,DS-82f7c7f6-545a-4988-9f07-e08b0637a432,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-b25e1290-448d-4bc8-bb78-684b90f882aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-009d70c8-7f1e-4514-a6d4-7bcc4b3d3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-de414cc8-7d25-4a58-bb58-0aaea39c50fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-18a3a20b-81f2-4df6-b247-47b42b9d6338,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-89b302fe-aa61-4a75-ae4b-62177eba6599,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-f4194b12-c996-439a-8b85-132a82faa4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-ca0b5de4-79c4-4af4-8b7e-6da935273c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118372572-172.17.0.4-1597560505361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33629,DS-6e5bb84f-38ec-41a0-b3b3-cc6b81707e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-50f7407f-d807-4713-9980-5b8e790737e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-0246d37c-992d-43e6-a95a-fccb2cf7a23e,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-09e6892a-f4db-4310-8116-e8ab62120d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-a14619d5-8182-4b34-88dc-75dfa7ce62ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-4f44c056-b0e9-4236-9b1f-fb7347dbf10c,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-0c48dbd2-94ae-4a8d-85d6-5e61e1f0a4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-e539925f-0295-4324-b80e-4c187a02257d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118372572-172.17.0.4-1597560505361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33629,DS-6e5bb84f-38ec-41a0-b3b3-cc6b81707e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-50f7407f-d807-4713-9980-5b8e790737e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-0246d37c-992d-43e6-a95a-fccb2cf7a23e,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-09e6892a-f4db-4310-8116-e8ab62120d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-a14619d5-8182-4b34-88dc-75dfa7ce62ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-4f44c056-b0e9-4236-9b1f-fb7347dbf10c,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-0c48dbd2-94ae-4a8d-85d6-5e61e1f0a4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-e539925f-0295-4324-b80e-4c187a02257d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055497728-172.17.0.4-1597560804015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-0688bbf4-a0f3-4bd5-b105-b0265ca5779e,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-a84d82dc-d8bd-47ac-9e6c-b6f02a0e52a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-fc8ec623-f9e6-4e4c-a546-a18e8701a8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-038106df-1115-40a5-a420-e37d3e567215,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-61b7525b-ade2-4220-b966-0b2611059d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-61ddbe6f-6063-421c-9a81-ed9c935b388f,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-26933c74-a55c-4b55-a5ce-65133787d1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-6f98af66-b746-471f-a45e-1e27800dbcee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055497728-172.17.0.4-1597560804015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43076,DS-0688bbf4-a0f3-4bd5-b105-b0265ca5779e,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-a84d82dc-d8bd-47ac-9e6c-b6f02a0e52a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-fc8ec623-f9e6-4e4c-a546-a18e8701a8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-038106df-1115-40a5-a420-e37d3e567215,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-61b7525b-ade2-4220-b966-0b2611059d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-61ddbe6f-6063-421c-9a81-ed9c935b388f,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-26933c74-a55c-4b55-a5ce-65133787d1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-6f98af66-b746-471f-a45e-1e27800dbcee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407158187-172.17.0.4-1597560894851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-4e8f3be1-169a-42c3-951f-3592f50aec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-1f546309-4d8c-4704-8d45-eb57e60ba0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-d2e12358-bb9f-4a76-8044-7ca8aa58e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-88c705f8-d970-4026-89f7-a0199cdf9916,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-fc4531da-af44-4964-917c-c2289e48ee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-8ef50dae-014f-409e-8646-7f93e0610178,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-d0895ac7-9d81-41cc-b48d-7b1ecc925bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-9649a688-6231-49bc-adb1-9c20e4c3c806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407158187-172.17.0.4-1597560894851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-4e8f3be1-169a-42c3-951f-3592f50aec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-1f546309-4d8c-4704-8d45-eb57e60ba0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-d2e12358-bb9f-4a76-8044-7ca8aa58e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-88c705f8-d970-4026-89f7-a0199cdf9916,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-fc4531da-af44-4964-917c-c2289e48ee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-8ef50dae-014f-409e-8646-7f93e0610178,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-d0895ac7-9d81-41cc-b48d-7b1ecc925bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-9649a688-6231-49bc-adb1-9c20e4c3c806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586942375-172.17.0.4-1597562114841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39705,DS-99b70f48-e915-4ce2-9e49-52f2bd055302,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-ac9fd60e-5350-40bc-9f6f-2538604c308f,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-ada4d046-187b-4544-ab24-456286aa74f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-5aaa6b6e-adb1-47e8-9aea-582e508aa45a,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-d297638e-ecc0-4a4f-889b-abf66e489535,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-d46baf43-4645-4edc-a48d-58d89b0e0801,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-a448bf0d-f7bb-43a3-a821-1c1666a60a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-02913dae-d130-4b8c-b5f5-d35b4420d0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586942375-172.17.0.4-1597562114841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39705,DS-99b70f48-e915-4ce2-9e49-52f2bd055302,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-ac9fd60e-5350-40bc-9f6f-2538604c308f,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-ada4d046-187b-4544-ab24-456286aa74f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-5aaa6b6e-adb1-47e8-9aea-582e508aa45a,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-d297638e-ecc0-4a4f-889b-abf66e489535,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-d46baf43-4645-4edc-a48d-58d89b0e0801,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-a448bf0d-f7bb-43a3-a821-1c1666a60a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-02913dae-d130-4b8c-b5f5-d35b4420d0de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563170582-172.17.0.4-1597562259292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-2aa809c4-4110-487e-9d1e-3db9ca65b6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-42c8e1c5-2c4f-45c5-87c3-88155271363b,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-315646be-75ae-4b9c-9198-88592d80331d,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-edeeaa86-e7c1-48d1-90dd-096a67fa0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-be56247f-77a4-4c55-9505-87b1723316df,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-f4d5bf19-a8f6-464d-9ee5-e53b256a89b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-070c82f5-cc90-41b9-b5a6-def8f582e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-cbf4b01b-0049-450c-a056-af1cb43d2b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563170582-172.17.0.4-1597562259292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-2aa809c4-4110-487e-9d1e-3db9ca65b6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-42c8e1c5-2c4f-45c5-87c3-88155271363b,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-315646be-75ae-4b9c-9198-88592d80331d,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-edeeaa86-e7c1-48d1-90dd-096a67fa0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-be56247f-77a4-4c55-9505-87b1723316df,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-f4d5bf19-a8f6-464d-9ee5-e53b256a89b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-070c82f5-cc90-41b9-b5a6-def8f582e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-cbf4b01b-0049-450c-a056-af1cb43d2b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761979362-172.17.0.4-1597562373638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36628,DS-273810d6-88eb-4e95-a2e9-dfe604c17f55,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-5f3af1c6-a690-4f5c-8d45-5ff15170787f,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-fe176029-28b0-4805-b758-125381fa286d,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-31cdb9bb-0aea-4896-9adc-100af579a725,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-9ce2ff2d-7944-4d95-b0ea-2e34e1eb4b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-a6f24a6a-3524-4222-9c26-fe671d16b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-34e5ccb1-3e68-44d2-800b-504758d6c852,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-0a6d9a49-b664-46e2-8dd4-fb94777817a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761979362-172.17.0.4-1597562373638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36628,DS-273810d6-88eb-4e95-a2e9-dfe604c17f55,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-5f3af1c6-a690-4f5c-8d45-5ff15170787f,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-fe176029-28b0-4805-b758-125381fa286d,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-31cdb9bb-0aea-4896-9adc-100af579a725,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-9ce2ff2d-7944-4d95-b0ea-2e34e1eb4b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-a6f24a6a-3524-4222-9c26-fe671d16b5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-34e5ccb1-3e68-44d2-800b-504758d6c852,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-0a6d9a49-b664-46e2-8dd4-fb94777817a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497831532-172.17.0.4-1597563957707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-0d67d083-ff33-46d0-86ae-081e1d3c843e,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-c4099967-2d03-4c14-a9d7-fff1c16e3792,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-791edc10-5903-410e-b9d8-b3c04f364e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-3a2c1be0-769c-408d-b87a-fb150479ac49,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-f3da0127-49c8-4a79-9cbc-8bb27a438070,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-1303ab1b-8731-49de-a834-9af299afd7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-c58202b3-7076-4f9d-bc50-24a80b944e56,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-29eec0c9-7e2c-4b7c-8d28-f96d5369f9d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497831532-172.17.0.4-1597563957707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36281,DS-0d67d083-ff33-46d0-86ae-081e1d3c843e,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-c4099967-2d03-4c14-a9d7-fff1c16e3792,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-791edc10-5903-410e-b9d8-b3c04f364e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-3a2c1be0-769c-408d-b87a-fb150479ac49,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-f3da0127-49c8-4a79-9cbc-8bb27a438070,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-1303ab1b-8731-49de-a834-9af299afd7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-c58202b3-7076-4f9d-bc50-24a80b944e56,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-29eec0c9-7e2c-4b7c-8d28-f96d5369f9d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116551624-172.17.0.4-1597564165029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-09ac7e5b-8092-4e29-9be3-ffeba7d93c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-b3df357f-e7ab-4e46-b136-564776362ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-75c0cc65-7fe5-4176-8edb-6fce32c48b73,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-0113abe3-ff90-4049-b889-c9af075aef09,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-6afc38c4-5e86-426a-afdc-f36ff8e22d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-aacce2fa-29a6-4fa8-a680-c41f895e0f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-00a9601d-afd8-4aa8-a9dd-87257aa7a4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-871a1e33-86ef-4dd9-a0b1-6f39aaffa911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116551624-172.17.0.4-1597564165029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-09ac7e5b-8092-4e29-9be3-ffeba7d93c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-b3df357f-e7ab-4e46-b136-564776362ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-75c0cc65-7fe5-4176-8edb-6fce32c48b73,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-0113abe3-ff90-4049-b889-c9af075aef09,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-6afc38c4-5e86-426a-afdc-f36ff8e22d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-aacce2fa-29a6-4fa8-a680-c41f895e0f30,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-00a9601d-afd8-4aa8-a9dd-87257aa7a4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-871a1e33-86ef-4dd9-a0b1-6f39aaffa911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827599476-172.17.0.4-1597564238994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40794,DS-12b888d4-e7fb-40cc-a0f6-7dceb042f05f,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-5610f251-16c5-433d-aaef-45e5dd5f2345,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-aac5c66e-002c-40e6-b584-1a2fa42fe751,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-9296ae01-a4e5-4945-a43a-504d12311401,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-10df6989-eb93-4804-a174-3d97d5554e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-c6b17289-22ea-463b-9f14-721122b6cfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-dcc7eba7-8784-49c2-8b5a-bf633098e555,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-039e7daf-339a-4adf-9c85-30026a25e302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827599476-172.17.0.4-1597564238994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40794,DS-12b888d4-e7fb-40cc-a0f6-7dceb042f05f,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-5610f251-16c5-433d-aaef-45e5dd5f2345,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-aac5c66e-002c-40e6-b584-1a2fa42fe751,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-9296ae01-a4e5-4945-a43a-504d12311401,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-10df6989-eb93-4804-a174-3d97d5554e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-c6b17289-22ea-463b-9f14-721122b6cfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-dcc7eba7-8784-49c2-8b5a-bf633098e555,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-039e7daf-339a-4adf-9c85-30026a25e302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697962059-172.17.0.4-1597564553838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39112,DS-6afbb03f-1890-4173-9298-32f08f7f9acf,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-05e3ee5f-fc24-448b-ae19-74a4d3396914,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-0275e8a5-7be5-44e8-b776-7d3f0792ecef,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-ff43eb8d-7bb7-4b68-8725-662a320f6ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-998e7b9e-5843-4e53-a037-366e4b2d3b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-f3456bf9-e1da-4888-bed9-e2fdb2b020f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-fef8ebc3-3e9e-4349-8e54-02186448374c,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-e565b116-d6fb-4e23-99bd-cf99429857b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697962059-172.17.0.4-1597564553838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39112,DS-6afbb03f-1890-4173-9298-32f08f7f9acf,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-05e3ee5f-fc24-448b-ae19-74a4d3396914,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-0275e8a5-7be5-44e8-b776-7d3f0792ecef,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-ff43eb8d-7bb7-4b68-8725-662a320f6ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-998e7b9e-5843-4e53-a037-366e4b2d3b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-f3456bf9-e1da-4888-bed9-e2fdb2b020f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-fef8ebc3-3e9e-4349-8e54-02186448374c,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-e565b116-d6fb-4e23-99bd-cf99429857b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917952290-172.17.0.4-1597564587776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-a65b3285-3974-41cc-8fec-3253aae78003,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-668acc9f-19e1-423f-941a-0b11b506c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-2b9aba62-a03e-48bf-9d24-6e3ab97978ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-e553a6a4-fd8a-488e-865a-19a08b492237,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-e2dc30e4-6f50-4009-a3a3-fb20adcdf6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-76d3fafd-0b2a-4999-ba6f-47d444dc326b,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-dd8c7845-b52d-4eab-98dc-02c0d850e245,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-8a378dd0-f0dc-4dee-9aaf-2c3e52db9ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917952290-172.17.0.4-1597564587776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-a65b3285-3974-41cc-8fec-3253aae78003,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-668acc9f-19e1-423f-941a-0b11b506c75d,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-2b9aba62-a03e-48bf-9d24-6e3ab97978ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-e553a6a4-fd8a-488e-865a-19a08b492237,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-e2dc30e4-6f50-4009-a3a3-fb20adcdf6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-76d3fafd-0b2a-4999-ba6f-47d444dc326b,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-dd8c7845-b52d-4eab-98dc-02c0d850e245,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-8a378dd0-f0dc-4dee-9aaf-2c3e52db9ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5727
