reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058336322-172.17.0.13-1597281965687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-b714ce66-1d59-4f4b-b93c-58a93a03e11a,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-b529c545-d1bb-425f-96fd-90c1e3927ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-131879a9-c324-4113-967e-a32905805b73,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-ab4fbeed-72ab-4ff1-9c0c-7a0b5ed822f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-94a7876d-a80f-4ff1-852f-ab7643d20870,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-6aebea55-0204-4dc2-83ca-4c20d671ef03,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-28182c49-d8c9-4217-aed3-88fa02541e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-9507673b-1d27-4d49-9ec2-8610d455747c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058336322-172.17.0.13-1597281965687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-b714ce66-1d59-4f4b-b93c-58a93a03e11a,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-b529c545-d1bb-425f-96fd-90c1e3927ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-131879a9-c324-4113-967e-a32905805b73,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-ab4fbeed-72ab-4ff1-9c0c-7a0b5ed822f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-94a7876d-a80f-4ff1-852f-ab7643d20870,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-6aebea55-0204-4dc2-83ca-4c20d671ef03,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-28182c49-d8c9-4217-aed3-88fa02541e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-9507673b-1d27-4d49-9ec2-8610d455747c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896292946-172.17.0.13-1597282386787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44546,DS-207b4d3c-32ba-48c4-babb-5aadce3bd74d,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-4db1710d-9035-4b4f-8ecf-65196561d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-1e6c6b70-419b-40c0-85f7-8b0fc7959fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-a3385a0b-2d12-4317-bd59-d147f5adab43,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-8d18c659-fbf1-4054-9b99-e3fd4fcc5dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-a6e123eb-ff01-41f3-9dfd-a3a01707f378,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-69be76ae-69e2-4363-9b5d-564b6979f360,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-9024cdfb-6480-49bc-9934-b5f902a4957f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896292946-172.17.0.13-1597282386787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44546,DS-207b4d3c-32ba-48c4-babb-5aadce3bd74d,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-4db1710d-9035-4b4f-8ecf-65196561d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-1e6c6b70-419b-40c0-85f7-8b0fc7959fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-a3385a0b-2d12-4317-bd59-d147f5adab43,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-8d18c659-fbf1-4054-9b99-e3fd4fcc5dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-a6e123eb-ff01-41f3-9dfd-a3a01707f378,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-69be76ae-69e2-4363-9b5d-564b6979f360,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-9024cdfb-6480-49bc-9934-b5f902a4957f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952080208-172.17.0.13-1597282502059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42966,DS-25969732-d83b-4514-ab54-d1d1d3d57b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-42ecec7f-cfb1-40b9-97af-1dbd64685216,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-048815fe-871a-431d-9c58-c5d708bd1cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-6e64a019-39d9-42fb-8fff-884ae2ea8f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-f24eb77f-6c09-4971-8982-1e47d9b3e40e,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-2f11cab9-c2e3-4933-9961-33735df8e140,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-9a0b0bee-4036-402f-88fa-b40156b2690a,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-8e9063cf-6e30-4058-b29d-2f591fd2d151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952080208-172.17.0.13-1597282502059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42966,DS-25969732-d83b-4514-ab54-d1d1d3d57b04,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-42ecec7f-cfb1-40b9-97af-1dbd64685216,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-048815fe-871a-431d-9c58-c5d708bd1cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-6e64a019-39d9-42fb-8fff-884ae2ea8f98,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-f24eb77f-6c09-4971-8982-1e47d9b3e40e,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-2f11cab9-c2e3-4933-9961-33735df8e140,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-9a0b0bee-4036-402f-88fa-b40156b2690a,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-8e9063cf-6e30-4058-b29d-2f591fd2d151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911432994-172.17.0.13-1597283473876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-2bd632d2-9c2f-4f9a-965d-846fa07627d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-8d703f8b-3bdb-4dff-a610-3eb9ece0a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-1f63d081-7e2f-420b-acf1-3341ca755e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-c2bf2b16-c286-4b52-badb-438321ae8bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-12124735-7035-4ef7-ab7c-cfffd04dc5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-6ca176d0-96a0-4397-b371-fec4d55bc532,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-3480634b-e524-4c6b-9a9f-9f88787eb682,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-c71f46d6-1819-41c8-a743-19742de1a3e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911432994-172.17.0.13-1597283473876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-2bd632d2-9c2f-4f9a-965d-846fa07627d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-8d703f8b-3bdb-4dff-a610-3eb9ece0a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-1f63d081-7e2f-420b-acf1-3341ca755e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-c2bf2b16-c286-4b52-badb-438321ae8bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-12124735-7035-4ef7-ab7c-cfffd04dc5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-6ca176d0-96a0-4397-b371-fec4d55bc532,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-3480634b-e524-4c6b-9a9f-9f88787eb682,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-c71f46d6-1819-41c8-a743-19742de1a3e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7366531-172.17.0.13-1597283552863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46304,DS-3c37cb32-0d71-4f4e-9df4-8a6473d805a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-28084c34-2e34-45df-9938-b56b568d6bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-134c19fb-196b-4378-9e8d-3c80906c4411,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-41f3b8a9-a5e5-402c-b48c-701947444bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-b7241226-7332-4e41-afe1-3cb503221930,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-8697a90b-3f7d-4c75-a9bb-32c5cd4830f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-525f1b88-9d31-459a-84dd-af3bc04fa237,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-96d1c448-d9c8-43a5-8376-638740813a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7366531-172.17.0.13-1597283552863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46304,DS-3c37cb32-0d71-4f4e-9df4-8a6473d805a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-28084c34-2e34-45df-9938-b56b568d6bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-134c19fb-196b-4378-9e8d-3c80906c4411,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-41f3b8a9-a5e5-402c-b48c-701947444bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-b7241226-7332-4e41-afe1-3cb503221930,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-8697a90b-3f7d-4c75-a9bb-32c5cd4830f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-525f1b88-9d31-459a-84dd-af3bc04fa237,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-96d1c448-d9c8-43a5-8376-638740813a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601560002-172.17.0.13-1597283704801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34544,DS-5e3e2946-cab1-416d-ba20-a154ed981fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-afb19fe4-60d4-4ba6-a209-0855d17da5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-c234edaa-650a-419a-a08f-bbebd99e5c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-857e218c-1896-4291-a2ab-5dbabe90c4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-dccb5c26-3b81-4b8d-be8d-797d6ba67bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-317d1ad0-9766-48e3-be22-a16920f1263a,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-f745ebc2-1f04-409f-b62e-92aa428a7b54,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-327dcde8-4cca-4b03-a225-a6d1b7e112c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601560002-172.17.0.13-1597283704801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34544,DS-5e3e2946-cab1-416d-ba20-a154ed981fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-afb19fe4-60d4-4ba6-a209-0855d17da5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-c234edaa-650a-419a-a08f-bbebd99e5c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-857e218c-1896-4291-a2ab-5dbabe90c4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-dccb5c26-3b81-4b8d-be8d-797d6ba67bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-317d1ad0-9766-48e3-be22-a16920f1263a,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-f745ebc2-1f04-409f-b62e-92aa428a7b54,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-327dcde8-4cca-4b03-a225-a6d1b7e112c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585172156-172.17.0.13-1597283942829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-2915640c-b598-4ecf-9374-895569225525,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-3a4c4a65-183d-4688-927b-5b364e87144f,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-debef85e-42f1-424c-a9ef-d2de33a4782d,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-66f02b40-ebf5-498d-84c5-cdfd9a8a3fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-c35543b0-a3ea-42d9-b905-5abcb3916b48,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-f503ac15-36f4-4d02-91e8-fa8de7100e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-b55c8d32-5b34-495c-a399-d1059cf6a2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-e0dcd8ba-eff2-436d-b2d3-f8dcbe50d4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585172156-172.17.0.13-1597283942829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32976,DS-2915640c-b598-4ecf-9374-895569225525,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-3a4c4a65-183d-4688-927b-5b364e87144f,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-debef85e-42f1-424c-a9ef-d2de33a4782d,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-66f02b40-ebf5-498d-84c5-cdfd9a8a3fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-c35543b0-a3ea-42d9-b905-5abcb3916b48,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-f503ac15-36f4-4d02-91e8-fa8de7100e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-b55c8d32-5b34-495c-a399-d1059cf6a2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-e0dcd8ba-eff2-436d-b2d3-f8dcbe50d4f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803032175-172.17.0.13-1597284106190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42574,DS-007dff14-29f7-4bd7-8dc6-7324358eff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-700d9cf0-55a9-4e37-8625-0a26f342d152,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-a8388eeb-c102-47ba-8321-4365d7b1a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-714f794c-7d8b-4c32-a40d-271678999f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-717e7815-def3-426a-91fb-260575cf4840,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-18fe3c40-0750-43ad-82f5-cba371cb92a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-3c7ba38c-4e63-4407-90de-2f15a4e837a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-3906685b-c024-4a10-a058-b229052b1be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803032175-172.17.0.13-1597284106190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42574,DS-007dff14-29f7-4bd7-8dc6-7324358eff2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-700d9cf0-55a9-4e37-8625-0a26f342d152,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-a8388eeb-c102-47ba-8321-4365d7b1a46f,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-714f794c-7d8b-4c32-a40d-271678999f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-717e7815-def3-426a-91fb-260575cf4840,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-18fe3c40-0750-43ad-82f5-cba371cb92a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-3c7ba38c-4e63-4407-90de-2f15a4e837a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-3906685b-c024-4a10-a058-b229052b1be1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801790996-172.17.0.13-1597284378345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-95e67593-6f2c-4e5a-ab02-4d6d1f9dda92,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-695ec7f8-c2c0-4b10-a44c-3fae6023c03e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-bd579092-a7e3-4401-b096-f687490e1097,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-e78a4ccb-dd73-491e-b2e5-2bd83420c401,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-cd0cc3f9-8156-424e-b74f-6160816d8782,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8de35885-f476-4549-81b9-2661dd2a24c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-021fd928-410d-45c4-89ed-01c1084e1469,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-737f6331-ecb5-4fe5-b717-fc9d088e1cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801790996-172.17.0.13-1597284378345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-95e67593-6f2c-4e5a-ab02-4d6d1f9dda92,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-695ec7f8-c2c0-4b10-a44c-3fae6023c03e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-bd579092-a7e3-4401-b096-f687490e1097,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-e78a4ccb-dd73-491e-b2e5-2bd83420c401,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-cd0cc3f9-8156-424e-b74f-6160816d8782,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8de35885-f476-4549-81b9-2661dd2a24c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-021fd928-410d-45c4-89ed-01c1084e1469,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-737f6331-ecb5-4fe5-b717-fc9d088e1cfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814593507-172.17.0.13-1597285217405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35527,DS-e5e39e42-8d5b-47c9-93ae-dbe7483363dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-e05d4761-5a2c-44a4-b428-d096f759e0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-27e17ed2-f980-43fa-ae65-1a37251aac21,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-1a67f17b-f746-416f-8cb0-383cc85e83dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-be82f8dc-7407-4d69-92a9-8aa976f1d8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-f6728bb3-3676-4679-b6d6-f8fd4157fff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-344f2f64-4bc2-4079-966d-e04656f50a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-29493fa4-6fac-4212-add3-8eea4ea562ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814593507-172.17.0.13-1597285217405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35527,DS-e5e39e42-8d5b-47c9-93ae-dbe7483363dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-e05d4761-5a2c-44a4-b428-d096f759e0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-27e17ed2-f980-43fa-ae65-1a37251aac21,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-1a67f17b-f746-416f-8cb0-383cc85e83dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-be82f8dc-7407-4d69-92a9-8aa976f1d8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-f6728bb3-3676-4679-b6d6-f8fd4157fff2,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-344f2f64-4bc2-4079-966d-e04656f50a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-29493fa4-6fac-4212-add3-8eea4ea562ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786971898-172.17.0.13-1597285811672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41492,DS-4e253f0c-8470-426b-a383-e1c0255546ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-f5960f6c-826c-42a3-b538-471d2f8c6922,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-ed819e74-22d3-4358-9b35-51990a3a52fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-9237ff42-9b8d-42b2-9e9e-7db4997a0055,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4d94f176-d873-414b-bc2a-e1210e472195,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-a240a282-68fb-40d9-8bb7-5bd095f3d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-d19df24d-6bd6-4ed6-aced-17925cce6749,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-5c2013ac-f58e-48b2-a45c-551adef1d6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786971898-172.17.0.13-1597285811672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41492,DS-4e253f0c-8470-426b-a383-e1c0255546ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-f5960f6c-826c-42a3-b538-471d2f8c6922,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-ed819e74-22d3-4358-9b35-51990a3a52fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-9237ff42-9b8d-42b2-9e9e-7db4997a0055,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-4d94f176-d873-414b-bc2a-e1210e472195,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-a240a282-68fb-40d9-8bb7-5bd095f3d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-d19df24d-6bd6-4ed6-aced-17925cce6749,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-5c2013ac-f58e-48b2-a45c-551adef1d6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152044008-172.17.0.13-1597286171008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39468,DS-f73e14d5-0a76-42ac-80dc-950ab4b588e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-d0265b4d-3899-42c5-a86f-51479e376714,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-9cc52f3b-983b-4fe3-a51d-258f22bf33ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-5ae761dc-59b4-4049-a920-03c9e30827fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-f00bfd35-d54c-4dd5-9ab0-47ef682e343a,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-fc442064-6fe5-4a77-8e43-3b17bb7f6ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-18265652-25e9-4aa6-946e-66580f826adf,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-4ce3838f-f49a-47e7-9558-6fff3cdf20cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152044008-172.17.0.13-1597286171008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39468,DS-f73e14d5-0a76-42ac-80dc-950ab4b588e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-d0265b4d-3899-42c5-a86f-51479e376714,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-9cc52f3b-983b-4fe3-a51d-258f22bf33ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-5ae761dc-59b4-4049-a920-03c9e30827fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-f00bfd35-d54c-4dd5-9ab0-47ef682e343a,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-fc442064-6fe5-4a77-8e43-3b17bb7f6ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-18265652-25e9-4aa6-946e-66580f826adf,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-4ce3838f-f49a-47e7-9558-6fff3cdf20cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784280593-172.17.0.13-1597286766228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-f117207a-c16c-4927-a6ab-a866fea0afe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-7a51c0b4-15e7-4aed-a33c-dd02744de3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-e4b228d9-684f-43de-b507-aa6b995e4073,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-c14da2f4-d044-4cd9-b588-6f2386591d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-2d0a54f4-080d-47cd-8f4d-88b79ecc934e,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-4b99fc0a-17de-4988-8730-36d7cd664207,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-00e40c8f-b99d-40e3-a435-6b9b45b30284,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-8a390352-659b-430f-841f-33c138e41bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784280593-172.17.0.13-1597286766228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-f117207a-c16c-4927-a6ab-a866fea0afe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-7a51c0b4-15e7-4aed-a33c-dd02744de3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-e4b228d9-684f-43de-b507-aa6b995e4073,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-c14da2f4-d044-4cd9-b588-6f2386591d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-2d0a54f4-080d-47cd-8f4d-88b79ecc934e,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-4b99fc0a-17de-4988-8730-36d7cd664207,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-00e40c8f-b99d-40e3-a435-6b9b45b30284,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-8a390352-659b-430f-841f-33c138e41bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664309298-172.17.0.13-1597286958048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33131,DS-0f849a44-54c7-4b34-b48a-41d93027fa32,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-32214cc9-dbfe-4caf-825c-577216c400fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-17e6d905-7207-4022-8849-1e86ce07bbec,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-4a3634f2-f837-4137-adce-8e0021a44c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-58fd527a-a33f-4129-a9f8-fdd383fd9125,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-a1a07a77-bd3d-4e27-8d1e-276ad74ffa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-ee3910f6-47a6-4037-84e9-2055b7e03054,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-840ae835-9568-427b-9f65-181162670795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664309298-172.17.0.13-1597286958048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33131,DS-0f849a44-54c7-4b34-b48a-41d93027fa32,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-32214cc9-dbfe-4caf-825c-577216c400fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-17e6d905-7207-4022-8849-1e86ce07bbec,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-4a3634f2-f837-4137-adce-8e0021a44c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-58fd527a-a33f-4129-a9f8-fdd383fd9125,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-a1a07a77-bd3d-4e27-8d1e-276ad74ffa7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-ee3910f6-47a6-4037-84e9-2055b7e03054,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-840ae835-9568-427b-9f65-181162670795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82988922-172.17.0.13-1597287204253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-6445f5f9-799b-436c-b19f-0e82a44037c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-85e11308-6b65-491a-9e4a-a59dde03d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-ae77e9f7-3e3e-4909-b968-d44f181fb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-26210c59-6e57-40c1-a32d-43a25c970e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-b8c19e6c-39a3-4bfd-a049-89ba8e0d6a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-0907bfea-f39b-41fd-bdda-1c7519769324,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-c1a78df2-a58c-4339-b9d8-6c6475355ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-9621a39d-5c7f-4c0a-9d1e-e3e829939bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82988922-172.17.0.13-1597287204253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-6445f5f9-799b-436c-b19f-0e82a44037c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-85e11308-6b65-491a-9e4a-a59dde03d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-ae77e9f7-3e3e-4909-b968-d44f181fb4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-26210c59-6e57-40c1-a32d-43a25c970e25,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-b8c19e6c-39a3-4bfd-a049-89ba8e0d6a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-0907bfea-f39b-41fd-bdda-1c7519769324,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-c1a78df2-a58c-4339-b9d8-6c6475355ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-9621a39d-5c7f-4c0a-9d1e-e3e829939bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75904997-172.17.0.13-1597287350954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44984,DS-df40827d-d805-4625-be00-e1d3af9200ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-4a2571d8-2b1f-438f-9f45-2b4d77e63e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-af7687a1-3758-4dc8-81f9-623cc7c25a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-25e408c1-3f1c-4408-89b8-7121bbb56b32,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-13702adc-4135-4a4e-abf1-52703d447dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-1634e753-273d-4970-af62-1ae716b0b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-8a1b6fea-6e31-4afc-875b-a440ba9488db,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-d843a41e-3317-4d71-82d3-54ea2fc8d8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75904997-172.17.0.13-1597287350954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44984,DS-df40827d-d805-4625-be00-e1d3af9200ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-4a2571d8-2b1f-438f-9f45-2b4d77e63e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-af7687a1-3758-4dc8-81f9-623cc7c25a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-25e408c1-3f1c-4408-89b8-7121bbb56b32,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-13702adc-4135-4a4e-abf1-52703d447dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-1634e753-273d-4970-af62-1ae716b0b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-8a1b6fea-6e31-4afc-875b-a440ba9488db,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-d843a41e-3317-4d71-82d3-54ea2fc8d8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5763
