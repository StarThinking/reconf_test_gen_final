reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252844481-172.17.0.19-1597289726834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-e9fc5473-abd3-40c5-93f7-bf0d5748d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-80a46e7f-fa2b-4c03-b81b-184f98af2917,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-dea907d0-fa2e-44e2-913c-9ad2f5194341,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-295e0b0d-eb4a-4e8b-b87d-9276132a5834,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-c501604a-7f6d-4cc5-b5fa-75a8319320ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-2a20cf85-016a-4456-af48-8eb8aa5ce5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-3000cb1a-6a67-4ef0-92cf-db2bcfdc2248,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-49468fee-a18e-41ce-be61-e8b86e899b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252844481-172.17.0.19-1597289726834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-e9fc5473-abd3-40c5-93f7-bf0d5748d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-80a46e7f-fa2b-4c03-b81b-184f98af2917,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-dea907d0-fa2e-44e2-913c-9ad2f5194341,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-295e0b0d-eb4a-4e8b-b87d-9276132a5834,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-c501604a-7f6d-4cc5-b5fa-75a8319320ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-2a20cf85-016a-4456-af48-8eb8aa5ce5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-3000cb1a-6a67-4ef0-92cf-db2bcfdc2248,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-49468fee-a18e-41ce-be61-e8b86e899b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173580134-172.17.0.19-1597289800908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45958,DS-48b9a9ab-9c02-4491-b1ab-ef12d0539b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-7c41b2ad-5ee6-4177-8281-e2526f42aed5,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-6ba040fe-70c2-4ce7-89a4-63c12a039387,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-0d32f256-840a-400b-aea3-8923a888279c,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-0ca2f9d1-59b4-436d-9708-24205f7ec280,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-b2f77150-b8ff-4585-b87c-6d9aab441f46,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-75999642-fc86-4e12-b20a-786df1569396,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-cb6bed32-312b-4bdd-a63f-9e3528e706b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173580134-172.17.0.19-1597289800908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45958,DS-48b9a9ab-9c02-4491-b1ab-ef12d0539b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-7c41b2ad-5ee6-4177-8281-e2526f42aed5,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-6ba040fe-70c2-4ce7-89a4-63c12a039387,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-0d32f256-840a-400b-aea3-8923a888279c,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-0ca2f9d1-59b4-436d-9708-24205f7ec280,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-b2f77150-b8ff-4585-b87c-6d9aab441f46,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-75999642-fc86-4e12-b20a-786df1569396,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-cb6bed32-312b-4bdd-a63f-9e3528e706b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018086239-172.17.0.19-1597290125803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-bbc3b55b-a34e-4e0c-9ac3-5bccebd0a520,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-00f0ec89-caed-43b7-9e6d-1537a6544ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-8641fa47-e327-4f4d-bcc4-925ad93f9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-8825be89-2486-4754-8b9a-002b1593bfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-fc52448b-87ce-4c12-a1e4-221d3a7972cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-c9503fb2-8aa6-4340-8c2b-2c4f23e5f195,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-d5ce6094-4a32-4cb6-9ed0-32bee135a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-f1aa4308-5a5e-4ca0-a3f8-c033f5c2b491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018086239-172.17.0.19-1597290125803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-bbc3b55b-a34e-4e0c-9ac3-5bccebd0a520,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-00f0ec89-caed-43b7-9e6d-1537a6544ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-8641fa47-e327-4f4d-bcc4-925ad93f9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-8825be89-2486-4754-8b9a-002b1593bfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-fc52448b-87ce-4c12-a1e4-221d3a7972cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-c9503fb2-8aa6-4340-8c2b-2c4f23e5f195,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-d5ce6094-4a32-4cb6-9ed0-32bee135a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-f1aa4308-5a5e-4ca0-a3f8-c033f5c2b491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246045805-172.17.0.19-1597290352462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44113,DS-95c71567-32e4-45df-84d3-ab417ca8db32,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-31294bdd-9b5d-4c25-b37a-a0873e3ddb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-d74e1900-8d0a-44d7-a1fd-211752e9ccea,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-54e10dc0-eacc-4a98-9831-2d056f8ebd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-b095999b-df1f-417c-9e70-276656462863,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-23994650-e2a8-417c-bfc5-82cb44b7afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-0d9e35b6-c16c-4faf-bfde-108287b4afed,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-0ac8f486-e4f3-4ed2-825f-83b4f0dbcb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246045805-172.17.0.19-1597290352462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44113,DS-95c71567-32e4-45df-84d3-ab417ca8db32,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-31294bdd-9b5d-4c25-b37a-a0873e3ddb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-d74e1900-8d0a-44d7-a1fd-211752e9ccea,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-54e10dc0-eacc-4a98-9831-2d056f8ebd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-b095999b-df1f-417c-9e70-276656462863,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-23994650-e2a8-417c-bfc5-82cb44b7afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-0d9e35b6-c16c-4faf-bfde-108287b4afed,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-0ac8f486-e4f3-4ed2-825f-83b4f0dbcb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562423514-172.17.0.19-1597290385828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-6281d3c3-1b96-4ec5-bc7e-6a112e91c616,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-ee6cf0ad-85dd-4787-8685-a7dccf698658,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-faacd41b-b8cd-41e9-b543-09bf61b81c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-3c0f4e6f-0451-41c1-965e-18cd7073c027,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-e50ce2ab-40b3-4aee-92c0-c2be4ded805d,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-7738add8-4e2b-45b6-98f2-6a8addd6d429,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-ff6282e9-013f-40ec-942d-7f6885b62253,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-e5958999-5765-4da3-a0f9-a5a174d761e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562423514-172.17.0.19-1597290385828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34648,DS-6281d3c3-1b96-4ec5-bc7e-6a112e91c616,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-ee6cf0ad-85dd-4787-8685-a7dccf698658,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-faacd41b-b8cd-41e9-b543-09bf61b81c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-3c0f4e6f-0451-41c1-965e-18cd7073c027,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-e50ce2ab-40b3-4aee-92c0-c2be4ded805d,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-7738add8-4e2b-45b6-98f2-6a8addd6d429,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-ff6282e9-013f-40ec-942d-7f6885b62253,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-e5958999-5765-4da3-a0f9-a5a174d761e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545252626-172.17.0.19-1597290459816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-101af3e1-bf58-4fdb-b594-7cc20d282a82,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-a52e0566-cb41-421e-8d18-b4042f6a6206,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-9d978258-9dba-43eb-a237-7c18dafdef77,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-c9c34bdf-2ef8-4903-b3af-97b7232257a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-53cb720f-a7e1-4625-b839-277f25a7dbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-59f461a6-cdc9-4a15-b814-2df7e5a18956,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-505d4364-8f42-4b17-95a5-6dd0e606b761,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-95664c1d-9fc5-492e-9280-10898fb7b7e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545252626-172.17.0.19-1597290459816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-101af3e1-bf58-4fdb-b594-7cc20d282a82,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-a52e0566-cb41-421e-8d18-b4042f6a6206,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-9d978258-9dba-43eb-a237-7c18dafdef77,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-c9c34bdf-2ef8-4903-b3af-97b7232257a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-53cb720f-a7e1-4625-b839-277f25a7dbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-59f461a6-cdc9-4a15-b814-2df7e5a18956,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-505d4364-8f42-4b17-95a5-6dd0e606b761,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-95664c1d-9fc5-492e-9280-10898fb7b7e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862884963-172.17.0.19-1597291039605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41950,DS-06c13adb-493a-4071-9f15-98860037a98f,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-91c84a78-9c37-4f4d-8e4f-a14f43e5cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-9587511a-71fc-43ec-981a-ae87ea748cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-b6a9a6ba-0de5-4e9b-a227-cca3c10bfc94,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-13235894-3564-4372-ab3c-3ee343240f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-ca58317f-8dcf-4848-a7d3-724f53765db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-3fa45552-fc2e-4533-9074-ff7db1903c68,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-d8d60bae-3e15-4332-bae8-d0cf702f56bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862884963-172.17.0.19-1597291039605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41950,DS-06c13adb-493a-4071-9f15-98860037a98f,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-91c84a78-9c37-4f4d-8e4f-a14f43e5cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-9587511a-71fc-43ec-981a-ae87ea748cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-b6a9a6ba-0de5-4e9b-a227-cca3c10bfc94,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-13235894-3564-4372-ab3c-3ee343240f21,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-ca58317f-8dcf-4848-a7d3-724f53765db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-3fa45552-fc2e-4533-9074-ff7db1903c68,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-d8d60bae-3e15-4332-bae8-d0cf702f56bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300633323-172.17.0.19-1597291219455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-a4f4c63d-65dd-4e79-a103-c92c677dd845,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-ac3c2627-6aca-4af1-b8c8-eccab1a73dec,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-82f1142c-c27a-437d-a8c4-5e0ffffe779a,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-cc5fa34f-8c20-4b55-ad1a-0c6c5458ece4,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-8c955355-4e19-4c91-884d-2ca07b097b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-6dc8426e-31a3-4173-bdf3-9483febe49dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-c5b9e4fb-ca2e-4c3c-a4a1-4a17c8d1589e,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-18f044c4-f0f7-4145-b37c-15d5db6157b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300633323-172.17.0.19-1597291219455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-a4f4c63d-65dd-4e79-a103-c92c677dd845,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-ac3c2627-6aca-4af1-b8c8-eccab1a73dec,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-82f1142c-c27a-437d-a8c4-5e0ffffe779a,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-cc5fa34f-8c20-4b55-ad1a-0c6c5458ece4,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-8c955355-4e19-4c91-884d-2ca07b097b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-6dc8426e-31a3-4173-bdf3-9483febe49dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-c5b9e4fb-ca2e-4c3c-a4a1-4a17c8d1589e,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-18f044c4-f0f7-4145-b37c-15d5db6157b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608139125-172.17.0.19-1597291368924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35882,DS-6ce7c9cb-ef30-4e98-b461-dfd9d8b986ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-e8b543ea-9278-4417-8f12-08900860b342,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-a40829d5-7af3-4c0a-832c-1d37549f6947,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-6a8d9808-2b07-4048-aead-cbe919ed531f,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-812c448a-56dd-44dd-bfb3-58695ee2820b,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-727bfb6f-2b3b-4cd4-a2a0-ce6dfe1514e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-d158dfea-6083-46b6-9693-64c9a3a8a394,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-a9a45908-2b65-42ae-a411-ffacf9a8044d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608139125-172.17.0.19-1597291368924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35882,DS-6ce7c9cb-ef30-4e98-b461-dfd9d8b986ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-e8b543ea-9278-4417-8f12-08900860b342,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-a40829d5-7af3-4c0a-832c-1d37549f6947,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-6a8d9808-2b07-4048-aead-cbe919ed531f,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-812c448a-56dd-44dd-bfb3-58695ee2820b,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-727bfb6f-2b3b-4cd4-a2a0-ce6dfe1514e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-d158dfea-6083-46b6-9693-64c9a3a8a394,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-a9a45908-2b65-42ae-a411-ffacf9a8044d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040004934-172.17.0.19-1597291586605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-4821bfa6-6a92-4617-9732-4c0e311a70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-c0837c9e-6ed7-4bd8-b282-b9ae8981eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-9dc18fdb-a975-4991-86f6-b3b870dc8f13,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-f8fe322a-1379-4356-8e0a-dd9b4114837b,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-f83090b8-f55c-4ade-a735-d3f847e87fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-e34550a8-c01f-4dc7-a097-d3b2767273ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-b95ea4c0-62da-49b0-a237-981a35b03cba,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-0803ee56-a550-430a-aa71-ae3664266499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040004934-172.17.0.19-1597291586605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-4821bfa6-6a92-4617-9732-4c0e311a70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-c0837c9e-6ed7-4bd8-b282-b9ae8981eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-9dc18fdb-a975-4991-86f6-b3b870dc8f13,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-f8fe322a-1379-4356-8e0a-dd9b4114837b,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-f83090b8-f55c-4ade-a735-d3f847e87fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-e34550a8-c01f-4dc7-a097-d3b2767273ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-b95ea4c0-62da-49b0-a237-981a35b03cba,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-0803ee56-a550-430a-aa71-ae3664266499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866619381-172.17.0.19-1597291726880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-e1a2e4c7-1f82-4e23-ab98-b4eeabaa0562,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-5ed61d41-9d72-4c53-a83e-3affe55e7d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-148ff8ec-65bc-4ca4-ab2b-503c31e295ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-0d9dd2d8-d95b-47df-aec1-084ff60648c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-4366c3cd-4f24-4c01-982f-0dfbb16c1eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-41b8b9d7-738f-4849-a988-2b67a2a6da98,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-74c21e1a-3400-44b9-a82d-bd1282701270,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-a8bf05ba-40e8-45da-8129-8b3b484bd361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-866619381-172.17.0.19-1597291726880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-e1a2e4c7-1f82-4e23-ab98-b4eeabaa0562,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-5ed61d41-9d72-4c53-a83e-3affe55e7d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-148ff8ec-65bc-4ca4-ab2b-503c31e295ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-0d9dd2d8-d95b-47df-aec1-084ff60648c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-4366c3cd-4f24-4c01-982f-0dfbb16c1eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-41b8b9d7-738f-4849-a988-2b67a2a6da98,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-74c21e1a-3400-44b9-a82d-bd1282701270,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-a8bf05ba-40e8-45da-8129-8b3b484bd361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738771619-172.17.0.19-1597291758948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35690,DS-5ce5da32-b9d7-4402-8018-3733b1b644da,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-5e80807d-47f0-4bbf-a58d-998b57cc80fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-6a66a041-6050-4381-8a5f-b85fa7d9260a,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-95da25eb-abbc-447d-8fb4-0816c27e362e,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-17d3d1c9-b92a-492b-a01e-9ffdbb92d440,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-453f1907-495b-4efc-983b-ce780c5cabcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-61dea05e-bb5a-4296-8dab-ac43ed35206e,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-07e773d5-3786-4df4-baa1-57bd74076022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1738771619-172.17.0.19-1597291758948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35690,DS-5ce5da32-b9d7-4402-8018-3733b1b644da,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-5e80807d-47f0-4bbf-a58d-998b57cc80fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-6a66a041-6050-4381-8a5f-b85fa7d9260a,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-95da25eb-abbc-447d-8fb4-0816c27e362e,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-17d3d1c9-b92a-492b-a01e-9ffdbb92d440,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-453f1907-495b-4efc-983b-ce780c5cabcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-61dea05e-bb5a-4296-8dab-ac43ed35206e,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-07e773d5-3786-4df4-baa1-57bd74076022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189789170-172.17.0.19-1597291835963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46277,DS-bc06bfa0-65e2-485e-8bf2-239186501b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-2b82c1c0-962e-476b-83f2-699e14391a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-eb371eaa-58d4-496b-8ae2-03bf50bd05f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-49787d65-399d-4e04-9b6a-74cfb93a50a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-6d41f4df-96b0-4220-960f-f98a819dee51,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-d989803b-5e69-4117-a037-88e8c8ac7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-ce0b62c5-8775-4476-ad90-52cb4bea4d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-486e8a6f-7bd9-4c8d-8f08-d6f54e7fc5fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189789170-172.17.0.19-1597291835963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46277,DS-bc06bfa0-65e2-485e-8bf2-239186501b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-2b82c1c0-962e-476b-83f2-699e14391a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-eb371eaa-58d4-496b-8ae2-03bf50bd05f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-49787d65-399d-4e04-9b6a-74cfb93a50a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-6d41f4df-96b0-4220-960f-f98a819dee51,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-d989803b-5e69-4117-a037-88e8c8ac7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-ce0b62c5-8775-4476-ad90-52cb4bea4d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-486e8a6f-7bd9-4c8d-8f08-d6f54e7fc5fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791799521-172.17.0.19-1597292011062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-04f743c7-36ba-4369-be8b-9ff7a8749b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-a1ba02e7-7a31-4f01-9679-b34f7c704d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-fa73427d-e8a2-4616-8842-4d51aec4f462,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-9b295ac3-c92d-4acb-ac9c-7f9ddac82886,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-1506b7a3-afee-4115-bb9e-7a8c80425428,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-97499673-789a-4c54-8034-47d51ffd4864,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-bb2eca36-aaff-4f25-92c1-e6d874831eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-04ea4490-0bd2-464c-95f1-9dc0ce9272f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791799521-172.17.0.19-1597292011062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-04f743c7-36ba-4369-be8b-9ff7a8749b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-a1ba02e7-7a31-4f01-9679-b34f7c704d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-fa73427d-e8a2-4616-8842-4d51aec4f462,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-9b295ac3-c92d-4acb-ac9c-7f9ddac82886,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-1506b7a3-afee-4115-bb9e-7a8c80425428,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-97499673-789a-4c54-8034-47d51ffd4864,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-bb2eca36-aaff-4f25-92c1-e6d874831eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-04ea4490-0bd2-464c-95f1-9dc0ce9272f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689370995-172.17.0.19-1597292382671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-16f995ac-b3ab-4af2-b8c3-f760705116a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-0807da50-69b9-4dc2-b601-a0cf4780170d,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-7e7bb9f0-a6e5-464f-8b5d-439b053a76c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-7d24a43f-6d02-4e33-8bdf-84f50f4179c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-ebf3f590-bcdc-41b5-beec-de99736a7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-9fa0bbd6-0695-4782-bec2-9eb0ffcf9ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-7484166a-30ed-4cd5-8e76-5f3f68999d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-c71c0803-4ed8-424d-ac99-79324130ee0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689370995-172.17.0.19-1597292382671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-16f995ac-b3ab-4af2-b8c3-f760705116a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-0807da50-69b9-4dc2-b601-a0cf4780170d,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-7e7bb9f0-a6e5-464f-8b5d-439b053a76c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-7d24a43f-6d02-4e33-8bdf-84f50f4179c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-ebf3f590-bcdc-41b5-beec-de99736a7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-9fa0bbd6-0695-4782-bec2-9eb0ffcf9ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-7484166a-30ed-4cd5-8e76-5f3f68999d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-c71c0803-4ed8-424d-ac99-79324130ee0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001455293-172.17.0.19-1597293072338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33606,DS-f2843de3-ba90-4091-a212-5ffcdf903920,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-4b7924f1-a90d-4639-91aa-6809e5b12237,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-d0ba8ec5-a72e-47d8-bf52-8ef9fde2524a,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-9e0a4250-dd3a-4f03-bc70-82979e341b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-ddac3a25-2961-493d-9d90-904eb8cdc8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-78b39bb4-4eeb-4b25-9dba-9340e056ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-0ddc157d-a103-4ed0-8ed3-0a375ec7ba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-0af9527b-b92a-4a25-bfcb-ea17681425f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001455293-172.17.0.19-1597293072338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33606,DS-f2843de3-ba90-4091-a212-5ffcdf903920,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-4b7924f1-a90d-4639-91aa-6809e5b12237,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-d0ba8ec5-a72e-47d8-bf52-8ef9fde2524a,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-9e0a4250-dd3a-4f03-bc70-82979e341b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-ddac3a25-2961-493d-9d90-904eb8cdc8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-78b39bb4-4eeb-4b25-9dba-9340e056ee96,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-0ddc157d-a103-4ed0-8ed3-0a375ec7ba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-0af9527b-b92a-4a25-bfcb-ea17681425f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940197725-172.17.0.19-1597293342514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-63b863f1-3b17-4a62-8295-398c78466649,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-565a4ef5-ba6d-4b24-b3bc-9d698c395567,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-a5a86ff9-c74a-4a5d-b342-45b6b5254684,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-a265e201-5399-482a-908c-0e4d10d227c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-8fcbbe6d-7608-459f-9ed2-f43e0d1f0e87,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-1a5f3064-b529-4ad9-a420-3913b9ea8931,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-caf155c1-e545-4e06-ba94-5e4ba73c9cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-8f3bf5cb-e27b-464d-8f4b-1f17ac075916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940197725-172.17.0.19-1597293342514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40745,DS-63b863f1-3b17-4a62-8295-398c78466649,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-565a4ef5-ba6d-4b24-b3bc-9d698c395567,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-a5a86ff9-c74a-4a5d-b342-45b6b5254684,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-a265e201-5399-482a-908c-0e4d10d227c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-8fcbbe6d-7608-459f-9ed2-f43e0d1f0e87,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-1a5f3064-b529-4ad9-a420-3913b9ea8931,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-caf155c1-e545-4e06-ba94-5e4ba73c9cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-8f3bf5cb-e27b-464d-8f4b-1f17ac075916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5533
