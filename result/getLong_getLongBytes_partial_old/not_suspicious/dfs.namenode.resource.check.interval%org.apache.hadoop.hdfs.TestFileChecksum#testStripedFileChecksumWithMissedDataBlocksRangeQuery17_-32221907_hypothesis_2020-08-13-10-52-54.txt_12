reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579385512-172.17.0.17-1597316027963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42176,DS-dfdcea51-0e8a-49b9-8549-a810b55d3ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-306f6d75-073c-444f-87f3-3c0abcb400e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-c9003345-3fd1-4a5e-b24a-ceb41888d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-1ecd23f5-f816-4bda-b80c-44ce8e0940aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-7acc7862-c3a3-4af0-b32b-9df21f496c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-15729a0c-73f3-4b6a-b732-7912153f6dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-921c2be8-9eb1-4c1c-9722-cbfb8ea11f98,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-ae0009e4-e150-4842-b220-15c9784286d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579385512-172.17.0.17-1597316027963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42176,DS-dfdcea51-0e8a-49b9-8549-a810b55d3ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-306f6d75-073c-444f-87f3-3c0abcb400e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-c9003345-3fd1-4a5e-b24a-ceb41888d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-1ecd23f5-f816-4bda-b80c-44ce8e0940aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-7acc7862-c3a3-4af0-b32b-9df21f496c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-15729a0c-73f3-4b6a-b732-7912153f6dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-921c2be8-9eb1-4c1c-9722-cbfb8ea11f98,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-ae0009e4-e150-4842-b220-15c9784286d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907389361-172.17.0.17-1597316712387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42383,DS-06990662-cd7b-4fc5-941f-f2bb0d5c6913,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-9e0be08f-5806-49f1-bc54-d743345d9df6,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-1ea2ba33-ec6d-4c9d-93d8-ac25eab20a46,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-25db6bdf-569a-445e-a5ea-f00fd4dd5b08,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-07eb9d4b-c9b7-47b3-9759-8e78b1d302b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-40d689d1-470e-4f23-a637-e5844d4f1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-5971fa23-514e-4747-90e2-84a0589bb2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-05d01e97-2c7f-42bc-8f79-a93bc820fdaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907389361-172.17.0.17-1597316712387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42383,DS-06990662-cd7b-4fc5-941f-f2bb0d5c6913,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-9e0be08f-5806-49f1-bc54-d743345d9df6,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-1ea2ba33-ec6d-4c9d-93d8-ac25eab20a46,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-25db6bdf-569a-445e-a5ea-f00fd4dd5b08,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-07eb9d4b-c9b7-47b3-9759-8e78b1d302b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-40d689d1-470e-4f23-a637-e5844d4f1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-5971fa23-514e-4747-90e2-84a0589bb2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-05d01e97-2c7f-42bc-8f79-a93bc820fdaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738398455-172.17.0.17-1597316980489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41888,DS-d48980ed-5296-435f-aee4-c3dda9d4285e,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-d7e68058-0a1c-477a-8c7c-8c4e4ab5d29f,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-99c4cb55-8be8-4033-b4e8-75cd0ed4a9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-32fb7659-062c-400f-a7a6-fa0778d1ad72,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-ebdcf36d-61bf-449a-89d0-52674bc23353,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-513efa41-93f0-4427-b7ce-66a6a0e3b922,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-59b65ca1-c06f-42d9-a8b9-bf74c97e00e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-5701338b-4148-4369-bb0c-743353193896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738398455-172.17.0.17-1597316980489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41888,DS-d48980ed-5296-435f-aee4-c3dda9d4285e,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-d7e68058-0a1c-477a-8c7c-8c4e4ab5d29f,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-99c4cb55-8be8-4033-b4e8-75cd0ed4a9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-32fb7659-062c-400f-a7a6-fa0778d1ad72,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-ebdcf36d-61bf-449a-89d0-52674bc23353,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-513efa41-93f0-4427-b7ce-66a6a0e3b922,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-59b65ca1-c06f-42d9-a8b9-bf74c97e00e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-5701338b-4148-4369-bb0c-743353193896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680145631-172.17.0.17-1597317137287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44870,DS-23a353a2-7dc7-4734-8359-e54a5dd5bd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-33dd79ea-53c1-4f6c-ace2-2ac9a5506b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-9472482f-a94d-4fc7-bbe5-0f2d1ac38dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-10c81b85-b85b-4341-b19f-409b41825514,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-0eb102e3-eb25-4c00-9c21-ef6c726ed14e,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-5a01886e-9755-43dc-b3ee-e9f064cc5df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-16a88d4c-0a3e-4c18-86b4-6e6808b8022f,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-da8aa13c-80eb-4904-89ab-40d2df5cea76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680145631-172.17.0.17-1597317137287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44870,DS-23a353a2-7dc7-4734-8359-e54a5dd5bd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-33dd79ea-53c1-4f6c-ace2-2ac9a5506b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-9472482f-a94d-4fc7-bbe5-0f2d1ac38dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-10c81b85-b85b-4341-b19f-409b41825514,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-0eb102e3-eb25-4c00-9c21-ef6c726ed14e,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-5a01886e-9755-43dc-b3ee-e9f064cc5df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-16a88d4c-0a3e-4c18-86b4-6e6808b8022f,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-da8aa13c-80eb-4904-89ab-40d2df5cea76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763221970-172.17.0.17-1597317217582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34686,DS-79d9a5ae-b824-499c-8f4c-2938170831ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-68da8bdb-af77-4c39-971a-8e7aa9b4e445,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-b4195356-0598-47a7-a651-a30fdb314e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-5253c7d8-5b76-49bc-8683-c297964cf2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-7ddb967b-e3e3-4ca2-83c0-cead74dded89,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-a2af6b81-16cf-4718-9c87-f3e301b5659d,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-2a8478f3-85f6-449a-8c43-c51b92b31fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-8382c94d-f901-45e0-9727-ffaf963a0ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763221970-172.17.0.17-1597317217582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34686,DS-79d9a5ae-b824-499c-8f4c-2938170831ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-68da8bdb-af77-4c39-971a-8e7aa9b4e445,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-b4195356-0598-47a7-a651-a30fdb314e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-5253c7d8-5b76-49bc-8683-c297964cf2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-7ddb967b-e3e3-4ca2-83c0-cead74dded89,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-a2af6b81-16cf-4718-9c87-f3e301b5659d,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-2a8478f3-85f6-449a-8c43-c51b92b31fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-8382c94d-f901-45e0-9727-ffaf963a0ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923985405-172.17.0.17-1597317250292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-a11e2688-8f43-47c8-b6ef-f91fa8dd9958,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-26e51401-1baf-4cf7-8c43-063ae5dee0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-b42abe8a-23a7-4356-b219-1948da2a201d,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-8defa1cf-f306-4737-a7d6-c43bc45b46b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-4a8cbed8-0165-48ec-bd72-2ec426f517df,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-6c543fde-bfcf-4fd2-aa30-ce324a949f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-7863d7f3-1232-40ad-a111-8290a8805fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-8a87335f-f268-4d8a-a013-e445743c0e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923985405-172.17.0.17-1597317250292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-a11e2688-8f43-47c8-b6ef-f91fa8dd9958,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-26e51401-1baf-4cf7-8c43-063ae5dee0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-b42abe8a-23a7-4356-b219-1948da2a201d,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-8defa1cf-f306-4737-a7d6-c43bc45b46b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-4a8cbed8-0165-48ec-bd72-2ec426f517df,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-6c543fde-bfcf-4fd2-aa30-ce324a949f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-7863d7f3-1232-40ad-a111-8290a8805fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-8a87335f-f268-4d8a-a013-e445743c0e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460364657-172.17.0.17-1597317932993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-b569ea2c-b620-4390-9d16-5a9a19c4369a,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-8a19c0c4-bbf0-48a7-814b-4bb3f5183ced,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-9f5707ef-ca6e-4133-8485-b5cc96114e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-d1ff7d28-34ad-4998-8f3a-3037d9ac1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-4a8730f8-91f5-4b56-be25-624739be377b,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-dcdd56ef-bcb0-407f-8747-54a0666307bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-bc73711c-0be0-4c40-95bc-e0230c69c938,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-53533514-b850-474d-acae-f593d2d4ae45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460364657-172.17.0.17-1597317932993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35714,DS-b569ea2c-b620-4390-9d16-5a9a19c4369a,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-8a19c0c4-bbf0-48a7-814b-4bb3f5183ced,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-9f5707ef-ca6e-4133-8485-b5cc96114e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-d1ff7d28-34ad-4998-8f3a-3037d9ac1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-4a8730f8-91f5-4b56-be25-624739be377b,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-dcdd56ef-bcb0-407f-8747-54a0666307bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-bc73711c-0be0-4c40-95bc-e0230c69c938,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-53533514-b850-474d-acae-f593d2d4ae45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684262027-172.17.0.17-1597318127646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-624cb14d-4e08-4fab-83de-2f72106c9d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-ca76d1df-5304-40f5-a6bc-3be7e5318cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-30dd52db-1ccd-40fe-9cc8-e7adf83ceccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-1e8468a2-d832-4dbc-b88f-84394d37fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-2fcc2a9c-4301-4634-835d-3154feb1dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-3c7d65e4-76ca-441e-bc4e-44bd541c49a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-6788c84f-10ee-4201-a04f-8dbd886699b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-b22f127f-f922-481c-9aa2-c2b363de0174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1684262027-172.17.0.17-1597318127646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-624cb14d-4e08-4fab-83de-2f72106c9d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-ca76d1df-5304-40f5-a6bc-3be7e5318cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-30dd52db-1ccd-40fe-9cc8-e7adf83ceccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-1e8468a2-d832-4dbc-b88f-84394d37fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-2fcc2a9c-4301-4634-835d-3154feb1dd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-3c7d65e4-76ca-441e-bc4e-44bd541c49a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-6788c84f-10ee-4201-a04f-8dbd886699b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-b22f127f-f922-481c-9aa2-c2b363de0174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893926034-172.17.0.17-1597318638464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-7d7363c2-0e60-46ff-a839-96f6627e4409,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-56d9ca42-5a7c-4051-b62b-56533e22ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-5b28c117-2d35-436e-97fc-d17995c56806,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-b24bf1aa-37ca-46ba-95d7-346bbb7d7431,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-0d2ea109-b617-41e9-9d91-c0333185ba76,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-da002a15-a7c7-410a-a1e5-cabe79c5f597,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-37d91c01-2fb4-4ecc-b40b-cefa57674e68,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-6180521c-53ed-4d49-a57d-2b66b5cdaadb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893926034-172.17.0.17-1597318638464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-7d7363c2-0e60-46ff-a839-96f6627e4409,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-56d9ca42-5a7c-4051-b62b-56533e22ac57,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-5b28c117-2d35-436e-97fc-d17995c56806,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-b24bf1aa-37ca-46ba-95d7-346bbb7d7431,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-0d2ea109-b617-41e9-9d91-c0333185ba76,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-da002a15-a7c7-410a-a1e5-cabe79c5f597,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-37d91c01-2fb4-4ecc-b40b-cefa57674e68,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-6180521c-53ed-4d49-a57d-2b66b5cdaadb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264361409-172.17.0.17-1597319256488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-58455724-c307-4b18-8173-59beba584201,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-2a662a4f-d10b-45fe-b42a-b4de50ab6da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-a79aa258-8af5-4b59-91e9-f0396390739f,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-73df2e01-aa1d-4e5b-9a76-e6c761c775c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-0d25c5e1-43a7-4066-a736-829bfff255d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-bbf03157-9475-41b1-a994-ff1a8ca41128,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-beb3bceb-c436-4738-aabb-f1f7635dfe81,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-31f2fc15-c289-4297-a56c-168ff3abb2c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264361409-172.17.0.17-1597319256488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-58455724-c307-4b18-8173-59beba584201,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-2a662a4f-d10b-45fe-b42a-b4de50ab6da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-a79aa258-8af5-4b59-91e9-f0396390739f,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-73df2e01-aa1d-4e5b-9a76-e6c761c775c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-0d25c5e1-43a7-4066-a736-829bfff255d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-bbf03157-9475-41b1-a994-ff1a8ca41128,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-beb3bceb-c436-4738-aabb-f1f7635dfe81,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-31f2fc15-c289-4297-a56c-168ff3abb2c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080024535-172.17.0.17-1597319822789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38438,DS-cb09c2a2-09fc-47ae-bd37-c523e9349395,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-46dcef4e-e210-42c9-b1d2-dd5158a944d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-d8eb531c-8f3e-4ffd-ad62-e790f219ec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-6ff7f530-8a24-4cbc-b6fa-c79750e3dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-c03953b1-0a45-48d0-b8b9-eb124e1c8b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-3773bbff-2aa8-43aa-b722-d805154f0b45,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-70e69198-cd0f-4dc9-9920-8ef750c5d994,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-943bbb5d-ce12-44ed-8573-083e321db88f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2080024535-172.17.0.17-1597319822789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38438,DS-cb09c2a2-09fc-47ae-bd37-c523e9349395,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-46dcef4e-e210-42c9-b1d2-dd5158a944d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-d8eb531c-8f3e-4ffd-ad62-e790f219ec2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-6ff7f530-8a24-4cbc-b6fa-c79750e3dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-c03953b1-0a45-48d0-b8b9-eb124e1c8b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-3773bbff-2aa8-43aa-b722-d805154f0b45,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-70e69198-cd0f-4dc9-9920-8ef750c5d994,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-943bbb5d-ce12-44ed-8573-083e321db88f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329067518-172.17.0.17-1597320317047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39089,DS-3589d52e-069d-4d5e-a1c0-f381b67dbc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-8a5e2f94-8950-4140-a874-00a80aab667f,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-d3eab87c-fdb3-434f-82a4-2397434c779f,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-590ab502-c48a-427d-9bc7-81fef8e3cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-09f5166d-c7bf-4dd4-8147-bf77a4530b31,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-11ef5d7f-e324-4a49-9930-be4535b5cf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-60ace06c-86a4-4612-89c0-c63951bff8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-a91acfe4-2afd-4314-81da-6914cd68396c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1329067518-172.17.0.17-1597320317047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39089,DS-3589d52e-069d-4d5e-a1c0-f381b67dbc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-8a5e2f94-8950-4140-a874-00a80aab667f,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-d3eab87c-fdb3-434f-82a4-2397434c779f,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-590ab502-c48a-427d-9bc7-81fef8e3cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-09f5166d-c7bf-4dd4-8147-bf77a4530b31,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-11ef5d7f-e324-4a49-9930-be4535b5cf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-60ace06c-86a4-4612-89c0-c63951bff8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-a91acfe4-2afd-4314-81da-6914cd68396c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133163955-172.17.0.17-1597320426642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-5642b253-c91e-4d20-bb07-aa2890eb34f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-8ab89f89-1ec1-46ff-b699-c2e01789b803,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-914ea4f2-37c2-4c7d-a7e2-9406c5205642,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-bc51d99c-f780-40e8-b565-e31cbecd644e,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-8ad12480-37c5-40a5-8ad7-cc4acb98a7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-6f380484-702d-41f9-a565-2d166621d190,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-8150e295-2e44-4f99-babb-495948cc9728,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-942425aa-7475-468e-973f-cc39f716bad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133163955-172.17.0.17-1597320426642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46041,DS-5642b253-c91e-4d20-bb07-aa2890eb34f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-8ab89f89-1ec1-46ff-b699-c2e01789b803,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-914ea4f2-37c2-4c7d-a7e2-9406c5205642,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-bc51d99c-f780-40e8-b565-e31cbecd644e,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-8ad12480-37c5-40a5-8ad7-cc4acb98a7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-6f380484-702d-41f9-a565-2d166621d190,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-8150e295-2e44-4f99-babb-495948cc9728,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-942425aa-7475-468e-973f-cc39f716bad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7184786-172.17.0.17-1597320497080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-7db614c5-1a2e-42f7-96bc-49e0f4d73134,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-514f2ec0-c429-4302-860e-80b0c3687db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-a0a9ffcc-1e24-410d-870d-3ef3d0f87396,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-1db24a82-267f-485d-abbc-ab3e23260e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-01be42e1-8c2e-4e0c-bdb8-a28b0fd3a5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-d58737e2-bf28-4712-90e3-39bec398179a,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-78e0e65e-9849-4f97-8caf-350526edf866,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-1c77bd4b-c3b4-4ef3-b7b0-46407cc04845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7184786-172.17.0.17-1597320497080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-7db614c5-1a2e-42f7-96bc-49e0f4d73134,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-514f2ec0-c429-4302-860e-80b0c3687db5,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-a0a9ffcc-1e24-410d-870d-3ef3d0f87396,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-1db24a82-267f-485d-abbc-ab3e23260e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-01be42e1-8c2e-4e0c-bdb8-a28b0fd3a5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-d58737e2-bf28-4712-90e3-39bec398179a,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-78e0e65e-9849-4f97-8caf-350526edf866,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-1c77bd4b-c3b4-4ef3-b7b0-46407cc04845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992001891-172.17.0.17-1597320884404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32969,DS-69a172a5-1510-42fe-817e-67568abac052,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-3b6d1cc7-1e82-4aab-ad36-ae4dab415b72,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-1024abbb-96b1-49c4-b01d-c06a002e6068,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-f9251fc4-7858-46d5-a008-a1c98b927ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-33d1b5f4-5da1-4818-9af7-a2a2c5db0e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-bbf0b32e-13f3-48ac-b4a4-9ac0cc8ace15,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-a62abad0-47ee-465d-aa9d-07a9b718c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-2a2f9d77-661d-48bc-9766-bf7a77d41325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992001891-172.17.0.17-1597320884404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32969,DS-69a172a5-1510-42fe-817e-67568abac052,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-3b6d1cc7-1e82-4aab-ad36-ae4dab415b72,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-1024abbb-96b1-49c4-b01d-c06a002e6068,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-f9251fc4-7858-46d5-a008-a1c98b927ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-33d1b5f4-5da1-4818-9af7-a2a2c5db0e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-bbf0b32e-13f3-48ac-b4a4-9ac0cc8ace15,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-a62abad0-47ee-465d-aa9d-07a9b718c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-2a2f9d77-661d-48bc-9766-bf7a77d41325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5648
