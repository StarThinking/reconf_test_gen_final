reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079837178-172.17.0.20-1597274771190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46583,DS-932a3abc-9d2c-4d1e-aebc-8ed82992e6de,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-c66f3e53-470d-4c8a-8543-562163f287b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-724bcf36-8bf3-457b-bebe-f5a52d3901bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-ed7e4b85-59af-4fe6-9b69-cfecca4bb30d,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-317bb569-ba1f-43a5-995a-e6b57d44d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-6f5693a5-9caa-4e75-9950-73494a0a87c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-21350c31-5f89-4abc-8ff8-19aec0eb6766,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-341a3337-000a-434f-ad0f-0f1163f94a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079837178-172.17.0.20-1597274771190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46583,DS-932a3abc-9d2c-4d1e-aebc-8ed82992e6de,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-c66f3e53-470d-4c8a-8543-562163f287b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-724bcf36-8bf3-457b-bebe-f5a52d3901bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-ed7e4b85-59af-4fe6-9b69-cfecca4bb30d,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-317bb569-ba1f-43a5-995a-e6b57d44d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-6f5693a5-9caa-4e75-9950-73494a0a87c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-21350c31-5f89-4abc-8ff8-19aec0eb6766,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-341a3337-000a-434f-ad0f-0f1163f94a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270852671-172.17.0.20-1597274809709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39503,DS-95fb289d-a997-4143-8af9-ca9624ff224b,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-62d5abe4-ecaa-4189-966d-c512f8d4bc42,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-b8b93c6e-d4e2-40ad-8ca5-e6dc342e8ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-6dccd4d6-dbb8-4f23-b6cf-f5e5c756e4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-cb7877c1-639d-4581-9958-47801df362b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-cac9b130-66cf-425b-abc4-849e1b513c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-b568efa4-9cbf-434a-af08-6eb1ac8ef286,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-19499804-beb2-40ab-bbdf-93feaa2f5938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270852671-172.17.0.20-1597274809709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39503,DS-95fb289d-a997-4143-8af9-ca9624ff224b,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-62d5abe4-ecaa-4189-966d-c512f8d4bc42,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-b8b93c6e-d4e2-40ad-8ca5-e6dc342e8ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-6dccd4d6-dbb8-4f23-b6cf-f5e5c756e4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-cb7877c1-639d-4581-9958-47801df362b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-cac9b130-66cf-425b-abc4-849e1b513c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-b568efa4-9cbf-434a-af08-6eb1ac8ef286,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-19499804-beb2-40ab-bbdf-93feaa2f5938,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413233891-172.17.0.20-1597274952284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35631,DS-be5951a6-98c8-4049-b481-a47475cebd38,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-84f56f21-97db-4a0d-9a08-5d2ee5b4152d,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-1bd90db8-d865-4e55-b956-fba19c6a05d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-95ae3b41-e78e-4175-81a5-5a61429a8f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-04aef4fa-4772-48ef-8080-009867bd625d,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-571e99ee-7eb1-4477-aba2-2ccb9ec63df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-a501e064-f09e-4b21-8690-b19036dbf2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-bdfcf196-e33c-4eea-b473-35c190d50f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413233891-172.17.0.20-1597274952284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35631,DS-be5951a6-98c8-4049-b481-a47475cebd38,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-84f56f21-97db-4a0d-9a08-5d2ee5b4152d,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-1bd90db8-d865-4e55-b956-fba19c6a05d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-95ae3b41-e78e-4175-81a5-5a61429a8f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-04aef4fa-4772-48ef-8080-009867bd625d,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-571e99ee-7eb1-4477-aba2-2ccb9ec63df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-a501e064-f09e-4b21-8690-b19036dbf2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-bdfcf196-e33c-4eea-b473-35c190d50f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144099781-172.17.0.20-1597275136877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36416,DS-f64e309f-b410-46a0-bb55-a8e85473cced,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-71220fde-e9bd-40f9-b82f-2a71b0d376c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-e578a976-7806-4a03-bbaa-454849b105ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-5bb66e35-e2a6-4f4a-b0c8-8717f6ae0a93,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-5ab60cec-1d95-4935-94d8-380c8dad2dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-081315cd-af7b-4781-b679-bbd6bf63ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a35ef8a8-3d74-4618-afff-74cdc278a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-affe6be8-1b70-40dd-a2d7-9de213d1c881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144099781-172.17.0.20-1597275136877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36416,DS-f64e309f-b410-46a0-bb55-a8e85473cced,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-71220fde-e9bd-40f9-b82f-2a71b0d376c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-e578a976-7806-4a03-bbaa-454849b105ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-5bb66e35-e2a6-4f4a-b0c8-8717f6ae0a93,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-5ab60cec-1d95-4935-94d8-380c8dad2dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-081315cd-af7b-4781-b679-bbd6bf63ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a35ef8a8-3d74-4618-afff-74cdc278a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-affe6be8-1b70-40dd-a2d7-9de213d1c881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650349084-172.17.0.20-1597275486312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32967,DS-effd52dc-a7f6-483f-b8f0-c52a4e890cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-5173e7ff-688d-4ee6-8f92-95d24ca77136,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-f4fae704-abfe-4838-b6df-0168f34c2d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-aec10996-8974-44e0-8f78-9f15f9ac37a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-982d0db2-2818-48fe-b984-57b39ca92e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-e38036b5-ed89-4a0d-bd0c-0be470a94b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-a91edae8-56a5-471a-8dfd-515bab98ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-4310187d-33d7-4a49-9c35-315bc641ac42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650349084-172.17.0.20-1597275486312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32967,DS-effd52dc-a7f6-483f-b8f0-c52a4e890cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-5173e7ff-688d-4ee6-8f92-95d24ca77136,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-f4fae704-abfe-4838-b6df-0168f34c2d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-aec10996-8974-44e0-8f78-9f15f9ac37a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-982d0db2-2818-48fe-b984-57b39ca92e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-e38036b5-ed89-4a0d-bd0c-0be470a94b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-a91edae8-56a5-471a-8dfd-515bab98ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-4310187d-33d7-4a49-9c35-315bc641ac42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019554066-172.17.0.20-1597275518139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-71cec8fe-181d-4db3-a0be-2b7cee508b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-e9f502eb-de7c-47ae-b1b4-8faf46fb2fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-a11c15f1-063c-45be-92cb-6005464ff5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-7ae46697-250a-4fc9-99cf-646d4f05d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-0c28885b-cd5d-4009-9e6b-7f4913c178ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-21507d4c-5529-4463-9770-09cc8a3af324,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-6d990c3c-1ead-4766-b8c5-5208f4f5052f,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-118ea716-c5dc-4965-9449-ff0a63b9cd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1019554066-172.17.0.20-1597275518139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-71cec8fe-181d-4db3-a0be-2b7cee508b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-e9f502eb-de7c-47ae-b1b4-8faf46fb2fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-a11c15f1-063c-45be-92cb-6005464ff5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-7ae46697-250a-4fc9-99cf-646d4f05d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-0c28885b-cd5d-4009-9e6b-7f4913c178ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-21507d4c-5529-4463-9770-09cc8a3af324,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-6d990c3c-1ead-4766-b8c5-5208f4f5052f,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-118ea716-c5dc-4965-9449-ff0a63b9cd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339143762-172.17.0.20-1597275993408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-153fa1a5-fec3-4224-833a-e7eb18ee90e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-4b1cd483-1b13-4221-a241-8cd7082d5035,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-07d73ea2-bfef-4c05-8483-418193718dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-27f0579f-5827-4ec3-9ee6-22e541ff5483,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-b958cace-1ac7-47b2-a725-54b50e443410,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-6ce14a9d-1034-4dbb-9c4c-4b42172bf079,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-4e6e266e-0edb-4b73-8b7c-414fe5268584,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-adc6bb98-2f23-4df0-995f-8108e28879b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339143762-172.17.0.20-1597275993408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-153fa1a5-fec3-4224-833a-e7eb18ee90e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-4b1cd483-1b13-4221-a241-8cd7082d5035,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-07d73ea2-bfef-4c05-8483-418193718dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-27f0579f-5827-4ec3-9ee6-22e541ff5483,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-b958cace-1ac7-47b2-a725-54b50e443410,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-6ce14a9d-1034-4dbb-9c4c-4b42172bf079,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-4e6e266e-0edb-4b73-8b7c-414fe5268584,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-adc6bb98-2f23-4df0-995f-8108e28879b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238587901-172.17.0.20-1597276029975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-bf2bdc59-2ae5-4f42-9fce-690f1bcd4dff,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-6857bc18-475f-4d2c-882b-b2ca44cff78c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-e037f548-eb0f-4b74-bc30-fb9facf07549,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-1945cfc5-b6de-4837-9d5d-a37dce39b851,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-c8176f34-6553-47f2-b654-96035fc7dae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-0f4d606b-f1ef-4f33-9391-cc105e3c62d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-285537e8-e4ad-4c3f-a463-4c0c3b947232,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-9b163bdb-1d0a-48c7-bc3a-b9d5e1ab30c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-238587901-172.17.0.20-1597276029975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-bf2bdc59-2ae5-4f42-9fce-690f1bcd4dff,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-6857bc18-475f-4d2c-882b-b2ca44cff78c,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-e037f548-eb0f-4b74-bc30-fb9facf07549,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-1945cfc5-b6de-4837-9d5d-a37dce39b851,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-c8176f34-6553-47f2-b654-96035fc7dae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-0f4d606b-f1ef-4f33-9391-cc105e3c62d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-285537e8-e4ad-4c3f-a463-4c0c3b947232,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-9b163bdb-1d0a-48c7-bc3a-b9d5e1ab30c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700780869-172.17.0.20-1597276134129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38928,DS-d8dd5e2b-76cf-45ac-a537-432c5680e702,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-cd75496f-bbdd-444d-b273-330f23b09e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-f59893ed-8a5c-4f51-badf-548c7330ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-ce261cd6-0066-4385-a4f8-6277bf5a5264,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-f318d626-5fd4-41f5-a669-c7e0d8f56aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-132d011b-d284-4d1a-98ba-aee68bc9b68d,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-87a6acd0-1772-43b2-ab4a-c21ddb3fdea9,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-e629871a-5ac0-418a-a4dd-28fd0bf73556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700780869-172.17.0.20-1597276134129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38928,DS-d8dd5e2b-76cf-45ac-a537-432c5680e702,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-cd75496f-bbdd-444d-b273-330f23b09e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-f59893ed-8a5c-4f51-badf-548c7330ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-ce261cd6-0066-4385-a4f8-6277bf5a5264,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-f318d626-5fd4-41f5-a669-c7e0d8f56aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-132d011b-d284-4d1a-98ba-aee68bc9b68d,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-87a6acd0-1772-43b2-ab4a-c21ddb3fdea9,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-e629871a-5ac0-418a-a4dd-28fd0bf73556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078537745-172.17.0.20-1597276215662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-1105d69a-2582-42c7-87c5-2ab46ba894a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-8fc9fffa-3807-4c90-88b5-7df867dc590c,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-687de088-22bf-4067-acec-e581eeaaa5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-197f7ad6-2da2-442e-83e2-39d37389899e,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-e3202eca-1363-4c20-ab32-339ec10163a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-b039214f-01be-42ac-9d5d-2ca4ca246b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-c2dae21b-499c-451f-bfb2-436243777657,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-69b03d72-036d-44b7-901a-6fdfbf61c4a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078537745-172.17.0.20-1597276215662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-1105d69a-2582-42c7-87c5-2ab46ba894a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-8fc9fffa-3807-4c90-88b5-7df867dc590c,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-687de088-22bf-4067-acec-e581eeaaa5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-197f7ad6-2da2-442e-83e2-39d37389899e,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-e3202eca-1363-4c20-ab32-339ec10163a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-b039214f-01be-42ac-9d5d-2ca4ca246b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-c2dae21b-499c-451f-bfb2-436243777657,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-69b03d72-036d-44b7-901a-6fdfbf61c4a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070544459-172.17.0.20-1597276247760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-340da4a5-d913-4d4c-95f3-3d620ff86a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-92a2ea11-5208-44f0-b0dd-4507bcf28f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-ce9bc2e6-8ee7-4cca-8e18-3921a0ef7acc,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-33bf44cc-1114-463f-8308-68ba5c6a9ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-548ccd1b-b894-43b8-ad24-4c00e52a22a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-3fb45e77-6f61-43b2-9a16-ea78e4f22e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-129e7037-762b-4e27-8dc3-8d514307f58a,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-f26cb0dc-0b45-4221-989a-2aabe7afa002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070544459-172.17.0.20-1597276247760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-340da4a5-d913-4d4c-95f3-3d620ff86a26,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-92a2ea11-5208-44f0-b0dd-4507bcf28f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-ce9bc2e6-8ee7-4cca-8e18-3921a0ef7acc,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-33bf44cc-1114-463f-8308-68ba5c6a9ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-548ccd1b-b894-43b8-ad24-4c00e52a22a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-3fb45e77-6f61-43b2-9a16-ea78e4f22e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-129e7037-762b-4e27-8dc3-8d514307f58a,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-f26cb0dc-0b45-4221-989a-2aabe7afa002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603783388-172.17.0.20-1597276322229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46564,DS-021c5f68-e87b-40d7-948d-fa6e9d4a06f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-296454e0-3fd4-4479-940b-a892e4689df2,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4db97e21-1a86-4361-85c7-5c910bb0dd46,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-d867ed10-d946-4f20-ac37-8d100f71e798,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-df6f6b93-4b2c-4de4-b04f-f14a1718a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-6b35ac3c-a301-48f2-ae4c-1573d6ebe55a,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-6d306bed-800c-4866-9210-6c49766a514c,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-b6afbba0-f64c-4244-a327-f967209d5464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603783388-172.17.0.20-1597276322229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46564,DS-021c5f68-e87b-40d7-948d-fa6e9d4a06f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-296454e0-3fd4-4479-940b-a892e4689df2,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-4db97e21-1a86-4361-85c7-5c910bb0dd46,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-d867ed10-d946-4f20-ac37-8d100f71e798,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-df6f6b93-4b2c-4de4-b04f-f14a1718a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-6b35ac3c-a301-48f2-ae4c-1573d6ebe55a,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-6d306bed-800c-4866-9210-6c49766a514c,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-b6afbba0-f64c-4244-a327-f967209d5464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296771-172.17.0.20-1597276363186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34050,DS-84b52604-e91d-44fd-b482-74c8603a79c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-2b3bc96b-c62f-4c22-9be0-3c0912d8d5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-2cb3d551-eb66-4c14-acf3-8949e23e29ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-ff2a6df5-08df-4543-8991-c427d7592246,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-7437429a-4dab-46be-8c07-c1c5df41c234,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-52e4cb32-e198-4433-b9c8-dd7f8f23a311,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-17e97199-1bea-4fda-a1c2-16345e413bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-219112d3-e5e1-4a55-8147-c1f3a11329c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296771-172.17.0.20-1597276363186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34050,DS-84b52604-e91d-44fd-b482-74c8603a79c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-2b3bc96b-c62f-4c22-9be0-3c0912d8d5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-2cb3d551-eb66-4c14-acf3-8949e23e29ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-ff2a6df5-08df-4543-8991-c427d7592246,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-7437429a-4dab-46be-8c07-c1c5df41c234,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-52e4cb32-e198-4433-b9c8-dd7f8f23a311,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-17e97199-1bea-4fda-a1c2-16345e413bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-219112d3-e5e1-4a55-8147-c1f3a11329c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709745666-172.17.0.20-1597277685407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39030,DS-c9795243-c674-461f-95b6-4aca5f94a589,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-1c0c774b-f134-409e-89a4-ac731053cd99,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-377b8af8-1361-4e5c-a819-cf49d104f7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-23eb6e36-099e-44ab-ae06-a9d60d49088d,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-93860f31-505d-4ccb-91cf-d8118e37bdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-be6b0a65-7894-49ae-8905-a3f32b6e21f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-cd5b0e7e-4cef-42f7-9dc0-2c5a3d31a87b,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-4fa68938-1916-4471-8e35-7ecb1992cecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709745666-172.17.0.20-1597277685407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39030,DS-c9795243-c674-461f-95b6-4aca5f94a589,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-1c0c774b-f134-409e-89a4-ac731053cd99,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-377b8af8-1361-4e5c-a819-cf49d104f7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-23eb6e36-099e-44ab-ae06-a9d60d49088d,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-93860f31-505d-4ccb-91cf-d8118e37bdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-be6b0a65-7894-49ae-8905-a3f32b6e21f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-cd5b0e7e-4cef-42f7-9dc0-2c5a3d31a87b,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-4fa68938-1916-4471-8e35-7ecb1992cecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854855807-172.17.0.20-1597277812581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-30c1e582-02ce-4bcf-a7fd-afb3ac28832f,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-9ad87a6c-b05c-4acf-8812-fd2267e7fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-31170fda-fd8b-4a52-bdb0-a8ef88abfac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-6cd2256f-8626-43fc-8e95-48b18afac3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-5ab4bee5-f20d-43b8-a53f-386c1a48cda4,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-09aa21d4-09e1-4442-85d8-a8188b0228a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-2dc2f8fb-2ee5-44d4-af2e-eb75d7c3916d,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-8b8c711d-9f7d-46fd-a897-fd0ca69f4e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854855807-172.17.0.20-1597277812581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44324,DS-30c1e582-02ce-4bcf-a7fd-afb3ac28832f,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-9ad87a6c-b05c-4acf-8812-fd2267e7fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-31170fda-fd8b-4a52-bdb0-a8ef88abfac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-6cd2256f-8626-43fc-8e95-48b18afac3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-5ab4bee5-f20d-43b8-a53f-386c1a48cda4,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-09aa21d4-09e1-4442-85d8-a8188b0228a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-2dc2f8fb-2ee5-44d4-af2e-eb75d7c3916d,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-8b8c711d-9f7d-46fd-a897-fd0ca69f4e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689144427-172.17.0.20-1597278334330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44082,DS-6f5797b5-786c-49c6-b3e2-3f79968f4336,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-56c286a4-ca36-4d15-9bca-7d14eb930246,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-27728525-6b21-4026-9c76-48ecd13fe81d,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-57291576-4662-4d37-b02e-82c770ffe381,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-5a4aef9d-97f7-43be-8d03-68979f1e8bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-4d8be9bd-95fb-4fde-86f5-85f72094a9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-9aa8c04b-a903-4b97-96b6-7ca3681c2053,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-c7449c05-a789-428a-835b-c6a31acd90f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689144427-172.17.0.20-1597278334330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44082,DS-6f5797b5-786c-49c6-b3e2-3f79968f4336,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-56c286a4-ca36-4d15-9bca-7d14eb930246,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-27728525-6b21-4026-9c76-48ecd13fe81d,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-57291576-4662-4d37-b02e-82c770ffe381,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-5a4aef9d-97f7-43be-8d03-68979f1e8bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-4d8be9bd-95fb-4fde-86f5-85f72094a9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-9aa8c04b-a903-4b97-96b6-7ca3681c2053,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-c7449c05-a789-428a-835b-c6a31acd90f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775289750-172.17.0.20-1597278569443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35052,DS-2d80a8cc-48fc-4bc1-8a94-ff59c8a0cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-64302778-3c5a-4e8c-854b-0e8f84e42594,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-9d24609b-9279-4895-a18f-c10ccf45da9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-9203fcbc-f209-4fbc-a58c-6f67ba0bdb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-10afe9cb-7066-4f37-9f98-419e9f330973,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-46fce76b-0b69-4b52-abb7-c5091b39e2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-45a0225f-6ab4-4d8b-9406-46f6875ff85a,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-1543ae6e-3df8-4f4b-ba98-b26a7cd9a18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775289750-172.17.0.20-1597278569443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35052,DS-2d80a8cc-48fc-4bc1-8a94-ff59c8a0cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-64302778-3c5a-4e8c-854b-0e8f84e42594,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-9d24609b-9279-4895-a18f-c10ccf45da9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-9203fcbc-f209-4fbc-a58c-6f67ba0bdb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-10afe9cb-7066-4f37-9f98-419e9f330973,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-46fce76b-0b69-4b52-abb7-c5091b39e2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-45a0225f-6ab4-4d8b-9406-46f6875ff85a,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-1543ae6e-3df8-4f4b-ba98-b26a7cd9a18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698392185-172.17.0.20-1597278609637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-2e2baf19-a89d-4f97-9591-73c4179f102c,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-0d690702-af45-44fb-b640-b46f257d4a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-bd713840-fff0-4ee4-9cf6-3fd1af8b0153,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-d553c209-a64a-49b5-9ec9-b6a05a21eaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-bc703abc-2541-4a46-8080-c2b0f69c7a07,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-a8a4f7a2-e67f-4bac-963c-faef82446b21,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-f70fc90d-8517-4f1c-867a-19edb6aeb0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-5cbb807c-b09c-4b93-b7db-62efc06708e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698392185-172.17.0.20-1597278609637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-2e2baf19-a89d-4f97-9591-73c4179f102c,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-0d690702-af45-44fb-b640-b46f257d4a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-bd713840-fff0-4ee4-9cf6-3fd1af8b0153,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-d553c209-a64a-49b5-9ec9-b6a05a21eaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-bc703abc-2541-4a46-8080-c2b0f69c7a07,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-a8a4f7a2-e67f-4bac-963c-faef82446b21,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-f70fc90d-8517-4f1c-867a-19edb6aeb0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-5cbb807c-b09c-4b93-b7db-62efc06708e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744225218-172.17.0.20-1597278882718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-103466b3-89b7-46ab-bb66-7984f1b50448,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-9e9907da-ff8e-434b-929c-9af5a8400a94,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-6ddf65ce-8928-4a11-8efc-e0b69ffd474f,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-05424023-a396-4d0e-956e-b2fe94a9062a,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-88fc90dd-0aba-490e-9b61-cd54d5438693,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-34f8605a-7a42-4e8e-b789-e03b1a26db8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-7366589f-e7d7-4cd7-bab6-69d71b6e2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-a5fc8fc4-ff0c-4ed0-be54-0777928c652e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744225218-172.17.0.20-1597278882718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46872,DS-103466b3-89b7-46ab-bb66-7984f1b50448,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-9e9907da-ff8e-434b-929c-9af5a8400a94,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-6ddf65ce-8928-4a11-8efc-e0b69ffd474f,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-05424023-a396-4d0e-956e-b2fe94a9062a,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-88fc90dd-0aba-490e-9b61-cd54d5438693,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-34f8605a-7a42-4e8e-b789-e03b1a26db8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-7366589f-e7d7-4cd7-bab6-69d71b6e2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-a5fc8fc4-ff0c-4ed0-be54-0777928c652e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266823830-172.17.0.20-1597279655592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36325,DS-948c65df-38d9-4f4f-996c-1eec5347da15,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-fe32ac1c-d75f-4adf-89be-74026585d217,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-41c9b033-0ba2-40bd-9446-7f8c1f9dbd97,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-b336c5da-b336-4792-bdb1-860967623e62,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-c6e8f3d4-dadc-4154-bafb-e1616ae5936c,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-4282a9e6-92ba-409d-90c7-5a6e412124b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-4033d6be-585a-4977-9ab3-eccecfd30b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-97b12b9d-7467-4103-9f6b-e0a8f34217df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266823830-172.17.0.20-1597279655592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36325,DS-948c65df-38d9-4f4f-996c-1eec5347da15,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-fe32ac1c-d75f-4adf-89be-74026585d217,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-41c9b033-0ba2-40bd-9446-7f8c1f9dbd97,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-b336c5da-b336-4792-bdb1-860967623e62,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-c6e8f3d4-dadc-4154-bafb-e1616ae5936c,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-4282a9e6-92ba-409d-90c7-5a6e412124b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-4033d6be-585a-4977-9ab3-eccecfd30b43,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-97b12b9d-7467-4103-9f6b-e0a8f34217df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704935389-172.17.0.20-1597279733014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45179,DS-cb4cd910-b2d8-420d-9f17-14c16bbb1595,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-8fbc384f-367b-468f-883a-8f40dfb2f8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-7d0c403c-432b-469b-8c29-217504931225,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-65624507-b5a4-44d0-ad5a-719b0d0198b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-0b3ad7fc-7494-4041-9376-9c38b5d4b3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-a0152848-97ab-4186-b024-6644c858b78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-e58423d3-3743-49a8-b1fe-6afedcfb47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-679844b4-9569-4f79-baae-26762a2fcdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704935389-172.17.0.20-1597279733014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45179,DS-cb4cd910-b2d8-420d-9f17-14c16bbb1595,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-8fbc384f-367b-468f-883a-8f40dfb2f8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-7d0c403c-432b-469b-8c29-217504931225,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-65624507-b5a4-44d0-ad5a-719b0d0198b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-0b3ad7fc-7494-4041-9376-9c38b5d4b3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-a0152848-97ab-4186-b024-6644c858b78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-e58423d3-3743-49a8-b1fe-6afedcfb47f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-679844b4-9569-4f79-baae-26762a2fcdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877004154-172.17.0.20-1597279995551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-9c571cfc-445b-4852-a743-ac0435d357b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-037d64d0-1914-4b50-9165-4acb65e1312e,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-27726ccc-70a5-4894-a910-8d6bac3ebf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-69ec79ee-6648-46b0-b780-c6d22179fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-e8ecb3e7-0fa0-49a3-9036-bf5ef2444b55,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-ece5972a-b13a-48a5-b039-38ec9068af71,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-2e475df3-17f0-4ec6-9ad6-fac925a47afd,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-ea23c176-d8e8-4ba2-9a8f-a694ee3dc627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877004154-172.17.0.20-1597279995551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-9c571cfc-445b-4852-a743-ac0435d357b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-037d64d0-1914-4b50-9165-4acb65e1312e,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-27726ccc-70a5-4894-a910-8d6bac3ebf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-69ec79ee-6648-46b0-b780-c6d22179fdea,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-e8ecb3e7-0fa0-49a3-9036-bf5ef2444b55,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-ece5972a-b13a-48a5-b039-38ec9068af71,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-2e475df3-17f0-4ec6-9ad6-fac925a47afd,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-ea23c176-d8e8-4ba2-9a8f-a694ee3dc627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5596
