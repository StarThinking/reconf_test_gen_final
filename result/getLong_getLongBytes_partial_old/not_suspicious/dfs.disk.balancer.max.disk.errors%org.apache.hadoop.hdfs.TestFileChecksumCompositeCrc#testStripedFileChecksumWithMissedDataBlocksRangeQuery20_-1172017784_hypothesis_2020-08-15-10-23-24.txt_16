reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945874040-172.17.0.4-1597487362046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45647,DS-82ec504b-3ba6-4281-a8c4-3918a517d3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-55ba7f45-3cd4-425f-82fc-84a52322cd33,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-f89f80eb-c10d-47a0-a493-1952c02070cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-53ce9b81-d971-4415-9904-97069e3f31e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-7a51aebb-7697-45fa-b0ce-c73b1ba73920,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-f62f8fcd-be05-47bc-844c-482817b63660,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-6b875cab-4ceb-4c9f-bda3-0416a1352adc,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-f665dca8-6e86-4cfc-aa84-520f99bdd757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945874040-172.17.0.4-1597487362046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45647,DS-82ec504b-3ba6-4281-a8c4-3918a517d3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-55ba7f45-3cd4-425f-82fc-84a52322cd33,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-f89f80eb-c10d-47a0-a493-1952c02070cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-53ce9b81-d971-4415-9904-97069e3f31e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-7a51aebb-7697-45fa-b0ce-c73b1ba73920,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-f62f8fcd-be05-47bc-844c-482817b63660,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-6b875cab-4ceb-4c9f-bda3-0416a1352adc,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-f665dca8-6e86-4cfc-aa84-520f99bdd757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599626113-172.17.0.4-1597487404077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-715a3677-8f2e-41fa-bf02-b1df550ce864,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-a7531fcc-83d4-4dea-b75d-257eba378a43,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-de1383c8-f921-4aca-ad1d-d9d1aecb80d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-84e72aa9-eb74-44a1-bf59-3c8d9db0b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-ba71685c-c397-4af2-9220-9a15f3fe127f,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-82f70c40-a8b6-44ee-b7b4-aceea4754b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-70206c7f-5233-4cef-9776-d39886fdbf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-48b39a98-899c-42c1-bdab-f26e27d633f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599626113-172.17.0.4-1597487404077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-715a3677-8f2e-41fa-bf02-b1df550ce864,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-a7531fcc-83d4-4dea-b75d-257eba378a43,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-de1383c8-f921-4aca-ad1d-d9d1aecb80d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-84e72aa9-eb74-44a1-bf59-3c8d9db0b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-ba71685c-c397-4af2-9220-9a15f3fe127f,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-82f70c40-a8b6-44ee-b7b4-aceea4754b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-70206c7f-5233-4cef-9776-d39886fdbf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-48b39a98-899c-42c1-bdab-f26e27d633f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671240037-172.17.0.4-1597487749132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46263,DS-d62fde9d-8149-4824-8aa9-e7c76219dcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-1918f816-3ac0-42c1-9516-7ddd16ca1d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-20a8e9ff-d67f-4cea-9191-3c5cc192f862,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-30051b2f-edd1-429b-beaf-763884315561,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-732c54c8-e8ec-4516-b083-78fb89ee631e,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-f1d942f2-65b7-434a-8a8f-20e9bb8b8d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-632bab9a-9529-49be-a070-ec4632ded130,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-7ea356e6-280f-413a-bf6e-143af8f1b01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671240037-172.17.0.4-1597487749132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46263,DS-d62fde9d-8149-4824-8aa9-e7c76219dcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-1918f816-3ac0-42c1-9516-7ddd16ca1d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-20a8e9ff-d67f-4cea-9191-3c5cc192f862,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-30051b2f-edd1-429b-beaf-763884315561,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-732c54c8-e8ec-4516-b083-78fb89ee631e,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-f1d942f2-65b7-434a-8a8f-20e9bb8b8d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-632bab9a-9529-49be-a070-ec4632ded130,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-7ea356e6-280f-413a-bf6e-143af8f1b01c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734550955-172.17.0.4-1597488435586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-68bbb0f8-9448-42e3-85f1-d69cd5bee780,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-c21a3e3c-a3a3-447c-a58d-0039d49719a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-5e57aa78-30db-45ed-94a2-13e8c88f816c,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-12e3cef4-fc87-4edc-938c-52d8ba98c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-c0209234-f46d-4788-a6d9-bd5d00869192,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-47e63793-9d8b-42eb-b80a-e38787c26455,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-6711aef8-c05e-4d8e-922b-f52295134557,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-8e7092bd-92b9-48fa-bd01-b76784f87128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1734550955-172.17.0.4-1597488435586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-68bbb0f8-9448-42e3-85f1-d69cd5bee780,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-c21a3e3c-a3a3-447c-a58d-0039d49719a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-5e57aa78-30db-45ed-94a2-13e8c88f816c,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-12e3cef4-fc87-4edc-938c-52d8ba98c43a,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-c0209234-f46d-4788-a6d9-bd5d00869192,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-47e63793-9d8b-42eb-b80a-e38787c26455,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-6711aef8-c05e-4d8e-922b-f52295134557,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-8e7092bd-92b9-48fa-bd01-b76784f87128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582675488-172.17.0.4-1597488574678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-cb24ddcf-7b14-4ee1-9e4e-53fe742ffb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-79accfbb-4cde-4cb3-918a-b657336c4f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-433b46db-cecf-41c1-aaf2-1937ef641513,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-18a6c145-100e-4801-9e83-ea1836a45ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-9c05aae1-255e-485c-a962-9afcf0222ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-34695bb8-02d8-4a97-9c39-9c80e65a9a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-13ba1ad8-26f0-4374-b504-7e4d3eabab25,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-9cd8004d-1813-4a63-925b-efcce24bf38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582675488-172.17.0.4-1597488574678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-cb24ddcf-7b14-4ee1-9e4e-53fe742ffb53,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-79accfbb-4cde-4cb3-918a-b657336c4f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-433b46db-cecf-41c1-aaf2-1937ef641513,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-18a6c145-100e-4801-9e83-ea1836a45ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-9c05aae1-255e-485c-a962-9afcf0222ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-34695bb8-02d8-4a97-9c39-9c80e65a9a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-13ba1ad8-26f0-4374-b504-7e4d3eabab25,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-9cd8004d-1813-4a63-925b-efcce24bf38b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648937725-172.17.0.4-1597489111791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-d129e374-e2a7-4e28-a095-e9943f6749d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-163a6510-bd0d-4992-9dc8-95df9271bc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-f139f9ee-8a81-48a4-a346-d9d3beabbdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-bfdb9806-ae8c-4d18-813f-2a95ce3c1e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-1e9ce164-0ba6-4ef0-b10b-927ac7af6961,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-eb0516bb-6869-4a48-b572-d95efa44df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-8c280b89-7e68-4795-9c54-6aab29b3270d,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-f426481e-0486-4333-b616-91b17fdd4b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1648937725-172.17.0.4-1597489111791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-d129e374-e2a7-4e28-a095-e9943f6749d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-163a6510-bd0d-4992-9dc8-95df9271bc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-f139f9ee-8a81-48a4-a346-d9d3beabbdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-bfdb9806-ae8c-4d18-813f-2a95ce3c1e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-1e9ce164-0ba6-4ef0-b10b-927ac7af6961,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-eb0516bb-6869-4a48-b572-d95efa44df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-8c280b89-7e68-4795-9c54-6aab29b3270d,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-f426481e-0486-4333-b616-91b17fdd4b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125158159-172.17.0.4-1597489537114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-6f8b819a-99a0-4ff0-954b-17e250fab814,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-62c0d4be-97b4-4dd8-82bd-dc1e887976a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-d569bd87-9273-4c5d-acd4-bcd7cb9c2fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-60c0c7a9-b53d-4d6f-8dff-86430bec3f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-ea8d241a-f44c-403a-85d3-84efb25a814a,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-c1e54fa1-37a2-463d-b133-cf16c3153aee,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-42e84c63-d106-4815-bf07-b93453173bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-2f78352b-914c-4611-bc20-74fcbcef5487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125158159-172.17.0.4-1597489537114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-6f8b819a-99a0-4ff0-954b-17e250fab814,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-62c0d4be-97b4-4dd8-82bd-dc1e887976a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-d569bd87-9273-4c5d-acd4-bcd7cb9c2fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-60c0c7a9-b53d-4d6f-8dff-86430bec3f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-ea8d241a-f44c-403a-85d3-84efb25a814a,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-c1e54fa1-37a2-463d-b133-cf16c3153aee,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-42e84c63-d106-4815-bf07-b93453173bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-2f78352b-914c-4611-bc20-74fcbcef5487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29881905-172.17.0.4-1597491817685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37523,DS-0da28954-2933-4de9-aa3a-53a68f3c43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-26a8758c-5c4b-4397-b49f-48068ae7c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-3d08d144-04f7-4c93-8124-ad2cc187bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-7400cf50-a5fd-4ed7-ac09-e37a4731b434,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-9f5bf23b-b507-49c6-b74a-7162f491a34b,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-f5cb5768-4ead-424a-9633-39ddd3ce6d30,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-911bd0f3-f152-4bf7-8931-d1310c7f9f87,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-d47a2fa9-1d60-49de-994e-9d64eed34b89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29881905-172.17.0.4-1597491817685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37523,DS-0da28954-2933-4de9-aa3a-53a68f3c43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-26a8758c-5c4b-4397-b49f-48068ae7c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-3d08d144-04f7-4c93-8124-ad2cc187bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-7400cf50-a5fd-4ed7-ac09-e37a4731b434,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-9f5bf23b-b507-49c6-b74a-7162f491a34b,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-f5cb5768-4ead-424a-9633-39ddd3ce6d30,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-911bd0f3-f152-4bf7-8931-d1310c7f9f87,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-d47a2fa9-1d60-49de-994e-9d64eed34b89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100502286-172.17.0.4-1597491856033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-36add3b9-8447-4375-8713-79eb98cd136c,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-e96c1e6f-5406-4f61-b52e-b45793b590ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-ecd8e765-66f9-4f11-be91-7084d44c7faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-6165b80f-2624-4882-b592-497de2f6a941,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-4cb752b4-fb9c-4509-92cd-7906210ccfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-66520fbf-42ef-47b6-8bb3-725159166762,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-55f9aa73-cd70-45f1-943f-40e56bcee570,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-2739e8d6-ddcd-41ee-9df4-10bb068acd08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100502286-172.17.0.4-1597491856033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-36add3b9-8447-4375-8713-79eb98cd136c,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-e96c1e6f-5406-4f61-b52e-b45793b590ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-ecd8e765-66f9-4f11-be91-7084d44c7faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-6165b80f-2624-4882-b592-497de2f6a941,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-4cb752b4-fb9c-4509-92cd-7906210ccfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-66520fbf-42ef-47b6-8bb3-725159166762,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-55f9aa73-cd70-45f1-943f-40e56bcee570,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-2739e8d6-ddcd-41ee-9df4-10bb068acd08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267588409-172.17.0.4-1597491952562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37816,DS-72a9b0ce-ad4f-43f6-b72d-9547f3185e48,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-4b023b81-4eed-4fca-9750-5f9290de952f,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-d4fef493-f48c-4938-8be5-671d43d6ba92,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-c0f5cfe6-d8dc-4b51-84a4-8f211afbecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-f0fdcd3a-f4ee-4796-8a5a-30a155e1c4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-6ee31a6d-b2ab-4835-b430-62d05736eb86,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-4795819f-69bc-42e6-aa90-c90b70198154,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-1accc868-3e34-41c0-83c4-49d28c6a76ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1267588409-172.17.0.4-1597491952562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37816,DS-72a9b0ce-ad4f-43f6-b72d-9547f3185e48,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-4b023b81-4eed-4fca-9750-5f9290de952f,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-d4fef493-f48c-4938-8be5-671d43d6ba92,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-c0f5cfe6-d8dc-4b51-84a4-8f211afbecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-f0fdcd3a-f4ee-4796-8a5a-30a155e1c4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-6ee31a6d-b2ab-4835-b430-62d05736eb86,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-4795819f-69bc-42e6-aa90-c90b70198154,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-1accc868-3e34-41c0-83c4-49d28c6a76ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805131765-172.17.0.4-1597492129583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-01325515-22bd-430c-8233-d84cca066f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-cc2bfd17-3fc7-4a17-9d5a-4a5ad128afa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-43e2afec-edb3-4f40-92e0-6cd7cdfde045,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-0f096582-4153-42c5-9a9b-deeb167fe9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-a79b5b2f-5d8f-4dbe-bbc1-b5eddb6fe333,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-6b22b170-7be6-4f21-aac3-53b76aa8ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-277f0ceb-4399-42bd-8862-726db261320b,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-86d7c203-8950-4eb2-a837-085a048b0b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805131765-172.17.0.4-1597492129583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-01325515-22bd-430c-8233-d84cca066f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-cc2bfd17-3fc7-4a17-9d5a-4a5ad128afa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-43e2afec-edb3-4f40-92e0-6cd7cdfde045,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-0f096582-4153-42c5-9a9b-deeb167fe9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-a79b5b2f-5d8f-4dbe-bbc1-b5eddb6fe333,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-6b22b170-7be6-4f21-aac3-53b76aa8ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-277f0ceb-4399-42bd-8862-726db261320b,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-86d7c203-8950-4eb2-a837-085a048b0b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496854121-172.17.0.4-1597492172251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40754,DS-1c1c75c3-e71c-46c6-81bb-4a50ce7bcc77,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-730be7ec-bab7-4c4a-a67f-3470571692e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-7e15e7dc-b959-4928-b11c-9b9e3f40165e,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-bb7de546-c745-4e36-9caf-66389fe11efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-d0c2deeb-a04d-4f17-8b9c-bb9b4d7a2e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-c06dcf25-4d32-409c-8196-b40020863f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-abed6508-cc44-46d1-8ce7-3941756f4a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-f05205b8-db99-4e81-ba00-5b6224c8facd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496854121-172.17.0.4-1597492172251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40754,DS-1c1c75c3-e71c-46c6-81bb-4a50ce7bcc77,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-730be7ec-bab7-4c4a-a67f-3470571692e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-7e15e7dc-b959-4928-b11c-9b9e3f40165e,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-bb7de546-c745-4e36-9caf-66389fe11efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-d0c2deeb-a04d-4f17-8b9c-bb9b4d7a2e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-c06dcf25-4d32-409c-8196-b40020863f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-abed6508-cc44-46d1-8ce7-3941756f4a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-f05205b8-db99-4e81-ba00-5b6224c8facd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114876218-172.17.0.4-1597492525407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-69633cd5-9400-4b3d-b64c-8adc07eaa152,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-ae755c55-6403-43b0-ac72-d645a0eb1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-a6db32aa-b949-4125-8a96-2e0f14e848bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-077028aa-b4fc-4a44-ac23-536c1e5159b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-f4eb00e4-108a-4488-9285-459541063a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-faf60ff4-9cc9-4adb-bc4d-a9316a046f57,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-1244377a-d260-4006-968e-0c94f23983c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-bc54b429-2955-4f88-8599-3788ae48e0ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1114876218-172.17.0.4-1597492525407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36406,DS-69633cd5-9400-4b3d-b64c-8adc07eaa152,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-ae755c55-6403-43b0-ac72-d645a0eb1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-a6db32aa-b949-4125-8a96-2e0f14e848bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-077028aa-b4fc-4a44-ac23-536c1e5159b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-f4eb00e4-108a-4488-9285-459541063a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-faf60ff4-9cc9-4adb-bc4d-a9316a046f57,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-1244377a-d260-4006-968e-0c94f23983c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-bc54b429-2955-4f88-8599-3788ae48e0ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646596947-172.17.0.4-1597493022107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32873,DS-56e22b0c-463c-401a-8add-64e9c032e289,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-1da1ab31-0f8c-4f8a-ad5f-6b70bb5dbf44,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-ed1003ea-1770-476a-824f-b9711e4262be,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-bb884280-c806-472f-bffb-3c8b36fa98ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-9ccacae7-80f1-4245-baf7-54c6a4f1e43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-0a22fc2f-aeab-4a02-8c7d-24eede858d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-5e95fe30-91bd-4837-92f9-192e05fe0313,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-5e27c419-6826-4b0e-afcb-aba92faa625f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646596947-172.17.0.4-1597493022107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32873,DS-56e22b0c-463c-401a-8add-64e9c032e289,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-1da1ab31-0f8c-4f8a-ad5f-6b70bb5dbf44,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-ed1003ea-1770-476a-824f-b9711e4262be,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-bb884280-c806-472f-bffb-3c8b36fa98ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-9ccacae7-80f1-4245-baf7-54c6a4f1e43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-0a22fc2f-aeab-4a02-8c7d-24eede858d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-5e95fe30-91bd-4837-92f9-192e05fe0313,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-5e27c419-6826-4b0e-afcb-aba92faa625f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784136569-172.17.0.4-1597493189164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42310,DS-08315bcb-2c58-436e-94b3-cc09c8187dff,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-415a60fd-57fc-46b8-ae42-e5579bc22573,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-7bb1b48e-39f8-46fd-8e2a-ddbc3e27c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-6a3c2522-e203-44fd-ad4f-aaf5f4f94a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-71ed88bc-1a54-4aff-8abb-805ee36ffa04,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-3bda16c9-7ef5-4394-aec8-3cf5fa1d72d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-45c081f5-70b2-4fe2-83cc-05144aec8dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-e78fd762-23dd-4632-8d54-17c04b3db6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784136569-172.17.0.4-1597493189164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42310,DS-08315bcb-2c58-436e-94b3-cc09c8187dff,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-415a60fd-57fc-46b8-ae42-e5579bc22573,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-7bb1b48e-39f8-46fd-8e2a-ddbc3e27c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-6a3c2522-e203-44fd-ad4f-aaf5f4f94a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-71ed88bc-1a54-4aff-8abb-805ee36ffa04,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-3bda16c9-7ef5-4394-aec8-3cf5fa1d72d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-45c081f5-70b2-4fe2-83cc-05144aec8dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-e78fd762-23dd-4632-8d54-17c04b3db6af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125913490-172.17.0.4-1597493237555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-14c86f75-4a5d-461c-9450-6d0fdc7eed23,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-80a14f5d-f5d4-4313-bfb7-8008c05d83c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-8d172cfd-e0b1-4d9c-b923-c8ec509a5862,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-e6d4dbab-4859-42a5-82e6-b2cfa8a970f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-156df46f-87fe-49f0-afe6-899b5d4bac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-c5c67d74-5bc9-433d-84cd-403bbf7e4b69,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-917b2720-6060-49be-b229-87e3d1344033,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-6f6322b7-2003-4c05-bfec-9be1c9697a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125913490-172.17.0.4-1597493237555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42756,DS-14c86f75-4a5d-461c-9450-6d0fdc7eed23,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-80a14f5d-f5d4-4313-bfb7-8008c05d83c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-8d172cfd-e0b1-4d9c-b923-c8ec509a5862,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-e6d4dbab-4859-42a5-82e6-b2cfa8a970f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-156df46f-87fe-49f0-afe6-899b5d4bac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-c5c67d74-5bc9-433d-84cd-403bbf7e4b69,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-917b2720-6060-49be-b229-87e3d1344033,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-6f6322b7-2003-4c05-bfec-9be1c9697a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829149191-172.17.0.4-1597493418601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43964,DS-35338441-75ec-4bfd-b4d8-7ac48e88fa58,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-662b5b17-8d8a-4bc6-8463-8c1e3c99b147,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-5f97ecec-0f69-4151-a77e-a2d9deba2c54,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-72d3cbe0-5b5a-497f-81b2-f17d8d016eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-4a70a8cb-84ba-4383-80c3-284731a61542,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-baab433a-b4b6-41c3-a495-05c63e100726,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-4cd1f729-e5ec-4d6c-8240-42316721fe69,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-a7e447be-1e47-447b-a9c5-325f716cecb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829149191-172.17.0.4-1597493418601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43964,DS-35338441-75ec-4bfd-b4d8-7ac48e88fa58,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-662b5b17-8d8a-4bc6-8463-8c1e3c99b147,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-5f97ecec-0f69-4151-a77e-a2d9deba2c54,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-72d3cbe0-5b5a-497f-81b2-f17d8d016eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-4a70a8cb-84ba-4383-80c3-284731a61542,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-baab433a-b4b6-41c3-a495-05c63e100726,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-4cd1f729-e5ec-4d6c-8240-42316721fe69,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-a7e447be-1e47-447b-a9c5-325f716cecb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092883122-172.17.0.4-1597493647587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-ceebefdf-cba5-4688-949f-0a8baa090de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-54e7cc03-6ac3-4419-8561-c9e7dea5b232,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-8dfdc13e-eb25-4384-aa89-a9ddfc2231be,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-2b478918-584c-48fe-8cef-5bf5c28d2951,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-3250c296-2c6e-46fe-8219-5d7a8c265dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-6a5d5746-c833-4dff-aaac-af884848d545,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-abede3a1-7e87-456c-8bbc-1a6bbd032840,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c06dda86-6768-46e3-8381-533bc44dd93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092883122-172.17.0.4-1597493647587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43458,DS-ceebefdf-cba5-4688-949f-0a8baa090de4,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-54e7cc03-6ac3-4419-8561-c9e7dea5b232,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-8dfdc13e-eb25-4384-aa89-a9ddfc2231be,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-2b478918-584c-48fe-8cef-5bf5c28d2951,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-3250c296-2c6e-46fe-8219-5d7a8c265dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-6a5d5746-c833-4dff-aaac-af884848d545,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-abede3a1-7e87-456c-8bbc-1a6bbd032840,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-c06dda86-6768-46e3-8381-533bc44dd93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6813
