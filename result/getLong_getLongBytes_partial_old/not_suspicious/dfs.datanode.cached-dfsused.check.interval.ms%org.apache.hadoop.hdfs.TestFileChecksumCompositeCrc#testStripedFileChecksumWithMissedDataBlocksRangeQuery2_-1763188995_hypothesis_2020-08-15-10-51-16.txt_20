reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817862672-172.17.0.6-1597488996434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-4b2e8fd8-04ea-44b8-a1a8-a8ca2e654c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-3731baad-8015-4b46-8a8f-47cef6bf1108,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-142a47fb-3245-49c6-b23f-798e5e0ce6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-0c89791e-796a-4c25-80f9-308e5cc80880,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-96230cf4-8d9b-4364-9220-490b2bde5c73,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-73402778-2265-4e90-96de-29e5b9d3989a,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-a00e52e5-8b13-4a54-a41c-6ec3a73d3cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-32d4a805-2441-4703-bf1e-4d30c2b9d7ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817862672-172.17.0.6-1597488996434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33899,DS-4b2e8fd8-04ea-44b8-a1a8-a8ca2e654c95,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-3731baad-8015-4b46-8a8f-47cef6bf1108,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-142a47fb-3245-49c6-b23f-798e5e0ce6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-0c89791e-796a-4c25-80f9-308e5cc80880,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-96230cf4-8d9b-4364-9220-490b2bde5c73,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-73402778-2265-4e90-96de-29e5b9d3989a,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-a00e52e5-8b13-4a54-a41c-6ec3a73d3cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-32d4a805-2441-4703-bf1e-4d30c2b9d7ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422556757-172.17.0.6-1597489572974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-5c87f991-a9ed-41bf-a43a-471e54095b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-767f1e7a-6f41-4b0c-adbe-4f239b795136,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-08358dbf-1b1d-4f9c-b626-26576b611dec,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-c1c1a7ba-15ca-4fce-baad-49cab2933e13,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-36ced250-bdd3-4078-9631-654bfedc8416,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-8b27d082-1678-43e2-a142-c7b6344ce8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-3de9abe9-292d-4f31-bf4d-9ded23dae2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-9950bb62-71be-4966-97ae-9dbd4ab33fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422556757-172.17.0.6-1597489572974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42907,DS-5c87f991-a9ed-41bf-a43a-471e54095b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-767f1e7a-6f41-4b0c-adbe-4f239b795136,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-08358dbf-1b1d-4f9c-b626-26576b611dec,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-c1c1a7ba-15ca-4fce-baad-49cab2933e13,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-36ced250-bdd3-4078-9631-654bfedc8416,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-8b27d082-1678-43e2-a142-c7b6344ce8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-3de9abe9-292d-4f31-bf4d-9ded23dae2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-9950bb62-71be-4966-97ae-9dbd4ab33fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189221271-172.17.0.6-1597489665596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33858,DS-7eb543b6-eea9-4bb6-bbf8-4a0524a5d551,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-d2acc231-75d4-4dc5-b04e-152433b4bddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-3081d63d-a31d-4a0b-9e77-427d26e91c56,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-a3c8b813-27af-46ad-a557-c45ac5fd30d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-47d8b8d8-664d-4751-b733-6749338a8e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-6b3aee78-3a2f-4297-a721-4b5c94741d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-07ab5b2d-6b2f-4e98-93e1-53f6b256ea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-9b25daf8-c1a3-42e4-9bb3-2aea42cb8667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189221271-172.17.0.6-1597489665596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33858,DS-7eb543b6-eea9-4bb6-bbf8-4a0524a5d551,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-d2acc231-75d4-4dc5-b04e-152433b4bddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-3081d63d-a31d-4a0b-9e77-427d26e91c56,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-a3c8b813-27af-46ad-a557-c45ac5fd30d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-47d8b8d8-664d-4751-b733-6749338a8e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-6b3aee78-3a2f-4297-a721-4b5c94741d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-07ab5b2d-6b2f-4e98-93e1-53f6b256ea3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-9b25daf8-c1a3-42e4-9bb3-2aea42cb8667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139188134-172.17.0.6-1597490828224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-d18696e3-162f-453b-b706-5b67c0414e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-22e657f5-dfd8-402f-8e43-6096661f43c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-6c081806-cf10-4e4d-b87f-ee6e5999b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-4bbe182f-e045-46ae-b009-617a6775074d,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-958889f8-b266-474b-8066-01e265b349d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-91959f6f-e51b-42f9-9ef5-c91cd1b75783,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-4289d572-2e4e-4346-97f6-c77b0283e972,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-9599a6fd-bfbb-4611-9262-401aa61a7d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139188134-172.17.0.6-1597490828224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-d18696e3-162f-453b-b706-5b67c0414e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-22e657f5-dfd8-402f-8e43-6096661f43c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-6c081806-cf10-4e4d-b87f-ee6e5999b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-4bbe182f-e045-46ae-b009-617a6775074d,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-958889f8-b266-474b-8066-01e265b349d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-91959f6f-e51b-42f9-9ef5-c91cd1b75783,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-4289d572-2e4e-4346-97f6-c77b0283e972,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-9599a6fd-bfbb-4611-9262-401aa61a7d04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899390305-172.17.0.6-1597490919089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46425,DS-ca733cb3-c321-4c38-ad05-3ed9389ad283,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-a9f1e55c-70f0-4ceb-8b50-6bca9f830dab,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-151d339e-c6c1-4a0a-91a3-166fc66f15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-dc2eddbe-8c78-45bf-84c5-a85ee43da717,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-9d227a37-a293-4ba4-bb01-96660db6e7db,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-29bed318-df35-43ba-a5b0-b59daf55771c,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-7605d9ef-ccbd-46ef-9ced-c5b9dcbff731,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-f6187f5f-ff83-4ee3-8ef5-d72c9bc28e19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899390305-172.17.0.6-1597490919089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46425,DS-ca733cb3-c321-4c38-ad05-3ed9389ad283,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-a9f1e55c-70f0-4ceb-8b50-6bca9f830dab,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-151d339e-c6c1-4a0a-91a3-166fc66f15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-dc2eddbe-8c78-45bf-84c5-a85ee43da717,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-9d227a37-a293-4ba4-bb01-96660db6e7db,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-29bed318-df35-43ba-a5b0-b59daf55771c,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-7605d9ef-ccbd-46ef-9ced-c5b9dcbff731,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-f6187f5f-ff83-4ee3-8ef5-d72c9bc28e19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555089344-172.17.0.6-1597491613503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44069,DS-2f2ed177-cb1c-4a12-8783-2992b98846da,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-34b96df3-1d38-4fc8-9ca9-77d1b8f79937,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-48bfb535-aeeb-46b3-859d-2af5d0a80a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-2183686f-51fb-47bb-8db1-b805be605c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-ebce2fc1-9bfe-443d-8720-e76a95ddc6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-77fd93d2-a59a-4bd9-81d6-52f545149b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-49142d1d-5a76-4f0f-abd2-7b458f34c99d,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-2dda0a87-b9d9-428d-98fb-48f433ea2ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555089344-172.17.0.6-1597491613503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44069,DS-2f2ed177-cb1c-4a12-8783-2992b98846da,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-34b96df3-1d38-4fc8-9ca9-77d1b8f79937,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-48bfb535-aeeb-46b3-859d-2af5d0a80a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-2183686f-51fb-47bb-8db1-b805be605c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-ebce2fc1-9bfe-443d-8720-e76a95ddc6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-77fd93d2-a59a-4bd9-81d6-52f545149b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-49142d1d-5a76-4f0f-abd2-7b458f34c99d,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-2dda0a87-b9d9-428d-98fb-48f433ea2ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448152112-172.17.0.6-1597492008285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-a2f8eeea-3dcb-4371-bedb-adfe24df529d,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-ff4506ed-94f1-4ceb-b08f-bef4e446a1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-538885ce-261d-4884-80d0-3defd4f36c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-438ca066-9df2-4914-9716-b53a053eafc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-6001b3dc-c0d9-485d-b9ed-d9d70973ab0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-172f1a6d-bd0c-4d43-9faa-4351eef0878b,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-58dae8c7-9081-4e48-abce-3b2fbf90b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-81601587-d2db-491e-9123-add1762c0f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448152112-172.17.0.6-1597492008285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-a2f8eeea-3dcb-4371-bedb-adfe24df529d,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-ff4506ed-94f1-4ceb-b08f-bef4e446a1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-538885ce-261d-4884-80d0-3defd4f36c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-438ca066-9df2-4914-9716-b53a053eafc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-6001b3dc-c0d9-485d-b9ed-d9d70973ab0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-172f1a6d-bd0c-4d43-9faa-4351eef0878b,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-58dae8c7-9081-4e48-abce-3b2fbf90b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-81601587-d2db-491e-9123-add1762c0f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896243058-172.17.0.6-1597492345997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39291,DS-3de36e71-2388-4b21-9a2c-029704e36c83,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-e0e58b4c-b84f-465b-842b-fd7fbe76132f,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-d4e06c80-f95c-40a5-8276-584b132437a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-93a49281-5fbb-49c3-8147-ed13991d2ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-c7bf291d-6a1e-403a-b842-687ac278051e,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-90ae2682-c8ed-471d-92cd-3e228613d240,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-72587332-6dbc-4676-b42c-649f3777b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-2f9099fc-e21c-47b4-ba05-9569a6593adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896243058-172.17.0.6-1597492345997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39291,DS-3de36e71-2388-4b21-9a2c-029704e36c83,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-e0e58b4c-b84f-465b-842b-fd7fbe76132f,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-d4e06c80-f95c-40a5-8276-584b132437a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-93a49281-5fbb-49c3-8147-ed13991d2ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-c7bf291d-6a1e-403a-b842-687ac278051e,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-90ae2682-c8ed-471d-92cd-3e228613d240,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-72587332-6dbc-4676-b42c-649f3777b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-2f9099fc-e21c-47b4-ba05-9569a6593adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840413413-172.17.0.6-1597493190112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35016,DS-ef34f5aa-86f5-4509-83dc-4f882cdcca36,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-7336e5dd-47af-4244-8e79-0c41e209b7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-2c20a330-fc2c-44c7-905d-1043f1f71552,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-ea6a5334-78b9-46ff-9940-c6b480ca0b58,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-0b2ce05c-cf5c-479a-8aea-5736b9db46d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-a3edac73-501a-45ea-90b8-96097803945d,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-864be072-9f58-4385-9f5e-ac3e390e8bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-c5c1a28c-3858-4d17-8213-9ba6ebc60811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840413413-172.17.0.6-1597493190112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35016,DS-ef34f5aa-86f5-4509-83dc-4f882cdcca36,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-7336e5dd-47af-4244-8e79-0c41e209b7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-2c20a330-fc2c-44c7-905d-1043f1f71552,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-ea6a5334-78b9-46ff-9940-c6b480ca0b58,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-0b2ce05c-cf5c-479a-8aea-5736b9db46d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-a3edac73-501a-45ea-90b8-96097803945d,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-864be072-9f58-4385-9f5e-ac3e390e8bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-c5c1a28c-3858-4d17-8213-9ba6ebc60811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937731134-172.17.0.6-1597493269552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35576,DS-38215ccd-1dc3-402b-8939-110a7ff6fe20,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-2ff48296-60a1-4d0f-92f8-8c9410c635a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-e99a7809-6b05-4482-be48-2255f7c0d8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-d6ad4919-274f-4116-8397-94d1448b3087,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-51361b2f-bbcb-4832-9035-71ed17894b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-d75ade35-e285-4ae9-952f-6fc8ce085117,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-933d0a3b-91dd-4aac-9f71-4e14b2aa1d28,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-85377929-a0d2-4680-a528-c5416771cb72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937731134-172.17.0.6-1597493269552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35576,DS-38215ccd-1dc3-402b-8939-110a7ff6fe20,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-2ff48296-60a1-4d0f-92f8-8c9410c635a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-e99a7809-6b05-4482-be48-2255f7c0d8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-d6ad4919-274f-4116-8397-94d1448b3087,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-51361b2f-bbcb-4832-9035-71ed17894b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-d75ade35-e285-4ae9-952f-6fc8ce085117,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-933d0a3b-91dd-4aac-9f71-4e14b2aa1d28,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-85377929-a0d2-4680-a528-c5416771cb72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069387287-172.17.0.6-1597493455053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33367,DS-5f9bb373-32e8-4902-9939-430f0f3d2456,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-bc6fcb7e-5aab-4ae8-9d31-18c4218ddd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-79e0b226-cfb7-49dd-8d8d-ae92e8c80a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-70ff1aff-2ae6-4e3f-93cb-572a7c806e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-369ba3eb-5460-4509-9b02-09fa712bcae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-a1ae659e-b24d-4c21-920b-e9199ace5113,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-5162f122-94d5-4d28-833a-624a2069e27b,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-103cb3be-d923-4c46-95d7-289ed9a52d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069387287-172.17.0.6-1597493455053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33367,DS-5f9bb373-32e8-4902-9939-430f0f3d2456,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-bc6fcb7e-5aab-4ae8-9d31-18c4218ddd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-79e0b226-cfb7-49dd-8d8d-ae92e8c80a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-70ff1aff-2ae6-4e3f-93cb-572a7c806e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-369ba3eb-5460-4509-9b02-09fa712bcae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-a1ae659e-b24d-4c21-920b-e9199ace5113,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-5162f122-94d5-4d28-833a-624a2069e27b,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-103cb3be-d923-4c46-95d7-289ed9a52d25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60478323-172.17.0.6-1597493739212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39000,DS-e20035d7-bc06-42b8-bc1e-f55789d65d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-04479cfd-1e36-49f0-ad1d-5c379c0ccc49,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-33a646c6-297a-44b3-a01b-92781b975a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-3bcb74d1-683a-497e-83ee-5a9451d10a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-7fe4bc7e-dad4-428e-88f0-2f2a03971385,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-12446346-e5ee-4ada-b987-e26a937d7ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-1cc01b00-1782-4734-b47a-6786c4a3ba55,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-44e8ee9c-1033-45a8-b2a5-5e0ea793875e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60478323-172.17.0.6-1597493739212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39000,DS-e20035d7-bc06-42b8-bc1e-f55789d65d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-04479cfd-1e36-49f0-ad1d-5c379c0ccc49,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-33a646c6-297a-44b3-a01b-92781b975a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-3bcb74d1-683a-497e-83ee-5a9451d10a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-7fe4bc7e-dad4-428e-88f0-2f2a03971385,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-12446346-e5ee-4ada-b987-e26a937d7ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-1cc01b00-1782-4734-b47a-6786c4a3ba55,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-44e8ee9c-1033-45a8-b2a5-5e0ea793875e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113751637-172.17.0.6-1597494218809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37270,DS-825b0be4-0d2f-43c0-892f-5ce181a222c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-49f819a2-ac93-47f8-8dac-740b7814036e,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-3d6ffd69-bfb1-4ee3-8116-b2ea81d976a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-ce2272c1-7256-413d-a081-45faa81ce622,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-125ddb62-b337-4d8d-90d0-3a7146ea48fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-ce0305a1-6bae-4d8d-93ab-d68e49da7c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-468bf9ba-7e7e-44db-a79a-64cb377cca48,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-c903bf41-e71f-41be-9229-bde0295b369a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113751637-172.17.0.6-1597494218809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37270,DS-825b0be4-0d2f-43c0-892f-5ce181a222c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-49f819a2-ac93-47f8-8dac-740b7814036e,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-3d6ffd69-bfb1-4ee3-8116-b2ea81d976a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-ce2272c1-7256-413d-a081-45faa81ce622,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-125ddb62-b337-4d8d-90d0-3a7146ea48fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-ce0305a1-6bae-4d8d-93ab-d68e49da7c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-468bf9ba-7e7e-44db-a79a-64cb377cca48,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-c903bf41-e71f-41be-9229-bde0295b369a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847372341-172.17.0.6-1597494480045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-7485abfb-02ed-45a4-9c48-bb68f43614e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-1c1d33cf-6f73-4ef1-af01-3f99e41cc63e,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-9feb8446-0aa7-4170-b736-f4ae54e2f17f,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-c47e5a6c-0281-40a5-8b07-6864cb4e432c,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-bb537322-b461-4fc9-a515-78b1e9799e88,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-e8fba333-396d-4e47-add6-f8f3b00f5357,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-6b97a06a-30ac-407e-bba3-316bfc933d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-4bc9b637-16d3-472d-9798-366b7535aa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847372341-172.17.0.6-1597494480045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42933,DS-7485abfb-02ed-45a4-9c48-bb68f43614e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-1c1d33cf-6f73-4ef1-af01-3f99e41cc63e,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-9feb8446-0aa7-4170-b736-f4ae54e2f17f,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-c47e5a6c-0281-40a5-8b07-6864cb4e432c,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-bb537322-b461-4fc9-a515-78b1e9799e88,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-e8fba333-396d-4e47-add6-f8f3b00f5357,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-6b97a06a-30ac-407e-bba3-316bfc933d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-4bc9b637-16d3-472d-9798-366b7535aa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79243781-172.17.0.6-1597494662430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-6a38f64c-5211-415f-aeca-d11c4b8c40f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-12215a6d-d58a-4854-ba98-272f8e78d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-5229ff81-9dce-4c1f-b454-273f48351f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-2d4d1adb-26ae-413b-8c30-35c930cad9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-c96847d8-6e96-45ac-b3ed-2a4a29ba8560,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-5b2edd25-a3c2-42eb-bd1d-3032ab8180fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-cdc17e79-3c88-453b-b6d2-825fd14c9517,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-0a4faf2d-76ea-40b6-85e8-66b4f09eb4db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79243781-172.17.0.6-1597494662430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46268,DS-6a38f64c-5211-415f-aeca-d11c4b8c40f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-12215a6d-d58a-4854-ba98-272f8e78d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-5229ff81-9dce-4c1f-b454-273f48351f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-2d4d1adb-26ae-413b-8c30-35c930cad9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-c96847d8-6e96-45ac-b3ed-2a4a29ba8560,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-5b2edd25-a3c2-42eb-bd1d-3032ab8180fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-cdc17e79-3c88-453b-b6d2-825fd14c9517,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-0a4faf2d-76ea-40b6-85e8-66b4f09eb4db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536791260-172.17.0.6-1597495222039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-e69adbc0-cbff-48b9-91d0-57352c0c0051,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-7997791a-fece-4fec-ad01-692ad744c3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-7eb8ae24-219b-4b60-b4c5-a75c7e6c1a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-eccb919e-4a68-4630-88a3-b4f75601c975,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-d0b51830-4acf-4f95-9131-f7982a104518,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-05a9a9a5-fafb-4157-9e84-a1f6a86b58ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-b353002a-6d8d-47c3-9927-89ca7df33268,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-e2c8f33f-1168-4d18-8b47-8d8dab76fab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536791260-172.17.0.6-1597495222039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40813,DS-e69adbc0-cbff-48b9-91d0-57352c0c0051,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-7997791a-fece-4fec-ad01-692ad744c3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-7eb8ae24-219b-4b60-b4c5-a75c7e6c1a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-eccb919e-4a68-4630-88a3-b4f75601c975,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-d0b51830-4acf-4f95-9131-f7982a104518,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-05a9a9a5-fafb-4157-9e84-a1f6a86b58ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-b353002a-6d8d-47c3-9927-89ca7df33268,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-e2c8f33f-1168-4d18-8b47-8d8dab76fab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6622
