reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392389500-172.17.0.6-1597371212364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37633,DS-75c04a1a-75f5-438d-80b6-cd2c9b3a5982,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-66ad7413-7063-4326-9bea-951169da294e,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-42f98555-f17a-40d1-a870-0578119b6fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-f167e0c2-6e86-4bd9-857d-ab22460c1da1,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-c43f3928-7fc7-4e42-aa6d-2f9509738c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-cd2cc773-bc48-4295-ab37-c45e3baec9da,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-83a3307c-362a-4190-ae33-d83cf30df8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-31ecc12f-2010-4aa7-a8b3-d2853d9a93c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392389500-172.17.0.6-1597371212364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37633,DS-75c04a1a-75f5-438d-80b6-cd2c9b3a5982,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-66ad7413-7063-4326-9bea-951169da294e,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-42f98555-f17a-40d1-a870-0578119b6fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-f167e0c2-6e86-4bd9-857d-ab22460c1da1,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-c43f3928-7fc7-4e42-aa6d-2f9509738c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-cd2cc773-bc48-4295-ab37-c45e3baec9da,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-83a3307c-362a-4190-ae33-d83cf30df8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-31ecc12f-2010-4aa7-a8b3-d2853d9a93c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104302049-172.17.0.6-1597371316260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35741,DS-9b37cd39-b2bc-4cad-9980-b25c32db0a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-ae48d1b2-b478-45df-abcf-c26960522796,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-95d8a19a-de75-441a-ad48-70b0387c1648,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-23cfa2d6-d888-4010-8501-b44b53c6fd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-5e050bb1-4636-4221-9a1b-ee93fcb52b98,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-61be75d8-f37c-4bc1-bec6-969f7f35a9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-fc7cf9ea-f412-4fa8-a2a0-267b52b41acb,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-8ef18df0-1659-4b20-9589-43a2db1fb270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104302049-172.17.0.6-1597371316260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35741,DS-9b37cd39-b2bc-4cad-9980-b25c32db0a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-ae48d1b2-b478-45df-abcf-c26960522796,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-95d8a19a-de75-441a-ad48-70b0387c1648,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-23cfa2d6-d888-4010-8501-b44b53c6fd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-5e050bb1-4636-4221-9a1b-ee93fcb52b98,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-61be75d8-f37c-4bc1-bec6-969f7f35a9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-fc7cf9ea-f412-4fa8-a2a0-267b52b41acb,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-8ef18df0-1659-4b20-9589-43a2db1fb270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606328400-172.17.0.6-1597371644741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34120,DS-ff505d59-8456-481c-b4be-ee163293c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-78f52ae8-5edf-48b2-8998-d0963888c696,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-80fad83c-30e3-4ef5-bf89-b518334c5529,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-2a8d72af-e42f-4dff-8e1d-9908ba939a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-cfd28150-062f-44d1-9b3f-7812d5d8906c,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-848bff66-ae30-4979-aca0-11e311a7eea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-99677738-fe9a-4d5d-86a4-cb30cb635eec,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-5583f466-6b15-48ab-862c-b58032930eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606328400-172.17.0.6-1597371644741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34120,DS-ff505d59-8456-481c-b4be-ee163293c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-78f52ae8-5edf-48b2-8998-d0963888c696,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-80fad83c-30e3-4ef5-bf89-b518334c5529,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-2a8d72af-e42f-4dff-8e1d-9908ba939a59,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-cfd28150-062f-44d1-9b3f-7812d5d8906c,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-848bff66-ae30-4979-aca0-11e311a7eea5,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-99677738-fe9a-4d5d-86a4-cb30cb635eec,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-5583f466-6b15-48ab-862c-b58032930eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828763078-172.17.0.6-1597371737099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-94a7169f-273e-40e4-add4-a161acff8c64,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-6c588a86-bb19-4e36-9fe0-2e136cf69850,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-5187e9cf-4b44-4b72-babf-9180c6c406ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-4b3cb757-2933-4016-baa0-6aac329edc88,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-0379abf1-4d34-4f2d-b3a5-e4a2a6bafe91,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-0d5437ce-707f-4601-9d7c-ddba2859dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-c8b58ef7-0de4-4ad4-abea-99a21dcaf633,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-3b4522ef-ab27-4c92-b21d-9edda2bc3a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828763078-172.17.0.6-1597371737099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-94a7169f-273e-40e4-add4-a161acff8c64,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-6c588a86-bb19-4e36-9fe0-2e136cf69850,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-5187e9cf-4b44-4b72-babf-9180c6c406ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-4b3cb757-2933-4016-baa0-6aac329edc88,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-0379abf1-4d34-4f2d-b3a5-e4a2a6bafe91,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-0d5437ce-707f-4601-9d7c-ddba2859dc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-c8b58ef7-0de4-4ad4-abea-99a21dcaf633,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-3b4522ef-ab27-4c92-b21d-9edda2bc3a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832136289-172.17.0.6-1597372093162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-aff032f6-1a70-4d9f-90b1-2bae9d79109b,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-4a4439cc-d281-4c75-8679-e758748905a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-27725d14-d57f-4c30-b5a7-a6b60b08aa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-ad01486b-1871-4b39-8e5e-0fdea96980a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-e8d3591c-c32d-4fd9-a626-83621d8cef40,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-6d95b836-fabb-4a1f-bf13-a759504b586b,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-b9e89f29-f3e2-4804-895d-6a6ce306b1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-eb5a3fc7-1e64-47d3-99e1-e88f01dba040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832136289-172.17.0.6-1597372093162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-aff032f6-1a70-4d9f-90b1-2bae9d79109b,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-4a4439cc-d281-4c75-8679-e758748905a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-27725d14-d57f-4c30-b5a7-a6b60b08aa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-ad01486b-1871-4b39-8e5e-0fdea96980a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-e8d3591c-c32d-4fd9-a626-83621d8cef40,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-6d95b836-fabb-4a1f-bf13-a759504b586b,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-b9e89f29-f3e2-4804-895d-6a6ce306b1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-eb5a3fc7-1e64-47d3-99e1-e88f01dba040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846786824-172.17.0.6-1597372346581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41772,DS-4f4c2a20-6cb4-4104-baef-622c761be34a,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-d76f868a-0e0b-4064-9653-55564f81ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-00ec6e4d-f200-436b-9647-eb0ddaf7de59,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-1ab5fca6-2cf1-4c52-8e04-2389b76bec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-dcbc4a16-505f-45d0-9219-bd1abc08f663,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-1aadc492-2721-4e5a-9e71-9c0f0ad344ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-ad33670e-f463-40f2-9501-6c320a762da8,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-9914f2ba-7920-4673-98cc-8222237f8b64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846786824-172.17.0.6-1597372346581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41772,DS-4f4c2a20-6cb4-4104-baef-622c761be34a,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-d76f868a-0e0b-4064-9653-55564f81ec31,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-00ec6e4d-f200-436b-9647-eb0ddaf7de59,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-1ab5fca6-2cf1-4c52-8e04-2389b76bec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-dcbc4a16-505f-45d0-9219-bd1abc08f663,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-1aadc492-2721-4e5a-9e71-9c0f0ad344ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-ad33670e-f463-40f2-9501-6c320a762da8,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-9914f2ba-7920-4673-98cc-8222237f8b64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553588128-172.17.0.6-1597372775220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44519,DS-6bae7b65-9c8e-4f17-af77-4875317ee54f,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-989dec36-d866-4174-abf1-8f84cf13f086,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-3ac7dc28-d77b-46de-9825-71bbeab4d571,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-9f5c1f89-83b8-497d-a12e-34eb8bfde56f,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-becdcc75-f1db-4e7d-bc88-79f2cd132494,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-6307b6e8-3628-48f7-a800-a94418ee7004,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-8f297a20-5b23-4eac-8539-e5f8f3553581,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-c481faaf-ffd4-4f9a-950b-6bc0518b2043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553588128-172.17.0.6-1597372775220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44519,DS-6bae7b65-9c8e-4f17-af77-4875317ee54f,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-989dec36-d866-4174-abf1-8f84cf13f086,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-3ac7dc28-d77b-46de-9825-71bbeab4d571,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-9f5c1f89-83b8-497d-a12e-34eb8bfde56f,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-becdcc75-f1db-4e7d-bc88-79f2cd132494,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-6307b6e8-3628-48f7-a800-a94418ee7004,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-8f297a20-5b23-4eac-8539-e5f8f3553581,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-c481faaf-ffd4-4f9a-950b-6bc0518b2043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707771358-172.17.0.6-1597372819475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36525,DS-18ded57e-0623-43ad-bf38-66b6cb6cc703,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-1f23ee67-4489-48b6-8449-a743e55eff70,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-e1b13274-c24f-4d7e-9481-4af88579d493,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-436defa6-5f65-4702-8e16-a1064ede5c08,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-b637b7e9-04c2-4b49-bba0-cf219a7d6e11,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-5293e79c-3744-4109-adce-26cb08e5ff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-76313ee8-7c99-49ed-86e0-f79fe0b51030,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-b8588b01-47ad-4cb2-b887-520546fe0dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707771358-172.17.0.6-1597372819475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36525,DS-18ded57e-0623-43ad-bf38-66b6cb6cc703,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-1f23ee67-4489-48b6-8449-a743e55eff70,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-e1b13274-c24f-4d7e-9481-4af88579d493,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-436defa6-5f65-4702-8e16-a1064ede5c08,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-b637b7e9-04c2-4b49-bba0-cf219a7d6e11,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-5293e79c-3744-4109-adce-26cb08e5ff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-76313ee8-7c99-49ed-86e0-f79fe0b51030,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-b8588b01-47ad-4cb2-b887-520546fe0dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083238730-172.17.0.6-1597373199566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-56edefcb-db1e-4e22-bede-680ac92cc609,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-f8504b8a-0d18-445a-bcad-e896cf5dead7,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-2fd64780-ed2d-48c0-a0f5-d2ff8e525e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-6fd136b4-d94f-4801-9857-5d5d9b10836a,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-78e620ff-564f-44c5-ba5f-454dbec9c780,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-107680b6-726a-4a3e-b216-950c46417a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-55add745-44c9-48ec-a19e-811a7c3c213c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-db792122-104f-4999-91f9-6e8d79ba8fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2083238730-172.17.0.6-1597373199566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43433,DS-56edefcb-db1e-4e22-bede-680ac92cc609,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-f8504b8a-0d18-445a-bcad-e896cf5dead7,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-2fd64780-ed2d-48c0-a0f5-d2ff8e525e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-6fd136b4-d94f-4801-9857-5d5d9b10836a,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-78e620ff-564f-44c5-ba5f-454dbec9c780,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-107680b6-726a-4a3e-b216-950c46417a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-55add745-44c9-48ec-a19e-811a7c3c213c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-db792122-104f-4999-91f9-6e8d79ba8fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17113512-172.17.0.6-1597373628178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45755,DS-b620b498-3ca9-475b-b47d-009181f0631c,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-2e86e79a-46b4-4b81-a411-a95d0f4bd6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-7af44c06-ccec-4c0f-bfea-b194b92e0ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-e2e3f4df-1888-43fb-9c0e-34eed6b21306,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-df356a66-b71f-4a2d-b3c9-16c3bdc06b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-0626b062-bb7a-467f-8edc-7dd098b9eec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-40e78ebc-7b0f-4c3e-a916-7292a487fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-6b3df4e2-e8c4-4a28-85d8-a88438daaaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17113512-172.17.0.6-1597373628178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45755,DS-b620b498-3ca9-475b-b47d-009181f0631c,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-2e86e79a-46b4-4b81-a411-a95d0f4bd6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-7af44c06-ccec-4c0f-bfea-b194b92e0ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-e2e3f4df-1888-43fb-9c0e-34eed6b21306,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-df356a66-b71f-4a2d-b3c9-16c3bdc06b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-0626b062-bb7a-467f-8edc-7dd098b9eec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-40e78ebc-7b0f-4c3e-a916-7292a487fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-6b3df4e2-e8c4-4a28-85d8-a88438daaaa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154504983-172.17.0.6-1597374415077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41319,DS-b8f460d3-8e02-4ece-9548-77805d07e89e,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-41d54388-ab6a-47d9-ac53-55a3176d622c,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-b830a9a3-568f-438c-b201-c38fbe25da80,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-687d5b19-6ea2-440d-a78e-7e8707218434,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-6969460c-1955-42a7-91f6-6210f5710c17,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-51a1ab06-a7a7-4263-bf72-1d6dd2a961af,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-c680fae7-fc67-4fd2-820f-071604ae1fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-e3fb9557-da80-4f3b-b565-4147e4a4067e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154504983-172.17.0.6-1597374415077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41319,DS-b8f460d3-8e02-4ece-9548-77805d07e89e,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-41d54388-ab6a-47d9-ac53-55a3176d622c,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-b830a9a3-568f-438c-b201-c38fbe25da80,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-687d5b19-6ea2-440d-a78e-7e8707218434,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-6969460c-1955-42a7-91f6-6210f5710c17,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-51a1ab06-a7a7-4263-bf72-1d6dd2a961af,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-c680fae7-fc67-4fd2-820f-071604ae1fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-e3fb9557-da80-4f3b-b565-4147e4a4067e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445826229-172.17.0.6-1597374795279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-1d8d03ed-6ec1-4417-b5ea-1f98933935f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-2bfc23a8-983d-4da3-b3f7-7258eb8fe1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-c443fbda-7e42-442f-a82d-3b59d98307a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-1e3ab76c-4ddc-4008-b507-50c523c93f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-143bef7f-f6c3-4198-8555-9f215d928b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-0c09f74f-eeb1-4ede-9da8-539bd55985ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-c781e8f8-5aca-4c9a-ab11-20106d55c454,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-b8d277d9-c9a8-4267-a448-25aed1baed9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445826229-172.17.0.6-1597374795279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-1d8d03ed-6ec1-4417-b5ea-1f98933935f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-2bfc23a8-983d-4da3-b3f7-7258eb8fe1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-c443fbda-7e42-442f-a82d-3b59d98307a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-1e3ab76c-4ddc-4008-b507-50c523c93f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-143bef7f-f6c3-4198-8555-9f215d928b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-0c09f74f-eeb1-4ede-9da8-539bd55985ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-c781e8f8-5aca-4c9a-ab11-20106d55c454,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-b8d277d9-c9a8-4267-a448-25aed1baed9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896163187-172.17.0.6-1597375036271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-88813a07-6d05-42cd-a5ef-cfa18f82796d,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-284f9870-473e-499c-bd59-95385e5d0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-807dfe16-11a5-4874-b469-762b391d9fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-c4116139-7e7d-41ae-a0d4-dc623a4a4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-e0689937-5851-43ba-a211-0b346d203802,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-c5a3f9af-c824-4b68-afa5-fc396bb91874,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-b3fecbe6-1831-41d3-8680-e57519d47b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-8da116a0-0eca-43e9-b12c-6c1682ce3005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896163187-172.17.0.6-1597375036271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-88813a07-6d05-42cd-a5ef-cfa18f82796d,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-284f9870-473e-499c-bd59-95385e5d0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-807dfe16-11a5-4874-b469-762b391d9fec,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-c4116139-7e7d-41ae-a0d4-dc623a4a4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-e0689937-5851-43ba-a211-0b346d203802,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-c5a3f9af-c824-4b68-afa5-fc396bb91874,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-b3fecbe6-1831-41d3-8680-e57519d47b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-8da116a0-0eca-43e9-b12c-6c1682ce3005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499217577-172.17.0.6-1597375082995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45365,DS-86f3403c-97c1-4ab6-9387-3dc992c84966,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-5e31204f-4c9c-48c4-85e6-2a24e1f2efcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-bf5812e1-a2d0-42b2-a42b-42d0ff9c9d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-92237462-425a-48ab-a6b0-cf5c46123703,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-31d4cc67-8e90-4808-9e1c-19a987a9c205,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e60ed115-ff50-4f7e-ba05-88089a08ca83,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-839df03f-1fb5-4fd1-a8eb-d4582270f673,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-309855ce-a0b4-45b0-baf7-54ba212f1fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499217577-172.17.0.6-1597375082995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45365,DS-86f3403c-97c1-4ab6-9387-3dc992c84966,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-5e31204f-4c9c-48c4-85e6-2a24e1f2efcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-bf5812e1-a2d0-42b2-a42b-42d0ff9c9d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-92237462-425a-48ab-a6b0-cf5c46123703,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-31d4cc67-8e90-4808-9e1c-19a987a9c205,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e60ed115-ff50-4f7e-ba05-88089a08ca83,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-839df03f-1fb5-4fd1-a8eb-d4582270f673,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-309855ce-a0b4-45b0-baf7-54ba212f1fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222173020-172.17.0.6-1597375263808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35976,DS-17927042-3ced-43e7-8ff1-cb8cafa9e788,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-63b06005-6e95-49a5-ba5b-75691d6a011f,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-1a44d5e6-b76d-407d-bda4-97723129eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-e4862062-356b-4fec-af03-0713894e2958,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-31327ee2-c06e-4db1-9ef7-58a2e4a07549,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-3961d249-062e-4757-9154-9c55ece0f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-1ee7d850-1e92-4ddb-8e0b-975bc24887a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-54c55180-bb9c-4653-8cf8-88fc4a0647ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222173020-172.17.0.6-1597375263808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35976,DS-17927042-3ced-43e7-8ff1-cb8cafa9e788,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-63b06005-6e95-49a5-ba5b-75691d6a011f,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-1a44d5e6-b76d-407d-bda4-97723129eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-e4862062-356b-4fec-af03-0713894e2958,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-31327ee2-c06e-4db1-9ef7-58a2e4a07549,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-3961d249-062e-4757-9154-9c55ece0f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-1ee7d850-1e92-4ddb-8e0b-975bc24887a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-54c55180-bb9c-4653-8cf8-88fc4a0647ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665273040-172.17.0.6-1597375940097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35986,DS-39106659-de52-4217-be4a-1412c8346fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-0009dd80-63e5-44b4-9341-9957b4196d40,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-52bb317d-a112-4546-9ae8-9755d39b959e,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-2955ee45-c447-4413-aac0-293ec325a81d,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-566565b1-d679-4248-87dc-8770483a6bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-bcff756a-98d9-415c-9ad4-f0c92ed0e754,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-f8e9ce63-470d-4670-9cf5-60b105746135,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-47bfd746-c6ea-456d-b255-4d3f9966048a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665273040-172.17.0.6-1597375940097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35986,DS-39106659-de52-4217-be4a-1412c8346fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-0009dd80-63e5-44b4-9341-9957b4196d40,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-52bb317d-a112-4546-9ae8-9755d39b959e,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-2955ee45-c447-4413-aac0-293ec325a81d,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-566565b1-d679-4248-87dc-8770483a6bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-bcff756a-98d9-415c-9ad4-f0c92ed0e754,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-f8e9ce63-470d-4670-9cf5-60b105746135,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-47bfd746-c6ea-456d-b255-4d3f9966048a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008335108-172.17.0.6-1597376300598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32850,DS-9d3cc820-1555-41d5-aabc-25024032e74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-2f8d1e0e-2c84-44a5-8ccf-d0304f1d7f75,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-2fe988f5-63b2-464f-adf8-1f0eab52d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-7b87bf2e-a158-4fe3-831a-6ce55c8d0901,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-2b018a79-0fa1-4d56-9e0d-f3e11d57e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-a1c2a872-d614-4f56-bf8e-2eaf73298cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-c815c779-157a-44b5-82ac-e6bcc380d30b,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-8d3d4e6b-1cfb-4085-aa25-164fa430069d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008335108-172.17.0.6-1597376300598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32850,DS-9d3cc820-1555-41d5-aabc-25024032e74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-2f8d1e0e-2c84-44a5-8ccf-d0304f1d7f75,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-2fe988f5-63b2-464f-adf8-1f0eab52d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-7b87bf2e-a158-4fe3-831a-6ce55c8d0901,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-2b018a79-0fa1-4d56-9e0d-f3e11d57e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-a1c2a872-d614-4f56-bf8e-2eaf73298cee,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-c815c779-157a-44b5-82ac-e6bcc380d30b,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-8d3d4e6b-1cfb-4085-aa25-164fa430069d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732170476-172.17.0.6-1597376511151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-cc0c57cd-79d9-47dd-8d51-75f626ec42e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-080aa19c-c7a5-48f1-a000-865ffb55a966,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-6168e898-e7f3-4080-88ee-0d1de3bfe860,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-7c47ce06-d61b-44bd-b50b-5dfa05900686,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-ddda011e-7b2c-46e0-8bfc-3c91ebc41c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-a7e10a63-0067-40d6-a466-5eba65bcb50b,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-b78435f3-528a-45a0-8ed3-2a2c114a4e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-0142d704-c13e-4deb-a948-9fe1775c8b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732170476-172.17.0.6-1597376511151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33475,DS-cc0c57cd-79d9-47dd-8d51-75f626ec42e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-080aa19c-c7a5-48f1-a000-865ffb55a966,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-6168e898-e7f3-4080-88ee-0d1de3bfe860,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-7c47ce06-d61b-44bd-b50b-5dfa05900686,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-ddda011e-7b2c-46e0-8bfc-3c91ebc41c07,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-a7e10a63-0067-40d6-a466-5eba65bcb50b,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-b78435f3-528a-45a0-8ed3-2a2c114a4e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-0142d704-c13e-4deb-a948-9fe1775c8b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226312116-172.17.0.6-1597376610555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-5f9c2bb4-5923-418a-a57a-93e2967ca021,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-464c818c-41d4-4531-ab78-2dba4cbc1489,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-fa7e85f5-9bec-4618-81e0-07464fd0aefd,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-be7b4054-1486-4a27-a6b4-8091e404eccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-c91a9196-e5eb-45e1-b81a-e2bb5f03ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-01549700-cb14-4626-859b-a8ca71ac4f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-763e8174-095d-4029-8ac6-22d2e82c4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-82d39391-7381-4a57-93bd-60c4ad50e4a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226312116-172.17.0.6-1597376610555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-5f9c2bb4-5923-418a-a57a-93e2967ca021,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-464c818c-41d4-4531-ab78-2dba4cbc1489,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-fa7e85f5-9bec-4618-81e0-07464fd0aefd,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-be7b4054-1486-4a27-a6b4-8091e404eccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-c91a9196-e5eb-45e1-b81a-e2bb5f03ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-01549700-cb14-4626-859b-a8ca71ac4f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-763e8174-095d-4029-8ac6-22d2e82c4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-82d39391-7381-4a57-93bd-60c4ad50e4a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015183904-172.17.0.6-1597376695875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38889,DS-4a4dcc2d-a459-4be7-9c43-4a51bd629dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-e8a1973f-6562-43f1-86bb-4f19ffa8afea,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-52abc4e0-079f-4e9d-b054-408a5ce876ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-bcc9ed8d-bf75-41cb-996b-bd99473f70fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-6dec7323-4c95-437b-b442-db8f0bb10f01,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-d377c80e-3bf2-4af8-92ac-ae20ed68bc89,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-50d8e672-7e56-441c-a2f8-0d084611b530,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-7848e040-d2c4-40a7-ae57-8d6967afcc14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015183904-172.17.0.6-1597376695875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38889,DS-4a4dcc2d-a459-4be7-9c43-4a51bd629dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-e8a1973f-6562-43f1-86bb-4f19ffa8afea,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-52abc4e0-079f-4e9d-b054-408a5ce876ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-bcc9ed8d-bf75-41cb-996b-bd99473f70fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-6dec7323-4c95-437b-b442-db8f0bb10f01,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-d377c80e-3bf2-4af8-92ac-ae20ed68bc89,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-50d8e672-7e56-441c-a2f8-0d084611b530,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-7848e040-d2c4-40a7-ae57-8d6967afcc14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090327746-172.17.0.6-1597376743736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45387,DS-56510d6f-ead2-4b4d-9184-d8677cc2a144,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-0dabd7af-a32e-4ba4-a1ba-d0fe620bb10e,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-b506ab1b-8e27-47bc-a1b1-b3b34a961305,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-244d3e1c-b669-4a54-a4b8-0231f956bf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-98283156-55aa-49b6-9751-91f2026f246f,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-2977fa09-904f-4983-8311-83e4f7a83a82,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-3dcb3419-9a23-4054-b1c3-bf2c5727734d,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-443bbbbf-6c65-4a3f-8d4a-21e2b6780e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090327746-172.17.0.6-1597376743736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45387,DS-56510d6f-ead2-4b4d-9184-d8677cc2a144,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-0dabd7af-a32e-4ba4-a1ba-d0fe620bb10e,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-b506ab1b-8e27-47bc-a1b1-b3b34a961305,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-244d3e1c-b669-4a54-a4b8-0231f956bf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-98283156-55aa-49b6-9751-91f2026f246f,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-2977fa09-904f-4983-8311-83e4f7a83a82,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-3dcb3419-9a23-4054-b1c3-bf2c5727734d,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-443bbbbf-6c65-4a3f-8d4a-21e2b6780e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079538566-172.17.0.6-1597377434838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-438220a5-8423-4acc-923a-b99ecbfded11,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-f0f990b3-0e41-41e9-b5fc-12103f334dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-9e016cec-281e-4428-9750-95f94082a677,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-7f9b13e0-ed91-4851-97c9-b26705a81d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-b741d8df-6392-45d3-b08c-0fd99f5500b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-eac70dbe-bac1-4e30-95b2-bbe8a29b3174,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-40c672e0-4f70-4fc6-8459-b0b6cc983cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-741a7be8-50e2-413d-873b-9a5315370f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079538566-172.17.0.6-1597377434838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36565,DS-438220a5-8423-4acc-923a-b99ecbfded11,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-f0f990b3-0e41-41e9-b5fc-12103f334dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-9e016cec-281e-4428-9750-95f94082a677,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-7f9b13e0-ed91-4851-97c9-b26705a81d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-b741d8df-6392-45d3-b08c-0fd99f5500b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-eac70dbe-bac1-4e30-95b2-bbe8a29b3174,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-40c672e0-4f70-4fc6-8459-b0b6cc983cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-741a7be8-50e2-413d-873b-9a5315370f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449741508-172.17.0.6-1597378195935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40343,DS-56340f72-72cf-41d0-aa40-1f3087e16a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-a9c6b26e-1520-42b1-a0bb-fe45d1ea055a,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-c0a411c7-899a-4699-ae88-7c1dab5b46db,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-88409b13-5fdf-4b5c-9a87-38b732089b14,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-c8971226-9400-4944-ba81-48a929978501,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-313a1c75-80d7-4dc5-952c-405459a0a78d,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-69152602-ca90-435d-8933-95ae2ccde09d,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-d28294e7-cc64-4f10-8fa0-f3163718548b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449741508-172.17.0.6-1597378195935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40343,DS-56340f72-72cf-41d0-aa40-1f3087e16a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-a9c6b26e-1520-42b1-a0bb-fe45d1ea055a,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-c0a411c7-899a-4699-ae88-7c1dab5b46db,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-88409b13-5fdf-4b5c-9a87-38b732089b14,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-c8971226-9400-4944-ba81-48a929978501,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-313a1c75-80d7-4dc5-952c-405459a0a78d,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-69152602-ca90-435d-8933-95ae2ccde09d,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-d28294e7-cc64-4f10-8fa0-f3163718548b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 7125
