reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139647324-172.17.0.17-1597281372572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35841,DS-fb970a12-ef1f-4bc9-b697-eb537c5d5e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-a3064d12-aa15-4eea-ba84-de64382bd644,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-b48b81a5-ea31-41c9-ba38-818af28b5d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-390b75fa-024f-4ab9-9851-b80f43fb0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-407a3a31-d275-42e5-9455-bb5b7f48f015,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-f61863ad-b988-4e08-8bd4-0a3b2a1bb9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-1a978971-027f-4669-924d-f1c9affcd3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-0dc0a3ab-46b2-4835-8adc-f04861a764f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139647324-172.17.0.17-1597281372572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35841,DS-fb970a12-ef1f-4bc9-b697-eb537c5d5e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-a3064d12-aa15-4eea-ba84-de64382bd644,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-b48b81a5-ea31-41c9-ba38-818af28b5d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-390b75fa-024f-4ab9-9851-b80f43fb0d46,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-407a3a31-d275-42e5-9455-bb5b7f48f015,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-f61863ad-b988-4e08-8bd4-0a3b2a1bb9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-1a978971-027f-4669-924d-f1c9affcd3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-0dc0a3ab-46b2-4835-8adc-f04861a764f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205362275-172.17.0.17-1597281727331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34783,DS-63e59dd0-432b-408f-84f4-a996bfea80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-c10691c6-d4b2-4c21-9aeb-8172216b9aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-258a20aa-9175-4f8e-a836-042130a43c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-b509016d-497d-4668-abb1-d2aae0c81cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-15270220-7782-453c-9ad2-795ad21e4480,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-39e51c50-b556-4e16-a539-3a9ae79055ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-48181b59-610d-4a06-8ee8-dc95fab32314,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-8ebba4b8-bcf6-427c-b298-2d13c9169ff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205362275-172.17.0.17-1597281727331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34783,DS-63e59dd0-432b-408f-84f4-a996bfea80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-c10691c6-d4b2-4c21-9aeb-8172216b9aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-258a20aa-9175-4f8e-a836-042130a43c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-b509016d-497d-4668-abb1-d2aae0c81cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-15270220-7782-453c-9ad2-795ad21e4480,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-39e51c50-b556-4e16-a539-3a9ae79055ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-48181b59-610d-4a06-8ee8-dc95fab32314,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-8ebba4b8-bcf6-427c-b298-2d13c9169ff5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534341459-172.17.0.17-1597281941675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-b5af044f-e88e-41b2-af75-266f65783ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-6ea0dae2-7746-4382-a304-c0b7d4408af3,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-a7f798d5-7ea1-46ff-bc8f-df74c09941ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-1c1e29ec-f422-4b9e-962e-d0dd070b5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-c45cbda4-ba26-4f60-9d82-de24658ab3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-cebdeffb-fa16-4f7f-8421-0f4473b5c246,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-1118a23b-ed8e-48d6-b693-c1b4eb7c50fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-bc582856-38f1-4523-9f2c-4bd248e9c8d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534341459-172.17.0.17-1597281941675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-b5af044f-e88e-41b2-af75-266f65783ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-6ea0dae2-7746-4382-a304-c0b7d4408af3,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-a7f798d5-7ea1-46ff-bc8f-df74c09941ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-1c1e29ec-f422-4b9e-962e-d0dd070b5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-c45cbda4-ba26-4f60-9d82-de24658ab3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-cebdeffb-fa16-4f7f-8421-0f4473b5c246,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-1118a23b-ed8e-48d6-b693-c1b4eb7c50fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-bc582856-38f1-4523-9f2c-4bd248e9c8d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513994295-172.17.0.17-1597282335932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-a9345e13-f7ef-48ec-95d4-ec256d432bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-711662c6-bbb9-48ee-96fc-23fa57ca637e,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-fdb42cbf-c333-4b79-b763-cd0e61fa8319,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-1f604574-58c4-4bf8-b066-60b135204fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-1aadcbbb-f7fc-4aca-a193-8bfde8ea4715,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-d67084b8-24a5-403b-a5f8-f54c53ef21d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-2dd00a1e-d8e4-4687-b10e-6e0f4dd59295,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-d75f43bd-218c-4284-bd8b-ec16e97ca528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513994295-172.17.0.17-1597282335932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-a9345e13-f7ef-48ec-95d4-ec256d432bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-711662c6-bbb9-48ee-96fc-23fa57ca637e,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-fdb42cbf-c333-4b79-b763-cd0e61fa8319,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-1f604574-58c4-4bf8-b066-60b135204fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-1aadcbbb-f7fc-4aca-a193-8bfde8ea4715,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-d67084b8-24a5-403b-a5f8-f54c53ef21d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-2dd00a1e-d8e4-4687-b10e-6e0f4dd59295,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-d75f43bd-218c-4284-bd8b-ec16e97ca528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086213747-172.17.0.17-1597282929048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-0cf1422f-c28e-4748-a49b-f8c68b8e7f66,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-6811e569-3bcc-42b3-81e6-240e5e336f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-4b5d2b6f-5dff-4d78-a6aa-488971f63333,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-80e38dcc-3539-41d0-b0f6-11b8da674c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-6de4801d-0b21-413d-8320-1238fb16a4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-17dede92-8083-4e76-a910-259cbd7bacce,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-97bea83b-693e-4661-8722-8d8917710e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-1257f729-36ab-4f30-ae44-80355788236f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086213747-172.17.0.17-1597282929048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-0cf1422f-c28e-4748-a49b-f8c68b8e7f66,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-6811e569-3bcc-42b3-81e6-240e5e336f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-4b5d2b6f-5dff-4d78-a6aa-488971f63333,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-80e38dcc-3539-41d0-b0f6-11b8da674c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-6de4801d-0b21-413d-8320-1238fb16a4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-17dede92-8083-4e76-a910-259cbd7bacce,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-97bea83b-693e-4661-8722-8d8917710e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-1257f729-36ab-4f30-ae44-80355788236f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-863199261-172.17.0.17-1597282994786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-ee0fcfa5-a6f0-4b80-88d0-d0e38495c611,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-b84fac94-2310-4d0e-b1b5-69cb11c4c770,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-651c804b-cc5e-4537-b5f9-c87f408da832,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-855a2916-fb2f-40e8-9993-5c866986e103,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-309b0005-ee67-4974-a2d5-d6b634c88583,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-8dd207bb-f87b-4418-b01f-81be337b6973,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-52344b82-bcc4-4202-8a88-5324977507a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-23c37f20-79b3-4fab-8adc-df19a493115d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-863199261-172.17.0.17-1597282994786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44623,DS-ee0fcfa5-a6f0-4b80-88d0-d0e38495c611,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-b84fac94-2310-4d0e-b1b5-69cb11c4c770,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-651c804b-cc5e-4537-b5f9-c87f408da832,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-855a2916-fb2f-40e8-9993-5c866986e103,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-309b0005-ee67-4974-a2d5-d6b634c88583,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-8dd207bb-f87b-4418-b01f-81be337b6973,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-52344b82-bcc4-4202-8a88-5324977507a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-23c37f20-79b3-4fab-8adc-df19a493115d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903635059-172.17.0.17-1597283096506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-280aa737-206d-446b-95e7-70fd66fd3ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-b9cb460a-1428-4e3a-ac67-a60a6955d508,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-f328fbb5-e33c-498e-82e9-56bf79e56752,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-bb66a673-7719-4b0c-90aa-d6fb424fbe03,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-7e730ee5-898b-41b0-96be-88c0fc9b7452,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-57b080ff-7bc3-4eea-99ee-c925ad29e112,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-87342789-ccd3-46e6-b1f3-2797d27c7dec,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-729c0f83-a865-4472-8bad-3640286c8aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903635059-172.17.0.17-1597283096506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-280aa737-206d-446b-95e7-70fd66fd3ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-b9cb460a-1428-4e3a-ac67-a60a6955d508,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-f328fbb5-e33c-498e-82e9-56bf79e56752,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-bb66a673-7719-4b0c-90aa-d6fb424fbe03,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-7e730ee5-898b-41b0-96be-88c0fc9b7452,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-57b080ff-7bc3-4eea-99ee-c925ad29e112,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-87342789-ccd3-46e6-b1f3-2797d27c7dec,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-729c0f83-a865-4472-8bad-3640286c8aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45064099-172.17.0.17-1597283376480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43116,DS-1b1c830e-54c3-4d82-8821-d6e6aa58a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-c1acd3b2-09da-4124-a0d2-6bebc6f00f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-0242c447-4531-47a6-bcc2-652d99442286,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-68451e7e-b9d2-46ba-afe3-9fe821cbde92,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-21d82d5b-9bfc-4e17-b00e-4a0598666e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-b67e91fe-a296-4687-bd47-9e03c91e9c39,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-9ffbe91b-a7c2-4dab-87fa-ba6797122374,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-589ce39e-66a6-4af0-a2e1-9731275706ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45064099-172.17.0.17-1597283376480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43116,DS-1b1c830e-54c3-4d82-8821-d6e6aa58a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-c1acd3b2-09da-4124-a0d2-6bebc6f00f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-0242c447-4531-47a6-bcc2-652d99442286,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-68451e7e-b9d2-46ba-afe3-9fe821cbde92,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-21d82d5b-9bfc-4e17-b00e-4a0598666e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-b67e91fe-a296-4687-bd47-9e03c91e9c39,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-9ffbe91b-a7c2-4dab-87fa-ba6797122374,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-589ce39e-66a6-4af0-a2e1-9731275706ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735187568-172.17.0.17-1597284371844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-9efab0a2-5178-4d4b-a022-7b218d0d40bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-5980f854-f091-4c02-a6bd-0fdec1efa600,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-e15dec06-263f-462c-8489-0a8c3a8ecbef,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-6beee304-324d-4bd2-b53a-ddc85059ae95,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-ad2d13d8-8f55-4dc8-9242-a7b61f6989cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-4cc0c5ce-9232-4730-bc1d-0214f89a1279,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-202ed0d7-c827-4026-ba74-d6f91755194d,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-73fe1d77-7147-4514-a64c-d57cde88cb6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735187568-172.17.0.17-1597284371844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-9efab0a2-5178-4d4b-a022-7b218d0d40bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-5980f854-f091-4c02-a6bd-0fdec1efa600,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-e15dec06-263f-462c-8489-0a8c3a8ecbef,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-6beee304-324d-4bd2-b53a-ddc85059ae95,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-ad2d13d8-8f55-4dc8-9242-a7b61f6989cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-4cc0c5ce-9232-4730-bc1d-0214f89a1279,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-202ed0d7-c827-4026-ba74-d6f91755194d,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-73fe1d77-7147-4514-a64c-d57cde88cb6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436313509-172.17.0.17-1597284413225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-2b25e247-87ec-4ca3-bceb-a41f0c63ebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-ac6a1a79-dfb9-4a5a-aff6-be298a53ff32,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-fe763d7e-e95d-4c74-99ba-664170c9fe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-abb43eef-a474-4380-acaa-eaefc2050a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-20288ff2-f54e-4f1e-beed-d2297fdfa99d,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-9c92969b-a6cb-4ca7-a3a7-b6db6b931104,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-7ccae268-adc7-40e9-b487-106b879ead20,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-2e752589-0cf6-4873-9b7f-109331022f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436313509-172.17.0.17-1597284413225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35946,DS-2b25e247-87ec-4ca3-bceb-a41f0c63ebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-ac6a1a79-dfb9-4a5a-aff6-be298a53ff32,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-fe763d7e-e95d-4c74-99ba-664170c9fe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-abb43eef-a474-4380-acaa-eaefc2050a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-20288ff2-f54e-4f1e-beed-d2297fdfa99d,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-9c92969b-a6cb-4ca7-a3a7-b6db6b931104,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-7ccae268-adc7-40e9-b487-106b879ead20,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-2e752589-0cf6-4873-9b7f-109331022f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446607726-172.17.0.17-1597284458037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-a057e923-7e5e-4643-9c80-1bdbb7ce9280,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-5cf2ddec-2234-49e2-8949-de940fa99f48,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-c6b98cff-e898-4306-9846-c945343cb50f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-39b85db1-b5b0-4f4a-a577-6367ee98a24a,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-23694209-1fc1-4ba7-97e8-0f8fdc1cf58c,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-ee518fdf-dff5-4f6a-9659-3d323219d809,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-a6816f6e-ca24-4314-9433-86e4403c960b,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-7f15bdce-876f-4ff8-b68f-6d3a2c81f3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446607726-172.17.0.17-1597284458037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-a057e923-7e5e-4643-9c80-1bdbb7ce9280,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-5cf2ddec-2234-49e2-8949-de940fa99f48,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-c6b98cff-e898-4306-9846-c945343cb50f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-39b85db1-b5b0-4f4a-a577-6367ee98a24a,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-23694209-1fc1-4ba7-97e8-0f8fdc1cf58c,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-ee518fdf-dff5-4f6a-9659-3d323219d809,DISK], DatanodeInfoWithStorage[127.0.0.1:42182,DS-a6816f6e-ca24-4314-9433-86e4403c960b,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-7f15bdce-876f-4ff8-b68f-6d3a2c81f3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901507658-172.17.0.17-1597284499923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-c59743e5-24f0-4626-b0f8-f46757257a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-4a8c8f35-f340-456d-b2e9-e805169e6bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-90f30f2b-aac8-4753-b4a3-c43ef86b2ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-f1927e69-3d13-4399-9622-5d6e16d33a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-c93cff2a-9b46-4fdd-b849-dc59fde1651a,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-602dff7e-a5c4-471f-93d5-216dfa2a89ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-3ad402b5-3883-4bca-b793-d8a579cbb9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-467f95a8-3acf-49ee-9fc6-3010a6b77960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901507658-172.17.0.17-1597284499923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39371,DS-c59743e5-24f0-4626-b0f8-f46757257a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-4a8c8f35-f340-456d-b2e9-e805169e6bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-90f30f2b-aac8-4753-b4a3-c43ef86b2ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-f1927e69-3d13-4399-9622-5d6e16d33a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-c93cff2a-9b46-4fdd-b849-dc59fde1651a,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-602dff7e-a5c4-471f-93d5-216dfa2a89ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-3ad402b5-3883-4bca-b793-d8a579cbb9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-467f95a8-3acf-49ee-9fc6-3010a6b77960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277774773-172.17.0.17-1597284538480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40106,DS-d05a0572-ff16-4dc6-95f1-85a0e8664d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-2ad15c24-21c3-4445-82c3-ff3265f7427e,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-5f909eeb-addc-48a2-a210-bd5042d6cbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-e093390a-71a5-4c2d-9c6e-07f070b17755,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-9442acc0-b751-45b3-9b4f-055bfa9aa9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-7c6d11e0-c1a1-46d2-a891-1354bf04bb87,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-06b55008-1e7c-4de7-89e4-6781c5a3a154,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-46766cb9-c610-4e34-9a1d-f91239c1d1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277774773-172.17.0.17-1597284538480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40106,DS-d05a0572-ff16-4dc6-95f1-85a0e8664d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-2ad15c24-21c3-4445-82c3-ff3265f7427e,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-5f909eeb-addc-48a2-a210-bd5042d6cbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-e093390a-71a5-4c2d-9c6e-07f070b17755,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-9442acc0-b751-45b3-9b4f-055bfa9aa9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-7c6d11e0-c1a1-46d2-a891-1354bf04bb87,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-06b55008-1e7c-4de7-89e4-6781c5a3a154,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-46766cb9-c610-4e34-9a1d-f91239c1d1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474355766-172.17.0.17-1597284847030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33077,DS-5b7b2a02-0ff3-4de7-8319-5283c22610a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-824dafd3-c960-4fb8-a592-9957fa4c7e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-cf12d42f-1581-45e9-8dd2-5ae4263095d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-6c405b75-2054-4044-abb1-0deb24d445b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-1002af82-fc80-4f80-a273-bf8c01db097e,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-cb07fc6f-0b00-48ce-b6a7-97a4639ec1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-5645442a-5613-4b54-a160-9f0f9bf7727a,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-2efcebf2-3013-4090-aa47-3a4b67ccc1f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-474355766-172.17.0.17-1597284847030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33077,DS-5b7b2a02-0ff3-4de7-8319-5283c22610a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-824dafd3-c960-4fb8-a592-9957fa4c7e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-cf12d42f-1581-45e9-8dd2-5ae4263095d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-6c405b75-2054-4044-abb1-0deb24d445b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-1002af82-fc80-4f80-a273-bf8c01db097e,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-cb07fc6f-0b00-48ce-b6a7-97a4639ec1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-5645442a-5613-4b54-a160-9f0f9bf7727a,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-2efcebf2-3013-4090-aa47-3a4b67ccc1f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780992104-172.17.0.17-1597285545569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33308,DS-3040168c-4111-4cd6-a67a-763c8dd61db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-0addd0c6-e4fe-4686-b93c-40d4884bae0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-508444cd-275b-4a5b-a55d-127e6db7a971,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-4b156195-414c-450b-85ef-2ceaf2ab25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-70fded27-2b37-4ade-935f-ee77b7b4f458,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-bd6fdf49-8f76-4195-8f46-96a7729d1b99,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-e482152b-3da3-47a7-9805-cfbc471083e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-471fe727-7ae3-4fc4-8e95-10d03b93b468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780992104-172.17.0.17-1597285545569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33308,DS-3040168c-4111-4cd6-a67a-763c8dd61db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-0addd0c6-e4fe-4686-b93c-40d4884bae0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-508444cd-275b-4a5b-a55d-127e6db7a971,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-4b156195-414c-450b-85ef-2ceaf2ab25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-70fded27-2b37-4ade-935f-ee77b7b4f458,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-bd6fdf49-8f76-4195-8f46-96a7729d1b99,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-e482152b-3da3-47a7-9805-cfbc471083e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-471fe727-7ae3-4fc4-8e95-10d03b93b468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097191156-172.17.0.17-1597285867719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37638,DS-c96dde25-819d-415a-8ef7-d681e3aa927c,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-7bb9108d-ac73-4006-880f-b057a7d2b519,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-d37e8245-8810-4f41-90c5-f189748f4c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-2d435f9e-36c4-4e32-aa6f-909f28443ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-ba9c08a2-0f52-4c32-b751-b1d9e33814f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-e17ec272-e79c-475f-ab28-05953332adb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-025c26d7-cfe9-453b-b30d-32fb4faa3146,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-4a44e21d-53cd-4da4-b9dc-5fa018e68b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097191156-172.17.0.17-1597285867719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37638,DS-c96dde25-819d-415a-8ef7-d681e3aa927c,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-7bb9108d-ac73-4006-880f-b057a7d2b519,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-d37e8245-8810-4f41-90c5-f189748f4c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-2d435f9e-36c4-4e32-aa6f-909f28443ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-ba9c08a2-0f52-4c32-b751-b1d9e33814f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-e17ec272-e79c-475f-ab28-05953332adb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-025c26d7-cfe9-453b-b30d-32fb4faa3146,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-4a44e21d-53cd-4da4-b9dc-5fa018e68b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243913588-172.17.0.17-1597286024918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33241,DS-23667f19-880a-48ea-9f90-464e38ab842b,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-f3cd7de1-d4d5-41fc-87f1-30dff231cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-46dd2899-eb39-4d86-8c7a-0469540b7891,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-cddb96f8-4e66-40c0-89c0-b4e515fd24d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-2894dae3-7d71-435d-b827-cd076bcc333e,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-5e28dab3-5839-4d0d-ac8e-841a6fc3196b,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-a72d4b6c-73ef-43ae-8949-cb45767c6ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-053888f9-5d35-4cce-bfaa-480b58a5e12b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243913588-172.17.0.17-1597286024918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33241,DS-23667f19-880a-48ea-9f90-464e38ab842b,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-f3cd7de1-d4d5-41fc-87f1-30dff231cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-46dd2899-eb39-4d86-8c7a-0469540b7891,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-cddb96f8-4e66-40c0-89c0-b4e515fd24d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-2894dae3-7d71-435d-b827-cd076bcc333e,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-5e28dab3-5839-4d0d-ac8e-841a6fc3196b,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-a72d4b6c-73ef-43ae-8949-cb45767c6ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-053888f9-5d35-4cce-bfaa-480b58a5e12b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877309542-172.17.0.17-1597286061191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35209,DS-c7e5d8cb-085d-4726-b80c-dc4d6588cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-51508e2f-e5e2-40b6-bb3e-b79c4db9cb60,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-bd442e66-11a5-4355-bc97-4863f2d65eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-c07f65fa-1715-464d-bdc8-a9c9b82cfb01,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-fff039c3-7f93-4e0d-9c7e-638f83b1f34f,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-523f7378-f506-4f88-bf28-684edb27279e,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-2fa1b2c0-0862-4b5a-8a73-7b25a04a2634,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-8158e9d3-77ab-445b-9f95-e0baf985e23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877309542-172.17.0.17-1597286061191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35209,DS-c7e5d8cb-085d-4726-b80c-dc4d6588cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-51508e2f-e5e2-40b6-bb3e-b79c4db9cb60,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-bd442e66-11a5-4355-bc97-4863f2d65eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-c07f65fa-1715-464d-bdc8-a9c9b82cfb01,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-fff039c3-7f93-4e0d-9c7e-638f83b1f34f,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-523f7378-f506-4f88-bf28-684edb27279e,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-2fa1b2c0-0862-4b5a-8a73-7b25a04a2634,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-8158e9d3-77ab-445b-9f95-e0baf985e23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1073741824
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769031055-172.17.0.17-1597286511173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44215,DS-72148a02-8340-488f-a875-a22d7ffb5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-fd8a333f-61bd-4645-961e-c978d1534665,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-4eeb7f3d-6d8a-4ec5-b1df-bd6c94efaa10,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-cb0e3022-6d43-4bd2-b548-89d39c8c1d43,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-257db672-810c-4bd8-b0f5-51fc356b30c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-c25de1ed-e8a7-4cb0-8afb-2de79ea63c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-1b255c07-4671-45c0-9b19-79616f336874,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-999182db-d5fb-439a-a18c-e062b1420770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769031055-172.17.0.17-1597286511173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44215,DS-72148a02-8340-488f-a875-a22d7ffb5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-fd8a333f-61bd-4645-961e-c978d1534665,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-4eeb7f3d-6d8a-4ec5-b1df-bd6c94efaa10,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-cb0e3022-6d43-4bd2-b548-89d39c8c1d43,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-257db672-810c-4bd8-b0f5-51fc356b30c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-c25de1ed-e8a7-4cb0-8afb-2de79ea63c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-1b255c07-4671-45c0-9b19-79616f336874,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-999182db-d5fb-439a-a18c-e062b1420770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5659
