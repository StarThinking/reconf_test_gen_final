reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827377060-172.17.0.21-1597533574515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46249,DS-8d338857-29d9-4cd2-ae6c-f85e597157fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-8247d5c9-f016-43d8-9b15-e0e5f0e8fe70,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-08b9ecc1-ed2a-4e89-96b9-48244eead5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-92a72982-da0e-4c98-bf29-5cd659f84e81,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d9f4790a-72cc-467e-9479-44faa3cf4871,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-98c0ec06-a29a-42db-a1d1-bb62f921a33a,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-e05300e2-fe43-4d25-bd19-a2067580beef,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-43b121ad-f28b-4f29-b66d-e6788f3eecdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827377060-172.17.0.21-1597533574515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46249,DS-8d338857-29d9-4cd2-ae6c-f85e597157fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-8247d5c9-f016-43d8-9b15-e0e5f0e8fe70,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-08b9ecc1-ed2a-4e89-96b9-48244eead5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-92a72982-da0e-4c98-bf29-5cd659f84e81,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d9f4790a-72cc-467e-9479-44faa3cf4871,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-98c0ec06-a29a-42db-a1d1-bb62f921a33a,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-e05300e2-fe43-4d25-bd19-a2067580beef,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-43b121ad-f28b-4f29-b66d-e6788f3eecdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132485143-172.17.0.21-1597533678483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38233,DS-fcaf5d7c-dc64-43ef-b573-85eb88701381,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-8d174a80-6ceb-4e25-8778-692f38e6c9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-51d03c7d-8ed9-4d7a-9747-b2d1b9a26798,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-c79f49d2-75b2-4972-9c30-a44b1f8766db,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-fa7a3be4-bb4f-4b14-99a4-125246cfde17,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-0b2f966f-ab13-482c-ba3f-a373ebcfa693,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-eed82bf8-576d-40fa-8ba8-94841a38817f,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-8c1ef807-da77-4c0e-9c71-2273a909fa10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132485143-172.17.0.21-1597533678483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38233,DS-fcaf5d7c-dc64-43ef-b573-85eb88701381,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-8d174a80-6ceb-4e25-8778-692f38e6c9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-51d03c7d-8ed9-4d7a-9747-b2d1b9a26798,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-c79f49d2-75b2-4972-9c30-a44b1f8766db,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-fa7a3be4-bb4f-4b14-99a4-125246cfde17,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-0b2f966f-ab13-482c-ba3f-a373ebcfa693,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-eed82bf8-576d-40fa-8ba8-94841a38817f,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-8c1ef807-da77-4c0e-9c71-2273a909fa10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829756863-172.17.0.21-1597533822309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-d40a5eb9-0955-45aa-b523-461f8476cdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-ebac4fe2-59c3-449d-b70c-3daf040ee58f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-11a43c52-0935-46e5-8262-b0533bac7185,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-ed055523-7406-43a3-a4ef-999258959458,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-1da0c2c4-d43c-4ba0-bc56-1a6718eca1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-73b0db43-2540-498e-93e4-8270b0f8b6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-63bf2e63-532f-4f4a-82a6-a91b04f1f8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-6fa71e01-ee9a-4855-97d6-c560f580944c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829756863-172.17.0.21-1597533822309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43055,DS-d40a5eb9-0955-45aa-b523-461f8476cdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-ebac4fe2-59c3-449d-b70c-3daf040ee58f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-11a43c52-0935-46e5-8262-b0533bac7185,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-ed055523-7406-43a3-a4ef-999258959458,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-1da0c2c4-d43c-4ba0-bc56-1a6718eca1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-73b0db43-2540-498e-93e4-8270b0f8b6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-63bf2e63-532f-4f4a-82a6-a91b04f1f8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-6fa71e01-ee9a-4855-97d6-c560f580944c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14572796-172.17.0.21-1597533886180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37328,DS-cc3e057e-90ae-4cda-92f3-d16b67d25579,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-ef5128ad-f740-4e8f-8aeb-99d198966ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-36d2f5a6-1306-438d-b8b6-595d42d3c8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-1315fe4b-6d97-43df-9982-43306bbec929,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-78248b96-1b49-4551-8934-3b0d25f4481f,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-dbef0f3f-e972-4d64-909e-f053d89704d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-f2a07a70-d3b3-4f5c-9fcb-3b76ce8bbae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-6d221201-4b4a-46a2-bb21-b83a272d0793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14572796-172.17.0.21-1597533886180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37328,DS-cc3e057e-90ae-4cda-92f3-d16b67d25579,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-ef5128ad-f740-4e8f-8aeb-99d198966ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-36d2f5a6-1306-438d-b8b6-595d42d3c8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-1315fe4b-6d97-43df-9982-43306bbec929,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-78248b96-1b49-4551-8934-3b0d25f4481f,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-dbef0f3f-e972-4d64-909e-f053d89704d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-f2a07a70-d3b3-4f5c-9fcb-3b76ce8bbae5,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-6d221201-4b4a-46a2-bb21-b83a272d0793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126036498-172.17.0.21-1597534034202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45897,DS-6f8d0af3-0780-4baa-8344-af00b460b72d,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-dfef314c-4938-4d83-b4d5-e3b7e1e79920,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-134ecd3e-f75b-4c71-bc88-88af70d4df9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-78cb0c7f-8b15-401e-a64d-c75b71dfb898,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-552cbe7a-1df7-41da-ae0b-0360991fd956,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-d2f3f35d-895b-4746-8918-cd00bb98d763,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-61a859d5-3c29-49c0-88dd-6d574bb57bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-a62ba09e-7033-4f52-8f93-fd2d6662ce46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126036498-172.17.0.21-1597534034202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45897,DS-6f8d0af3-0780-4baa-8344-af00b460b72d,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-dfef314c-4938-4d83-b4d5-e3b7e1e79920,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-134ecd3e-f75b-4c71-bc88-88af70d4df9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-78cb0c7f-8b15-401e-a64d-c75b71dfb898,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-552cbe7a-1df7-41da-ae0b-0360991fd956,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-d2f3f35d-895b-4746-8918-cd00bb98d763,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-61a859d5-3c29-49c0-88dd-6d574bb57bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-a62ba09e-7033-4f52-8f93-fd2d6662ce46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772430176-172.17.0.21-1597534082028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37100,DS-6e76f99a-ed2a-4f03-a661-ebde39319b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-59c1fe06-a6c7-4141-8ea1-0fca83b335c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-0fdb4d0e-4cb0-40d1-b34e-5cd4fae24bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-6210daab-6866-484d-9902-98905d13fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-313d03de-9a19-47f0-9728-b1a2d1c078fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-732d4702-27f3-4fa6-bbcc-c49dbfdfcbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1931d178-b3bb-4e48-b7b6-f479c3927948,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-15678991-5ff2-4d75-8f9a-35fd2b7cbb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772430176-172.17.0.21-1597534082028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37100,DS-6e76f99a-ed2a-4f03-a661-ebde39319b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-59c1fe06-a6c7-4141-8ea1-0fca83b335c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-0fdb4d0e-4cb0-40d1-b34e-5cd4fae24bca,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-6210daab-6866-484d-9902-98905d13fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-313d03de-9a19-47f0-9728-b1a2d1c078fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-732d4702-27f3-4fa6-bbcc-c49dbfdfcbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1931d178-b3bb-4e48-b7b6-f479c3927948,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-15678991-5ff2-4d75-8f9a-35fd2b7cbb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161872763-172.17.0.21-1597534556519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34704,DS-7b3034eb-7441-4279-8115-b8b2e7cee8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-02587dd4-fac3-425c-9153-3183a323dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-2b1fdace-9b16-49d5-a823-99522db82c65,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-b9303b97-22c7-46a3-af60-976910b2b8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-dee726dd-db65-4729-8979-235098da0c34,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-12c3ae3d-b5f8-4f7c-af57-1b169bb8984b,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-49cb19ac-a4f4-4620-b994-99ae111badbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-41b5e7f5-508b-4b47-99b6-090d9f129dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161872763-172.17.0.21-1597534556519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34704,DS-7b3034eb-7441-4279-8115-b8b2e7cee8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-02587dd4-fac3-425c-9153-3183a323dceb,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-2b1fdace-9b16-49d5-a823-99522db82c65,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-b9303b97-22c7-46a3-af60-976910b2b8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-dee726dd-db65-4729-8979-235098da0c34,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-12c3ae3d-b5f8-4f7c-af57-1b169bb8984b,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-49cb19ac-a4f4-4620-b994-99ae111badbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-41b5e7f5-508b-4b47-99b6-090d9f129dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895620968-172.17.0.21-1597534669367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-d6792dba-72dd-4e82-9bf8-20f551edda74,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-710f8334-21a7-46d2-ad15-16b3b4bbd725,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-10ffbdc8-bd0d-4271-aa86-7abce01acebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-8566c651-70a0-47dd-8138-7b861ef9f844,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-3bcd989a-6052-4d2c-bddd-55f3c9a84b96,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-0ef78b02-e23c-42f8-8152-2a8e06b9db97,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-71016563-b439-4199-8250-37ce5077e271,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-38806359-da1a-4e93-8b29-01a960b06ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895620968-172.17.0.21-1597534669367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-d6792dba-72dd-4e82-9bf8-20f551edda74,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-710f8334-21a7-46d2-ad15-16b3b4bbd725,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-10ffbdc8-bd0d-4271-aa86-7abce01acebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-8566c651-70a0-47dd-8138-7b861ef9f844,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-3bcd989a-6052-4d2c-bddd-55f3c9a84b96,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-0ef78b02-e23c-42f8-8152-2a8e06b9db97,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-71016563-b439-4199-8250-37ce5077e271,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-38806359-da1a-4e93-8b29-01a960b06ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717708301-172.17.0.21-1597534916427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-31d25893-6275-4f80-a7f4-4e1f4db7c22b,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-18dae387-c9b2-4ac4-98f3-0db074a0ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-1d82569a-3a48-4c8b-bad9-028bc9153d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-5cd28d93-84dd-4bec-b2d4-f22c7ac0d4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-c9bc8e09-cfc4-4163-8b26-fb87b65889fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-421520dc-862f-4406-a43f-923f9c8d73ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-b04b051a-6f82-4261-bf71-84f1f3392ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-cea8817a-0e57-4472-ac2f-dd9c7f77d8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717708301-172.17.0.21-1597534916427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-31d25893-6275-4f80-a7f4-4e1f4db7c22b,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-18dae387-c9b2-4ac4-98f3-0db074a0ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-1d82569a-3a48-4c8b-bad9-028bc9153d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-5cd28d93-84dd-4bec-b2d4-f22c7ac0d4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-c9bc8e09-cfc4-4163-8b26-fb87b65889fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-421520dc-862f-4406-a43f-923f9c8d73ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-b04b051a-6f82-4261-bf71-84f1f3392ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-cea8817a-0e57-4472-ac2f-dd9c7f77d8a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338344507-172.17.0.21-1597535334474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38373,DS-8293c593-d326-4a0b-8003-c72baa0834ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-13ec6e3e-7c07-4ccc-ac36-3527d51abefe,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-5c60e8b5-b665-407a-a3b8-62eda0ee6e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-b6b7bab3-bb88-4fb5-8f22-f4f324f8916e,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-b4f20f6e-77f1-472e-a271-f13e85d891b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-8a0a23f6-a147-4d7e-ab63-dc1a6046a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-c033710c-22d8-4c3b-ac92-712711178bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-3eec2fb3-1e42-406f-a210-835150463227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338344507-172.17.0.21-1597535334474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38373,DS-8293c593-d326-4a0b-8003-c72baa0834ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-13ec6e3e-7c07-4ccc-ac36-3527d51abefe,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-5c60e8b5-b665-407a-a3b8-62eda0ee6e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-b6b7bab3-bb88-4fb5-8f22-f4f324f8916e,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-b4f20f6e-77f1-472e-a271-f13e85d891b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-8a0a23f6-a147-4d7e-ab63-dc1a6046a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-c033710c-22d8-4c3b-ac92-712711178bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-3eec2fb3-1e42-406f-a210-835150463227,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266780905-172.17.0.21-1597535528147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44105,DS-e3f3cd50-fb3d-4d1e-9322-9ceaf3b64fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-906bcc7a-0bd9-4699-a9eb-42bc845d432c,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-b52fbca5-e584-47e4-a49a-663ef8bdbe70,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-18b4c15d-2697-471e-af4b-1062421a3e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-54c5fce7-f3d5-4810-8337-7189e86e57c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-48b6cc25-b2ce-4c06-a698-b0a8b186add6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-6bea8130-ce07-400a-bc2a-63106e2bc747,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-e8542f2e-330a-4927-b1ad-8c05997952e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266780905-172.17.0.21-1597535528147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44105,DS-e3f3cd50-fb3d-4d1e-9322-9ceaf3b64fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-906bcc7a-0bd9-4699-a9eb-42bc845d432c,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-b52fbca5-e584-47e4-a49a-663ef8bdbe70,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-18b4c15d-2697-471e-af4b-1062421a3e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-54c5fce7-f3d5-4810-8337-7189e86e57c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-48b6cc25-b2ce-4c06-a698-b0a8b186add6,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-6bea8130-ce07-400a-bc2a-63106e2bc747,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-e8542f2e-330a-4927-b1ad-8c05997952e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421963624-172.17.0.21-1597535726229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42256,DS-c2fe865a-3d57-4dbd-8b98-2cd8136d6122,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-9b9afddd-6edb-4e81-8995-87d53fe13044,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-0cf51c40-009d-48b6-9bdb-7207c6adc889,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-ddccd8e6-57c1-4953-9987-8ce8f3dcc151,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-30a0ea50-7fcf-400a-9914-bf57415113b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-3992edfc-c366-4794-af49-492df8e3b012,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-1675c5bd-31d6-420c-9aa4-3c8362c2badf,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-cd07b703-fbe3-4bb6-8373-bfe08e56d29e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421963624-172.17.0.21-1597535726229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42256,DS-c2fe865a-3d57-4dbd-8b98-2cd8136d6122,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-9b9afddd-6edb-4e81-8995-87d53fe13044,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-0cf51c40-009d-48b6-9bdb-7207c6adc889,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-ddccd8e6-57c1-4953-9987-8ce8f3dcc151,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-30a0ea50-7fcf-400a-9914-bf57415113b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-3992edfc-c366-4794-af49-492df8e3b012,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-1675c5bd-31d6-420c-9aa4-3c8362c2badf,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-cd07b703-fbe3-4bb6-8373-bfe08e56d29e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485523263-172.17.0.21-1597536335301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37573,DS-ffc2371c-60e0-4514-9349-624137119b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-4d95c4e1-1412-4127-9013-89956f279190,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-2614fd2c-b3b6-405d-8069-a0ae6497f853,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-9b179e91-2e5f-4b84-aa51-cea571b962fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-83382e75-2d4b-4081-8af0-79aec9f29cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-e10964f7-50a5-409b-8a69-2b6d60415974,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-57003261-3db7-48cc-90dd-afee69d815a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-a5e8d264-468f-4b64-9f9d-43ad176ca513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485523263-172.17.0.21-1597536335301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37573,DS-ffc2371c-60e0-4514-9349-624137119b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-4d95c4e1-1412-4127-9013-89956f279190,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-2614fd2c-b3b6-405d-8069-a0ae6497f853,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-9b179e91-2e5f-4b84-aa51-cea571b962fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-83382e75-2d4b-4081-8af0-79aec9f29cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-e10964f7-50a5-409b-8a69-2b6d60415974,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-57003261-3db7-48cc-90dd-afee69d815a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-a5e8d264-468f-4b64-9f9d-43ad176ca513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793871338-172.17.0.21-1597536573828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44118,DS-4a43d8c0-4c98-4908-9c61-9f69c7326f90,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-480f6ea7-eae6-4bfc-8c8b-c02691578e17,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-ec88b07d-216b-46bc-a2e7-326113bc3a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-d3d1b89b-ca6c-47c5-a27c-d08425ca6951,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-ae66195b-a26d-4ac8-94a2-ddfeb5b14487,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-6e3ccfc2-4a8a-4c93-b2bb-8795fe20f759,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-bb3c47f7-822a-4e03-9539-acc08ed0dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-3ce197c4-be11-4b61-a9a2-412a61346fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793871338-172.17.0.21-1597536573828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44118,DS-4a43d8c0-4c98-4908-9c61-9f69c7326f90,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-480f6ea7-eae6-4bfc-8c8b-c02691578e17,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-ec88b07d-216b-46bc-a2e7-326113bc3a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-d3d1b89b-ca6c-47c5-a27c-d08425ca6951,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-ae66195b-a26d-4ac8-94a2-ddfeb5b14487,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-6e3ccfc2-4a8a-4c93-b2bb-8795fe20f759,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-bb3c47f7-822a-4e03-9539-acc08ed0dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-3ce197c4-be11-4b61-a9a2-412a61346fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265161746-172.17.0.21-1597536606341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44076,DS-1060d845-5e9c-4d34-ab85-612884df8990,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-3b164ae9-d88b-49ee-9bf7-52cb56ddceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-45584877-193e-4ab4-92a3-c52d3289f5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-e470e216-f9c6-443b-89cb-e87ee9998b19,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-c5767aa2-878b-49d2-b054-18a01b63b795,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-dd1f985a-6344-4eac-a55c-61b319c9d874,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-84edb41c-e941-4e0d-a122-60e983bcaef8,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-82014025-e5f0-46b2-8505-99c4b2c645b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265161746-172.17.0.21-1597536606341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44076,DS-1060d845-5e9c-4d34-ab85-612884df8990,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-3b164ae9-d88b-49ee-9bf7-52cb56ddceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-45584877-193e-4ab4-92a3-c52d3289f5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-e470e216-f9c6-443b-89cb-e87ee9998b19,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-c5767aa2-878b-49d2-b054-18a01b63b795,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-dd1f985a-6344-4eac-a55c-61b319c9d874,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-84edb41c-e941-4e0d-a122-60e983bcaef8,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-82014025-e5f0-46b2-8505-99c4b2c645b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110003481-172.17.0.21-1597536852515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43549,DS-b92060da-3314-47bd-bafd-5a7b4042e142,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-1cb3e3b9-d183-4494-bdec-275e312b48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-f48d2196-2d71-4adb-8cf6-7fdff854ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-1f6f0868-6f80-452b-8bfe-7e8c3bcef2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-6c854eb2-31f9-47b3-b0b0-32804b8b69cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-1a6cb0cd-fd82-4cf4-9061-15ae3911af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-f3390921-b6f5-44ac-857e-3f72352b12b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-0aa88389-1a96-4a47-a9d8-3934c58349ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110003481-172.17.0.21-1597536852515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43549,DS-b92060da-3314-47bd-bafd-5a7b4042e142,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-1cb3e3b9-d183-4494-bdec-275e312b48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-f48d2196-2d71-4adb-8cf6-7fdff854ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-1f6f0868-6f80-452b-8bfe-7e8c3bcef2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-6c854eb2-31f9-47b3-b0b0-32804b8b69cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-1a6cb0cd-fd82-4cf4-9061-15ae3911af4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-f3390921-b6f5-44ac-857e-3f72352b12b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-0aa88389-1a96-4a47-a9d8-3934c58349ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728040217-172.17.0.21-1597537408664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-90e1c8cc-593b-44bd-b911-7a490ed100f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-9e2d7f1c-afb4-4ea3-8c37-546511665823,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-fb24cec5-49d9-4162-8c2d-ff9899a41af6,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-3b0f49e6-3e93-4c1f-b39c-200809d0ec19,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-739aecc5-36fc-4cad-83ed-7123a84c424c,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-f2dab592-4cd5-4e05-a3fc-5c426ede432b,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-75539d3a-64b2-4d33-ae12-d6b25802ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-925d321e-0696-4f60-88e5-9e38c840e086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728040217-172.17.0.21-1597537408664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39098,DS-90e1c8cc-593b-44bd-b911-7a490ed100f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-9e2d7f1c-afb4-4ea3-8c37-546511665823,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-fb24cec5-49d9-4162-8c2d-ff9899a41af6,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-3b0f49e6-3e93-4c1f-b39c-200809d0ec19,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-739aecc5-36fc-4cad-83ed-7123a84c424c,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-f2dab592-4cd5-4e05-a3fc-5c426ede432b,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-75539d3a-64b2-4d33-ae12-d6b25802ae21,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-925d321e-0696-4f60-88e5-9e38c840e086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163263335-172.17.0.21-1597537607850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-cc6625df-07fd-4569-b4b5-f20fd442d7af,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-f5efd7ba-c96f-4a3f-9fcb-05c058df15e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-5500d247-ccc3-419e-8f52-d27707db52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-ae83f665-bc52-4daf-8044-5a5a8ebe0e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-a5cbc454-1e6c-4236-85e7-3e90e1863776,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-daf9867a-8385-4202-bc8c-c7313172c6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-b157a1ea-964f-41a7-8db7-a833c05f2390,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-be5f32e5-c365-4975-90cc-b4c4b784a514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163263335-172.17.0.21-1597537607850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-cc6625df-07fd-4569-b4b5-f20fd442d7af,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-f5efd7ba-c96f-4a3f-9fcb-05c058df15e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-5500d247-ccc3-419e-8f52-d27707db52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-ae83f665-bc52-4daf-8044-5a5a8ebe0e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-a5cbc454-1e6c-4236-85e7-3e90e1863776,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-daf9867a-8385-4202-bc8c-c7313172c6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-b157a1ea-964f-41a7-8db7-a833c05f2390,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-be5f32e5-c365-4975-90cc-b4c4b784a514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500097480-172.17.0.21-1597538166765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34225,DS-147e6d0d-1f4c-4afa-be4a-4e5fd6f6c8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-43aa185e-cd2c-41a9-883a-90f93812a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-df4ac4aa-6282-4596-bfdd-79a48d9f3513,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-a802e020-d650-4b59-9e79-25dee499b399,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-dc98ff3b-6db7-4f77-acd8-a955e44f29ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-cc2b343a-a8cc-43f2-914a-80a671d2e155,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-865ad6f8-f253-43c0-8698-90a1be82be71,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-a7280a63-e013-438d-8e03-fa03e1d4b4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500097480-172.17.0.21-1597538166765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34225,DS-147e6d0d-1f4c-4afa-be4a-4e5fd6f6c8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-43aa185e-cd2c-41a9-883a-90f93812a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-df4ac4aa-6282-4596-bfdd-79a48d9f3513,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-a802e020-d650-4b59-9e79-25dee499b399,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-dc98ff3b-6db7-4f77-acd8-a955e44f29ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-cc2b343a-a8cc-43f2-914a-80a671d2e155,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-865ad6f8-f253-43c0-8698-90a1be82be71,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-a7280a63-e013-438d-8e03-fa03e1d4b4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454930561-172.17.0.21-1597538320719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-e9f7eb3e-1664-4233-9969-87bdd7d34782,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-3c738c99-f8df-4749-83ac-681d42ce1ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-03d09fcc-5066-43a2-b1b6-b9563e59d785,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-44cbdaa0-ae21-4fa3-9c68-0862d7d1c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-20b5c4c4-1234-40c2-81a2-3796cb427c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-015b1e82-0c2d-45ff-b854-3060f67ccba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-7b202b7b-7eb6-4c8d-bcad-0db64c893596,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-de88339d-1e75-47a0-b373-07462bcf4d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454930561-172.17.0.21-1597538320719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-e9f7eb3e-1664-4233-9969-87bdd7d34782,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-3c738c99-f8df-4749-83ac-681d42ce1ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-03d09fcc-5066-43a2-b1b6-b9563e59d785,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-44cbdaa0-ae21-4fa3-9c68-0862d7d1c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-20b5c4c4-1234-40c2-81a2-3796cb427c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-015b1e82-0c2d-45ff-b854-3060f67ccba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-7b202b7b-7eb6-4c8d-bcad-0db64c893596,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-de88339d-1e75-47a0-b373-07462bcf4d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091843661-172.17.0.21-1597538394794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-38feab38-fd79-42d0-9014-e41eaa65c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-413fcf8b-fe10-44f6-96d9-04437d3fe67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-af9edbc0-b4a9-4b40-ba49-4f48c0356bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-6f72a2d3-b545-444d-8036-8c10c99206ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-ae801d76-7900-4581-b426-8ab94de89dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-58a936d6-7c51-4189-9a60-a43bb8d375f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-5c7140d2-fc5c-4cd2-8212-f26513e70bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-e3e9715b-e166-45ce-ae43-6aa4c2d4a88c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091843661-172.17.0.21-1597538394794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-38feab38-fd79-42d0-9014-e41eaa65c17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-413fcf8b-fe10-44f6-96d9-04437d3fe67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-af9edbc0-b4a9-4b40-ba49-4f48c0356bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-6f72a2d3-b545-444d-8036-8c10c99206ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-ae801d76-7900-4581-b426-8ab94de89dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-58a936d6-7c51-4189-9a60-a43bb8d375f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-5c7140d2-fc5c-4cd2-8212-f26513e70bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-e3e9715b-e166-45ce-ae43-6aa4c2d4a88c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790792472-172.17.0.21-1597538738689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42537,DS-304f31a3-1630-4f2e-865b-b124128d7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-1e7cb900-38fa-4ec5-aeab-f5ad36e074a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-ec58e3cf-0605-4410-a947-e62cec7ba59b,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-86cfa1da-69ba-4913-9545-2fd8ca93b2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-b0d98892-ae8a-42aa-9411-33386a428768,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-5b11d4d9-49cf-4704-9d94-682cf5c3487b,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-29ff0f7a-30c0-4882-9908-ca4db934507a,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-053c637d-a028-46a9-9c20-42f70457e4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790792472-172.17.0.21-1597538738689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42537,DS-304f31a3-1630-4f2e-865b-b124128d7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-1e7cb900-38fa-4ec5-aeab-f5ad36e074a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-ec58e3cf-0605-4410-a947-e62cec7ba59b,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-86cfa1da-69ba-4913-9545-2fd8ca93b2af,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-b0d98892-ae8a-42aa-9411-33386a428768,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-5b11d4d9-49cf-4704-9d94-682cf5c3487b,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-29ff0f7a-30c0-4882-9908-ca4db934507a,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-053c637d-a028-46a9-9c20-42f70457e4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267008770-172.17.0.21-1597538775951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-b871ff44-64a8-48c5-a29d-01e51eabde83,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-439bfd9a-634e-4011-8677-585e06f34bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-68636f72-9dcb-4f60-9544-71809c7319b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-ff6a529b-bbff-48d8-83e9-1cec0314e8df,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-516c96e4-d235-44c2-a7a2-351f38225a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-e021ec6c-dd64-4e9a-badb-42112446dc51,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-ab02c857-7687-4474-a0e3-52e806f788c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-6d87faa6-9710-41d5-8f54-ba31c226b664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267008770-172.17.0.21-1597538775951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-b871ff44-64a8-48c5-a29d-01e51eabde83,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-439bfd9a-634e-4011-8677-585e06f34bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-68636f72-9dcb-4f60-9544-71809c7319b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-ff6a529b-bbff-48d8-83e9-1cec0314e8df,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-516c96e4-d235-44c2-a7a2-351f38225a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-e021ec6c-dd64-4e9a-badb-42112446dc51,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-ab02c857-7687-4474-a0e3-52e806f788c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-6d87faa6-9710-41d5-8f54-ba31c226b664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5625
