reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545346286-172.17.0.18-1597508545466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-c8b5d68b-f1e2-4a42-ae63-1046ccadd08d,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-09860e35-3a80-40d4-8ef0-605bdcd5258a,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-aea36161-81db-4735-a630-00dd63515c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-d75d8990-e78b-4323-b6e9-d884214ec59a,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-d6c2acb0-5c64-4bff-bf34-e5a2e12a3025,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-4f2bc56c-f450-45b5-8567-ebbd4d55d86c,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-3f2e0037-cc75-4341-9e93-b9beb413f090,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-dc30b980-d97e-46ac-bd1c-5b7a7725107b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545346286-172.17.0.18-1597508545466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-c8b5d68b-f1e2-4a42-ae63-1046ccadd08d,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-09860e35-3a80-40d4-8ef0-605bdcd5258a,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-aea36161-81db-4735-a630-00dd63515c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-d75d8990-e78b-4323-b6e9-d884214ec59a,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-d6c2acb0-5c64-4bff-bf34-e5a2e12a3025,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-4f2bc56c-f450-45b5-8567-ebbd4d55d86c,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-3f2e0037-cc75-4341-9e93-b9beb413f090,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-dc30b980-d97e-46ac-bd1c-5b7a7725107b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479440873-172.17.0.18-1597508806544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-71df425f-35b2-44a7-bbfb-bb96c2ecddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-dcdbc1e5-5d6d-43cd-bb95-0b03e4a7bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-df1165c3-d562-46b7-b440-22a6e76c619c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-f2b367d3-fcd7-4a37-a85d-e7797b6011cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-f380b980-b25f-4473-a259-09f0b545cc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-95c0a433-ecd3-4673-9c95-c02208436867,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-c58fcefb-3f9d-4267-942b-7d3d31349ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-13b03f37-bb71-46b6-b9ef-e0bc5bd4974a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479440873-172.17.0.18-1597508806544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-71df425f-35b2-44a7-bbfb-bb96c2ecddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-dcdbc1e5-5d6d-43cd-bb95-0b03e4a7bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-df1165c3-d562-46b7-b440-22a6e76c619c,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-f2b367d3-fcd7-4a37-a85d-e7797b6011cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-f380b980-b25f-4473-a259-09f0b545cc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-95c0a433-ecd3-4673-9c95-c02208436867,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-c58fcefb-3f9d-4267-942b-7d3d31349ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-13b03f37-bb71-46b6-b9ef-e0bc5bd4974a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221587883-172.17.0.18-1597508877205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37478,DS-bba673c1-d4b5-49f4-a73d-8aaff7c9bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-3c6f1ea1-1f5f-4298-b3c2-b2f398a98875,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-bec1c7ac-f2cc-411f-a5d1-ac88ba7aa8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-9d6fe80e-5f39-4e17-9faa-6c51a427f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-d26d227d-0fca-4eeb-8a52-dc51404a94e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-2a5dec34-3474-4153-abdc-ed907b9760a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-e2a7633a-63c4-4827-8db8-86f78049fe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-48bc5376-92c8-4982-8b18-4740e7166882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1221587883-172.17.0.18-1597508877205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37478,DS-bba673c1-d4b5-49f4-a73d-8aaff7c9bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-3c6f1ea1-1f5f-4298-b3c2-b2f398a98875,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-bec1c7ac-f2cc-411f-a5d1-ac88ba7aa8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-9d6fe80e-5f39-4e17-9faa-6c51a427f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-d26d227d-0fca-4eeb-8a52-dc51404a94e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-2a5dec34-3474-4153-abdc-ed907b9760a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-e2a7633a-63c4-4827-8db8-86f78049fe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-48bc5376-92c8-4982-8b18-4740e7166882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134402802-172.17.0.18-1597509068053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41794,DS-9a199933-2b56-4208-9847-3c8796ed598a,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-2aa199ba-c066-49f2-b986-a98aeb6e2fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-a9d6469a-e647-4175-a810-adcf83ae2288,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-1cda5138-3fd8-4e4c-9335-0874d80a7861,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-1d953633-148a-49b1-b91c-0c77c9cdda9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-efa42bc3-21c9-4148-b5a1-3523db7fa963,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-ff8f0bc9-6d0a-42a7-b6a2-24fa1c87f88c,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-87311147-174d-4481-ae73-dc85195cff77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134402802-172.17.0.18-1597509068053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41794,DS-9a199933-2b56-4208-9847-3c8796ed598a,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-2aa199ba-c066-49f2-b986-a98aeb6e2fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-a9d6469a-e647-4175-a810-adcf83ae2288,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-1cda5138-3fd8-4e4c-9335-0874d80a7861,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-1d953633-148a-49b1-b91c-0c77c9cdda9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-efa42bc3-21c9-4148-b5a1-3523db7fa963,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-ff8f0bc9-6d0a-42a7-b6a2-24fa1c87f88c,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-87311147-174d-4481-ae73-dc85195cff77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436505038-172.17.0.18-1597509099288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36922,DS-0d752fa9-48c6-4106-be3b-2284851ca04f,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-8cbecf2b-0146-4b18-ad25-88e9517a97e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-7981ed44-0ac5-4f47-8a2c-ee7490098ade,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-4d531952-03fb-4405-91f4-1494458b185c,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-f9bf09f7-1234-4394-98b4-54106ad00dce,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-7dd9a9ec-5ae3-47b2-8491-d86d9cd7793c,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-9e4b5c23-4747-4dd7-a5a4-6b7bcf04cda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-cffaccb4-d705-4878-bd48-ac923c236069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436505038-172.17.0.18-1597509099288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36922,DS-0d752fa9-48c6-4106-be3b-2284851ca04f,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-8cbecf2b-0146-4b18-ad25-88e9517a97e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-7981ed44-0ac5-4f47-8a2c-ee7490098ade,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-4d531952-03fb-4405-91f4-1494458b185c,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-f9bf09f7-1234-4394-98b4-54106ad00dce,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-7dd9a9ec-5ae3-47b2-8491-d86d9cd7793c,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-9e4b5c23-4747-4dd7-a5a4-6b7bcf04cda5,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-cffaccb4-d705-4878-bd48-ac923c236069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750210109-172.17.0.18-1597509251834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34756,DS-56a98426-4156-4e1d-bbd0-d3bec71b350e,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-be6b4880-7748-4ecc-8c63-f4152f6199cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-2a7d5ac3-eb46-4e8b-93de-889940735284,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-a4f36285-e4fa-43e0-a3a4-064c93b48e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-19389aee-1775-4676-97e3-fb281ad8420c,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-e58c8a60-8840-4b31-aa37-d6eec669dba9,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-7a1ccb53-8c16-4ee8-883d-ff3c6fb0d4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-2fa45fd0-7699-4079-a81e-4e4b6863a006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750210109-172.17.0.18-1597509251834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34756,DS-56a98426-4156-4e1d-bbd0-d3bec71b350e,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-be6b4880-7748-4ecc-8c63-f4152f6199cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-2a7d5ac3-eb46-4e8b-93de-889940735284,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-a4f36285-e4fa-43e0-a3a4-064c93b48e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-19389aee-1775-4676-97e3-fb281ad8420c,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-e58c8a60-8840-4b31-aa37-d6eec669dba9,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-7a1ccb53-8c16-4ee8-883d-ff3c6fb0d4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-2fa45fd0-7699-4079-a81e-4e4b6863a006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270059748-172.17.0.18-1597509391382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-8c2f3fa2-c6da-4b07-9c38-7808d601a64f,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-9995746e-2dd5-4afd-824e-92f481a02ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-fcf02b37-32b0-41e7-9b40-a014f8c86ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-287eecb1-18a0-4757-a5b6-fbb22f9de870,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-45aa9070-6070-48c7-b37f-357a9b087b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-bc46f46f-cbd2-40ab-898a-0fa396b7a74c,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-2987cd4c-49f0-43ae-b0a0-18cf3cb30493,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-10f6c211-caca-48ca-a759-4eddd88aa3aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270059748-172.17.0.18-1597509391382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32837,DS-8c2f3fa2-c6da-4b07-9c38-7808d601a64f,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-9995746e-2dd5-4afd-824e-92f481a02ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-fcf02b37-32b0-41e7-9b40-a014f8c86ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-287eecb1-18a0-4757-a5b6-fbb22f9de870,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-45aa9070-6070-48c7-b37f-357a9b087b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-bc46f46f-cbd2-40ab-898a-0fa396b7a74c,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-2987cd4c-49f0-43ae-b0a0-18cf3cb30493,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-10f6c211-caca-48ca-a759-4eddd88aa3aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203443356-172.17.0.18-1597509580285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44556,DS-6f2852b6-58d5-4dda-baec-99e6df564cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-3878b0c1-4f7c-48fe-98a6-df78d7fd8eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-41034af4-3932-426e-8820-b155285de3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-0f03f863-e488-4400-ac45-a040dc01a561,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-ba6f2240-76b4-4524-b274-a48ea2ff42ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-0fb6e533-5f30-4f83-a48c-93dc88ab5c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-5e604385-b153-4476-b537-a4dd22ee45fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-ef8baef3-65c8-4665-9a70-e2715ce2652b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203443356-172.17.0.18-1597509580285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44556,DS-6f2852b6-58d5-4dda-baec-99e6df564cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-3878b0c1-4f7c-48fe-98a6-df78d7fd8eea,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-41034af4-3932-426e-8820-b155285de3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-0f03f863-e488-4400-ac45-a040dc01a561,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-ba6f2240-76b4-4524-b274-a48ea2ff42ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-0fb6e533-5f30-4f83-a48c-93dc88ab5c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34749,DS-5e604385-b153-4476-b537-a4dd22ee45fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-ef8baef3-65c8-4665-9a70-e2715ce2652b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111505245-172.17.0.18-1597509696562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-30fd0034-f9ac-4c0a-8583-85172b84ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-cdf7fd27-ec7b-4763-9161-8376212b6026,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-26ef5b8a-21c8-4890-a3ba-bad6fd00d2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-1b8a2678-e432-4f33-a5a9-e128e529daaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-f6d18d9c-0670-4b3c-b73b-539c25c0063e,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-8efbb80e-db1d-480b-901f-dca5eaaf4dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-ede4654e-f0dc-487a-aa19-0aef07c5f16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-358d70d1-bedd-4f0f-86b6-047f942a4f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111505245-172.17.0.18-1597509696562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38105,DS-30fd0034-f9ac-4c0a-8583-85172b84ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-cdf7fd27-ec7b-4763-9161-8376212b6026,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-26ef5b8a-21c8-4890-a3ba-bad6fd00d2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-1b8a2678-e432-4f33-a5a9-e128e529daaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-f6d18d9c-0670-4b3c-b73b-539c25c0063e,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-8efbb80e-db1d-480b-901f-dca5eaaf4dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-ede4654e-f0dc-487a-aa19-0aef07c5f16b,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-358d70d1-bedd-4f0f-86b6-047f942a4f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996571870-172.17.0.18-1597509736100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-36f0d80e-2e81-480f-af05-3d9d133d00c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-4e656be4-221a-4470-a51d-4d6ce46348c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-3df964a4-8f42-4172-ac7f-b11a79ead967,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-6e1522ec-fbfb-47d1-a8d1-efac50c2332d,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-6572cbd7-4cf1-48ab-924a-735d1f7d8b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-4a32703c-7a38-4969-b9be-ae0ac8dad5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-6a580bf9-0d68-402e-b46e-f22ca2641da7,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-f20ee384-e0e3-4734-90eb-1117bd80aa73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996571870-172.17.0.18-1597509736100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40054,DS-36f0d80e-2e81-480f-af05-3d9d133d00c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-4e656be4-221a-4470-a51d-4d6ce46348c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-3df964a4-8f42-4172-ac7f-b11a79ead967,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-6e1522ec-fbfb-47d1-a8d1-efac50c2332d,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-6572cbd7-4cf1-48ab-924a-735d1f7d8b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-4a32703c-7a38-4969-b9be-ae0ac8dad5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-6a580bf9-0d68-402e-b46e-f22ca2641da7,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-f20ee384-e0e3-4734-90eb-1117bd80aa73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873422456-172.17.0.18-1597510294976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-c2b0f7be-63c8-4529-a810-33ad7edc9ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-2ca6ba37-7a12-4366-b417-52494d0dde1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-21f9d99e-87f7-4450-916d-516ec978a4da,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-ca2af380-0f9b-4a1b-bbf1-13f02ad6ab7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-f98a339a-883c-4e6e-8029-fce332ab0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-139df3ad-1a1c-465b-b32e-26b67cefe701,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-7fab0305-8f6a-41b5-af6e-d68e5656e427,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-55a93825-2377-4769-9bc8-6859c12f1fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873422456-172.17.0.18-1597510294976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-c2b0f7be-63c8-4529-a810-33ad7edc9ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-2ca6ba37-7a12-4366-b417-52494d0dde1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-21f9d99e-87f7-4450-916d-516ec978a4da,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-ca2af380-0f9b-4a1b-bbf1-13f02ad6ab7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-f98a339a-883c-4e6e-8029-fce332ab0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-139df3ad-1a1c-465b-b32e-26b67cefe701,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-7fab0305-8f6a-41b5-af6e-d68e5656e427,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-55a93825-2377-4769-9bc8-6859c12f1fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206860512-172.17.0.18-1597510865965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36071,DS-d7d44be7-38e5-49d7-9ce6-d00c2d2e88af,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-c68dbbc6-6209-4651-834d-7bf99a265fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-303f6904-d2e4-4634-83a0-8e672fdd0856,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-c8c8abaa-92c0-4335-b40b-c3f952ff2894,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-a280b93b-91fb-4372-8562-b1f99729e684,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-beefa8d6-805d-4679-a0aa-b73665ae5488,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-0c9f7f21-ae24-49ac-ab99-d541767ad6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-336c53c8-0ea6-43f0-8a80-a39c527158b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206860512-172.17.0.18-1597510865965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36071,DS-d7d44be7-38e5-49d7-9ce6-d00c2d2e88af,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-c68dbbc6-6209-4651-834d-7bf99a265fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-303f6904-d2e4-4634-83a0-8e672fdd0856,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-c8c8abaa-92c0-4335-b40b-c3f952ff2894,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-a280b93b-91fb-4372-8562-b1f99729e684,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-beefa8d6-805d-4679-a0aa-b73665ae5488,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-0c9f7f21-ae24-49ac-ab99-d541767ad6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-336c53c8-0ea6-43f0-8a80-a39c527158b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140046897-172.17.0.18-1597511066692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44937,DS-87f9fdfa-6678-4a3a-b36b-12b58756095f,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-c62a0a57-6582-4281-8faf-0d3af4398750,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-dc077724-9292-4275-81cc-d32a36cf00ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-244d635c-70d4-4f40-9499-a2d45ce0a1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-0ffb6704-7830-41a5-bd18-23d38851e212,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-56f1b985-8dc9-49f5-9f74-deb1f2dabd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-e9465f0c-8c63-46cf-8e8f-e22e4b31bead,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-f5507abd-ef81-438a-842d-435ccc76e48e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140046897-172.17.0.18-1597511066692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44937,DS-87f9fdfa-6678-4a3a-b36b-12b58756095f,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-c62a0a57-6582-4281-8faf-0d3af4398750,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-dc077724-9292-4275-81cc-d32a36cf00ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-244d635c-70d4-4f40-9499-a2d45ce0a1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-0ffb6704-7830-41a5-bd18-23d38851e212,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-56f1b985-8dc9-49f5-9f74-deb1f2dabd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-e9465f0c-8c63-46cf-8e8f-e22e4b31bead,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-f5507abd-ef81-438a-842d-435ccc76e48e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059574053-172.17.0.18-1597512404537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-788f5306-8df7-4067-98c7-773c4b5a9f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-2affcb5b-8310-4845-a8c0-424556dbb39b,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-fbda6fa4-a147-4ac2-866e-45e022aba3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-cf3bfe6a-ed38-4278-b9a9-3ebb0dedabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-6053a788-9e02-4e78-9ef1-401bc6ee38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-9e68a0fc-ccc1-47ae-b653-684940add25b,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-e19b4413-11b0-43f1-a281-b5e30f7bd007,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-9d34ded3-26c6-47e9-bd9c-51573b2fb746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059574053-172.17.0.18-1597512404537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-788f5306-8df7-4067-98c7-773c4b5a9f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-2affcb5b-8310-4845-a8c0-424556dbb39b,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-fbda6fa4-a147-4ac2-866e-45e022aba3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-cf3bfe6a-ed38-4278-b9a9-3ebb0dedabf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-6053a788-9e02-4e78-9ef1-401bc6ee38eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-9e68a0fc-ccc1-47ae-b653-684940add25b,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-e19b4413-11b0-43f1-a281-b5e30f7bd007,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-9d34ded3-26c6-47e9-bd9c-51573b2fb746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374128471-172.17.0.18-1597512635100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-de4cb1ed-1b9d-4929-853b-d05bff2811be,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-ade7e31e-7980-4d60-9c74-8052e6bcce89,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-2a6caffe-34bb-4461-8563-ce3eb7f25be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-9bfbb3ec-9ad0-4344-8729-dd7f236be30e,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-1cc3a565-2146-4cdb-8192-8a966af8f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-e73a916a-09db-406c-894b-1edc6ddf80aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-ec9d69ba-7acd-47a4-a38f-9e80b6101d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-add205b8-b9b5-4341-bfd7-05004be28846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374128471-172.17.0.18-1597512635100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46788,DS-de4cb1ed-1b9d-4929-853b-d05bff2811be,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-ade7e31e-7980-4d60-9c74-8052e6bcce89,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-2a6caffe-34bb-4461-8563-ce3eb7f25be9,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-9bfbb3ec-9ad0-4344-8729-dd7f236be30e,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-1cc3a565-2146-4cdb-8192-8a966af8f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-e73a916a-09db-406c-894b-1edc6ddf80aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-ec9d69ba-7acd-47a4-a38f-9e80b6101d69,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-add205b8-b9b5-4341-bfd7-05004be28846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 5000
v2: 50000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089156498-172.17.0.18-1597513204729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-07a4b827-6a43-4ee1-8636-92f720307db3,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-ec0d3ed6-d287-45d2-abd2-c7a56fe47d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-5763275e-f314-4020-9893-15d4d946d107,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-6d4d8d65-63e3-4593-ab48-b99983ae6605,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-01904d81-2dba-4c62-ac9a-01f19bcd375e,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-5dabc70c-daa2-4ea8-b0ed-8493720c84c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-6c83bfd9-fe89-4ef5-a177-0bbffd19894a,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-d49dada7-f0b4-485c-b1cf-829db3cd44a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2089156498-172.17.0.18-1597513204729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33853,DS-07a4b827-6a43-4ee1-8636-92f720307db3,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-ec0d3ed6-d287-45d2-abd2-c7a56fe47d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-5763275e-f314-4020-9893-15d4d946d107,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-6d4d8d65-63e3-4593-ab48-b99983ae6605,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-01904d81-2dba-4c62-ac9a-01f19bcd375e,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-5dabc70c-daa2-4ea8-b0ed-8493720c84c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-6c83bfd9-fe89-4ef5-a177-0bbffd19894a,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-d49dada7-f0b4-485c-b1cf-829db3cd44a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5560
