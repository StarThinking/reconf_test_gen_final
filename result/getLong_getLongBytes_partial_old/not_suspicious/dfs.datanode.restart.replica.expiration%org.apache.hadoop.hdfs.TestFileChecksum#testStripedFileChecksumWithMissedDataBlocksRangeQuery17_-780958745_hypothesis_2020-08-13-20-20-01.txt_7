reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947402152-172.17.0.6-1597350276251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33360,DS-96de78a9-72be-46b5-b03d-8eea93835064,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-905342a1-a19c-4a34-b036-51a618266f28,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-9fc5b978-0ec9-4c64-af24-e72bb063c06b,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-66258832-ec7b-47d1-95b6-de67bac394a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-6b018812-5fb6-4a35-81b9-8cbfc1dd6dce,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-22c3bef9-37c1-4c64-8d84-9296eb60bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-3ec0dede-33ea-4ea9-9f57-15d85e3639db,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-6e3fcf69-0a30-4b16-b986-179bbddd1611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947402152-172.17.0.6-1597350276251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33360,DS-96de78a9-72be-46b5-b03d-8eea93835064,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-905342a1-a19c-4a34-b036-51a618266f28,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-9fc5b978-0ec9-4c64-af24-e72bb063c06b,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-66258832-ec7b-47d1-95b6-de67bac394a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-6b018812-5fb6-4a35-81b9-8cbfc1dd6dce,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-22c3bef9-37c1-4c64-8d84-9296eb60bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-3ec0dede-33ea-4ea9-9f57-15d85e3639db,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-6e3fcf69-0a30-4b16-b986-179bbddd1611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190218489-172.17.0.6-1597350506352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37705,DS-d7d3c13a-1468-4ff3-a89c-366d571eb60a,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-102821e7-7fa9-4cf8-80fa-2f6ea578eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-82f471a1-b961-48da-ae89-b08c02845dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-d77e3af9-931c-4532-99fb-1bcb16b30caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-c77a8f86-cda3-4173-bda9-be21240e3f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-8583b5ce-9895-441d-8b6b-ffced681345e,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-69b8649a-473a-4beb-b059-38d0ba064bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-f536b192-93b8-4266-bc66-f0662cb6af98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190218489-172.17.0.6-1597350506352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37705,DS-d7d3c13a-1468-4ff3-a89c-366d571eb60a,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-102821e7-7fa9-4cf8-80fa-2f6ea578eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-82f471a1-b961-48da-ae89-b08c02845dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-d77e3af9-931c-4532-99fb-1bcb16b30caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-c77a8f86-cda3-4173-bda9-be21240e3f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-8583b5ce-9895-441d-8b6b-ffced681345e,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-69b8649a-473a-4beb-b059-38d0ba064bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-f536b192-93b8-4266-bc66-f0662cb6af98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577449313-172.17.0.6-1597350831315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-9d654a58-d844-436e-a8b1-4f240b3cdf03,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-c53fcae4-4e9c-4de9-bfaf-73562c542fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-047b0ad1-5fba-4056-b611-51835fdcd8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-1a4e758c-7bad-4c4d-9f7e-2fb7eb1d3d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-d08184b3-a983-40c5-ae93-237c1915bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-6166c9f2-7387-4169-8948-99c7ec136fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-a41e0067-a302-4ed2-a6a3-ad00ec18a525,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-06fe11de-74ab-403f-8ce6-a5c2e0c7a7bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577449313-172.17.0.6-1597350831315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-9d654a58-d844-436e-a8b1-4f240b3cdf03,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-c53fcae4-4e9c-4de9-bfaf-73562c542fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-047b0ad1-5fba-4056-b611-51835fdcd8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-1a4e758c-7bad-4c4d-9f7e-2fb7eb1d3d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-d08184b3-a983-40c5-ae93-237c1915bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-6166c9f2-7387-4169-8948-99c7ec136fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-a41e0067-a302-4ed2-a6a3-ad00ec18a525,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-06fe11de-74ab-403f-8ce6-a5c2e0c7a7bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817965012-172.17.0.6-1597351344934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-cfb35534-8e12-4414-90d0-881063159425,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-ee030420-8d9f-4db4-bff4-f715a34fb2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-fddb397e-c544-4386-898c-bb64823d9f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-2f2204ba-a4f4-456f-b3e6-995a3c54db8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-492e916e-c2ff-4e03-9062-ea22341af496,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-7f3fb27e-6562-41f6-b04d-95b7ee353ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-90fd4b0e-aea8-458c-b7d8-61ff0cdc6e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-70ddf72a-1b15-465c-a22a-c58d3dfc7390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817965012-172.17.0.6-1597351344934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-cfb35534-8e12-4414-90d0-881063159425,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-ee030420-8d9f-4db4-bff4-f715a34fb2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-fddb397e-c544-4386-898c-bb64823d9f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-2f2204ba-a4f4-456f-b3e6-995a3c54db8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-492e916e-c2ff-4e03-9062-ea22341af496,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-7f3fb27e-6562-41f6-b04d-95b7ee353ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-90fd4b0e-aea8-458c-b7d8-61ff0cdc6e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-70ddf72a-1b15-465c-a22a-c58d3dfc7390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916759435-172.17.0.6-1597351738169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44762,DS-47f67978-6319-4b2c-8bcd-2e8f0c14a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-7d095c6e-bf40-4926-9440-d9e1136a2eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-8ef2e07e-cd53-4a7e-87ad-230cfebf6ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-be692741-2a55-4d35-a76b-9534fbfe17b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-aec21ba2-a111-47c6-aefd-0721cbad61ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-6fa0f08b-4977-4afb-867f-674662a7142c,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-7461d8d2-b4c4-4bab-b7a2-65c55952ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-a9ee30db-8093-4c6d-b0b2-de61bb16e4a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-916759435-172.17.0.6-1597351738169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44762,DS-47f67978-6319-4b2c-8bcd-2e8f0c14a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-7d095c6e-bf40-4926-9440-d9e1136a2eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-8ef2e07e-cd53-4a7e-87ad-230cfebf6ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-be692741-2a55-4d35-a76b-9534fbfe17b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-aec21ba2-a111-47c6-aefd-0721cbad61ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-6fa0f08b-4977-4afb-867f-674662a7142c,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-7461d8d2-b4c4-4bab-b7a2-65c55952ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-a9ee30db-8093-4c6d-b0b2-de61bb16e4a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255140374-172.17.0.6-1597351844277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37806,DS-fe3ac68d-9353-4d6d-92b8-15858800512b,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-954ad9f9-08fd-4c3c-b969-dad13823a541,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-22034768-76d7-4c00-ba89-e179146ca3df,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-9e6118ba-aae4-400a-9380-bf7124078b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-068578f0-563e-421c-bac3-4645ea091973,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-8cb43858-4ca5-43d7-805f-01afe8ac0edc,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-74a79076-9682-4f9b-ba4a-1a699da65a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-385e2873-d9bc-4d42-9bf9-55fd1bea4a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255140374-172.17.0.6-1597351844277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37806,DS-fe3ac68d-9353-4d6d-92b8-15858800512b,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-954ad9f9-08fd-4c3c-b969-dad13823a541,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-22034768-76d7-4c00-ba89-e179146ca3df,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-9e6118ba-aae4-400a-9380-bf7124078b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-068578f0-563e-421c-bac3-4645ea091973,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-8cb43858-4ca5-43d7-805f-01afe8ac0edc,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-74a79076-9682-4f9b-ba4a-1a699da65a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-385e2873-d9bc-4d42-9bf9-55fd1bea4a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984506271-172.17.0.6-1597352060281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46033,DS-2476d975-a4e0-4043-b49b-38042ec9c566,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-36083a7e-e30c-4a8d-be62-6c8f69d0063b,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-dbf885df-4aa6-495c-9349-ed7c6b8b92be,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-b648555e-5b4a-479e-8f99-9f1fdd620e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-e00134a2-e7a0-45ee-970d-ef9ee31b375b,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-4291df0b-3ad8-4f0a-a555-4e78e15b0456,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-bf297d14-2c6a-4d7a-bafa-2dc80a78f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-e6c8dc74-a02c-44fe-bd75-0372568267f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984506271-172.17.0.6-1597352060281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46033,DS-2476d975-a4e0-4043-b49b-38042ec9c566,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-36083a7e-e30c-4a8d-be62-6c8f69d0063b,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-dbf885df-4aa6-495c-9349-ed7c6b8b92be,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-b648555e-5b4a-479e-8f99-9f1fdd620e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-e00134a2-e7a0-45ee-970d-ef9ee31b375b,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-4291df0b-3ad8-4f0a-a555-4e78e15b0456,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-bf297d14-2c6a-4d7a-bafa-2dc80a78f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-e6c8dc74-a02c-44fe-bd75-0372568267f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034765765-172.17.0.6-1597352440559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40887,DS-1107afab-43d3-4c98-b0cb-28bc3c0e309a,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-edc05ca3-e78e-44f9-aec1-40bb90488e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-d1028d44-5a8d-44e3-a54e-4a2cb1740446,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-5c4f1744-2135-4f57-b91b-079b114d16be,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-14c52333-3b8f-4c05-8448-1f59fd431348,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-7cb73f3f-afc3-404e-abbe-ee2ba175881a,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-f3d67634-7386-4d4d-a489-0ed014939314,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-89dbdc46-72bc-47a8-862b-7ba62bc4e645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034765765-172.17.0.6-1597352440559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40887,DS-1107afab-43d3-4c98-b0cb-28bc3c0e309a,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-edc05ca3-e78e-44f9-aec1-40bb90488e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-d1028d44-5a8d-44e3-a54e-4a2cb1740446,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-5c4f1744-2135-4f57-b91b-079b114d16be,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-14c52333-3b8f-4c05-8448-1f59fd431348,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-7cb73f3f-afc3-404e-abbe-ee2ba175881a,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-f3d67634-7386-4d4d-a489-0ed014939314,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-89dbdc46-72bc-47a8-862b-7ba62bc4e645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70879682-172.17.0.6-1597352608002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37890,DS-56fca154-0365-454b-8707-9baef2b671aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-017290e1-4051-4980-930f-04727be48d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-29bfc6b3-d7f7-408b-90f8-6d3fcc52ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-c2d811d5-deaa-42dc-80ff-1e992c226de1,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-6af758ab-7744-4d7e-8c7b-24b9ef473775,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-f7d47886-5036-4a3c-9826-76de4d938338,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-4ac17886-faee-4e37-ba4c-7f9b547eb830,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-9c1400c5-9a47-43d3-87be-3947665cadac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70879682-172.17.0.6-1597352608002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37890,DS-56fca154-0365-454b-8707-9baef2b671aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-017290e1-4051-4980-930f-04727be48d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-29bfc6b3-d7f7-408b-90f8-6d3fcc52ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-c2d811d5-deaa-42dc-80ff-1e992c226de1,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-6af758ab-7744-4d7e-8c7b-24b9ef473775,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-f7d47886-5036-4a3c-9826-76de4d938338,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-4ac17886-faee-4e37-ba4c-7f9b547eb830,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-9c1400c5-9a47-43d3-87be-3947665cadac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586764503-172.17.0.6-1597353015300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41225,DS-5294dfe5-4d1e-49d2-86fd-7a82ca9579fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-1fad8dc3-b073-4e6a-8449-5ae5d7efc5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-3ec01b99-0074-4edc-a0d4-8e16fcf9d769,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-d2e88888-cc12-4ec3-ae66-ce880ef66855,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-070c25cb-6beb-4582-9922-ba53011255a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-40cfc32e-6c3a-4547-879e-becd203cc964,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-9682ba13-738f-405b-8fbf-a3fe6679b6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-bb86add2-ed33-4a95-98f2-bdb0eb66eacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586764503-172.17.0.6-1597353015300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41225,DS-5294dfe5-4d1e-49d2-86fd-7a82ca9579fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-1fad8dc3-b073-4e6a-8449-5ae5d7efc5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-3ec01b99-0074-4edc-a0d4-8e16fcf9d769,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-d2e88888-cc12-4ec3-ae66-ce880ef66855,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-070c25cb-6beb-4582-9922-ba53011255a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-40cfc32e-6c3a-4547-879e-becd203cc964,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-9682ba13-738f-405b-8fbf-a3fe6679b6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-bb86add2-ed33-4a95-98f2-bdb0eb66eacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518679773-172.17.0.6-1597353361454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-05b82cbe-18f2-4969-ad7e-ca1e68347a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-329cdb74-c601-463e-bacd-82c43cde4d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-32e4d968-ae93-43ab-abc5-9c80aa087933,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-c932114c-ae35-423c-835e-3aedcbbd7095,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-51e750cf-6af0-4950-a689-9dc5dba78ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-ee842a9c-387c-42ba-8d52-9b8db6abb451,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-60e1dc99-7dee-46a7-a51d-c5d514fa8029,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-983074d0-abe6-4de8-90c0-3e5fea8d40ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518679773-172.17.0.6-1597353361454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46195,DS-05b82cbe-18f2-4969-ad7e-ca1e68347a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-329cdb74-c601-463e-bacd-82c43cde4d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-32e4d968-ae93-43ab-abc5-9c80aa087933,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-c932114c-ae35-423c-835e-3aedcbbd7095,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-51e750cf-6af0-4950-a689-9dc5dba78ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-ee842a9c-387c-42ba-8d52-9b8db6abb451,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-60e1dc99-7dee-46a7-a51d-c5d514fa8029,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-983074d0-abe6-4de8-90c0-3e5fea8d40ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808504009-172.17.0.6-1597353531473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43563,DS-409bf643-ed6f-469c-a015-075f287d495f,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-394eb3f6-ffd2-402d-a56c-e6c586b0775d,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-f92c0a9c-31ab-4523-b7b6-e62b5c6a4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-cff7d8d7-5ffd-4cbd-a049-38e6d9373589,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-e55cd401-d77b-4c85-b1d5-60afc21fcea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-07c0db97-ddd5-4d4a-9c17-bc83f42c099a,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-eb38784c-3e39-42f4-8263-5d6173b481e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-c46c6892-6b35-437d-8e66-ab6887a7c339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808504009-172.17.0.6-1597353531473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43563,DS-409bf643-ed6f-469c-a015-075f287d495f,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-394eb3f6-ffd2-402d-a56c-e6c586b0775d,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-f92c0a9c-31ab-4523-b7b6-e62b5c6a4c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-cff7d8d7-5ffd-4cbd-a049-38e6d9373589,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-e55cd401-d77b-4c85-b1d5-60afc21fcea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-07c0db97-ddd5-4d4a-9c17-bc83f42c099a,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-eb38784c-3e39-42f4-8263-5d6173b481e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-c46c6892-6b35-437d-8e66-ab6887a7c339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000414180-172.17.0.6-1597354525807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45721,DS-f4432e0c-6598-4432-b067-94670e7a5605,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-8db69331-1288-4b6d-83da-0875ff913c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-a91e3a7f-b23b-4552-95a5-19cc9f060857,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-95bc5f19-849d-4f6a-b148-1b67e8da9e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-6514ae87-9cd0-48f0-a593-393be492266f,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-03e3c148-07cf-4455-ae19-131a2a475dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-e30c030a-49d5-4c42-bdb9-7ea5dfb50019,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-92fd61fb-888c-4727-9430-d115b2e112cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000414180-172.17.0.6-1597354525807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45721,DS-f4432e0c-6598-4432-b067-94670e7a5605,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-8db69331-1288-4b6d-83da-0875ff913c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-a91e3a7f-b23b-4552-95a5-19cc9f060857,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-95bc5f19-849d-4f6a-b148-1b67e8da9e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-6514ae87-9cd0-48f0-a593-393be492266f,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-03e3c148-07cf-4455-ae19-131a2a475dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-e30c030a-49d5-4c42-bdb9-7ea5dfb50019,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-92fd61fb-888c-4727-9430-d115b2e112cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863342923-172.17.0.6-1597355140596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-cfc65d7d-f4ce-4578-a0b8-a08b462c7817,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-4bc283aa-7c16-4e43-a124-dff8b4e691e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-8d748d90-1c6f-4ac1-95ab-8547d8122785,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-23dab0d7-df2e-4c99-8c55-bddb09c7c4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-23c9ebc0-6302-4df2-aa31-abdbdc27fa25,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-64a54490-dbea-4816-85ee-2a8b16c00f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-e2b8a4cc-728c-4d93-b88a-5401626493f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-322c737e-9074-40bc-9a8a-aab9ee3b8000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863342923-172.17.0.6-1597355140596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-cfc65d7d-f4ce-4578-a0b8-a08b462c7817,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-4bc283aa-7c16-4e43-a124-dff8b4e691e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-8d748d90-1c6f-4ac1-95ab-8547d8122785,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-23dab0d7-df2e-4c99-8c55-bddb09c7c4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-23c9ebc0-6302-4df2-aa31-abdbdc27fa25,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-64a54490-dbea-4816-85ee-2a8b16c00f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-e2b8a4cc-728c-4d93-b88a-5401626493f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-322c737e-9074-40bc-9a8a-aab9ee3b8000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615273783-172.17.0.6-1597355205714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44751,DS-1f31c95a-095f-415b-a52c-c992bb2403fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-64869d29-5968-48cc-9df0-22dad6e98ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-705402bb-e773-4475-9617-dbac061a3633,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-4f1f793e-6380-447f-802b-beef26772a11,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-039ea348-1062-4d75-bb29-b1075ac7b241,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-b035a460-2f1e-4aa9-9991-c86114bc0380,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-ecab61d4-523a-457f-97ba-c8258bb38ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-607582b5-8577-4f78-8b15-b021d5fc691c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615273783-172.17.0.6-1597355205714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44751,DS-1f31c95a-095f-415b-a52c-c992bb2403fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-64869d29-5968-48cc-9df0-22dad6e98ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-705402bb-e773-4475-9617-dbac061a3633,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-4f1f793e-6380-447f-802b-beef26772a11,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-039ea348-1062-4d75-bb29-b1075ac7b241,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-b035a460-2f1e-4aa9-9991-c86114bc0380,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-ecab61d4-523a-457f-97ba-c8258bb38ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-607582b5-8577-4f78-8b15-b021d5fc691c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82343249-172.17.0.6-1597355349766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35219,DS-74741b9b-2a30-4ea2-a449-b719c60c257e,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-9ddaf271-bf1e-43a2-9c41-8e7db1c19c07,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-5b234119-037a-4717-9bd7-9b55c61316c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-a46bad84-5435-4005-9c98-22c1c7e28a50,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-7aef8aab-75b2-461d-ab9d-2a25a88d351c,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-26b9af74-73b4-4c9d-85e4-bf79a7b7eab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-e99c9b58-e2f0-43b9-ab74-3e29a37ef284,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-7f3f5d3f-dc28-423e-b1fc-08bd61be67e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-82343249-172.17.0.6-1597355349766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35219,DS-74741b9b-2a30-4ea2-a449-b719c60c257e,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-9ddaf271-bf1e-43a2-9c41-8e7db1c19c07,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-5b234119-037a-4717-9bd7-9b55c61316c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-a46bad84-5435-4005-9c98-22c1c7e28a50,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-7aef8aab-75b2-461d-ab9d-2a25a88d351c,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-26b9af74-73b4-4c9d-85e4-bf79a7b7eab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-e99c9b58-e2f0-43b9-ab74-3e29a37ef284,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-7f3f5d3f-dc28-423e-b1fc-08bd61be67e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5408
