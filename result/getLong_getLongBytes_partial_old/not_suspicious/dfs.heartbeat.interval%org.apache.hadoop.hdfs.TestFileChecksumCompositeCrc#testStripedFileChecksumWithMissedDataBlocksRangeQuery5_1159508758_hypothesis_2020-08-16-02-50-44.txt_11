reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722579642-172.17.0.21-1597546452472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43894,DS-c509c778-3f06-4a6f-8765-1e0d26a932ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-d2c4ef17-45b9-49c2-86f9-98d5ea956ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-1c456e18-60d9-4601-90ee-a652f8296825,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-e33ce3c5-18f2-4355-825d-cc4a16a4fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-dc62fe23-1931-4733-aa31-e7925cc47452,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-ab2f7460-838e-42e4-b0f6-9ebbda9bf109,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-458449b5-0383-47bd-9cd5-ef6f26704a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-a496aef8-2d67-4d40-b3c0-614445731f11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722579642-172.17.0.21-1597546452472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43894,DS-c509c778-3f06-4a6f-8765-1e0d26a932ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-d2c4ef17-45b9-49c2-86f9-98d5ea956ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-1c456e18-60d9-4601-90ee-a652f8296825,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-e33ce3c5-18f2-4355-825d-cc4a16a4fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-dc62fe23-1931-4733-aa31-e7925cc47452,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-ab2f7460-838e-42e4-b0f6-9ebbda9bf109,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-458449b5-0383-47bd-9cd5-ef6f26704a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-a496aef8-2d67-4d40-b3c0-614445731f11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043940221-172.17.0.21-1597546490560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-be389699-1f0f-4342-9f5c-7644054ea442,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-cef5b32c-1e08-4135-b544-ef3449b714f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-f56d5765-3ca9-4e2f-8b45-20c83c5f3bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-7fa05196-061e-43d4-b4b7-7d97cfded786,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-1fca7ed9-cc25-4fe5-9905-df5bc5a73cce,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-28d0b5aa-29c0-4720-999a-fab6c10afb90,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-627c50b2-6446-4a2a-a383-4a89eea10a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-7d7e713b-bd01-42e4-864a-03900a87860a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043940221-172.17.0.21-1597546490560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42397,DS-be389699-1f0f-4342-9f5c-7644054ea442,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-cef5b32c-1e08-4135-b544-ef3449b714f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-f56d5765-3ca9-4e2f-8b45-20c83c5f3bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-7fa05196-061e-43d4-b4b7-7d97cfded786,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-1fca7ed9-cc25-4fe5-9905-df5bc5a73cce,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-28d0b5aa-29c0-4720-999a-fab6c10afb90,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-627c50b2-6446-4a2a-a383-4a89eea10a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-7d7e713b-bd01-42e4-864a-03900a87860a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925944059-172.17.0.21-1597546643949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-28fc4909-495e-43c3-9a14-43020cf82ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-7d5938d5-13c8-4073-900a-a35962247b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-1dd8ea97-edb5-4967-a9ac-510398e512e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-cecc797d-e4b6-49e8-8868-53a007313b44,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-7215fe80-859c-491b-8185-09576d21ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-3d200096-cad8-45ce-a41c-bb55a1700260,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-9b21292f-443b-416e-bee3-7bce9db3a937,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-99056ddc-23bb-486b-9867-81b225107027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925944059-172.17.0.21-1597546643949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42935,DS-28fc4909-495e-43c3-9a14-43020cf82ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-7d5938d5-13c8-4073-900a-a35962247b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-1dd8ea97-edb5-4967-a9ac-510398e512e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-cecc797d-e4b6-49e8-8868-53a007313b44,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-7215fe80-859c-491b-8185-09576d21ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-3d200096-cad8-45ce-a41c-bb55a1700260,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-9b21292f-443b-416e-bee3-7bce9db3a937,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-99056ddc-23bb-486b-9867-81b225107027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954729617-172.17.0.21-1597546905294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40941,DS-d87f8818-5024-4cbb-a422-a92bf9207101,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-dcce64a4-3845-4586-91bd-17feaf223ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-a74316bd-5fbd-44ba-8e77-0553e395fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-4e7670ca-dbe4-4d47-be8d-b428b30144a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-2d5f3746-daf9-4898-8311-7e1a7d0d796f,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-3fb22704-75b2-46fe-88d3-4f0efd4697f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-3197cf76-d12d-45dd-b6bd-1fad093b0c88,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-d27b32dd-6459-4140-ab14-a5087e6a099b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954729617-172.17.0.21-1597546905294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40941,DS-d87f8818-5024-4cbb-a422-a92bf9207101,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-dcce64a4-3845-4586-91bd-17feaf223ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-a74316bd-5fbd-44ba-8e77-0553e395fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-4e7670ca-dbe4-4d47-be8d-b428b30144a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-2d5f3746-daf9-4898-8311-7e1a7d0d796f,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-3fb22704-75b2-46fe-88d3-4f0efd4697f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-3197cf76-d12d-45dd-b6bd-1fad093b0c88,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-d27b32dd-6459-4140-ab14-a5087e6a099b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625293388-172.17.0.21-1597547051067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36756,DS-25588c15-fde2-4032-b0fe-c44805d12c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-ed184d53-b674-41ee-bdcc-9c7f8f7b825a,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-ca470d72-b065-4f42-a404-06d43dd9c31f,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-2b1a6509-2932-4f8e-b285-3a9a7361292b,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-a00b3333-e608-4388-8a8b-74c9f8df95ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-7a8db61c-81bb-413f-ab49-2761c26b9673,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-061e0b08-0e88-4b5f-a608-c2975aab10da,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-aee51553-b080-4a08-a039-61bd8c7c5a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-625293388-172.17.0.21-1597547051067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36756,DS-25588c15-fde2-4032-b0fe-c44805d12c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-ed184d53-b674-41ee-bdcc-9c7f8f7b825a,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-ca470d72-b065-4f42-a404-06d43dd9c31f,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-2b1a6509-2932-4f8e-b285-3a9a7361292b,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-a00b3333-e608-4388-8a8b-74c9f8df95ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-7a8db61c-81bb-413f-ab49-2761c26b9673,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-061e0b08-0e88-4b5f-a608-c2975aab10da,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-aee51553-b080-4a08-a039-61bd8c7c5a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089522552-172.17.0.21-1597547473572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-04f41475-8d8f-4188-849e-d466753b3aef,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-deff5a3c-c37b-4a31-b108-2d80bbe1963f,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-4715870c-e839-40d0-9992-9c349c340058,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-c8978f82-04dd-4301-bcf9-a99eef1452e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-dd93ab3f-a438-4eb3-b397-e361514046d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-fdbc10a9-9e72-4e40-abf4-0d2fd46f5cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-49b69a66-a90b-410b-a114-8da64b8ec847,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-e6acfc61-2d2c-40f4-a33c-dd6cb9487fd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089522552-172.17.0.21-1597547473572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-04f41475-8d8f-4188-849e-d466753b3aef,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-deff5a3c-c37b-4a31-b108-2d80bbe1963f,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-4715870c-e839-40d0-9992-9c349c340058,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-c8978f82-04dd-4301-bcf9-a99eef1452e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-dd93ab3f-a438-4eb3-b397-e361514046d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-fdbc10a9-9e72-4e40-abf4-0d2fd46f5cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-49b69a66-a90b-410b-a114-8da64b8ec847,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-e6acfc61-2d2c-40f4-a33c-dd6cb9487fd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206220238-172.17.0.21-1597547768669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46462,DS-82354061-ac2f-44b5-9822-8048192a5280,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-2b083cef-ca6e-4e6b-a00a-201aaed4eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-2069fdf0-e12b-48a0-8ec4-713d220cbe91,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-5ef412d1-67d6-450e-95c0-01ac3bd72cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-0e398a30-1568-43c4-8eb6-b2c8ed63714a,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-f348a058-8154-41a4-bb88-f3acf90fad10,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-5bf74154-9b91-4897-a64b-039c076b79c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-de4be140-6735-4a75-957f-b035b6d945a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206220238-172.17.0.21-1597547768669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46462,DS-82354061-ac2f-44b5-9822-8048192a5280,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-2b083cef-ca6e-4e6b-a00a-201aaed4eee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-2069fdf0-e12b-48a0-8ec4-713d220cbe91,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-5ef412d1-67d6-450e-95c0-01ac3bd72cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-0e398a30-1568-43c4-8eb6-b2c8ed63714a,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-f348a058-8154-41a4-bb88-f3acf90fad10,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-5bf74154-9b91-4897-a64b-039c076b79c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-de4be140-6735-4a75-957f-b035b6d945a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183809383-172.17.0.21-1597547835489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41206,DS-ef8fe738-c90a-4f22-84db-41be3baba7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-03184251-07e7-4cf7-9a35-103d0ab05753,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-0b564304-19cb-4b5f-b867-137a183cbbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-dcef8263-498f-4da4-95f8-240d31c7e273,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-bdc852c5-b726-4345-94f8-c29f9a888e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-4d0a4304-a461-4151-8b79-c8edeba36ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-1e50382e-bb83-47bd-a234-1777f098c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-9c50c114-88ad-400a-9f78-829cd9c8cb1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183809383-172.17.0.21-1597547835489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41206,DS-ef8fe738-c90a-4f22-84db-41be3baba7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-03184251-07e7-4cf7-9a35-103d0ab05753,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-0b564304-19cb-4b5f-b867-137a183cbbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-dcef8263-498f-4da4-95f8-240d31c7e273,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-bdc852c5-b726-4345-94f8-c29f9a888e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-4d0a4304-a461-4151-8b79-c8edeba36ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-1e50382e-bb83-47bd-a234-1777f098c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-9c50c114-88ad-400a-9f78-829cd9c8cb1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200564156-172.17.0.21-1597547941262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46319,DS-baad878d-9791-446b-a8ac-ad78d6d334ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-592de774-4fce-4cc5-bddb-cf2d75841a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-084ede6f-e131-46c5-8df3-f36745e27e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-a157cfb6-3f49-4bea-8850-2a543f80f9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-e3385872-c4e5-4a46-acb1-27a136344138,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-36d86690-53e0-445e-823d-f3bbeb0f32dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-4d1e6781-330b-4a6e-bfad-ba344c47743c,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-57b055ed-da06-446d-9519-e0d78c3925fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200564156-172.17.0.21-1597547941262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46319,DS-baad878d-9791-446b-a8ac-ad78d6d334ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-592de774-4fce-4cc5-bddb-cf2d75841a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-084ede6f-e131-46c5-8df3-f36745e27e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-a157cfb6-3f49-4bea-8850-2a543f80f9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-e3385872-c4e5-4a46-acb1-27a136344138,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-36d86690-53e0-445e-823d-f3bbeb0f32dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-4d1e6781-330b-4a6e-bfad-ba344c47743c,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-57b055ed-da06-446d-9519-e0d78c3925fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365850603-172.17.0.21-1597548153411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-1c33069f-2b21-422f-9475-319804f70ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-e867fd2e-a928-42a5-83ae-c84b29c03ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-bdeec244-154d-48a3-b8aa-4924cb02120a,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-754c3aac-632f-42b0-bbd8-2d442b2511b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-d3ce0f2e-4925-4d4e-8f6f-4d852bdcb3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-db8533cc-a7bd-421c-ad4d-43c0671b59f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-3de14bd0-7135-42b7-8d23-8770d8032932,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-8754a2fa-3418-4dcd-8636-8d68ed73e5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365850603-172.17.0.21-1597548153411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-1c33069f-2b21-422f-9475-319804f70ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-e867fd2e-a928-42a5-83ae-c84b29c03ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-bdeec244-154d-48a3-b8aa-4924cb02120a,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-754c3aac-632f-42b0-bbd8-2d442b2511b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-d3ce0f2e-4925-4d4e-8f6f-4d852bdcb3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-db8533cc-a7bd-421c-ad4d-43c0671b59f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-3de14bd0-7135-42b7-8d23-8770d8032932,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-8754a2fa-3418-4dcd-8636-8d68ed73e5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878038278-172.17.0.21-1597548460625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43192,DS-983c8025-2828-4d40-b7fd-c125d8843c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-cc1c4841-beac-4beb-a697-c50a22c6c704,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-abcbdac0-58ca-4780-9054-cc409957607f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-447124ee-cd4c-4773-92cf-0a6170625dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-1f295211-7cf7-442d-a16c-2ef51a7efabf,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-4515560f-5ca6-4b9a-8720-db5118ee7559,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-cedce977-00e3-430b-82d0-f222ddf18ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-b7efdf75-1667-4606-a6de-72dbe66dd8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878038278-172.17.0.21-1597548460625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43192,DS-983c8025-2828-4d40-b7fd-c125d8843c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-cc1c4841-beac-4beb-a697-c50a22c6c704,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-abcbdac0-58ca-4780-9054-cc409957607f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-447124ee-cd4c-4773-92cf-0a6170625dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-1f295211-7cf7-442d-a16c-2ef51a7efabf,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-4515560f-5ca6-4b9a-8720-db5118ee7559,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-cedce977-00e3-430b-82d0-f222ddf18ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-b7efdf75-1667-4606-a6de-72dbe66dd8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050508347-172.17.0.21-1597549103131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-e6caaad1-13ab-4c1c-ab32-3f5a4df2b062,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-deb9bfea-1359-415a-a725-f99acabb8184,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-3b033a87-990f-4d87-944c-fa62054bf4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-2591ca82-a7a1-4c7f-9a83-8b1cb2ee59ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-104d4eb0-9102-4ca0-b5f4-f24a4f8b614c,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-cb8afcca-b8c2-4592-a4b1-e9f149ee0faa,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-968e97a6-e31e-45cd-82ef-d1d3825eeba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-6cb95914-9d49-4e71-acef-89cccb3c8ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050508347-172.17.0.21-1597549103131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-e6caaad1-13ab-4c1c-ab32-3f5a4df2b062,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-deb9bfea-1359-415a-a725-f99acabb8184,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-3b033a87-990f-4d87-944c-fa62054bf4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-2591ca82-a7a1-4c7f-9a83-8b1cb2ee59ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-104d4eb0-9102-4ca0-b5f4-f24a4f8b614c,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-cb8afcca-b8c2-4592-a4b1-e9f149ee0faa,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-968e97a6-e31e-45cd-82ef-d1d3825eeba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-6cb95914-9d49-4e71-acef-89cccb3c8ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076742180-172.17.0.21-1597549224226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35051,DS-76a327de-f402-4e88-a127-d71fcd98727f,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-dc74624f-f38f-456e-a1e7-65a408afb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-aaf0d9f1-9bd3-4954-b554-0e5fad4d4281,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-172e1a8b-96c8-47d2-9b96-53e2b6983e11,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-aa41ea49-bfe8-45a0-a9a5-5a2e996c9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-3b9f45bf-29da-4ea3-8ab3-24fa77e8f4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-37e24021-7706-4d05-b153-d31a7eeeff93,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-b0af8575-6b30-46f2-bb7f-f72280a76105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076742180-172.17.0.21-1597549224226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35051,DS-76a327de-f402-4e88-a127-d71fcd98727f,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-dc74624f-f38f-456e-a1e7-65a408afb8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-aaf0d9f1-9bd3-4954-b554-0e5fad4d4281,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-172e1a8b-96c8-47d2-9b96-53e2b6983e11,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-aa41ea49-bfe8-45a0-a9a5-5a2e996c9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-3b9f45bf-29da-4ea3-8ab3-24fa77e8f4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-37e24021-7706-4d05-b153-d31a7eeeff93,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-b0af8575-6b30-46f2-bb7f-f72280a76105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466510169-172.17.0.21-1597549605774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-de4ba60f-9761-45ac-a055-3ef69ee6a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-b02de2eb-162e-4439-a273-872b42a8b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-6ca3844b-47a7-49f1-a2c7-cd7917808c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-e182cd37-5ff5-4076-93ee-6773b3f7619e,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-4e6747c7-a921-4421-932d-f6be66becd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-25680df9-f0cb-4de5-b2ff-785d58b49567,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-e4ac1065-f18f-445a-9aa7-cafd74ffbb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-9acbd429-76fe-4879-9299-3cd04d88a084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466510169-172.17.0.21-1597549605774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-de4ba60f-9761-45ac-a055-3ef69ee6a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-b02de2eb-162e-4439-a273-872b42a8b5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-6ca3844b-47a7-49f1-a2c7-cd7917808c76,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-e182cd37-5ff5-4076-93ee-6773b3f7619e,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-4e6747c7-a921-4421-932d-f6be66becd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-25680df9-f0cb-4de5-b2ff-785d58b49567,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-e4ac1065-f18f-445a-9aa7-cafd74ffbb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-9acbd429-76fe-4879-9299-3cd04d88a084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245684268-172.17.0.21-1597549984224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39598,DS-47e1e9e1-a646-4ce4-8077-341175c24aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-aa44b6ba-2b84-4c2c-9cb5-902b5b384cac,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-825fea23-e0a8-40b8-9949-6a01226b369c,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-1b918c39-ac15-4d72-af14-53a2def1e362,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-bda3d512-20c9-4a42-b237-700faf23b612,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-43d883ed-778e-49dd-b06d-a73e0553ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-4b004a8b-e3d1-4e78-bc06-aec9a01d69e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-192cc148-d976-4a83-acd1-b540c4c0a53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245684268-172.17.0.21-1597549984224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39598,DS-47e1e9e1-a646-4ce4-8077-341175c24aba,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-aa44b6ba-2b84-4c2c-9cb5-902b5b384cac,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-825fea23-e0a8-40b8-9949-6a01226b369c,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-1b918c39-ac15-4d72-af14-53a2def1e362,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-bda3d512-20c9-4a42-b237-700faf23b612,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-43d883ed-778e-49dd-b06d-a73e0553ccfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-4b004a8b-e3d1-4e78-bc06-aec9a01d69e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-192cc148-d976-4a83-acd1-b540c4c0a53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271187254-172.17.0.21-1597550180753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34170,DS-0dd3d4ef-2e0c-46a4-b2a4-effc5dd30493,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-83eb4316-aced-43cc-a79c-31f8f15f34e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-4b36bee8-5da3-4dea-a909-9d3abc624550,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-431652e7-2b34-45c1-a26b-5e77741a1919,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-eefab912-755e-4a76-abcd-b5aad2566d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-92646a72-91c1-45ec-80e7-ed441a986b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-70510966-64e4-4468-a999-3a4d5d60f4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-6b9dd698-78f0-433b-9f13-7cad6066ff5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271187254-172.17.0.21-1597550180753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34170,DS-0dd3d4ef-2e0c-46a4-b2a4-effc5dd30493,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-83eb4316-aced-43cc-a79c-31f8f15f34e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-4b36bee8-5da3-4dea-a909-9d3abc624550,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-431652e7-2b34-45c1-a26b-5e77741a1919,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-eefab912-755e-4a76-abcd-b5aad2566d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-92646a72-91c1-45ec-80e7-ed441a986b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-70510966-64e4-4468-a999-3a4d5d60f4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-6b9dd698-78f0-433b-9f13-7cad6066ff5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881698946-172.17.0.21-1597550285162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37456,DS-85aeca44-4842-47a7-9813-e3b54333079d,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-c53862b8-b4ae-4881-97da-b54a21153c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-286214ed-932f-4240-812b-2a15e5ad9ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-e4adfaab-67c3-4a11-8947-606674718252,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-a2f225e2-1b37-45f3-a14e-dc693cc816b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-ef801010-5c6b-49ae-b74a-b721e74aeffa,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-96962c4d-9fb8-4cbe-9619-ed46625afa72,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-87c3d71d-9d66-4fea-9210-a09799884cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881698946-172.17.0.21-1597550285162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37456,DS-85aeca44-4842-47a7-9813-e3b54333079d,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-c53862b8-b4ae-4881-97da-b54a21153c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-286214ed-932f-4240-812b-2a15e5ad9ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-e4adfaab-67c3-4a11-8947-606674718252,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-a2f225e2-1b37-45f3-a14e-dc693cc816b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-ef801010-5c6b-49ae-b74a-b721e74aeffa,DISK], DatanodeInfoWithStorage[127.0.0.1:39005,DS-96962c4d-9fb8-4cbe-9619-ed46625afa72,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-87c3d71d-9d66-4fea-9210-a09799884cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826719637-172.17.0.21-1597550320126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45858,DS-01246e1b-c334-46ab-a79c-b9cb8ca4b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-cf3b7eeb-b391-4fb5-8a81-500ec4804648,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-57a1e9d6-e8e7-49d9-a79a-7abb792aa483,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-def34133-c5b9-498a-8f2d-a3b323db9800,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-22733bd4-f7d7-4019-a9b3-0ec180a2d0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-90b403bd-c6b5-44b2-87a4-8e23e8f87871,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-066988b6-3b01-4e14-b543-9f34f9ff3510,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-28ede2e6-ca94-48bb-bb8f-f93a5b9a65e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826719637-172.17.0.21-1597550320126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45858,DS-01246e1b-c334-46ab-a79c-b9cb8ca4b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-cf3b7eeb-b391-4fb5-8a81-500ec4804648,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-57a1e9d6-e8e7-49d9-a79a-7abb792aa483,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-def34133-c5b9-498a-8f2d-a3b323db9800,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-22733bd4-f7d7-4019-a9b3-0ec180a2d0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-90b403bd-c6b5-44b2-87a4-8e23e8f87871,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-066988b6-3b01-4e14-b543-9f34f9ff3510,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-28ede2e6-ca94-48bb-bb8f-f93a5b9a65e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667980466-172.17.0.21-1597550400500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37017,DS-eb1a0335-547b-425e-8ace-07c37d128ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-4a377f07-e661-4478-ae17-38faeed85bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-7d8f6d4a-0a86-4459-9f23-bbc427634c66,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-ecb4aae6-acf4-400f-a8fc-1d659d68ff46,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-237a07ee-c02b-4e0a-bb5b-ea0c4e6889a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-a4cf3afe-5666-4238-bb17-c16dd4e0727c,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-2b17a011-f4f7-4844-a5e1-cb342a46284f,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-4ce96e4e-9d07-452e-9856-47fbeecc59ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667980466-172.17.0.21-1597550400500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37017,DS-eb1a0335-547b-425e-8ace-07c37d128ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-4a377f07-e661-4478-ae17-38faeed85bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-7d8f6d4a-0a86-4459-9f23-bbc427634c66,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-ecb4aae6-acf4-400f-a8fc-1d659d68ff46,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-237a07ee-c02b-4e0a-bb5b-ea0c4e6889a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-a4cf3afe-5666-4238-bb17-c16dd4e0727c,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-2b17a011-f4f7-4844-a5e1-cb342a46284f,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-4ce96e4e-9d07-452e-9856-47fbeecc59ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384494949-172.17.0.21-1597551009002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37057,DS-88593b39-79fe-4440-b8e3-5c332e7c7d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-a70abbe1-1b37-4398-b74f-f1881a56d590,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-ce51d8d2-4a3c-4993-bd9f-a7dcb86f4522,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-23faa988-6dcf-42b8-9641-61fa848414f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-9be99143-7d4b-4526-b024-a87fcff4e9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-1dba8a09-d435-41be-b930-61b2f276985a,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-7f98ed4c-d260-4e76-9b03-97f7798a191b,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-85639da6-adee-4926-ad51-b952f5db7fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384494949-172.17.0.21-1597551009002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37057,DS-88593b39-79fe-4440-b8e3-5c332e7c7d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-a70abbe1-1b37-4398-b74f-f1881a56d590,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-ce51d8d2-4a3c-4993-bd9f-a7dcb86f4522,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-23faa988-6dcf-42b8-9641-61fa848414f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-9be99143-7d4b-4526-b024-a87fcff4e9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-1dba8a09-d435-41be-b930-61b2f276985a,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-7f98ed4c-d260-4e76-9b03-97f7798a191b,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-85639da6-adee-4926-ad51-b952f5db7fb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 30ms
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951748306-172.17.0.21-1597551248152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44781,DS-9eb69ce7-d49c-4978-ab28-0efe865f197c,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-aa92ec09-dbb7-4edd-9d31-48cfa54a7a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-2088c94c-a4c4-49dd-ad13-970b2a309e56,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-3fcb2ace-f17f-4629-8594-3c7620a1a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-2c5a04a2-2a50-4872-a84f-3173d39c50b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-63bf9a64-69ab-47d4-96d9-cc3d2ee039e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-6edd3202-c20e-4087-92e4-e54a98fffa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-f8125a3d-a2e1-4f15-bc71-ca8e0b62825c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951748306-172.17.0.21-1597551248152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44781,DS-9eb69ce7-d49c-4978-ab28-0efe865f197c,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-aa92ec09-dbb7-4edd-9d31-48cfa54a7a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-2088c94c-a4c4-49dd-ad13-970b2a309e56,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-3fcb2ace-f17f-4629-8594-3c7620a1a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-2c5a04a2-2a50-4872-a84f-3173d39c50b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-63bf9a64-69ab-47d4-96d9-cc3d2ee039e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-6edd3202-c20e-4087-92e4-e54a98fffa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-f8125a3d-a2e1-4f15-bc71-ca8e0b62825c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5556
