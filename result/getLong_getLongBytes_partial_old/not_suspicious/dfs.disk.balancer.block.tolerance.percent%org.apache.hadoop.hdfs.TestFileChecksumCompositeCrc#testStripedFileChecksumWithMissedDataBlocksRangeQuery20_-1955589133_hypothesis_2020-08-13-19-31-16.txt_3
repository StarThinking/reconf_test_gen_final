reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071429714-172.17.0.7-1597347146188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-57d14697-8f30-4416-8d11-db1010b02054,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-59566f8b-4c57-44d8-b7e1-92028ae2d638,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-b1af277a-f5d2-456b-b669-580022b5de56,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-6ebb34ee-44bc-4d02-ac1a-81e5b1ec39f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-c20dab57-a200-4042-98dd-2fdc3d28cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-dd462e4e-75a5-4966-acd3-779cc3db39e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-90588e95-9fd6-41d6-b382-af0d1ec8b6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-275d0993-94ca-4e4e-af68-527637226ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071429714-172.17.0.7-1597347146188:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42368,DS-57d14697-8f30-4416-8d11-db1010b02054,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-59566f8b-4c57-44d8-b7e1-92028ae2d638,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-b1af277a-f5d2-456b-b669-580022b5de56,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-6ebb34ee-44bc-4d02-ac1a-81e5b1ec39f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-c20dab57-a200-4042-98dd-2fdc3d28cfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-dd462e4e-75a5-4966-acd3-779cc3db39e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-90588e95-9fd6-41d6-b382-af0d1ec8b6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-275d0993-94ca-4e4e-af68-527637226ef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743656051-172.17.0.7-1597347762730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-282d214a-21db-407a-a38c-8a1f7b92442a,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-38a670c5-293d-4e38-9c41-dec407d78d54,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-ec87903a-678d-4eb7-b05e-984e56374701,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-de654105-deaa-4521-9e4b-5461cdb520b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-02574ec2-24bd-413f-8c52-8729e4c806b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-782e6a67-1e52-4c6b-bc0e-49197c55da14,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-7396a792-a2d1-42a0-a5ae-084897bae71b,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-b9780e73-531c-4487-afb7-de8067ddda8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743656051-172.17.0.7-1597347762730:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-282d214a-21db-407a-a38c-8a1f7b92442a,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-38a670c5-293d-4e38-9c41-dec407d78d54,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-ec87903a-678d-4eb7-b05e-984e56374701,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-de654105-deaa-4521-9e4b-5461cdb520b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-02574ec2-24bd-413f-8c52-8729e4c806b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-782e6a67-1e52-4c6b-bc0e-49197c55da14,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-7396a792-a2d1-42a0-a5ae-084897bae71b,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-b9780e73-531c-4487-afb7-de8067ddda8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365003978-172.17.0.7-1597347807515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38697,DS-7369f6c6-533c-469e-aa0a-494fa1cbc44e,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-47a1e8c6-10fc-4f55-86d2-ac372fc31bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-72d4b091-dcad-4714-bfa2-f3d1517d040b,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-bfdf90d4-abee-4edd-a56e-31727ec597fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-afc024fb-616e-48cb-95bb-fdf872391e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-e7f1dac0-b8ba-4004-bf7e-0f2295d788dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-3c4fe02b-1956-4630-99c9-636eda60d313,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-470055ab-b708-47e9-b053-a24c71114342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365003978-172.17.0.7-1597347807515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38697,DS-7369f6c6-533c-469e-aa0a-494fa1cbc44e,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-47a1e8c6-10fc-4f55-86d2-ac372fc31bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-72d4b091-dcad-4714-bfa2-f3d1517d040b,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-bfdf90d4-abee-4edd-a56e-31727ec597fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-afc024fb-616e-48cb-95bb-fdf872391e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-e7f1dac0-b8ba-4004-bf7e-0f2295d788dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-3c4fe02b-1956-4630-99c9-636eda60d313,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-470055ab-b708-47e9-b053-a24c71114342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235495224-172.17.0.7-1597347846439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-a26692cb-dc1e-4613-9309-8908aae4d9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-e96b70a6-0a4b-4b93-9433-acd7c99b0308,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-aafe917b-e39d-4df8-a51d-463c003f03ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-a15f5915-003f-4fc7-a317-31db6b3cac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-a42fe3dd-e913-41ee-8c26-bc16df9ec410,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-206924e0-ce8e-4c80-81aa-f99549ceeb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-1411729c-3ea7-453d-ac5b-38a5e290bd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-e3d37769-db5e-4bac-9b34-3650515eb965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235495224-172.17.0.7-1597347846439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-a26692cb-dc1e-4613-9309-8908aae4d9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-e96b70a6-0a4b-4b93-9433-acd7c99b0308,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-aafe917b-e39d-4df8-a51d-463c003f03ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-a15f5915-003f-4fc7-a317-31db6b3cac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-a42fe3dd-e913-41ee-8c26-bc16df9ec410,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-206924e0-ce8e-4c80-81aa-f99549ceeb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-1411729c-3ea7-453d-ac5b-38a5e290bd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-e3d37769-db5e-4bac-9b34-3650515eb965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253796781-172.17.0.7-1597347949562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44431,DS-22c01a61-2136-404f-a543-271d6c2723ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-dd50f033-8940-449b-b04a-1a1e94c6dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-f73f2103-fec9-4f94-8e3e-fdfbf5acd877,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-36b0dce3-53b6-4000-a152-6765ea6c3b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-d1369af1-98b3-4dde-8e69-386667578324,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-6f50d4b2-da0b-467a-9d02-f7d3ccf668a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-4d32dc89-ec02-4f35-bb3f-b9a66ce71f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-28e4fab6-a97f-4c59-88e8-c223685c0033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253796781-172.17.0.7-1597347949562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44431,DS-22c01a61-2136-404f-a543-271d6c2723ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-dd50f033-8940-449b-b04a-1a1e94c6dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-f73f2103-fec9-4f94-8e3e-fdfbf5acd877,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-36b0dce3-53b6-4000-a152-6765ea6c3b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-d1369af1-98b3-4dde-8e69-386667578324,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-6f50d4b2-da0b-467a-9d02-f7d3ccf668a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-4d32dc89-ec02-4f35-bb3f-b9a66ce71f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-28e4fab6-a97f-4c59-88e8-c223685c0033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638617555-172.17.0.7-1597347999496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-ce371ecb-8e53-43db-8142-6ad41abfd880,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-daf1f444-158a-4c71-b0a9-03f0d6064c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-6f70dc00-4749-41fb-80eb-026e3ac89c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-3b1cac6d-3d75-4c2a-9023-eb7e16446393,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-9780bd51-8979-495c-a596-8777f98888b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-4db5a16e-7ffb-4eb9-861b-597d658d75cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-af7829ee-e8d4-42b2-8317-e8389602028e,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-f5bf4105-7f7f-4ab5-a95f-3cc3d0cfe520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638617555-172.17.0.7-1597347999496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35134,DS-ce371ecb-8e53-43db-8142-6ad41abfd880,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-daf1f444-158a-4c71-b0a9-03f0d6064c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-6f70dc00-4749-41fb-80eb-026e3ac89c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-3b1cac6d-3d75-4c2a-9023-eb7e16446393,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-9780bd51-8979-495c-a596-8777f98888b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-4db5a16e-7ffb-4eb9-861b-597d658d75cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-af7829ee-e8d4-42b2-8317-e8389602028e,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-f5bf4105-7f7f-4ab5-a95f-3cc3d0cfe520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356207281-172.17.0.7-1597348140486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39820,DS-20359668-5a5c-4308-8f4f-4b8ed81b4830,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-f771121a-e3af-494e-bb9b-ab8bee62a06c,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-21048b86-c352-4ca1-aabb-502d6618d999,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-a859e750-8813-4df8-8702-3628cd422d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-d5299aea-e613-4f33-aa88-b0af268bcaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0d5e3899-022f-4371-868b-e1047e295182,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-04bdc9d6-c15d-4730-aaf7-eacbf80402c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-06d5b94b-8ff8-4ba1-bed2-568347d802b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356207281-172.17.0.7-1597348140486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39820,DS-20359668-5a5c-4308-8f4f-4b8ed81b4830,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-f771121a-e3af-494e-bb9b-ab8bee62a06c,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-21048b86-c352-4ca1-aabb-502d6618d999,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-a859e750-8813-4df8-8702-3628cd422d34,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-d5299aea-e613-4f33-aa88-b0af268bcaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0d5e3899-022f-4371-868b-e1047e295182,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-04bdc9d6-c15d-4730-aaf7-eacbf80402c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-06d5b94b-8ff8-4ba1-bed2-568347d802b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755549214-172.17.0.7-1597348344461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-c1e040a3-b482-4716-b86d-78d848705067,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-632b1591-e0fb-46a6-b66c-22ce748b5b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-9c1c4bea-e94d-4ba6-98d2-991bcf5c14a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-14c4ecaa-660b-41f9-a681-1cb0bb3c02bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-9cbe92c2-809c-4bf9-8c45-0444b012b9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-d45c06cf-2e87-40ac-a66e-643f6ae7dae3,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-be3e49a1-6b05-43e7-93fe-4e2636223dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-1e726be2-6f1c-416a-b00b-fe0ce04ca81c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755549214-172.17.0.7-1597348344461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37630,DS-c1e040a3-b482-4716-b86d-78d848705067,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-632b1591-e0fb-46a6-b66c-22ce748b5b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-9c1c4bea-e94d-4ba6-98d2-991bcf5c14a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-14c4ecaa-660b-41f9-a681-1cb0bb3c02bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-9cbe92c2-809c-4bf9-8c45-0444b012b9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-d45c06cf-2e87-40ac-a66e-643f6ae7dae3,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-be3e49a1-6b05-43e7-93fe-4e2636223dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-1e726be2-6f1c-416a-b00b-fe0ce04ca81c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711450025-172.17.0.7-1597348475192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-6b7a0d82-9c85-4771-8d18-c62ca6b71a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-f6201d1d-1b72-4411-8e8c-4f0b7d8d6313,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-7a438548-152e-4fcb-9da8-509f23f1cfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-3123b150-113a-4bc1-9ccb-84226802b47d,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-df90348f-33e3-4291-9b70-ffab8c44f10e,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-e250941b-1e7e-45e8-a3a5-de70ef131844,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-81c8377a-5ae3-4bb3-a3fc-62c03c3f0beb,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ebef3122-8b78-413b-b332-d1587a82ed4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711450025-172.17.0.7-1597348475192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-6b7a0d82-9c85-4771-8d18-c62ca6b71a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-f6201d1d-1b72-4411-8e8c-4f0b7d8d6313,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-7a438548-152e-4fcb-9da8-509f23f1cfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-3123b150-113a-4bc1-9ccb-84226802b47d,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-df90348f-33e3-4291-9b70-ffab8c44f10e,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-e250941b-1e7e-45e8-a3a5-de70ef131844,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-81c8377a-5ae3-4bb3-a3fc-62c03c3f0beb,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-ebef3122-8b78-413b-b332-d1587a82ed4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997910143-172.17.0.7-1597349058243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-3a9a0499-3da4-488e-8f85-bae17d89e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-761b5209-18d8-4e0c-8f81-9e322e5991e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-eed912b8-2436-4e06-b68e-a4953de860e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-774119b1-5ac7-4acb-8157-fa8cb42329af,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-db12bc5c-c361-4d80-a64f-6af8f1d6903d,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-b2e983c8-75f9-4175-94a5-0ffd43e34a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-47e8f506-b305-4882-8bf4-58a98d6dcd71,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-3ff283db-24c8-4ce8-aaa7-c3d830139c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997910143-172.17.0.7-1597349058243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-3a9a0499-3da4-488e-8f85-bae17d89e6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-761b5209-18d8-4e0c-8f81-9e322e5991e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-eed912b8-2436-4e06-b68e-a4953de860e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-774119b1-5ac7-4acb-8157-fa8cb42329af,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-db12bc5c-c361-4d80-a64f-6af8f1d6903d,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-b2e983c8-75f9-4175-94a5-0ffd43e34a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-47e8f506-b305-4882-8bf4-58a98d6dcd71,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-3ff283db-24c8-4ce8-aaa7-c3d830139c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615578093-172.17.0.7-1597350690327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-8d157589-52e2-442c-90c0-2acc83f23c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-20f61ed2-efd6-404f-86d3-d39a5564748a,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-6e69b946-e3ed-49f0-b030-f43b122f7e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-664d1e32-d538-40cf-8188-216d56a82f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-e2398142-887b-460f-ba11-34f6e149d584,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-f526996c-9276-402e-a2a0-e45989822fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-69b762a5-385c-45a3-b5b4-224dfa5211fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-02be186d-3461-4004-a60f-b5466edbe279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615578093-172.17.0.7-1597350690327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-8d157589-52e2-442c-90c0-2acc83f23c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-20f61ed2-efd6-404f-86d3-d39a5564748a,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-6e69b946-e3ed-49f0-b030-f43b122f7e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-664d1e32-d538-40cf-8188-216d56a82f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-e2398142-887b-460f-ba11-34f6e149d584,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-f526996c-9276-402e-a2a0-e45989822fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-69b762a5-385c-45a3-b5b4-224dfa5211fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-02be186d-3461-4004-a60f-b5466edbe279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789076482-172.17.0.7-1597350816791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45113,DS-655e1b77-a783-42b8-93ba-293753c126f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-4eabb821-25f3-4707-9b6c-17e1f2f5e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-e1da1002-c616-4c14-92cf-80ead452a6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-1fbcd9fe-8d35-447a-aca1-86c8c3d2895a,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-ef32fd2c-678c-40bd-84da-aff7ef0688f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-3f8fa10f-792d-4bc6-b72e-db9bf06372d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-5814d197-8da9-4e43-8078-9ac996784031,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-27b15476-88d6-4f44-b58d-b4a708b968f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789076482-172.17.0.7-1597350816791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45113,DS-655e1b77-a783-42b8-93ba-293753c126f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-4eabb821-25f3-4707-9b6c-17e1f2f5e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-e1da1002-c616-4c14-92cf-80ead452a6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-1fbcd9fe-8d35-447a-aca1-86c8c3d2895a,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-ef32fd2c-678c-40bd-84da-aff7ef0688f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-3f8fa10f-792d-4bc6-b72e-db9bf06372d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-5814d197-8da9-4e43-8078-9ac996784031,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-27b15476-88d6-4f44-b58d-b4a708b968f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671584981-172.17.0.7-1597351355005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-a779bc34-0d4a-4927-ac1d-3a03cdd8dc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-62e64972-da1c-4c31-9ae8-05a5babe7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-6a56d55b-0b8c-443c-922a-5c90878617dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-b0a3dfe6-2b97-4da5-8f35-5e76d6fb858f,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-50d7409a-3b5f-4e70-88a8-ff85498038cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-05652ae2-4807-4189-951e-a5031965a763,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-89a26c6c-f207-44ec-a06f-f28ca3444d31,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-5da1f2fc-14e1-4be1-817f-7b02509d507f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671584981-172.17.0.7-1597351355005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-a779bc34-0d4a-4927-ac1d-3a03cdd8dc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-62e64972-da1c-4c31-9ae8-05a5babe7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-6a56d55b-0b8c-443c-922a-5c90878617dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-b0a3dfe6-2b97-4da5-8f35-5e76d6fb858f,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-50d7409a-3b5f-4e70-88a8-ff85498038cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-05652ae2-4807-4189-951e-a5031965a763,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-89a26c6c-f207-44ec-a06f-f28ca3444d31,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-5da1f2fc-14e1-4be1-817f-7b02509d507f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731568235-172.17.0.7-1597351772418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43981,DS-8b5276cb-4e49-4e42-94eb-dcdbf37397b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-43fe35cf-36d1-435d-bde2-fce6c50f0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-e9398b31-2a36-4332-a300-ed0e05c37150,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-9f7acacf-51cd-44f6-be5b-fd0ba4b770cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-a709d04a-c671-4242-b665-1bdb16505cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-7757fd52-cd31-447d-9afd-8c084a529e85,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-702eaf1f-8135-4efe-8608-e5154809e1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-ae2bdf1a-4a64-4ef2-b843-147fdf445fb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731568235-172.17.0.7-1597351772418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43981,DS-8b5276cb-4e49-4e42-94eb-dcdbf37397b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-43fe35cf-36d1-435d-bde2-fce6c50f0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-e9398b31-2a36-4332-a300-ed0e05c37150,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-9f7acacf-51cd-44f6-be5b-fd0ba4b770cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-a709d04a-c671-4242-b665-1bdb16505cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-7757fd52-cd31-447d-9afd-8c084a529e85,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-702eaf1f-8135-4efe-8608-e5154809e1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-ae2bdf1a-4a64-4ef2-b843-147fdf445fb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291702845-172.17.0.7-1597351957163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-ecdaacd8-8bc6-4b0d-8006-ac9e12716ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-2b98cfa5-a667-425d-837a-df6f369977fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-ac542117-5ab3-454a-89ee-97031ebc7c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-997df19d-33f8-4fc7-8b18-70afae52591d,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-1e7282ef-2e81-47f8-967b-24f4a94b7282,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-6495d049-cc49-41aa-9406-05928cac7bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-183ecbc3-2b4d-42b0-9ca6-5b336c798b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-87cdf263-9a2c-4a91-8746-14f365207d94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291702845-172.17.0.7-1597351957163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-ecdaacd8-8bc6-4b0d-8006-ac9e12716ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-2b98cfa5-a667-425d-837a-df6f369977fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-ac542117-5ab3-454a-89ee-97031ebc7c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-997df19d-33f8-4fc7-8b18-70afae52591d,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-1e7282ef-2e81-47f8-967b-24f4a94b7282,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-6495d049-cc49-41aa-9406-05928cac7bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-183ecbc3-2b4d-42b0-9ca6-5b336c798b17,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-87cdf263-9a2c-4a91-8746-14f365207d94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593908507-172.17.0.7-1597352152425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-b0ea6dc3-2371-4785-94d0-e158745bd434,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-580f0871-7461-4d59-a7bd-9c8582a907ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-40989aab-04b4-4522-93ba-f3f286ce7eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-87404c3a-01b7-44c2-962d-e06230dac82f,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-7829619b-0025-445f-af76-6b8bd135350b,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-8eaf406a-88dc-4444-a576-433b3d25108c,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-7aabd890-18aa-41ef-af56-8881ef3cdaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-65da714a-bec5-45db-9a37-480010cc4e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593908507-172.17.0.7-1597352152425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-b0ea6dc3-2371-4785-94d0-e158745bd434,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-580f0871-7461-4d59-a7bd-9c8582a907ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-40989aab-04b4-4522-93ba-f3f286ce7eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-87404c3a-01b7-44c2-962d-e06230dac82f,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-7829619b-0025-445f-af76-6b8bd135350b,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-8eaf406a-88dc-4444-a576-433b3d25108c,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-7aabd890-18aa-41ef-af56-8881ef3cdaf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-65da714a-bec5-45db-9a37-480010cc4e59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465312207-172.17.0.7-1597352247762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-217bfff7-c464-456f-a7cd-e1bb1b0fb99b,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-abdccfcd-c50c-4341-8f54-f8dfb9b681b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-afa1b216-c857-449d-8465-d7d6ddfb11ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-0384b3be-ceab-4f5c-be44-476758756598,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-703efe67-2de6-4bff-9a9b-68f1ea058d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-816e086b-6560-493f-8497-643775dbb661,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-e614e7b4-cd82-40cc-86f3-78e2e08c2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-c316aad9-9461-4f4e-a5e6-d05c25e95228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465312207-172.17.0.7-1597352247762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-217bfff7-c464-456f-a7cd-e1bb1b0fb99b,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-abdccfcd-c50c-4341-8f54-f8dfb9b681b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-afa1b216-c857-449d-8465-d7d6ddfb11ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-0384b3be-ceab-4f5c-be44-476758756598,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-703efe67-2de6-4bff-9a9b-68f1ea058d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-816e086b-6560-493f-8497-643775dbb661,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-e614e7b4-cd82-40cc-86f3-78e2e08c2fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-c316aad9-9461-4f4e-a5e6-d05c25e95228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487415048-172.17.0.7-1597352560738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34194,DS-6c488893-7e08-490a-9ee2-24666f167be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-3ad8ee41-8315-4b96-aa83-bcf1ef12f811,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-ea2c6263-cb4b-4f98-8ec1-b53746cc8d94,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-7aeae634-43e1-4e46-b9c1-48bf3192407a,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-c72190fc-9369-4ad4-a0f9-93560e20727a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-82dcb8d6-a46f-41a3-8037-44adcf0846dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-a995ccf2-327a-43a9-b8d0-89e034cac1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-062f0533-9935-4a79-9ab1-2524b7c19237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487415048-172.17.0.7-1597352560738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34194,DS-6c488893-7e08-490a-9ee2-24666f167be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-3ad8ee41-8315-4b96-aa83-bcf1ef12f811,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-ea2c6263-cb4b-4f98-8ec1-b53746cc8d94,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-7aeae634-43e1-4e46-b9c1-48bf3192407a,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-c72190fc-9369-4ad4-a0f9-93560e20727a,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-82dcb8d6-a46f-41a3-8037-44adcf0846dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-a995ccf2-327a-43a9-b8d0-89e034cac1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-062f0533-9935-4a79-9ab1-2524b7c19237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266800069-172.17.0.7-1597353455736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-09023566-4749-480c-a444-55ef089eaa23,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-4d4d7680-7bea-430c-9c9f-0dc7844e4470,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-2b4a36b8-22ff-4b3c-8961-c413129a6655,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-4fd12509-5677-4092-8d1d-8613cb5a376e,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-e3446cbd-fef8-4a21-88cb-40854ba03687,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-0455bd18-99c2-4508-949c-53d4d806142f,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-fd58df4a-5356-46d6-9249-f11734a857f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-d245e480-d0ac-4edc-91f3-da36c157a7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266800069-172.17.0.7-1597353455736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-09023566-4749-480c-a444-55ef089eaa23,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-4d4d7680-7bea-430c-9c9f-0dc7844e4470,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-2b4a36b8-22ff-4b3c-8961-c413129a6655,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-4fd12509-5677-4092-8d1d-8613cb5a376e,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-e3446cbd-fef8-4a21-88cb-40854ba03687,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-0455bd18-99c2-4508-949c-53d4d806142f,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-fd58df4a-5356-46d6-9249-f11734a857f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-d245e480-d0ac-4edc-91f3-da36c157a7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246881125-172.17.0.7-1597353742272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36883,DS-9b84f61e-d7b4-4acc-828d-222dfe0110f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-9afac1ff-2cc3-448c-88d3-f3e81bff8aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-84c48f03-43f9-4203-950f-1ed4348b256a,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-76be27c7-f599-4182-97df-253c7866af73,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-48cf7004-25bc-4506-bb73-4384f7edeec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-576c0261-9a02-4bb6-b73a-3e69f3e09f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-b5023820-2afd-4dd9-8944-39d6dd781439,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-6de1e2c5-59a9-44d6-94d4-02544af6ab8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246881125-172.17.0.7-1597353742272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36883,DS-9b84f61e-d7b4-4acc-828d-222dfe0110f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-9afac1ff-2cc3-448c-88d3-f3e81bff8aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-84c48f03-43f9-4203-950f-1ed4348b256a,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-76be27c7-f599-4182-97df-253c7866af73,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-48cf7004-25bc-4506-bb73-4384f7edeec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-576c0261-9a02-4bb6-b73a-3e69f3e09f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-b5023820-2afd-4dd9-8944-39d6dd781439,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-6de1e2c5-59a9-44d6-94d4-02544af6ab8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477671620-172.17.0.7-1597353842756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-04ac4015-3518-4fa3-88f8-593095597482,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-0bf6e998-9b08-4346-ac7a-87009309554f,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-a6dc0c71-4b46-4db8-8703-69ebe7aa10ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-8e3743d7-019c-4159-b3af-29e087b31d90,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-9d6f7a25-b248-4394-b045-b5991a55a240,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-8199200b-7afc-488f-85a0-cec412de6897,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-71d21096-27d5-4c1f-8563-c197a862c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-da4c2a97-b11e-463a-8d43-d13076524b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477671620-172.17.0.7-1597353842756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35766,DS-04ac4015-3518-4fa3-88f8-593095597482,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-0bf6e998-9b08-4346-ac7a-87009309554f,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-a6dc0c71-4b46-4db8-8703-69ebe7aa10ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-8e3743d7-019c-4159-b3af-29e087b31d90,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-9d6f7a25-b248-4394-b045-b5991a55a240,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-8199200b-7afc-488f-85a0-cec412de6897,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-71d21096-27d5-4c1f-8563-c197a862c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-da4c2a97-b11e-463a-8d43-d13076524b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6967
