reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145332079-172.17.0.6-1597505218936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-934674ed-2def-441e-9800-b65095892e05,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-e50647df-6eb8-47a0-a896-5bed97d1cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-37a2b2c7-e750-43fb-ae1b-9d9b3f793a20,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-a25e9d96-5301-4766-9bc2-d937481eac98,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-eea77563-2449-4132-b9ad-31d9b27ab713,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-6807e70c-7f38-486b-a719-3d279d91cf44,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-7dcbb46e-2d6e-49ac-a9e4-cf15c3c5d343,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-ac231b2e-9b80-4429-959d-b52003c20021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145332079-172.17.0.6-1597505218936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36322,DS-934674ed-2def-441e-9800-b65095892e05,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-e50647df-6eb8-47a0-a896-5bed97d1cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-37a2b2c7-e750-43fb-ae1b-9d9b3f793a20,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-a25e9d96-5301-4766-9bc2-d937481eac98,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-eea77563-2449-4132-b9ad-31d9b27ab713,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-6807e70c-7f38-486b-a719-3d279d91cf44,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-7dcbb46e-2d6e-49ac-a9e4-cf15c3c5d343,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-ac231b2e-9b80-4429-959d-b52003c20021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742716145-172.17.0.6-1597505410404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42519,DS-8c5da94e-d7e5-405f-b947-005d5937ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-e2068515-c1a0-4add-81ad-7bdb89ab6972,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-89a88d2a-a5ca-4fd4-a6e9-708015861933,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-dd3882bd-0c1d-4c33-bff0-ac7cb7b3c628,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-fc35ec69-cb67-4230-b45d-379ada0fe431,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-ac959776-51ec-470f-ae46-1a6e4f94cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-91a6a41f-1da3-4faf-b2cd-53f39a453062,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-4679a695-3df2-4c7a-bedb-6be96cb6cfc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742716145-172.17.0.6-1597505410404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42519,DS-8c5da94e-d7e5-405f-b947-005d5937ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-e2068515-c1a0-4add-81ad-7bdb89ab6972,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-89a88d2a-a5ca-4fd4-a6e9-708015861933,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-dd3882bd-0c1d-4c33-bff0-ac7cb7b3c628,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-fc35ec69-cb67-4230-b45d-379ada0fe431,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-ac959776-51ec-470f-ae46-1a6e4f94cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-91a6a41f-1da3-4faf-b2cd-53f39a453062,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-4679a695-3df2-4c7a-bedb-6be96cb6cfc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218582902-172.17.0.6-1597506110736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39024,DS-ded1a028-850a-472f-b1e4-d77879f541ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-33fe7e75-94b4-4b98-a12b-8fbd6e4a3db9,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-c98dcceb-ad74-4249-80f1-d7c66e3cd44a,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-a9be2b6c-f1c8-466a-87aa-b5a1ee5cd554,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-8c3aaa63-ae5b-4c20-b353-b4d7378b9897,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-e2947a6f-b351-498e-a672-5157c7b0019c,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-06464d29-a773-47f9-a64d-11d6545e09b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-85d46284-2828-4efb-8a69-931c6216fcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218582902-172.17.0.6-1597506110736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39024,DS-ded1a028-850a-472f-b1e4-d77879f541ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-33fe7e75-94b4-4b98-a12b-8fbd6e4a3db9,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-c98dcceb-ad74-4249-80f1-d7c66e3cd44a,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-a9be2b6c-f1c8-466a-87aa-b5a1ee5cd554,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-8c3aaa63-ae5b-4c20-b353-b4d7378b9897,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-e2947a6f-b351-498e-a672-5157c7b0019c,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-06464d29-a773-47f9-a64d-11d6545e09b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-85d46284-2828-4efb-8a69-931c6216fcfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579749902-172.17.0.6-1597506860291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-8097d898-bc87-41d0-9d26-737d7fbaf57d,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-287a0c8d-c9a0-483c-97f4-2dc6f9b03215,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-3cc852fc-6ba2-42c3-a70a-ff8cce231050,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-2ee226b3-4f51-42c5-a0be-5973156be1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-5559980f-554c-4d3a-b733-a456ade9904e,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-9b53a9e0-f4af-4c21-8e73-d3b1fe8a3b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-f207353e-6a84-49a6-943b-12793d39f57f,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-3b5afec4-cdea-4601-8ac7-7a2cd733b30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579749902-172.17.0.6-1597506860291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39137,DS-8097d898-bc87-41d0-9d26-737d7fbaf57d,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-287a0c8d-c9a0-483c-97f4-2dc6f9b03215,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-3cc852fc-6ba2-42c3-a70a-ff8cce231050,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-2ee226b3-4f51-42c5-a0be-5973156be1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-5559980f-554c-4d3a-b733-a456ade9904e,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-9b53a9e0-f4af-4c21-8e73-d3b1fe8a3b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-f207353e-6a84-49a6-943b-12793d39f57f,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-3b5afec4-cdea-4601-8ac7-7a2cd733b30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328528221-172.17.0.6-1597507008136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33356,DS-741aa44e-e488-4829-9969-62c6775f1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-1c518cdf-8f34-47fb-a503-5be2fdfc50be,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-40ef869a-2e07-4cc1-9e26-33f612978200,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-3f06a971-e192-4fca-917c-a5443c68a82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-67103ae7-fafa-402f-8532-0c6368f65c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-bd11c13a-c487-4a36-bd4e-710b628b9753,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-63bb29c1-feab-4787-9c4e-905212c7ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-8d9f4494-d051-426a-8b24-59ef8f69c64f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328528221-172.17.0.6-1597507008136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33356,DS-741aa44e-e488-4829-9969-62c6775f1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-1c518cdf-8f34-47fb-a503-5be2fdfc50be,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-40ef869a-2e07-4cc1-9e26-33f612978200,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-3f06a971-e192-4fca-917c-a5443c68a82a,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-67103ae7-fafa-402f-8532-0c6368f65c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-bd11c13a-c487-4a36-bd4e-710b628b9753,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-63bb29c1-feab-4787-9c4e-905212c7ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-8d9f4494-d051-426a-8b24-59ef8f69c64f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343719232-172.17.0.6-1597507130585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-a62c7043-d4d7-4cc0-9c2f-b07a3a607545,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-d8d721a8-df3b-47c3-9085-9c4bba01b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-aa748479-5740-4fce-afba-473f5bbbb047,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-21005e05-d7dc-42a5-ae19-d5f4faf46246,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-b20a679c-522d-4ca9-995f-8697dc12a21b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-2016fe6d-b100-43e2-929a-cd4249911474,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-2164acb6-6a05-4fcc-a0d8-b6b7ff1a543d,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-90fcb772-e427-4611-8db1-621517e98216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343719232-172.17.0.6-1597507130585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38616,DS-a62c7043-d4d7-4cc0-9c2f-b07a3a607545,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-d8d721a8-df3b-47c3-9085-9c4bba01b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-aa748479-5740-4fce-afba-473f5bbbb047,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-21005e05-d7dc-42a5-ae19-d5f4faf46246,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-b20a679c-522d-4ca9-995f-8697dc12a21b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-2016fe6d-b100-43e2-929a-cd4249911474,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-2164acb6-6a05-4fcc-a0d8-b6b7ff1a543d,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-90fcb772-e427-4611-8db1-621517e98216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421977852-172.17.0.6-1597507967210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-a921d87c-83ec-4273-951a-619bd0eda54e,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-18f1d8fe-60af-4f12-a2e5-bc21a193d50b,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-e4b6d5f3-be49-4c73-9520-61d0655ff1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-e80082e0-3c37-4f01-92a1-a82b39c20616,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-a85dd999-1e07-4440-ad52-7681cc099ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-b8e2e78d-7fe7-4b18-a3c9-d26d4143b98c,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-7844386c-b9ef-4774-b563-5b5d5e549ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-1d3711ca-8c1a-4daf-b7a1-e0b94612131a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421977852-172.17.0.6-1597507967210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-a921d87c-83ec-4273-951a-619bd0eda54e,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-18f1d8fe-60af-4f12-a2e5-bc21a193d50b,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-e4b6d5f3-be49-4c73-9520-61d0655ff1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-e80082e0-3c37-4f01-92a1-a82b39c20616,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-a85dd999-1e07-4440-ad52-7681cc099ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-b8e2e78d-7fe7-4b18-a3c9-d26d4143b98c,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-7844386c-b9ef-4774-b563-5b5d5e549ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-1d3711ca-8c1a-4daf-b7a1-e0b94612131a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021662957-172.17.0.6-1597508980120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-f401cac2-4bec-4516-b1d8-3676aca1bba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-8b257215-b053-489d-bdc5-6d38608c4b70,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-2c935aa8-da2e-4e16-a933-75a1ffaa95a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-1bd35cc5-9f1e-4e5a-a491-a21732e1af48,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-c6b4e8a2-333d-4b4d-ae24-5ce0caa057bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-a205af9f-239a-4809-bd00-852838917b42,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-7f2c25e3-2243-4b61-bb73-67365acb4db3,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-8415bc91-a67c-479a-9ad1-73acfb773af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021662957-172.17.0.6-1597508980120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-f401cac2-4bec-4516-b1d8-3676aca1bba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-8b257215-b053-489d-bdc5-6d38608c4b70,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-2c935aa8-da2e-4e16-a933-75a1ffaa95a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-1bd35cc5-9f1e-4e5a-a491-a21732e1af48,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-c6b4e8a2-333d-4b4d-ae24-5ce0caa057bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-a205af9f-239a-4809-bd00-852838917b42,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-7f2c25e3-2243-4b61-bb73-67365acb4db3,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-8415bc91-a67c-479a-9ad1-73acfb773af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494903735-172.17.0.6-1597509018325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39749,DS-b1fe51f8-c9dc-401f-b33f-4b7264a16cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-821ed758-c6ee-4af1-996a-47b53622b7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-ad9f4d28-1608-4e63-a9f7-93844e66b5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-a7b49160-49bf-44c0-b3e0-023a942faca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-02a7a9c8-214f-4e5d-9e93-971e7119d1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-28ea7bf2-5037-4515-a784-3df7cd2cb3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-5a27741e-f8a7-44e4-886c-b138d7b79613,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-271daf43-3c7c-4f8b-9292-0f25f891784e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494903735-172.17.0.6-1597509018325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39749,DS-b1fe51f8-c9dc-401f-b33f-4b7264a16cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-821ed758-c6ee-4af1-996a-47b53622b7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-ad9f4d28-1608-4e63-a9f7-93844e66b5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-a7b49160-49bf-44c0-b3e0-023a942faca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-02a7a9c8-214f-4e5d-9e93-971e7119d1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-28ea7bf2-5037-4515-a784-3df7cd2cb3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-5a27741e-f8a7-44e4-886c-b138d7b79613,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-271daf43-3c7c-4f8b-9292-0f25f891784e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431079353-172.17.0.6-1597509256457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41261,DS-9b429a3a-4183-43e3-bf8d-2a5076e719b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-74be41f7-99b6-46dd-906e-06eabef6e8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-8d469b8f-6ae5-4424-a88f-04ea2d35f29a,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-f2d67424-36db-4b5f-8708-54c931e0f3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-d63ca8ab-13c0-448f-9274-5fa84a664420,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-aae29eab-3026-4e85-a0dc-a2648939a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-095e3040-8e9f-4b06-8cfa-aecb538d152e,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-3a26eb61-ca53-4498-9687-32bebf16fcf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431079353-172.17.0.6-1597509256457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41261,DS-9b429a3a-4183-43e3-bf8d-2a5076e719b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-74be41f7-99b6-46dd-906e-06eabef6e8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-8d469b8f-6ae5-4424-a88f-04ea2d35f29a,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-f2d67424-36db-4b5f-8708-54c931e0f3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-d63ca8ab-13c0-448f-9274-5fa84a664420,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-aae29eab-3026-4e85-a0dc-a2648939a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-095e3040-8e9f-4b06-8cfa-aecb538d152e,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-3a26eb61-ca53-4498-9687-32bebf16fcf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44746193-172.17.0.6-1597509520992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-32aacfae-8e23-4a95-a4ff-16c278ea7883,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-79bffbc1-f29d-4190-bb31-cb519a5806e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-8caed63e-4569-4790-b628-a4a2a595ded2,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-d66c2722-197a-462f-b673-c8d51a5741f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-fa23ac9a-6afe-4d57-8eb6-013197c0300f,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-755edea0-5cb9-49dd-9c09-b39e22a6de08,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-5fa847de-1d2e-41c5-aab4-bf8bbcaad057,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-5369a447-1f36-440d-9b6c-33c4b304803e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44746193-172.17.0.6-1597509520992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-32aacfae-8e23-4a95-a4ff-16c278ea7883,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-79bffbc1-f29d-4190-bb31-cb519a5806e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-8caed63e-4569-4790-b628-a4a2a595ded2,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-d66c2722-197a-462f-b673-c8d51a5741f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-fa23ac9a-6afe-4d57-8eb6-013197c0300f,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-755edea0-5cb9-49dd-9c09-b39e22a6de08,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-5fa847de-1d2e-41c5-aab4-bf8bbcaad057,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-5369a447-1f36-440d-9b6c-33c4b304803e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789663035-172.17.0.6-1597509741470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38914,DS-a43ba9d5-0b17-4852-a444-bcf950752a06,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-f28e45a2-4166-4139-98af-e99ecaad5a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-349d22f4-87a3-4fad-b539-c80488e51842,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-cc651f89-8aa8-491f-b916-35c77c830014,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-9661c2d7-c395-44b6-8ca4-9ee77519e97e,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-e31512ae-b4f9-4082-b48b-3d17cdf38232,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-8afbc1da-92bb-470c-83d7-9e5c6d4ed2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-98847dc4-126e-4527-a6b8-54b962b382f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789663035-172.17.0.6-1597509741470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38914,DS-a43ba9d5-0b17-4852-a444-bcf950752a06,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-f28e45a2-4166-4139-98af-e99ecaad5a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-349d22f4-87a3-4fad-b539-c80488e51842,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-cc651f89-8aa8-491f-b916-35c77c830014,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-9661c2d7-c395-44b6-8ca4-9ee77519e97e,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-e31512ae-b4f9-4082-b48b-3d17cdf38232,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-8afbc1da-92bb-470c-83d7-9e5c6d4ed2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-98847dc4-126e-4527-a6b8-54b962b382f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915452075-172.17.0.6-1597509889826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39476,DS-24adf535-8b61-4552-b2d9-42d19ef194f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-96ec018b-7a50-48b9-87aa-1ba79c0fac44,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-ef01c29a-5c50-4240-899b-e8068fbab122,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-747fe7f8-5d54-4202-b109-2b3b487b17a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-a6cec49d-184d-40b7-87b6-86598c6033dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-b27e21db-62da-4172-9513-29dcb5a59a49,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-4f8251b6-527d-42f6-afb2-9b2c27ace487,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-c881ddf5-50d1-4dd9-8eea-2b4fd9390509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915452075-172.17.0.6-1597509889826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39476,DS-24adf535-8b61-4552-b2d9-42d19ef194f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-96ec018b-7a50-48b9-87aa-1ba79c0fac44,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-ef01c29a-5c50-4240-899b-e8068fbab122,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-747fe7f8-5d54-4202-b109-2b3b487b17a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-a6cec49d-184d-40b7-87b6-86598c6033dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-b27e21db-62da-4172-9513-29dcb5a59a49,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-4f8251b6-527d-42f6-afb2-9b2c27ace487,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-c881ddf5-50d1-4dd9-8eea-2b4fd9390509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5761
