reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407376997-172.17.0.18-1597518568897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-a0f36991-cd92-4db5-8553-369b2721273c,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-c1a92063-a4a4-4b30-8621-d6d7c8298763,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-bd94c5cd-ef35-471d-a9f1-0851c58c4771,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-7f388d56-95d6-410c-93bb-282148640e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-0383d318-0854-408a-83a3-20a71d929d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-05d1b7ad-e89d-4c62-8fe5-656d976e9573,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-7073f368-0659-4f23-856c-54e66ce7c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-a3e4421a-65bd-4642-be43-1df64a76fb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407376997-172.17.0.18-1597518568897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-a0f36991-cd92-4db5-8553-369b2721273c,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-c1a92063-a4a4-4b30-8621-d6d7c8298763,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-bd94c5cd-ef35-471d-a9f1-0851c58c4771,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-7f388d56-95d6-410c-93bb-282148640e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-0383d318-0854-408a-83a3-20a71d929d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-05d1b7ad-e89d-4c62-8fe5-656d976e9573,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-7073f368-0659-4f23-856c-54e66ce7c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-a3e4421a-65bd-4642-be43-1df64a76fb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329330745-172.17.0.18-1597518602586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39521,DS-6c0a038c-1e91-4393-9094-f7f5ebfe6468,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-60b0f942-b5f7-4d18-9494-f3d957addf35,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-2e274c31-3dd6-4388-861f-26ace091934c,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-9c820689-d122-4347-8ed9-06e4175f223c,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-a8422dbc-b3cd-4e2d-9c1b-9094ee3c574a,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-16fa47aa-f735-4e15-a7ce-9e88c8db8a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-77d736e2-4daa-4377-9efe-83a783927e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-22881731-1c0b-4854-a99e-0c538c9411ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329330745-172.17.0.18-1597518602586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39521,DS-6c0a038c-1e91-4393-9094-f7f5ebfe6468,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-60b0f942-b5f7-4d18-9494-f3d957addf35,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-2e274c31-3dd6-4388-861f-26ace091934c,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-9c820689-d122-4347-8ed9-06e4175f223c,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-a8422dbc-b3cd-4e2d-9c1b-9094ee3c574a,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-16fa47aa-f735-4e15-a7ce-9e88c8db8a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-77d736e2-4daa-4377-9efe-83a783927e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-22881731-1c0b-4854-a99e-0c538c9411ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329923917-172.17.0.18-1597518880766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-5a189185-f65d-497b-89e8-760f979c3846,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-32db7ee0-3e42-4529-ab92-28b1f8a09d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-40d59d32-1300-4166-9448-9cdc71a3e433,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-c8233a4c-d5e3-46b8-b604-1757f91a0b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-0c439c84-85cf-4aba-aebd-175c5173dd69,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-0ecad5db-e36b-42a3-9c7a-b5ad2ee3b8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-08b55f22-5ede-4918-9705-8c2fe0fa8d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-e7b0cb0a-5a9d-42ad-8a3c-b1879c9f8f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329923917-172.17.0.18-1597518880766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-5a189185-f65d-497b-89e8-760f979c3846,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-32db7ee0-3e42-4529-ab92-28b1f8a09d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-40d59d32-1300-4166-9448-9cdc71a3e433,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-c8233a4c-d5e3-46b8-b604-1757f91a0b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-0c439c84-85cf-4aba-aebd-175c5173dd69,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-0ecad5db-e36b-42a3-9c7a-b5ad2ee3b8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-08b55f22-5ede-4918-9705-8c2fe0fa8d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-e7b0cb0a-5a9d-42ad-8a3c-b1879c9f8f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139551327-172.17.0.18-1597518920139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-5a627c02-0d0e-41ef-abda-7f58fd040a52,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-fafead55-cd18-4534-8ea2-476ce592f31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-f861a2ca-e1f1-4a1f-ac13-5b0e862c03ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-998a74cb-3285-49eb-8bdf-88efa2eb640f,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-608b8562-0038-4db2-85b6-0b3402df7784,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-a612e454-08e3-4067-a61e-94bc14242195,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-706032e1-fea8-4039-9f7f-39bb85274286,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-d975974f-2c6e-44a1-ac28-cceab65c85a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2139551327-172.17.0.18-1597518920139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-5a627c02-0d0e-41ef-abda-7f58fd040a52,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-fafead55-cd18-4534-8ea2-476ce592f31e,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-f861a2ca-e1f1-4a1f-ac13-5b0e862c03ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-998a74cb-3285-49eb-8bdf-88efa2eb640f,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-608b8562-0038-4db2-85b6-0b3402df7784,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-a612e454-08e3-4067-a61e-94bc14242195,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-706032e1-fea8-4039-9f7f-39bb85274286,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-d975974f-2c6e-44a1-ac28-cceab65c85a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512495494-172.17.0.18-1597519126201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41185,DS-1b63df1c-f61d-4dc9-88a5-5873dd008619,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-78bdfbcd-dd9e-459a-8b59-186b3838b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-a5a1f94e-250a-4b91-bb2f-7be0e5a7e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-b0ec47ce-c48b-4479-bd43-4ee5ce89210c,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-4c9627b2-8072-40a0-a800-16ce7d6af8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-802e8af2-7725-41c5-b8f9-0efbf11b4c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-4f26ae98-3966-46d6-982d-5b320f220f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-192b117c-0308-4795-8228-0bd722a654a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512495494-172.17.0.18-1597519126201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41185,DS-1b63df1c-f61d-4dc9-88a5-5873dd008619,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-78bdfbcd-dd9e-459a-8b59-186b3838b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-a5a1f94e-250a-4b91-bb2f-7be0e5a7e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-b0ec47ce-c48b-4479-bd43-4ee5ce89210c,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-4c9627b2-8072-40a0-a800-16ce7d6af8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-802e8af2-7725-41c5-b8f9-0efbf11b4c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-4f26ae98-3966-46d6-982d-5b320f220f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-192b117c-0308-4795-8228-0bd722a654a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793186686-172.17.0.18-1597520045399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35261,DS-619603bb-62e1-45a3-9abd-4afdd3dec190,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-b33200ae-3980-4b7d-bc6f-1d6c0df69f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-200ed3e7-0680-4be4-ae3e-618139da69ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-268fd3f8-e91d-4b02-8f10-cb4de708fe88,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-124fdf3f-1120-46fc-9075-c3b5b2eff47e,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-299db028-0046-4e56-bb1f-22f86c9e405a,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-5c047452-2140-4208-9763-4f610d4bdc04,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-9515b102-d260-4176-b564-ecbd966ffcdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793186686-172.17.0.18-1597520045399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35261,DS-619603bb-62e1-45a3-9abd-4afdd3dec190,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-b33200ae-3980-4b7d-bc6f-1d6c0df69f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-200ed3e7-0680-4be4-ae3e-618139da69ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-268fd3f8-e91d-4b02-8f10-cb4de708fe88,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-124fdf3f-1120-46fc-9075-c3b5b2eff47e,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-299db028-0046-4e56-bb1f-22f86c9e405a,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-5c047452-2140-4208-9763-4f610d4bdc04,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-9515b102-d260-4176-b564-ecbd966ffcdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257844926-172.17.0.18-1597520127594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-9af2f227-911c-4f43-bb95-718709b45d53,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-c93bcc75-2f80-4b16-93ae-bc4b8850d910,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-eb4b91e7-9044-4486-9578-e17b4aaf427d,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-9085e638-02f7-45e2-bc11-1215aef99bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-ba02078d-3a3e-49a8-82ea-b153f1dd0cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-13cc7bcf-9f01-4f7a-84d8-149bb1111f33,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-34bbafad-923c-4edd-8397-a7319daec348,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-c26c5e02-d43a-4a16-be21-16f90467c21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257844926-172.17.0.18-1597520127594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35462,DS-9af2f227-911c-4f43-bb95-718709b45d53,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-c93bcc75-2f80-4b16-93ae-bc4b8850d910,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-eb4b91e7-9044-4486-9578-e17b4aaf427d,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-9085e638-02f7-45e2-bc11-1215aef99bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-ba02078d-3a3e-49a8-82ea-b153f1dd0cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-13cc7bcf-9f01-4f7a-84d8-149bb1111f33,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-34bbafad-923c-4edd-8397-a7319daec348,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-c26c5e02-d43a-4a16-be21-16f90467c21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793727064-172.17.0.18-1597520419383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34554,DS-df3c928b-9a1b-4775-8c87-601c0b83d830,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-0bca5aba-ad48-4da6-aeba-cf86f8457da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-e8b378e1-0d64-474e-bfac-81c926a2aa21,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-3db96060-c951-4143-b1ce-2ebc505152ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-28577150-7733-4210-842c-c2959b265249,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-a5824d40-4df2-4cb8-9610-341cdc782dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-393fe081-b83d-4a36-a65a-ddaf76ae2134,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-a32dc349-70df-4600-82ed-f2036faf3170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793727064-172.17.0.18-1597520419383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34554,DS-df3c928b-9a1b-4775-8c87-601c0b83d830,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-0bca5aba-ad48-4da6-aeba-cf86f8457da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-e8b378e1-0d64-474e-bfac-81c926a2aa21,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-3db96060-c951-4143-b1ce-2ebc505152ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-28577150-7733-4210-842c-c2959b265249,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-a5824d40-4df2-4cb8-9610-341cdc782dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-393fe081-b83d-4a36-a65a-ddaf76ae2134,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-a32dc349-70df-4600-82ed-f2036faf3170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596259864-172.17.0.18-1597520449254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-e0c635e8-d0c3-47c0-92f4-5cb66de256d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-966a4bec-0e4c-4dbb-b881-ff34ae13b333,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-4b7f5069-3505-48a9-bb50-ce23662866c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-9ecaa65f-421f-4ddd-8bf1-515e294fcd64,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-06858f1a-14ee-4aff-8658-263a0d7c313c,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-725979f3-41ff-48c1-ba0c-e0423a099e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-aa8bc37b-99d0-4884-96aa-c40fd129d15d,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-d667361f-baf1-4690-9087-204cb4c6b954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596259864-172.17.0.18-1597520449254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-e0c635e8-d0c3-47c0-92f4-5cb66de256d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-966a4bec-0e4c-4dbb-b881-ff34ae13b333,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-4b7f5069-3505-48a9-bb50-ce23662866c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-9ecaa65f-421f-4ddd-8bf1-515e294fcd64,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-06858f1a-14ee-4aff-8658-263a0d7c313c,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-725979f3-41ff-48c1-ba0c-e0423a099e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-aa8bc37b-99d0-4884-96aa-c40fd129d15d,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-d667361f-baf1-4690-9087-204cb4c6b954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284497923-172.17.0.18-1597520814090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40864,DS-13d443d1-7646-42cb-82e8-a30115adf696,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-6b042213-ef6d-4e13-8d25-e4bc09e4d2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-c3e17c91-cd74-4285-bc41-e1b771e9e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-96d30399-0c22-4363-a356-8da9f53b5b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-cae52796-b9ae-4bb5-b08b-49b90ef57a45,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-653e501a-c0d3-4ac7-b7fe-830496ff9981,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-6c83892e-e433-472a-bd8a-66cb4a60ade0,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-d21a9d17-ebb4-4bf4-92b5-4f6c1d7c9fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284497923-172.17.0.18-1597520814090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40864,DS-13d443d1-7646-42cb-82e8-a30115adf696,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-6b042213-ef6d-4e13-8d25-e4bc09e4d2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-c3e17c91-cd74-4285-bc41-e1b771e9e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-96d30399-0c22-4363-a356-8da9f53b5b58,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-cae52796-b9ae-4bb5-b08b-49b90ef57a45,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-653e501a-c0d3-4ac7-b7fe-830496ff9981,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-6c83892e-e433-472a-bd8a-66cb4a60ade0,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-d21a9d17-ebb4-4bf4-92b5-4f6c1d7c9fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697101226-172.17.0.18-1597521126557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-d9526ce0-d206-439c-bd21-14b5f3ea14b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-38ab586b-7cb9-4ffa-8dcb-d89f5054e08a,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-f125adb4-e6a3-4ef3-8be2-c790da9396f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-6c9282f8-474d-4187-991e-2d1b3f8c75a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-3ca560f4-a9aa-4f9a-95d4-e85b31c79680,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-5392ab72-8bb1-43bb-8824-532ea72ac06c,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-dc8fbff3-1003-4605-aaa7-4c8fa6a75a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-ad64b85d-e043-4209-bb50-c4c71b24b3c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697101226-172.17.0.18-1597521126557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-d9526ce0-d206-439c-bd21-14b5f3ea14b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-38ab586b-7cb9-4ffa-8dcb-d89f5054e08a,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-f125adb4-e6a3-4ef3-8be2-c790da9396f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-6c9282f8-474d-4187-991e-2d1b3f8c75a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-3ca560f4-a9aa-4f9a-95d4-e85b31c79680,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-5392ab72-8bb1-43bb-8824-532ea72ac06c,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-dc8fbff3-1003-4605-aaa7-4c8fa6a75a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-ad64b85d-e043-4209-bb50-c4c71b24b3c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376152280-172.17.0.18-1597521162441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41355,DS-4fb41fd9-152b-4c65-8935-43f0d85c8ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-9b523010-6a2d-4772-a6a6-c2ea1f4f52e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ace7f9f4-2a77-4464-916c-a337574d885c,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-bc6d095b-0d35-44a8-8af3-9ef5e2137f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-430963b7-df0e-4690-a2d9-1c407e3dbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-136d9426-1a11-41dc-a875-8c7b5809a8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-ecc4be9d-d20b-4914-a3fe-56fecf2fd710,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a3247f73-6b2b-4e45-b989-7235eba9c748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376152280-172.17.0.18-1597521162441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41355,DS-4fb41fd9-152b-4c65-8935-43f0d85c8ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-9b523010-6a2d-4772-a6a6-c2ea1f4f52e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ace7f9f4-2a77-4464-916c-a337574d885c,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-bc6d095b-0d35-44a8-8af3-9ef5e2137f67,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-430963b7-df0e-4690-a2d9-1c407e3dbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-136d9426-1a11-41dc-a875-8c7b5809a8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-ecc4be9d-d20b-4914-a3fe-56fecf2fd710,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a3247f73-6b2b-4e45-b989-7235eba9c748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43968862-172.17.0.18-1597521305543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39622,DS-a3e58ae0-4bf1-4112-998d-ee4a87043007,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-141e69db-7e7f-4c7f-8322-8e67a686bdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-30390436-3d57-4bd0-a544-fd1df26e4362,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-0f1a7b10-ab0d-4c61-824e-ba54da03064c,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-35e00b72-81eb-4444-8587-b4b23ccd139d,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-3153e691-7185-43a6-8003-abe1c74ba05b,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-58bbb50a-3d15-42d9-b3f8-8f73f2166bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-ef32c410-a44b-4755-ad6f-960037861b17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43968862-172.17.0.18-1597521305543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39622,DS-a3e58ae0-4bf1-4112-998d-ee4a87043007,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-141e69db-7e7f-4c7f-8322-8e67a686bdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-30390436-3d57-4bd0-a544-fd1df26e4362,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-0f1a7b10-ab0d-4c61-824e-ba54da03064c,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-35e00b72-81eb-4444-8587-b4b23ccd139d,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-3153e691-7185-43a6-8003-abe1c74ba05b,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-58bbb50a-3d15-42d9-b3f8-8f73f2166bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-ef32c410-a44b-4755-ad6f-960037861b17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008223122-172.17.0.18-1597521616683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-789ee190-88f7-43f5-a600-949049a35616,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-27f61f6b-a29c-460d-a0d9-b3149691c9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-c7e3dafa-0f58-42b9-b500-b38ea664f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-8980c60d-db7f-4310-b6b4-138b3eb42fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-f2742fed-b9fd-4c98-8b9b-4fcb2c900065,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-02b315f5-cb2f-47a7-9321-fa3d8e1b3dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-9c1c808a-474d-4d5c-a12f-dbdbcd502ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-734154c4-0bd0-417e-afbd-50831e36c89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008223122-172.17.0.18-1597521616683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-789ee190-88f7-43f5-a600-949049a35616,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-27f61f6b-a29c-460d-a0d9-b3149691c9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-c7e3dafa-0f58-42b9-b500-b38ea664f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-8980c60d-db7f-4310-b6b4-138b3eb42fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-f2742fed-b9fd-4c98-8b9b-4fcb2c900065,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-02b315f5-cb2f-47a7-9321-fa3d8e1b3dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-9c1c808a-474d-4d5c-a12f-dbdbcd502ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-734154c4-0bd0-417e-afbd-50831e36c89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990422069-172.17.0.18-1597521729873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-ce2f532d-473e-4328-ab44-626de3c0adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-5bb4e237-f9ee-41f2-ac11-b8afe6d7530f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-322314c5-1307-4d19-991b-1adba1fd4e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a8412cbb-bcc5-4d68-8b11-553d6e6ea044,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-3eb34c62-a9d2-4e15-ae7d-8a0c945f85a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-7432633c-1af6-4154-bd22-bb02e25b4220,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-68a3a75b-087f-401c-8036-857a6ad6d776,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-69ae3e8e-a781-4dd7-8001-59905befe686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990422069-172.17.0.18-1597521729873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-ce2f532d-473e-4328-ab44-626de3c0adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-5bb4e237-f9ee-41f2-ac11-b8afe6d7530f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-322314c5-1307-4d19-991b-1adba1fd4e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-a8412cbb-bcc5-4d68-8b11-553d6e6ea044,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-3eb34c62-a9d2-4e15-ae7d-8a0c945f85a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-7432633c-1af6-4154-bd22-bb02e25b4220,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-68a3a75b-087f-401c-8036-857a6ad6d776,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-69ae3e8e-a781-4dd7-8001-59905befe686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617321845-172.17.0.18-1597521893037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43701,DS-e04da7df-93b3-49af-9e8d-04b691f111ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-b08aa83d-a172-4e8c-a973-ed013a8369fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-d3a45283-5632-493b-bab0-92b5cb22d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-ae7d2fd1-9c20-4845-9672-328f89172b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-ae6f1150-37a8-4aaf-bf3f-daa4f32312a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-bb21c2af-4e9d-4fb2-802a-7f1cd8a4293a,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-1c45c1ea-f78e-40af-811e-15377a8cbbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-ca61d877-36d2-441e-874b-f4e4204f0e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617321845-172.17.0.18-1597521893037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43701,DS-e04da7df-93b3-49af-9e8d-04b691f111ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-b08aa83d-a172-4e8c-a973-ed013a8369fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-d3a45283-5632-493b-bab0-92b5cb22d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-ae7d2fd1-9c20-4845-9672-328f89172b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-ae6f1150-37a8-4aaf-bf3f-daa4f32312a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-bb21c2af-4e9d-4fb2-802a-7f1cd8a4293a,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-1c45c1ea-f78e-40af-811e-15377a8cbbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-ca61d877-36d2-441e-874b-f4e4204f0e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764765741-172.17.0.18-1597522031315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39536,DS-8a54d5b5-b2c0-4d16-9800-c27497378efc,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-8bb15019-d96b-4f38-a291-6fa96ab5c63c,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-0b761dc0-5aac-408f-8239-1804d66674e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-4133897a-4487-4080-ad4c-a4bfd931b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-567702c3-5ba6-4ccd-b93f-c0ecc91b2f36,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-5c4de9a6-01a1-4ecd-ba5c-9f2dd2359ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-e424b8f2-1f0f-44c4-b1f6-0e218686df9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-07d56fe3-2a1b-4706-a417-b8020530e5ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764765741-172.17.0.18-1597522031315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39536,DS-8a54d5b5-b2c0-4d16-9800-c27497378efc,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-8bb15019-d96b-4f38-a291-6fa96ab5c63c,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-0b761dc0-5aac-408f-8239-1804d66674e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-4133897a-4487-4080-ad4c-a4bfd931b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-567702c3-5ba6-4ccd-b93f-c0ecc91b2f36,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-5c4de9a6-01a1-4ecd-ba5c-9f2dd2359ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-e424b8f2-1f0f-44c4-b1f6-0e218686df9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-07d56fe3-2a1b-4706-a417-b8020530e5ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963418617-172.17.0.18-1597522471341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-fb8bb02d-6c57-4dc8-b4aa-7bceea1f379b,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-531d22dc-628a-4c12-9515-adb68f5ab3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-abae7ac1-4247-40fe-a10c-45907caea08d,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-55d04692-5771-4a83-8f2d-3831daed4008,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-0a88d7aa-92eb-468f-93df-0582978a10a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-a97b5215-3d3b-4e2a-a6ca-2d526284fd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-7020b971-0f24-4bd5-ab40-4c958b6a67fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-2219a928-3a78-45b0-9def-f9297975fa0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963418617-172.17.0.18-1597522471341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-fb8bb02d-6c57-4dc8-b4aa-7bceea1f379b,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-531d22dc-628a-4c12-9515-adb68f5ab3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-abae7ac1-4247-40fe-a10c-45907caea08d,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-55d04692-5771-4a83-8f2d-3831daed4008,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-0a88d7aa-92eb-468f-93df-0582978a10a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-a97b5215-3d3b-4e2a-a6ca-2d526284fd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-7020b971-0f24-4bd5-ab40-4c958b6a67fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-2219a928-3a78-45b0-9def-f9297975fa0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881742781-172.17.0.18-1597522793160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-d9227b02-7fc7-4d83-b3de-bc3721585a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-f394db56-9199-4d8b-9b73-1f2b99dea348,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-e97386bb-bb7d-4412-8d7a-553bc1cf7954,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-4f77f13f-a4c4-433d-ae46-29a68a0efa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-07e5bfea-2b6d-48fa-9e80-de4e9688244e,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-f9e3c4a0-f0fe-4100-8777-8c460d01d492,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-d24097e3-766b-4ca4-b4be-a5a8bda2c8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-24f23353-2ea8-401c-b0a1-fa82075d7829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881742781-172.17.0.18-1597522793160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-d9227b02-7fc7-4d83-b3de-bc3721585a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-f394db56-9199-4d8b-9b73-1f2b99dea348,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-e97386bb-bb7d-4412-8d7a-553bc1cf7954,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-4f77f13f-a4c4-433d-ae46-29a68a0efa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-07e5bfea-2b6d-48fa-9e80-de4e9688244e,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-f9e3c4a0-f0fe-4100-8777-8c460d01d492,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-d24097e3-766b-4ca4-b4be-a5a8bda2c8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-24f23353-2ea8-401c-b0a1-fa82075d7829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192278844-172.17.0.18-1597522951363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46730,DS-437246ce-530a-4b2d-95d7-6e8029d9209b,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-24544686-a78b-4036-87f3-461c35a4fd77,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-ea81e0a0-db74-4f02-9698-063fde6b06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-cb8dfb67-1831-424d-a1e4-bc79d95e1106,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-ebda82d3-8cfe-406f-b732-4a61777aff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-69940107-fc60-478b-b1a7-a936200e7506,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-28129b6b-ddcd-4ddd-b6dc-09243f39e6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-3b8fba50-ce10-4093-b3a2-557af7a4925b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192278844-172.17.0.18-1597522951363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46730,DS-437246ce-530a-4b2d-95d7-6e8029d9209b,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-24544686-a78b-4036-87f3-461c35a4fd77,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-ea81e0a0-db74-4f02-9698-063fde6b06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-cb8dfb67-1831-424d-a1e4-bc79d95e1106,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-ebda82d3-8cfe-406f-b732-4a61777aff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-69940107-fc60-478b-b1a7-a936200e7506,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-28129b6b-ddcd-4ddd-b6dc-09243f39e6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-3b8fba50-ce10-4093-b3a2-557af7a4925b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759091026-172.17.0.18-1597523033630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-f0fcbacc-8bce-449d-aefd-68eb48a428c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-a06c9323-c815-46d2-95f7-337afa13de5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-48bbdc76-0931-4600-9408-5010c9bfbbae,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-67491b74-8276-480d-a754-c40c8ea8c347,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-f238da12-302b-4e08-96d1-e940125e66da,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-e7294c1e-408b-4d78-9841-82663d34d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-6d1b675e-2cae-4732-99f2-bf790479ad6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-774b80af-1fa3-42b8-9b51-3cbe1f7b7d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759091026-172.17.0.18-1597523033630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-f0fcbacc-8bce-449d-aefd-68eb48a428c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-a06c9323-c815-46d2-95f7-337afa13de5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-48bbdc76-0931-4600-9408-5010c9bfbbae,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-67491b74-8276-480d-a754-c40c8ea8c347,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-f238da12-302b-4e08-96d1-e940125e66da,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-e7294c1e-408b-4d78-9841-82663d34d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-6d1b675e-2cae-4732-99f2-bf790479ad6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-774b80af-1fa3-42b8-9b51-3cbe1f7b7d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476516393-172.17.0.18-1597523431142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-8b421fb4-5ea6-4747-a152-bfbe3fdb4da4,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-e98ea140-5696-4459-bebe-a1db5cbd07d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-1ead0f2a-c486-4c6e-bad0-2baf76c5dae2,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-8954211a-36e8-46ae-a3ef-6f19cf3bd99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-32a8c615-50da-4bab-9a8e-8ca1f0cc9663,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-a63ee437-e5ce-411f-9c4b-7335f38127e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-9d7b35ba-1d6b-4f5a-9b81-660e4f579e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-4e0c7a91-346d-4e33-b896-145d0c709059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476516393-172.17.0.18-1597523431142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32943,DS-8b421fb4-5ea6-4747-a152-bfbe3fdb4da4,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-e98ea140-5696-4459-bebe-a1db5cbd07d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-1ead0f2a-c486-4c6e-bad0-2baf76c5dae2,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-8954211a-36e8-46ae-a3ef-6f19cf3bd99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-32a8c615-50da-4bab-9a8e-8ca1f0cc9663,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-a63ee437-e5ce-411f-9c4b-7335f38127e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-9d7b35ba-1d6b-4f5a-9b81-660e4f579e62,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-4e0c7a91-346d-4e33-b896-145d0c709059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638639499-172.17.0.18-1597523666773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37568,DS-47ff420c-cc92-4cd6-b2c2-7adedcef8aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-95dddb0e-d801-40f6-826c-d390f0ef133d,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-9ab9c907-7c21-4f32-a13a-12a7be8620e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c8dbb1eb-cc5c-4669-a92f-e7e87af164d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-088ad391-e67f-482c-a0f2-935263fe9517,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-9c67d2cc-4483-4b5f-9930-abc3585bcd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-d2b11ad5-5bd6-44e8-923d-09f5ef380bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-4fe3a816-ace9-46a5-b598-7712c79fba09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638639499-172.17.0.18-1597523666773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37568,DS-47ff420c-cc92-4cd6-b2c2-7adedcef8aac,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-95dddb0e-d801-40f6-826c-d390f0ef133d,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-9ab9c907-7c21-4f32-a13a-12a7be8620e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-c8dbb1eb-cc5c-4669-a92f-e7e87af164d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-088ad391-e67f-482c-a0f2-935263fe9517,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-9c67d2cc-4483-4b5f-9930-abc3585bcd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-d2b11ad5-5bd6-44e8-923d-09f5ef380bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-4fe3a816-ace9-46a5-b598-7712c79fba09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 30
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400847775-172.17.0.18-1597523700484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40502,DS-fc95426f-fdff-443a-ae23-e8096cc5e912,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-4e4926a4-6fa6-438e-bd01-09ab435032b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-3398b4c2-138b-4309-8d1c-0fcc13a401ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-e0b39ca6-ca92-4009-b5f0-edfd4d2ade13,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-69e811ad-8927-4e39-abbe-6b7041d16fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-b779eae5-4a8a-4c66-a332-e295e9f6e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-ccc332a1-ae38-405c-b433-adcd9f0a0bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-e3c43a13-e688-411d-8be1-c030e8424061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400847775-172.17.0.18-1597523700484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40502,DS-fc95426f-fdff-443a-ae23-e8096cc5e912,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-4e4926a4-6fa6-438e-bd01-09ab435032b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-3398b4c2-138b-4309-8d1c-0fcc13a401ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-e0b39ca6-ca92-4009-b5f0-edfd4d2ade13,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-69e811ad-8927-4e39-abbe-6b7041d16fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-b779eae5-4a8a-4c66-a332-e295e9f6e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-ccc332a1-ae38-405c-b433-adcd9f0a0bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-e3c43a13-e688-411d-8be1-c030e8424061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5499
