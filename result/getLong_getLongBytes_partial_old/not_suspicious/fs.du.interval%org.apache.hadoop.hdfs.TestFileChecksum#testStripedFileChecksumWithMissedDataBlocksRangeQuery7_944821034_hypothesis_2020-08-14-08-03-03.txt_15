reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884293678-172.17.0.17-1597392422481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-7afd534f-f718-4e39-a1e2-6a5e0b98f4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-9cf810ba-3567-43b2-9230-4760f054b56e,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-15540c5f-15f8-4835-ae08-20de115f9d28,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-8566cba9-5421-4854-94ca-58b4f957187f,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-2edbd99a-edfe-422a-87d7-aab4ab9014f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-0634345f-742b-4373-a334-abf7dc2bd090,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-cba987cf-4a49-46c4-bdef-803f9ae0567e,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-aa283bdc-cfd6-4e13-8121-3eebffcb7dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884293678-172.17.0.17-1597392422481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-7afd534f-f718-4e39-a1e2-6a5e0b98f4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-9cf810ba-3567-43b2-9230-4760f054b56e,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-15540c5f-15f8-4835-ae08-20de115f9d28,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-8566cba9-5421-4854-94ca-58b4f957187f,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-2edbd99a-edfe-422a-87d7-aab4ab9014f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-0634345f-742b-4373-a334-abf7dc2bd090,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-cba987cf-4a49-46c4-bdef-803f9ae0567e,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-aa283bdc-cfd6-4e13-8121-3eebffcb7dd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755141488-172.17.0.17-1597392461434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-8a8e7f27-2e0d-4b44-b205-758ee519c45c,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-dc6a1167-e837-4a53-a49c-3b9e31f1b693,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-f15e3d17-8e8b-4f1e-8336-ae3a00de19b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-12323895-5215-406a-8500-967c1c25678e,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-7d9b1445-997d-4c3a-b20e-f86e377097e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-d24af29a-7453-41c6-aa1b-ac1072ccf226,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-471c3773-66c9-47ce-87c1-ff15e1cb2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-003f81d7-9433-4748-ba9a-2dcf6909f66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755141488-172.17.0.17-1597392461434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-8a8e7f27-2e0d-4b44-b205-758ee519c45c,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-dc6a1167-e837-4a53-a49c-3b9e31f1b693,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-f15e3d17-8e8b-4f1e-8336-ae3a00de19b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-12323895-5215-406a-8500-967c1c25678e,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-7d9b1445-997d-4c3a-b20e-f86e377097e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-d24af29a-7453-41c6-aa1b-ac1072ccf226,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-471c3773-66c9-47ce-87c1-ff15e1cb2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-003f81d7-9433-4748-ba9a-2dcf6909f66b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030375686-172.17.0.17-1597392910039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35347,DS-b7f13744-1796-4fcd-b429-570437ec3780,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-7e25dc84-49a1-438e-84e0-266895383942,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-dd4872b8-4b54-4c63-8af7-adc9deed1828,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-e4d3dd75-70d6-412c-874f-bb83433d7b75,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-2f9ba272-aecb-4f18-80f8-868c18af9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-78f6026f-08fa-42bb-bdba-24a0994afa50,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-65b34657-2f45-4ec3-a961-8d8f4c3546cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-6266d1e9-aa22-46c4-a09c-25e698bb7e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030375686-172.17.0.17-1597392910039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35347,DS-b7f13744-1796-4fcd-b429-570437ec3780,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-7e25dc84-49a1-438e-84e0-266895383942,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-dd4872b8-4b54-4c63-8af7-adc9deed1828,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-e4d3dd75-70d6-412c-874f-bb83433d7b75,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-2f9ba272-aecb-4f18-80f8-868c18af9a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-78f6026f-08fa-42bb-bdba-24a0994afa50,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-65b34657-2f45-4ec3-a961-8d8f4c3546cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-6266d1e9-aa22-46c4-a09c-25e698bb7e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552503984-172.17.0.17-1597393007566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-b3a52e40-a80b-46aa-aae6-04bd6078119d,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-6a84715e-5085-42cc-9dbc-8b467d3bc21a,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-1e9492c8-ce1d-48e6-9796-936d8c78a986,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-175c0af8-9e19-44a2-926e-9afa8977844e,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-944c8322-e20e-47ea-b09a-00cd7a6df305,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-5c2ba719-a344-4547-8ca8-45aae2d8705e,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-a45069ea-8ad4-4a59-8d9b-1afcf28ef22d,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-0768a4af-a781-4057-ab20-848c0d506364,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552503984-172.17.0.17-1597393007566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-b3a52e40-a80b-46aa-aae6-04bd6078119d,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-6a84715e-5085-42cc-9dbc-8b467d3bc21a,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-1e9492c8-ce1d-48e6-9796-936d8c78a986,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-175c0af8-9e19-44a2-926e-9afa8977844e,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-944c8322-e20e-47ea-b09a-00cd7a6df305,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-5c2ba719-a344-4547-8ca8-45aae2d8705e,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-a45069ea-8ad4-4a59-8d9b-1afcf28ef22d,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-0768a4af-a781-4057-ab20-848c0d506364,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153384061-172.17.0.17-1597393148903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33485,DS-f33e5c81-0084-4cf8-96e5-28a81b11248b,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-bb32d375-1f0d-442f-a6aa-ce6a78b5982b,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-1815bee4-624c-480b-84d9-455cbf706dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-6e0eba3e-ac1e-4535-a023-4274869e23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-49f93d0c-5dd2-4cb4-9c10-860ac7f7e496,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-974dfc9a-40b0-4127-b32f-4ca89fb078ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-3edc7228-b8e2-48f3-9fdc-3368165c4e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-0d0fc3d1-4bd2-4ef2-81e4-e2d6eee0c1f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153384061-172.17.0.17-1597393148903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33485,DS-f33e5c81-0084-4cf8-96e5-28a81b11248b,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-bb32d375-1f0d-442f-a6aa-ce6a78b5982b,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-1815bee4-624c-480b-84d9-455cbf706dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-6e0eba3e-ac1e-4535-a023-4274869e23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-49f93d0c-5dd2-4cb4-9c10-860ac7f7e496,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-974dfc9a-40b0-4127-b32f-4ca89fb078ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-3edc7228-b8e2-48f3-9fdc-3368165c4e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-0d0fc3d1-4bd2-4ef2-81e4-e2d6eee0c1f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681282264-172.17.0.17-1597393262034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-87106370-63ea-4d0a-9d17-ae666b168c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-d38c2270-0643-4bfe-9cdd-0975f81d3f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-5ab3420f-40bc-4e2b-9f29-4412b83055dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-230f7a5d-2918-46a6-afae-0029c0fc445d,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-925cbc42-2c79-479d-b31a-74199cfcfb60,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-6fae97b0-bc3e-4344-834e-c1aa2252863b,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-b3ac791c-3ce3-4ca4-86f2-7f1079d18235,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-ce4d5291-599f-4d90-9221-e2497a480a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681282264-172.17.0.17-1597393262034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-87106370-63ea-4d0a-9d17-ae666b168c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-d38c2270-0643-4bfe-9cdd-0975f81d3f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-5ab3420f-40bc-4e2b-9f29-4412b83055dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-230f7a5d-2918-46a6-afae-0029c0fc445d,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-925cbc42-2c79-479d-b31a-74199cfcfb60,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-6fae97b0-bc3e-4344-834e-c1aa2252863b,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-b3ac791c-3ce3-4ca4-86f2-7f1079d18235,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-ce4d5291-599f-4d90-9221-e2497a480a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750638561-172.17.0.17-1597393490371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39213,DS-b7ea9500-1058-4edd-b4ee-b76dbf20c4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-54d4fa59-452a-47f9-80cc-f0ceed9a2275,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-0e571fb4-a74e-4699-81aa-92c90d9ac97b,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-7184a379-305b-4c22-bd1c-689d19837ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-bd945f33-026c-48ce-8b7a-9723d12d4c43,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-fc6c8235-1e13-4adb-a137-5e5b95c6559d,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-3a075858-836b-4ed4-ace5-2aa594d18dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-6f6667f0-212d-4621-8e4d-0a14bcc6f08b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750638561-172.17.0.17-1597393490371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39213,DS-b7ea9500-1058-4edd-b4ee-b76dbf20c4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-54d4fa59-452a-47f9-80cc-f0ceed9a2275,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-0e571fb4-a74e-4699-81aa-92c90d9ac97b,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-7184a379-305b-4c22-bd1c-689d19837ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-bd945f33-026c-48ce-8b7a-9723d12d4c43,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-fc6c8235-1e13-4adb-a137-5e5b95c6559d,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-3a075858-836b-4ed4-ace5-2aa594d18dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-6f6667f0-212d-4621-8e4d-0a14bcc6f08b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933734310-172.17.0.17-1597393523415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39169,DS-d24d300a-5d1f-45c5-819b-4f536d89b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-3cca436a-fbd3-4e15-b27d-dba3ea9e3802,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-fec7ad7f-7303-4a9e-927d-61194b9757bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-5c8deb7c-3fdc-44ab-a1a8-39ae22ca5759,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-42e7b2e7-2ad0-4276-945b-d0f5e2f9e06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-970cd673-3e22-483e-9f74-570bd9b477ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-50376335-944f-4103-ae4f-3c02a0c49656,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-a4053f29-1ea8-4680-aeb8-401818b8f9c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933734310-172.17.0.17-1597393523415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39169,DS-d24d300a-5d1f-45c5-819b-4f536d89b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-3cca436a-fbd3-4e15-b27d-dba3ea9e3802,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-fec7ad7f-7303-4a9e-927d-61194b9757bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-5c8deb7c-3fdc-44ab-a1a8-39ae22ca5759,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-42e7b2e7-2ad0-4276-945b-d0f5e2f9e06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-970cd673-3e22-483e-9f74-570bd9b477ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-50376335-944f-4103-ae4f-3c02a0c49656,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-a4053f29-1ea8-4680-aeb8-401818b8f9c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338455910-172.17.0.17-1597394196686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36508,DS-bc9fb21a-0fb1-4bfe-9e7d-a3fd58bd4331,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-16f05890-730b-4b6f-bc34-4cbc58ddb39e,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-485ed1d2-512b-421d-8dd9-4fda73f8424d,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-cb28780b-4312-4b98-82d8-82f7b7d623c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-a2b15bb8-3098-446b-aae5-a0683b3bd595,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-533368d0-6124-4596-9345-b2fac142617f,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-9fbdfb6f-ae59-4e7f-8390-51d7a94e53fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-dfc6cb79-cd52-42ff-a4fd-0c183cde2fa7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338455910-172.17.0.17-1597394196686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36508,DS-bc9fb21a-0fb1-4bfe-9e7d-a3fd58bd4331,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-16f05890-730b-4b6f-bc34-4cbc58ddb39e,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-485ed1d2-512b-421d-8dd9-4fda73f8424d,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-cb28780b-4312-4b98-82d8-82f7b7d623c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-a2b15bb8-3098-446b-aae5-a0683b3bd595,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-533368d0-6124-4596-9345-b2fac142617f,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-9fbdfb6f-ae59-4e7f-8390-51d7a94e53fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-dfc6cb79-cd52-42ff-a4fd-0c183cde2fa7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461816418-172.17.0.17-1597394320027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33700,DS-d617200a-c628-4e28-b438-9e92d7fb30ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-f3f0b2ec-44b9-438a-9344-69512a7cbcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-290e39df-5c27-494c-a48c-9c558fec2c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-e79a58aa-ac52-410b-b9c0-086ca0522ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-02edf6de-a7e2-40a2-8ca3-32f69f53ea34,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-1cf78726-b98a-4503-afa4-c3223858ee57,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-ac3d837a-403a-45a4-91d4-bd75e54f15e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-215e1dcd-9e64-4fa5-8209-240ece6e0e86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461816418-172.17.0.17-1597394320027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33700,DS-d617200a-c628-4e28-b438-9e92d7fb30ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-f3f0b2ec-44b9-438a-9344-69512a7cbcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-290e39df-5c27-494c-a48c-9c558fec2c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-e79a58aa-ac52-410b-b9c0-086ca0522ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-02edf6de-a7e2-40a2-8ca3-32f69f53ea34,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-1cf78726-b98a-4503-afa4-c3223858ee57,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-ac3d837a-403a-45a4-91d4-bd75e54f15e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-215e1dcd-9e64-4fa5-8209-240ece6e0e86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465512090-172.17.0.17-1597394399567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-bd392918-0dff-4f1e-b4c1-c79768b10eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-2f6862c5-daf7-40bb-bdcd-51cc49c93472,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-aec0b5c9-9bad-4954-ab96-9a5d535768ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-c2894aa9-14d5-4adc-8e4c-7f36ae9d86e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-4f566981-d068-4b25-a48c-9148299bda45,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-7c77375a-69cd-45a9-b628-abe5ef301aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-027dac0c-d681-4f63-89a2-694d96fdade1,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-9896d189-52bd-4d5b-98cb-8c69062487d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465512090-172.17.0.17-1597394399567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-bd392918-0dff-4f1e-b4c1-c79768b10eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-2f6862c5-daf7-40bb-bdcd-51cc49c93472,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-aec0b5c9-9bad-4954-ab96-9a5d535768ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-c2894aa9-14d5-4adc-8e4c-7f36ae9d86e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-4f566981-d068-4b25-a48c-9148299bda45,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-7c77375a-69cd-45a9-b628-abe5ef301aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-027dac0c-d681-4f63-89a2-694d96fdade1,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-9896d189-52bd-4d5b-98cb-8c69062487d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108631849-172.17.0.17-1597394634693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-dfc3eb5e-4b82-4e0d-99d1-823507e242cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-9e46eced-025d-42a5-9ea7-95ca7bd43eea,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-87228e8b-30c5-40ad-a642-b090b7656f65,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-9c8fc370-4e7f-4b9b-a860-b3365a2efad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-6a7979c7-64b3-4251-bf1c-1601714d9e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-11732310-eeb8-42d4-8bd8-fbcec688d437,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-46ff6942-4b98-41a1-be7b-d7e7128f7028,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-aae9b496-c457-47e8-b3ef-f7ba13813f95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108631849-172.17.0.17-1597394634693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41548,DS-dfc3eb5e-4b82-4e0d-99d1-823507e242cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-9e46eced-025d-42a5-9ea7-95ca7bd43eea,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-87228e8b-30c5-40ad-a642-b090b7656f65,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-9c8fc370-4e7f-4b9b-a860-b3365a2efad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-6a7979c7-64b3-4251-bf1c-1601714d9e96,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-11732310-eeb8-42d4-8bd8-fbcec688d437,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-46ff6942-4b98-41a1-be7b-d7e7128f7028,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-aae9b496-c457-47e8-b3ef-f7ba13813f95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048011116-172.17.0.17-1597394675953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-72bbfb46-8326-4a69-a84f-bd4bbcbccda6,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-e07068bd-c683-452b-9057-7100d2951e49,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-2e74761a-7e72-4a99-bef7-7be0d1d1d30e,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-56869d61-79ef-42f7-91ea-87bd8618199e,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-879fd8b0-e10c-4548-8458-432e8f3a40c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-3d94b8ac-cf48-4838-9a0f-7334b6ddb89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-1eca8589-95ff-43c1-901b-d306c9aee266,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-a0a9171b-df46-4dd5-b32f-f9e153a44562,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048011116-172.17.0.17-1597394675953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-72bbfb46-8326-4a69-a84f-bd4bbcbccda6,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-e07068bd-c683-452b-9057-7100d2951e49,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-2e74761a-7e72-4a99-bef7-7be0d1d1d30e,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-56869d61-79ef-42f7-91ea-87bd8618199e,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-879fd8b0-e10c-4548-8458-432e8f3a40c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-3d94b8ac-cf48-4838-9a0f-7334b6ddb89d,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-1eca8589-95ff-43c1-901b-d306c9aee266,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-a0a9171b-df46-4dd5-b32f-f9e153a44562,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553349154-172.17.0.17-1597394925355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36115,DS-cb4f23e2-2351-4594-b391-feb9eb9dcb87,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-3007fb99-66fe-4b37-a63a-a237f298be70,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-985e7733-7dab-4440-9592-12f3982a8315,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-836ca478-9ae8-4cd1-a41d-3337fa0ee615,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-c388b9d5-9bb4-44b2-ab23-5108e4a54f73,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-d3f50491-919f-4948-8306-bb550875d5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-3c6928a2-ca94-49b6-ae53-a1380a2223de,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-61070e31-fc44-426c-b286-ff37de504cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553349154-172.17.0.17-1597394925355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36115,DS-cb4f23e2-2351-4594-b391-feb9eb9dcb87,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-3007fb99-66fe-4b37-a63a-a237f298be70,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-985e7733-7dab-4440-9592-12f3982a8315,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-836ca478-9ae8-4cd1-a41d-3337fa0ee615,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-c388b9d5-9bb4-44b2-ab23-5108e4a54f73,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-d3f50491-919f-4948-8306-bb550875d5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-3c6928a2-ca94-49b6-ae53-a1380a2223de,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-61070e31-fc44-426c-b286-ff37de504cdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531546840-172.17.0.17-1597395218862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37796,DS-23eb89a3-38e5-4b0f-84ac-27479d0da07e,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-2ad80151-2850-4fb1-b266-6810f93a3d20,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-02ba25a9-cdf2-4705-8d15-b0be0b60f6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-42d634a8-0f32-4704-aa49-f7970f648cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-26f304a9-5475-4ab9-9a11-5ab72fc99984,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-b133fa55-bf00-40f9-af25-1c92a595ab21,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-d4d97a6a-fe04-4dfb-89fd-c85970a30279,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-b5e881c0-2631-48c6-b820-25315003fa74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531546840-172.17.0.17-1597395218862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37796,DS-23eb89a3-38e5-4b0f-84ac-27479d0da07e,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-2ad80151-2850-4fb1-b266-6810f93a3d20,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-02ba25a9-cdf2-4705-8d15-b0be0b60f6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-42d634a8-0f32-4704-aa49-f7970f648cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-26f304a9-5475-4ab9-9a11-5ab72fc99984,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-b133fa55-bf00-40f9-af25-1c92a595ab21,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-d4d97a6a-fe04-4dfb-89fd-c85970a30279,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-b5e881c0-2631-48c6-b820-25315003fa74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242800138-172.17.0.17-1597395253591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46134,DS-892f0e8d-4ab0-4646-9af0-71bdb2c28a90,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-902854fc-e225-4f5e-9e83-912131b211f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-c24e436e-a166-4a07-bc90-b0c9d71b7704,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-643ba191-c139-41f9-925d-9c57c04ddbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-4a4b1779-18bf-43a2-b901-62e6207ba5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-f448d403-2bae-4efb-827d-f9ce52edd2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-b4eb58f1-7f8f-4c86-a840-acfe06fbdb06,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-d9d2c2a8-dc20-48eb-928e-1b95cfdda8a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242800138-172.17.0.17-1597395253591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46134,DS-892f0e8d-4ab0-4646-9af0-71bdb2c28a90,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-902854fc-e225-4f5e-9e83-912131b211f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-c24e436e-a166-4a07-bc90-b0c9d71b7704,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-643ba191-c139-41f9-925d-9c57c04ddbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-4a4b1779-18bf-43a2-b901-62e6207ba5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-f448d403-2bae-4efb-827d-f9ce52edd2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-b4eb58f1-7f8f-4c86-a840-acfe06fbdb06,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-d9d2c2a8-dc20-48eb-928e-1b95cfdda8a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398806469-172.17.0.17-1597395431272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44128,DS-d8e293cd-2495-4cec-bcaa-0ca2063d0611,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-abb93e9f-c555-4888-a131-d092f047b9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-537662fc-7a97-4cdf-bf55-4b7e429ba92d,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-36a6d9d9-cf03-4af3-8fda-60188a6f31ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-11ebdc27-27ca-431b-a6a5-ea0dce3b3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-c759752c-f026-4ce2-9a39-d220382b8f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-1e96dbd4-479a-4fc7-b522-b03beb523949,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-f1c838f9-cb36-41ed-805d-bb82b5ebf0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398806469-172.17.0.17-1597395431272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44128,DS-d8e293cd-2495-4cec-bcaa-0ca2063d0611,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-abb93e9f-c555-4888-a131-d092f047b9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-537662fc-7a97-4cdf-bf55-4b7e429ba92d,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-36a6d9d9-cf03-4af3-8fda-60188a6f31ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-11ebdc27-27ca-431b-a6a5-ea0dce3b3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-c759752c-f026-4ce2-9a39-d220382b8f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-1e96dbd4-479a-4fc7-b522-b03beb523949,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-f1c838f9-cb36-41ed-805d-bb82b5ebf0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787093067-172.17.0.17-1597395505952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-67ad7453-d0b4-4bea-b2ea-aae917d7e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-30c95b77-9d99-4fe9-8558-a9c1ce546d50,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-e57b1ac8-ea4a-491d-9219-cdbe7e5e6176,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-e4bbb3f0-149c-4c39-b2a5-1b5607187b87,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-205450eb-2200-43e6-af67-b98b9e273a89,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-7fa805b3-e03e-4029-b420-85ddf5f5585c,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-6c5c7b73-0f3d-4dff-aecf-ba6c9465b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-8b5b5866-8257-4e27-9cf6-c6968d9eda0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787093067-172.17.0.17-1597395505952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43665,DS-67ad7453-d0b4-4bea-b2ea-aae917d7e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-30c95b77-9d99-4fe9-8558-a9c1ce546d50,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-e57b1ac8-ea4a-491d-9219-cdbe7e5e6176,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-e4bbb3f0-149c-4c39-b2a5-1b5607187b87,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-205450eb-2200-43e6-af67-b98b9e273a89,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-7fa805b3-e03e-4029-b420-85ddf5f5585c,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-6c5c7b73-0f3d-4dff-aecf-ba6c9465b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-8b5b5866-8257-4e27-9cf6-c6968d9eda0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649635369-172.17.0.17-1597395630850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-00a69313-3908-44ad-80cc-25551cf00006,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-d50d2d2f-9c36-4b66-acbb-fbc94fa70cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-dc3147bd-71cb-470e-b2f7-d11dd07e89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-6f497e3f-df17-4d94-8583-6e97809a4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-272827d1-9d94-4f6e-810e-e0d14469bb09,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-4f0f534a-3adb-4cdb-9cd4-41dfc6b8fc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-7a5d3b5b-3526-419f-8467-8896b4aac8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-a0fc8858-8f7b-441b-95d2-c3ca343c0daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649635369-172.17.0.17-1597395630850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-00a69313-3908-44ad-80cc-25551cf00006,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-d50d2d2f-9c36-4b66-acbb-fbc94fa70cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-dc3147bd-71cb-470e-b2f7-d11dd07e89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-6f497e3f-df17-4d94-8583-6e97809a4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-272827d1-9d94-4f6e-810e-e0d14469bb09,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-4f0f534a-3adb-4cdb-9cd4-41dfc6b8fc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-7a5d3b5b-3526-419f-8467-8896b4aac8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-a0fc8858-8f7b-441b-95d2-c3ca343c0daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50920717-172.17.0.17-1597395783846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-4361b6b6-b419-40b9-af4f-f427215ea5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-1235d9dc-5e5f-46a2-b45b-18d49ba2f726,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-5624a96c-bd31-42f9-963c-a94cf6bd81f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-33f09032-5189-46d1-86f9-187b496bc9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-eddbd6d2-7453-4a43-a4eb-55bbdaf2d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-8f039adb-53c9-44d4-88d5-59eaa0c4452d,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-4532190a-fe5c-4c6d-8375-fd16b4e80ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-9d6010c5-d85a-4bed-85d2-8d3d0adffaaa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50920717-172.17.0.17-1597395783846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-4361b6b6-b419-40b9-af4f-f427215ea5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-1235d9dc-5e5f-46a2-b45b-18d49ba2f726,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-5624a96c-bd31-42f9-963c-a94cf6bd81f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-33f09032-5189-46d1-86f9-187b496bc9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-eddbd6d2-7453-4a43-a4eb-55bbdaf2d81c,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-8f039adb-53c9-44d4-88d5-59eaa0c4452d,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-4532190a-fe5c-4c6d-8375-fd16b4e80ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-9d6010c5-d85a-4bed-85d2-8d3d0adffaaa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633064207-172.17.0.17-1597395926122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45744,DS-345293a8-3110-475f-a827-6123a8e73a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-ec38a9ba-7e98-49e2-a354-fb14bbc46241,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-c398d927-539a-4f88-9863-de92d0de53ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-4c1224fb-01e9-4a68-952e-17ddc33784b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-bc67b887-f454-4b45-be1d-e1d3f700d42c,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-9c47425c-b8de-4bee-8907-7ce6e7c229a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-085c1a74-d307-496f-84c2-0a84be139cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-cd527c46-1d64-43c3-85e7-a79ac10381f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633064207-172.17.0.17-1597395926122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45744,DS-345293a8-3110-475f-a827-6123a8e73a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-ec38a9ba-7e98-49e2-a354-fb14bbc46241,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-c398d927-539a-4f88-9863-de92d0de53ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-4c1224fb-01e9-4a68-952e-17ddc33784b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-bc67b887-f454-4b45-be1d-e1d3f700d42c,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-9c47425c-b8de-4bee-8907-7ce6e7c229a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-085c1a74-d307-496f-84c2-0a84be139cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-cd527c46-1d64-43c3-85e7-a79ac10381f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557430030-172.17.0.17-1597395968557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-f61dda92-3a9b-4246-b3b7-c48e65971ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-8f348f94-1b70-48f2-8249-c4acc602d605,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-ab469c7a-f40f-4625-afe3-b3152fcf47d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-c5242dd7-aa2a-4e5a-8a2a-897cd812082a,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-7c753489-d946-455d-966f-1a5c06b328f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4d9a356b-7881-4d51-b727-01dea08a6fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-32b3d61a-e10b-4258-a053-7a169b8d4a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-2a7aa662-6085-43c0-b652-7bc85944cf46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557430030-172.17.0.17-1597395968557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-f61dda92-3a9b-4246-b3b7-c48e65971ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-8f348f94-1b70-48f2-8249-c4acc602d605,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-ab469c7a-f40f-4625-afe3-b3152fcf47d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-c5242dd7-aa2a-4e5a-8a2a-897cd812082a,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-7c753489-d946-455d-966f-1a5c06b328f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4d9a356b-7881-4d51-b727-01dea08a6fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-32b3d61a-e10b-4258-a053-7a169b8d4a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-2a7aa662-6085-43c0-b652-7bc85944cf46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926792810-172.17.0.17-1597396266000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-6acaafec-5491-41d3-ac4c-f8939851f50b,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-9d7af9ff-bbd2-4c65-95b9-7e0f9bbd491c,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-09d523d4-1bea-4d05-a2d5-a47b604d9126,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-57bef60b-56b3-4cb7-a5d0-e62c66146706,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-f4fc1c6a-994a-4576-a8ba-7110e85918e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-6d6b96ff-5062-44fa-bcca-34696d7d8133,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-747b3db2-44a1-4b9f-bb03-66a0e9ea6a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-903efc98-4a6b-4e43-9ff9-c09fe889c30a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926792810-172.17.0.17-1597396266000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-6acaafec-5491-41d3-ac4c-f8939851f50b,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-9d7af9ff-bbd2-4c65-95b9-7e0f9bbd491c,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-09d523d4-1bea-4d05-a2d5-a47b604d9126,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-57bef60b-56b3-4cb7-a5d0-e62c66146706,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-f4fc1c6a-994a-4576-a8ba-7110e85918e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-6d6b96ff-5062-44fa-bcca-34696d7d8133,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-747b3db2-44a1-4b9f-bb03-66a0e9ea6a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-903efc98-4a6b-4e43-9ff9-c09fe889c30a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627692643-172.17.0.17-1597396347117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43498,DS-b39b27f7-de18-4f2d-9833-a014164b3031,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-49a86194-d4dc-4879-a546-b55f516bdd19,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-b1c6dcd6-b50d-4887-9d59-01d4b146057b,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-33d5b169-3dab-438c-87aa-6bdbbe7b00fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-acfb5164-8417-4f39-8231-74e3fc6b81c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-6f464534-7686-4211-af22-59cda2486282,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-7861504f-4ba8-4fcd-94d6-1738f51ba06e,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-6e97c223-1f7c-4502-9a6d-b7ace83baaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627692643-172.17.0.17-1597396347117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43498,DS-b39b27f7-de18-4f2d-9833-a014164b3031,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-49a86194-d4dc-4879-a546-b55f516bdd19,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-b1c6dcd6-b50d-4887-9d59-01d4b146057b,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-33d5b169-3dab-438c-87aa-6bdbbe7b00fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-acfb5164-8417-4f39-8231-74e3fc6b81c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-6f464534-7686-4211-af22-59cda2486282,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-7861504f-4ba8-4fcd-94d6-1738f51ba06e,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-6e97c223-1f7c-4502-9a6d-b7ace83baaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497501-172.17.0.17-1597396478846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-18ec04e0-d60a-49eb-912b-d7414f7fc5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-31a4f09d-7b96-4f5d-8ca9-b7cc9c349ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-1a65f931-7a0f-428c-9ceb-16e6a00928ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-6595798a-00ab-4e8c-9d22-574701c21b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-c001ab38-5851-472a-87fd-6de85cb583f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-92e6b885-8fcb-40a3-9a07-31c7459ead37,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-cfdd29a6-ac4b-43d8-9cea-0d652b611982,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-c66c3d21-6121-4df2-aa8a-74d427b31159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497501-172.17.0.17-1597396478846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-18ec04e0-d60a-49eb-912b-d7414f7fc5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-31a4f09d-7b96-4f5d-8ca9-b7cc9c349ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-1a65f931-7a0f-428c-9ceb-16e6a00928ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-6595798a-00ab-4e8c-9d22-574701c21b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-c001ab38-5851-472a-87fd-6de85cb583f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-92e6b885-8fcb-40a3-9a07-31c7459ead37,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-cfdd29a6-ac4b-43d8-9cea-0d652b611982,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-c66c3d21-6121-4df2-aa8a-74d427b31159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353249089-172.17.0.17-1597396557673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46146,DS-c26242df-6135-4f5b-bbef-2ed12c2ec3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-f5f1abe4-9001-4e0a-8020-35008f63462f,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-f88c6bda-abb9-4d97-ad25-6ff52af32e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-08a6bd43-c86d-432d-8270-27c25242f245,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-1586325f-789c-4df4-b685-59ec5c6f20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-9004a7e7-7fbd-4978-b6fb-2852e0449832,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-4a1418dd-eccc-4f31-8180-639928fca75e,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-243050b0-1c7f-412d-aabf-2f4db0dc04c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353249089-172.17.0.17-1597396557673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46146,DS-c26242df-6135-4f5b-bbef-2ed12c2ec3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-f5f1abe4-9001-4e0a-8020-35008f63462f,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-f88c6bda-abb9-4d97-ad25-6ff52af32e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-08a6bd43-c86d-432d-8270-27c25242f245,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-1586325f-789c-4df4-b685-59ec5c6f20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-9004a7e7-7fbd-4978-b6fb-2852e0449832,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-4a1418dd-eccc-4f31-8180-639928fca75e,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-243050b0-1c7f-412d-aabf-2f4db0dc04c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319151797-172.17.0.17-1597396667973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-56ede78c-da8f-4d54-bd74-fe9349892d21,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-3bae60b0-5f21-4113-9b1a-4e22a9c996c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-a06249a7-f6ff-47df-b673-9dbe56dde68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-d31edf9e-240b-4d9b-8a99-c2e453a0be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-26343369-7d34-4ba0-b0cf-e2c84ecbf7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-f0d7e19a-9fba-45dd-b490-b963f9e94350,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-92bb51da-68af-49e1-9760-e426eb2cbf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-ee6e2684-7163-41d7-8b4c-345c9906171e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319151797-172.17.0.17-1597396667973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-56ede78c-da8f-4d54-bd74-fe9349892d21,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-3bae60b0-5f21-4113-9b1a-4e22a9c996c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-a06249a7-f6ff-47df-b673-9dbe56dde68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-d31edf9e-240b-4d9b-8a99-c2e453a0be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-26343369-7d34-4ba0-b0cf-e2c84ecbf7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-f0d7e19a-9fba-45dd-b490-b963f9e94350,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-92bb51da-68af-49e1-9760-e426eb2cbf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-ee6e2684-7163-41d7-8b4c-345c9906171e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278626552-172.17.0.17-1597396973578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33620,DS-5e09580e-1ee5-45ec-98bb-17b7ad975a16,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-43781c76-f95d-4498-bacd-247c77c71c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-071f00f1-4dd6-41c4-84fc-6039670ecd96,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-5faefe9f-0fbd-48be-a13b-dd8c4cf285b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-f429c665-b35c-4dd4-aa28-e356a55c0df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-22bb6be5-06cd-412b-aae0-16ff9473f418,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-09f6f29d-0aa8-4cdf-8c5a-3ad65700b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-b3cffba9-9a92-43bd-b604-a743f068ad51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278626552-172.17.0.17-1597396973578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33620,DS-5e09580e-1ee5-45ec-98bb-17b7ad975a16,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-43781c76-f95d-4498-bacd-247c77c71c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-071f00f1-4dd6-41c4-84fc-6039670ecd96,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-5faefe9f-0fbd-48be-a13b-dd8c4cf285b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-f429c665-b35c-4dd4-aa28-e356a55c0df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-22bb6be5-06cd-412b-aae0-16ff9473f418,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-09f6f29d-0aa8-4cdf-8c5a-3ad65700b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-b3cffba9-9a92-43bd-b604-a743f068ad51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64877984-172.17.0.17-1597397049180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-595c0164-da4b-426b-adfd-72889a708e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-6cf40223-1b4f-409b-89a1-5595439d13d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-921517c8-182f-43b6-9eb9-6a8346933d69,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-fd5a90bd-0ceb-47d4-8b03-9ada589c8e07,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-55335779-6183-4339-ac28-433665b41588,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-8e52bcb8-8026-4167-ae70-43eef44de425,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-423b66f5-40a9-4665-979c-2496caea87fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-684f3f52-ed4b-46ac-b751-87faebc11b95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64877984-172.17.0.17-1597397049180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-595c0164-da4b-426b-adfd-72889a708e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-6cf40223-1b4f-409b-89a1-5595439d13d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-921517c8-182f-43b6-9eb9-6a8346933d69,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-fd5a90bd-0ceb-47d4-8b03-9ada589c8e07,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-55335779-6183-4339-ac28-433665b41588,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-8e52bcb8-8026-4167-ae70-43eef44de425,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-423b66f5-40a9-4665-979c-2496caea87fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-684f3f52-ed4b-46ac-b751-87faebc11b95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066560736-172.17.0.17-1597397131037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37392,DS-7a1a476b-53b1-45ed-b383-e5bb304a7470,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-d139a922-ee08-4f2a-b423-d63905f969e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-716a969a-c54d-4709-b310-928c7237fd00,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-82b01742-4f3b-4960-802e-bd8f2998d238,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-dce9db20-03ce-4a84-9839-21e2d09fc7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-b2e7f6f7-913b-4173-ac4e-d0a19fb5a060,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-ec9b70c8-53d8-49d6-b050-35510a15d790,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-4c923285-122d-4044-ab30-bf8f20a06043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066560736-172.17.0.17-1597397131037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37392,DS-7a1a476b-53b1-45ed-b383-e5bb304a7470,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-d139a922-ee08-4f2a-b423-d63905f969e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-716a969a-c54d-4709-b310-928c7237fd00,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-82b01742-4f3b-4960-802e-bd8f2998d238,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-dce9db20-03ce-4a84-9839-21e2d09fc7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-b2e7f6f7-913b-4173-ac4e-d0a19fb5a060,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-ec9b70c8-53d8-49d6-b050-35510a15d790,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-4c923285-122d-4044-ab30-bf8f20a06043,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263604046-172.17.0.17-1597397201674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-e2b23daf-0b8b-4997-a937-2f7b3d17e037,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-cff531af-58dd-45d8-9e11-c4fd143fd6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-95d6cb15-e423-48b6-a426-21959118555d,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-501dda61-b037-4a65-95a9-2005686fd9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-7d7a89a3-75d7-4683-967f-6c26ee53dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-da82f16f-f0fb-443a-aa66-4baf1e5a39ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-2b8ed3d7-b0e9-4c30-ad78-87c566f09df2,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-ccfc700e-6a31-48b9-9ac9-31b3256baf15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263604046-172.17.0.17-1597397201674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-e2b23daf-0b8b-4997-a937-2f7b3d17e037,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-cff531af-58dd-45d8-9e11-c4fd143fd6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-95d6cb15-e423-48b6-a426-21959118555d,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-501dda61-b037-4a65-95a9-2005686fd9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-7d7a89a3-75d7-4683-967f-6c26ee53dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-da82f16f-f0fb-443a-aa66-4baf1e5a39ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-2b8ed3d7-b0e9-4c30-ad78-87c566f09df2,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-ccfc700e-6a31-48b9-9ac9-31b3256baf15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090390594-172.17.0.17-1597397315510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36961,DS-4cf557db-5106-4410-83b9-27b04b9001f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-748d4a9a-48ef-4891-b7e8-5354e8fee9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-40664ec7-f991-48bb-ae14-e9c851ad1da2,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-fb75587b-88ad-44f8-b64c-118535f9b549,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-f5660e38-dc18-426d-adfe-cc58dd4f708f,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-e6c8bb39-f44e-4f87-901e-06c3e8afebe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-27f02df1-3ebf-4a9c-9d95-d39222a5198f,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-858ac1a0-049f-4385-ba1b-098b8a27936a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090390594-172.17.0.17-1597397315510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36961,DS-4cf557db-5106-4410-83b9-27b04b9001f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-748d4a9a-48ef-4891-b7e8-5354e8fee9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-40664ec7-f991-48bb-ae14-e9c851ad1da2,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-fb75587b-88ad-44f8-b64c-118535f9b549,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-f5660e38-dc18-426d-adfe-cc58dd4f708f,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-e6c8bb39-f44e-4f87-901e-06c3e8afebe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-27f02df1-3ebf-4a9c-9d95-d39222a5198f,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-858ac1a0-049f-4385-ba1b-098b8a27936a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315128949-172.17.0.17-1597397401593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33951,DS-cfcab0ec-bc86-447f-a80f-30ec017042d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-90a693c6-1b35-4ae2-be7c-596c54df3904,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-1d2028ef-ae47-410a-8c59-c828fa322ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-dcd12dbc-ef69-4f5d-b276-93e77bff63df,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-059c5e08-eb23-48db-a69f-934aa8613e16,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-972e6288-ef9b-4d3e-a3e5-2d26faa1d089,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-d11c712e-e282-4364-86bd-8f8a5ae7db2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-59ab4e8c-8447-4bc5-8c97-566a084c9e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315128949-172.17.0.17-1597397401593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33951,DS-cfcab0ec-bc86-447f-a80f-30ec017042d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-90a693c6-1b35-4ae2-be7c-596c54df3904,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-1d2028ef-ae47-410a-8c59-c828fa322ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-dcd12dbc-ef69-4f5d-b276-93e77bff63df,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-059c5e08-eb23-48db-a69f-934aa8613e16,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-972e6288-ef9b-4d3e-a3e5-2d26faa1d089,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-d11c712e-e282-4364-86bd-8f8a5ae7db2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-59ab4e8c-8447-4bc5-8c97-566a084c9e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26672685-172.17.0.17-1597397477001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44963,DS-a9c781f0-b4bf-4da8-90a3-45601f5887b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-c3c142db-78a3-4c5b-8839-c16b90b7fadb,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-47cef129-05db-4682-888c-7326c21f6697,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-1abaa032-705b-44d2-8d7e-4b04d781c733,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-ce393a66-9a47-4dec-bce9-b9c192239b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-5c64e221-7126-4a2a-912b-0bba9e780db0,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-d2d17fb6-2ee7-489b-8834-cffc090f5d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-e34515c7-f5ab-48d9-95d9-b7f9199448ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26672685-172.17.0.17-1597397477001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44963,DS-a9c781f0-b4bf-4da8-90a3-45601f5887b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-c3c142db-78a3-4c5b-8839-c16b90b7fadb,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-47cef129-05db-4682-888c-7326c21f6697,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-1abaa032-705b-44d2-8d7e-4b04d781c733,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-ce393a66-9a47-4dec-bce9-b9c192239b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-5c64e221-7126-4a2a-912b-0bba9e780db0,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-d2d17fb6-2ee7-489b-8834-cffc090f5d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-e34515c7-f5ab-48d9-95d9-b7f9199448ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5497
