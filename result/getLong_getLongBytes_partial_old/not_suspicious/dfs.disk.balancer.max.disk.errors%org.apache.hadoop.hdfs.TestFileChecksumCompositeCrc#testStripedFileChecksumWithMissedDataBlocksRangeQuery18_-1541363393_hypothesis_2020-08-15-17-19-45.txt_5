reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422035507-172.17.0.16-1597512150685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32894,DS-a6277476-cd52-480d-bc83-479b7dcf6399,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-872d755e-2850-4a01-b957-ca22b88c6f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-fd41b0d4-d3f6-4b7e-b8b5-55e61bdf2c64,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-c01887be-b938-473d-8733-046335d796bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-5bfb1dac-49c7-47d9-83ba-9c05cb57a6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-1f7a518c-eed6-4dd7-ab97-ad97245a91fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-3e154447-9c17-4acc-a8aa-4ee205043519,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-a4506175-59f8-426d-bdb1-ae6d1755e3da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422035507-172.17.0.16-1597512150685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32894,DS-a6277476-cd52-480d-bc83-479b7dcf6399,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-872d755e-2850-4a01-b957-ca22b88c6f15,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-fd41b0d4-d3f6-4b7e-b8b5-55e61bdf2c64,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-c01887be-b938-473d-8733-046335d796bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-5bfb1dac-49c7-47d9-83ba-9c05cb57a6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-1f7a518c-eed6-4dd7-ab97-ad97245a91fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-3e154447-9c17-4acc-a8aa-4ee205043519,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-a4506175-59f8-426d-bdb1-ae6d1755e3da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068428414-172.17.0.16-1597512218948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45785,DS-49162c1c-789f-47f3-b625-f0015c4e2029,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-38b0a1a9-d473-407a-8d02-3355d396f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-f0960372-f2c3-4458-8bd0-d6e2fcdc8776,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-178e46ec-9b58-46a5-906d-a052d4af7386,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-9156732d-3456-452c-ab37-3c01582fa74f,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-aa25ba3c-fbad-47bf-9f7a-673532a2e435,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-1777f3d3-d27c-4fc5-a472-84cedec211da,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-e7c25e64-6535-4ed8-992b-735846aa26c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068428414-172.17.0.16-1597512218948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45785,DS-49162c1c-789f-47f3-b625-f0015c4e2029,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-38b0a1a9-d473-407a-8d02-3355d396f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-f0960372-f2c3-4458-8bd0-d6e2fcdc8776,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-178e46ec-9b58-46a5-906d-a052d4af7386,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-9156732d-3456-452c-ab37-3c01582fa74f,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-aa25ba3c-fbad-47bf-9f7a-673532a2e435,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-1777f3d3-d27c-4fc5-a472-84cedec211da,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-e7c25e64-6535-4ed8-992b-735846aa26c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442469041-172.17.0.16-1597512642148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33884,DS-ebbb7c1f-0e13-41ac-b1cd-5c773cbe900f,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-d80b57a6-89cd-495e-a7cc-25277b83a19c,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-64e7a3cb-70d1-4325-a3b5-7fd2ee136912,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-e3912d5a-d102-4959-aef5-d63cfced2e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-7e59f66b-0d9d-4723-b8f9-2240c9af6894,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-5b6a3cd7-56e6-402d-8d16-a61d0c7bcda1,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-6efa3c5a-93ea-474d-b578-87565a5ea0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-e887d27b-b87c-4b65-b31e-3aa0b83ca894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442469041-172.17.0.16-1597512642148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33884,DS-ebbb7c1f-0e13-41ac-b1cd-5c773cbe900f,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-d80b57a6-89cd-495e-a7cc-25277b83a19c,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-64e7a3cb-70d1-4325-a3b5-7fd2ee136912,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-e3912d5a-d102-4959-aef5-d63cfced2e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-7e59f66b-0d9d-4723-b8f9-2240c9af6894,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-5b6a3cd7-56e6-402d-8d16-a61d0c7bcda1,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-6efa3c5a-93ea-474d-b578-87565a5ea0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-e887d27b-b87c-4b65-b31e-3aa0b83ca894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961206004-172.17.0.16-1597512909342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-82c956d6-a536-40e3-9f5c-00b182c16caa,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-8eb76dd4-3ad7-4c71-9804-3d93c7393ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-88da0974-50fa-4572-85b4-f5a93ae30e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-cd2147d1-dda7-419d-ab95-24d703148867,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-5406483b-902e-4722-a8ed-6d779f21d246,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-1d6bbb53-9e24-4bde-b37e-b44d9d68bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-7bc20b5e-dd06-4d05-a88c-ad96e0d21738,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-c42c68b2-4628-4854-ae6f-a58605ad9c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961206004-172.17.0.16-1597512909342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-82c956d6-a536-40e3-9f5c-00b182c16caa,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-8eb76dd4-3ad7-4c71-9804-3d93c7393ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-88da0974-50fa-4572-85b4-f5a93ae30e65,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-cd2147d1-dda7-419d-ab95-24d703148867,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-5406483b-902e-4722-a8ed-6d779f21d246,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-1d6bbb53-9e24-4bde-b37e-b44d9d68bb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-7bc20b5e-dd06-4d05-a88c-ad96e0d21738,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-c42c68b2-4628-4854-ae6f-a58605ad9c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397287482-172.17.0.16-1597513170906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-14cf5249-8c98-42c4-8357-99c774a2dcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-c0dfabf7-52b6-4a17-a766-3f5c04186be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-d7e4234d-0a58-45fb-bf97-54df55d5c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-b64cd9f5-8fa9-4cf7-84f2-e9873ca8bd75,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-6d5c403e-9c37-4da9-8851-fe8395e1c0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-d48a4493-07c7-4617-8741-6a680f714d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-82a20273-2dd7-420b-809f-fcb6c0a64c26,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-a74332f7-0aaf-4108-80ee-a813da15610f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1397287482-172.17.0.16-1597513170906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-14cf5249-8c98-42c4-8357-99c774a2dcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-c0dfabf7-52b6-4a17-a766-3f5c04186be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-d7e4234d-0a58-45fb-bf97-54df55d5c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-b64cd9f5-8fa9-4cf7-84f2-e9873ca8bd75,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-6d5c403e-9c37-4da9-8851-fe8395e1c0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-d48a4493-07c7-4617-8741-6a680f714d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-82a20273-2dd7-420b-809f-fcb6c0a64c26,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-a74332f7-0aaf-4108-80ee-a813da15610f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793373286-172.17.0.16-1597513316590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43735,DS-9d012156-81eb-402a-84f8-b88384914a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-10568d0f-e9d6-41da-9393-5679ffdea45e,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-067d88f7-1a1e-4312-8ec8-c4cde0ef5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-08550807-7b80-4688-bbc6-88f5117d2362,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-dddea44c-7f0f-454e-b225-3c5d9fb198a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-2bec1943-3503-46c9-9b21-84128f149489,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-b75714c5-e635-4598-990d-c9fa7af0350a,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-7f40c995-d548-4c55-b3a0-5ff03b25cdc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793373286-172.17.0.16-1597513316590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43735,DS-9d012156-81eb-402a-84f8-b88384914a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-10568d0f-e9d6-41da-9393-5679ffdea45e,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-067d88f7-1a1e-4312-8ec8-c4cde0ef5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-08550807-7b80-4688-bbc6-88f5117d2362,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-dddea44c-7f0f-454e-b225-3c5d9fb198a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-2bec1943-3503-46c9-9b21-84128f149489,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-b75714c5-e635-4598-990d-c9fa7af0350a,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-7f40c995-d548-4c55-b3a0-5ff03b25cdc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740069859-172.17.0.16-1597513641465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41413,DS-81df027f-0070-4150-999c-6a5084a24144,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-e24c155d-5ad5-47c8-be60-7b46f1ff82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-14dd10ff-be09-40e0-966b-9ba2928fa0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-95828f24-a05e-4d50-ad1c-450c3275d608,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-5ee20e28-d8ab-4c64-9eae-5f4b5a738437,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-69ab4661-9d8d-4562-8266-0fdeb243a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-a7154860-f520-4405-a79e-cccd7c4dfbef,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-483f1f91-12b7-4ade-bbbf-9dcc886259cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740069859-172.17.0.16-1597513641465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41413,DS-81df027f-0070-4150-999c-6a5084a24144,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-e24c155d-5ad5-47c8-be60-7b46f1ff82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-14dd10ff-be09-40e0-966b-9ba2928fa0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-95828f24-a05e-4d50-ad1c-450c3275d608,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-5ee20e28-d8ab-4c64-9eae-5f4b5a738437,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-69ab4661-9d8d-4562-8266-0fdeb243a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-a7154860-f520-4405-a79e-cccd7c4dfbef,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-483f1f91-12b7-4ade-bbbf-9dcc886259cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2127372908-172.17.0.16-1597514475967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41148,DS-fb5299a8-ccc9-4087-88c6-218237d41e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-86de7bd1-642e-4e7a-915a-c519e288c421,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-91a6c43e-73a6-4043-9e37-c4f204960fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-55225b9d-0952-4bc9-bc2f-7be9de987045,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-b5159d3e-e079-4000-9bae-7e2a4b7d158b,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-45a21778-fe98-4cf8-9bb9-4a3d9a346cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-dcfdb3c1-ca52-4efe-808d-e80cc6d52a85,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-3be527e8-7e93-4262-b7c5-aa8fb3e61f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2127372908-172.17.0.16-1597514475967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41148,DS-fb5299a8-ccc9-4087-88c6-218237d41e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-86de7bd1-642e-4e7a-915a-c519e288c421,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-91a6c43e-73a6-4043-9e37-c4f204960fde,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-55225b9d-0952-4bc9-bc2f-7be9de987045,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-b5159d3e-e079-4000-9bae-7e2a4b7d158b,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-45a21778-fe98-4cf8-9bb9-4a3d9a346cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-dcfdb3c1-ca52-4efe-808d-e80cc6d52a85,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-3be527e8-7e93-4262-b7c5-aa8fb3e61f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289310890-172.17.0.16-1597514626318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40515,DS-db83e96c-77c9-4117-9021-a34b4e5f6145,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-f79a206f-0515-4f7d-a90c-b42e513e2b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-1d67fc11-773b-4fb2-bcdc-6bf50667fe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-69d68e65-f675-4d41-aa92-e40c14aba152,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-dca3b63d-5c38-435a-80af-d292c6afb501,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-c4ce1085-50fa-4a46-b292-7ea37465f1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-392501ee-a52e-4c5a-a47b-8e2712e4b7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-9c060c6c-d18a-41c3-92ca-dbf346e3d388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289310890-172.17.0.16-1597514626318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40515,DS-db83e96c-77c9-4117-9021-a34b4e5f6145,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-f79a206f-0515-4f7d-a90c-b42e513e2b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-1d67fc11-773b-4fb2-bcdc-6bf50667fe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-69d68e65-f675-4d41-aa92-e40c14aba152,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-dca3b63d-5c38-435a-80af-d292c6afb501,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-c4ce1085-50fa-4a46-b292-7ea37465f1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-392501ee-a52e-4c5a-a47b-8e2712e4b7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-9c060c6c-d18a-41c3-92ca-dbf346e3d388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439907273-172.17.0.16-1597514662043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-5f482ed4-69c2-490a-a71e-718df03d1129,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-3fe92668-7c27-4e9b-9c71-b468ec3d0c37,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-883bfdde-f67a-4eab-98f9-93fa2d267adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-77b23ccc-c734-489f-b813-98d69269cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-e9cdacf2-1a48-4b2e-b68d-7d53fe367945,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-1dd10ca0-ffed-4531-8283-13df6668ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-e80daa8c-51a1-4392-97de-b0cb3aa5ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-334cdb42-93ca-4c3d-bdd6-fb92d2bf9f7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439907273-172.17.0.16-1597514662043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45666,DS-5f482ed4-69c2-490a-a71e-718df03d1129,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-3fe92668-7c27-4e9b-9c71-b468ec3d0c37,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-883bfdde-f67a-4eab-98f9-93fa2d267adc,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-77b23ccc-c734-489f-b813-98d69269cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-e9cdacf2-1a48-4b2e-b68d-7d53fe367945,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-1dd10ca0-ffed-4531-8283-13df6668ab32,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-e80daa8c-51a1-4392-97de-b0cb3aa5ffe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-334cdb42-93ca-4c3d-bdd6-fb92d2bf9f7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429361776-172.17.0.16-1597514694495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-4bbae58a-176d-4a3c-a5be-7a2b4590a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-326a08b2-2500-424b-a430-a8d839c4817c,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-75907684-0dca-4ec6-af9c-6b4908b1c351,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-d492c0aa-abf5-43ee-9e14-59a7f85146f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-d34c4f95-3d91-4f4e-bc49-190f46bd2500,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-3420d766-f8b7-412c-83b8-4aa49c3ee583,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-b83525ed-a477-47b0-bf8a-b9fc611f81d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-1244fc29-60fb-4358-8921-15f5ca495734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429361776-172.17.0.16-1597514694495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-4bbae58a-176d-4a3c-a5be-7a2b4590a5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-326a08b2-2500-424b-a430-a8d839c4817c,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-75907684-0dca-4ec6-af9c-6b4908b1c351,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-d492c0aa-abf5-43ee-9e14-59a7f85146f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-d34c4f95-3d91-4f4e-bc49-190f46bd2500,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-3420d766-f8b7-412c-83b8-4aa49c3ee583,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-b83525ed-a477-47b0-bf8a-b9fc611f81d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-1244fc29-60fb-4358-8921-15f5ca495734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787714088-172.17.0.16-1597514807197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-015c78d3-b71a-4419-9580-3dc3ef2a2e28,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-72778f92-ad39-48af-b327-2b656d29789b,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-47f96eff-4cdf-40b4-8529-88723f98ac63,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-e5ba00d2-6239-4e39-96b5-65945f4dc14b,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-052cd3a0-df12-43cf-9361-fe2f2c942023,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-9c460a04-5cde-4e59-ab46-27dabb5c9784,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-92cda043-caae-4738-9bfe-5563f992f114,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-583feb2a-b38f-4cac-be40-66aca96857bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787714088-172.17.0.16-1597514807197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-015c78d3-b71a-4419-9580-3dc3ef2a2e28,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-72778f92-ad39-48af-b327-2b656d29789b,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-47f96eff-4cdf-40b4-8529-88723f98ac63,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-e5ba00d2-6239-4e39-96b5-65945f4dc14b,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-052cd3a0-df12-43cf-9361-fe2f2c942023,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-9c460a04-5cde-4e59-ab46-27dabb5c9784,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-92cda043-caae-4738-9bfe-5563f992f114,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-583feb2a-b38f-4cac-be40-66aca96857bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783698914-172.17.0.16-1597515345938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-083ea2ff-f9a6-468a-9ca2-6ae1e3595e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-6ca66962-2dcf-4e20-b839-5ae89f086718,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-e052db9c-66d8-45f7-a6f7-c9864563034a,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-42deb9f8-761b-42e4-8729-e818ffeaee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-4ebdac76-b469-415b-a860-4296d79bf175,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-8efdb86e-b189-4310-81f6-620791297654,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-4c0e82d8-ad2b-44d4-a0f5-683bf927de0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-04020e71-24a8-4b11-9a96-222855e3b83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783698914-172.17.0.16-1597515345938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-083ea2ff-f9a6-468a-9ca2-6ae1e3595e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-6ca66962-2dcf-4e20-b839-5ae89f086718,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-e052db9c-66d8-45f7-a6f7-c9864563034a,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-42deb9f8-761b-42e4-8729-e818ffeaee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-4ebdac76-b469-415b-a860-4296d79bf175,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-8efdb86e-b189-4310-81f6-620791297654,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-4c0e82d8-ad2b-44d4-a0f5-683bf927de0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-04020e71-24a8-4b11-9a96-222855e3b83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727435571-172.17.0.16-1597515644264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33314,DS-4dc657ff-e334-44c4-955f-e92220ee1677,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-ee495cc3-ca21-4fc6-b0a0-ada09784ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-9530fce5-57f8-44a6-8cdc-ef620e1aadef,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-45494667-9ea5-4f12-9c7a-01228bc29613,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-d677d18d-945c-45b9-a85f-b6d58bf56048,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-d73e0959-117f-4e0e-850b-8c7c12453dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-dbf854a2-48ae-4384-9d45-1208af4f1939,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-b490a975-066a-49c8-9846-6cf6a4342393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-727435571-172.17.0.16-1597515644264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33314,DS-4dc657ff-e334-44c4-955f-e92220ee1677,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-ee495cc3-ca21-4fc6-b0a0-ada09784ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-9530fce5-57f8-44a6-8cdc-ef620e1aadef,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-45494667-9ea5-4f12-9c7a-01228bc29613,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-d677d18d-945c-45b9-a85f-b6d58bf56048,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-d73e0959-117f-4e0e-850b-8c7c12453dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-dbf854a2-48ae-4384-9d45-1208af4f1939,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-b490a975-066a-49c8-9846-6cf6a4342393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033851864-172.17.0.16-1597516266720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32876,DS-2642239d-a696-446c-ad7a-6211af2856e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-d13a4da3-57ee-4976-9f68-9c74a97d10f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-9fdb1618-0af5-4613-b36d-36f03fcab88f,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-3616c4ab-7948-4662-9009-a95eb8855377,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-f85340f7-2310-46ed-9888-841b706405b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-1035dbb0-2ea1-4163-b4fd-a5fcb83d30d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-d60ce821-4e0a-49a1-ba27-077ca0d09a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-cd812e6a-c01f-453e-8e5b-21d657683232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033851864-172.17.0.16-1597516266720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32876,DS-2642239d-a696-446c-ad7a-6211af2856e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-d13a4da3-57ee-4976-9f68-9c74a97d10f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-9fdb1618-0af5-4613-b36d-36f03fcab88f,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-3616c4ab-7948-4662-9009-a95eb8855377,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-f85340f7-2310-46ed-9888-841b706405b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-1035dbb0-2ea1-4163-b4fd-a5fcb83d30d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-d60ce821-4e0a-49a1-ba27-077ca0d09a66,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-cd812e6a-c01f-453e-8e5b-21d657683232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012628382-172.17.0.16-1597516816699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-af6a6b3f-7b11-4a31-be6a-94d78b50ac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-3874e578-0852-4c96-9f4d-1c63f8297dab,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-6e9851d7-9d81-4190-930b-a20a521eb12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-bc005c20-220b-41eb-9d21-4781f49e1d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-572773cf-1299-4a65-9878-6ba6eb0d4bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-fb2c4eab-d455-4290-85ef-ed75a38ad9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-a262886a-bce5-4dc0-a297-775fa75cdeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-110513b5-8449-4b2a-94e3-bebeaba2a69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012628382-172.17.0.16-1597516816699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-af6a6b3f-7b11-4a31-be6a-94d78b50ac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-3874e578-0852-4c96-9f4d-1c63f8297dab,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-6e9851d7-9d81-4190-930b-a20a521eb12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-bc005c20-220b-41eb-9d21-4781f49e1d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-572773cf-1299-4a65-9878-6ba6eb0d4bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-fb2c4eab-d455-4290-85ef-ed75a38ad9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-a262886a-bce5-4dc0-a297-775fa75cdeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-110513b5-8449-4b2a-94e3-bebeaba2a69e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414971751-172.17.0.16-1597516961224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43451,DS-fbb7a995-34aa-40dd-b58e-97b88d43604c,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-289fd73b-cb7d-4545-80ee-5cf2741ac75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-dacded04-f40b-48a3-b6c6-78ef8b8f4689,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-dcde3d98-b738-43c2-b062-5120211e449f,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-46e06886-5d43-4ace-b4b2-5144333d6948,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-0c269002-a441-45fa-b3c3-e80c3c048baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-62ee642f-1d3b-41c4-b8a3-c3d303588cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-62bd595d-90de-4d22-a821-fd62bc9dba37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414971751-172.17.0.16-1597516961224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43451,DS-fbb7a995-34aa-40dd-b58e-97b88d43604c,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-289fd73b-cb7d-4545-80ee-5cf2741ac75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-dacded04-f40b-48a3-b6c6-78ef8b8f4689,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-dcde3d98-b738-43c2-b062-5120211e449f,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-46e06886-5d43-4ace-b4b2-5144333d6948,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-0c269002-a441-45fa-b3c3-e80c3c048baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-62ee642f-1d3b-41c4-b8a3-c3d303588cee,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-62bd595d-90de-4d22-a821-fd62bc9dba37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476252691-172.17.0.16-1597517263640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45992,DS-aaac8a28-d663-485b-bde5-5c30fbc54f20,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-ab74a794-5bb3-4b6a-aa05-34faba9ac2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-41011e6b-1a10-472d-9c0d-c39e41eff526,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-1d91cbde-551d-4786-b7df-d73ff2e57592,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-9e16f453-8978-4ec6-8887-152642d00630,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-1f6e6f6d-67ff-498a-a3af-128056bf8e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-2b7dd2f2-11b4-4c16-ac5b-44fc47ec178b,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-99e80421-fd3a-4ea6-b868-4567f1b41eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476252691-172.17.0.16-1597517263640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45992,DS-aaac8a28-d663-485b-bde5-5c30fbc54f20,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-ab74a794-5bb3-4b6a-aa05-34faba9ac2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-41011e6b-1a10-472d-9c0d-c39e41eff526,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-1d91cbde-551d-4786-b7df-d73ff2e57592,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-9e16f453-8978-4ec6-8887-152642d00630,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-1f6e6f6d-67ff-498a-a3af-128056bf8e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-2b7dd2f2-11b4-4c16-ac5b-44fc47ec178b,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-99e80421-fd3a-4ea6-b868-4567f1b41eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5549
