reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400928711-172.17.0.21-1597459223965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-5f0d360e-f2ee-4043-b9c1-ad74141758c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-aec866cc-189c-42d3-ac1d-25502f2d31d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-c260c7e5-c317-4d4d-8849-c7e61de94bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-94aea5b1-3c40-4679-ac60-4d2862dc85c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-aca2d27e-1358-44f5-b9f7-c311d039d458,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-5635095e-4429-4e46-b42d-9e85e4885480,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-5c3f560a-2cb5-4f10-a919-ee147489c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-a378cc64-4eb8-4730-8d08-7254922f9b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400928711-172.17.0.21-1597459223965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36955,DS-5f0d360e-f2ee-4043-b9c1-ad74141758c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-aec866cc-189c-42d3-ac1d-25502f2d31d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-c260c7e5-c317-4d4d-8849-c7e61de94bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-94aea5b1-3c40-4679-ac60-4d2862dc85c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-aca2d27e-1358-44f5-b9f7-c311d039d458,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-5635095e-4429-4e46-b42d-9e85e4885480,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-5c3f560a-2cb5-4f10-a919-ee147489c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-a378cc64-4eb8-4730-8d08-7254922f9b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440162321-172.17.0.21-1597459364267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-e67d8ece-332c-4cd4-adb9-6af417614d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-4e0eeaef-df86-4583-bb2e-e49fa6b50dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-65ec7768-a34b-43e6-93d8-86a9f24309d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-7c777d87-207f-4dde-a286-036a5d5ad3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-57207cd1-ee3e-4005-b089-0afb396d61ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-f89d4e32-b47f-428a-be21-c3ae4188ae15,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-1d6b8d3f-9774-4bc3-bd6f-90de08cee735,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-9f6bcc53-0b1e-4ab1-948d-c9043be4184f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440162321-172.17.0.21-1597459364267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-e67d8ece-332c-4cd4-adb9-6af417614d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-4e0eeaef-df86-4583-bb2e-e49fa6b50dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-65ec7768-a34b-43e6-93d8-86a9f24309d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-7c777d87-207f-4dde-a286-036a5d5ad3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-57207cd1-ee3e-4005-b089-0afb396d61ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-f89d4e32-b47f-428a-be21-c3ae4188ae15,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-1d6b8d3f-9774-4bc3-bd6f-90de08cee735,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-9f6bcc53-0b1e-4ab1-948d-c9043be4184f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512163818-172.17.0.21-1597460316238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44431,DS-bd21103c-8d6a-4855-a7fb-18a402e28dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-af0baa04-ab0b-4588-b192-7b09c97b9f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-2d623458-6c91-4f79-830b-44556be75cda,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-ed67e9f0-25ee-4086-92c1-263aa9712a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-d781d52b-dc4c-4b57-8771-1f6a02e97e23,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-7ba47c16-4356-4e2f-9b76-f3d0cda06d50,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-542c484d-7b9a-4ce3-8ebc-bd005838fc21,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-6e848fad-13e8-41c5-804c-eb674be9e384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512163818-172.17.0.21-1597460316238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44431,DS-bd21103c-8d6a-4855-a7fb-18a402e28dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-af0baa04-ab0b-4588-b192-7b09c97b9f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-2d623458-6c91-4f79-830b-44556be75cda,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-ed67e9f0-25ee-4086-92c1-263aa9712a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-d781d52b-dc4c-4b57-8771-1f6a02e97e23,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-7ba47c16-4356-4e2f-9b76-f3d0cda06d50,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-542c484d-7b9a-4ce3-8ebc-bd005838fc21,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-6e848fad-13e8-41c5-804c-eb674be9e384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636543680-172.17.0.21-1597461576337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-a3b0373e-d109-4bce-85c7-beb48f3427ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-c1efefb1-caef-489d-bedb-70b9f7aad9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-a2ad391d-f2a9-4657-bb9f-a486eb0ab38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-b79cfbef-9c07-4e38-9544-b0ad4d3e7ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-d086a29a-99c9-41f6-9808-4f26dcedf843,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-164c60f2-e582-4e51-b21b-33d8a792ebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-202923b1-9160-42c1-94b8-8c8bc8c64ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-55e3fd81-55c8-4a84-a0f1-d7b6727457f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1636543680-172.17.0.21-1597461576337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-a3b0373e-d109-4bce-85c7-beb48f3427ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-c1efefb1-caef-489d-bedb-70b9f7aad9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-a2ad391d-f2a9-4657-bb9f-a486eb0ab38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-b79cfbef-9c07-4e38-9544-b0ad4d3e7ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-d086a29a-99c9-41f6-9808-4f26dcedf843,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-164c60f2-e582-4e51-b21b-33d8a792ebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-202923b1-9160-42c1-94b8-8c8bc8c64ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-55e3fd81-55c8-4a84-a0f1-d7b6727457f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457038300-172.17.0.21-1597461670845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44153,DS-0c61d97b-b737-459e-a782-de9e007b0dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-ab4e5e49-21b9-485d-8399-7a5f436af054,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-0e5879e8-2bcc-41f5-b133-572f497858e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-4ad97f3b-a309-4248-b216-a4cc992a43ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-20fff6f0-ecdb-452d-afa8-b155e6b19949,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-4d19348d-498c-4376-b30d-cf1234b0452d,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-41ed6416-40e1-40b6-9873-bd49af819f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-8d942967-234b-4d48-8d36-b3e5cb2060aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457038300-172.17.0.21-1597461670845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44153,DS-0c61d97b-b737-459e-a782-de9e007b0dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-ab4e5e49-21b9-485d-8399-7a5f436af054,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-0e5879e8-2bcc-41f5-b133-572f497858e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-4ad97f3b-a309-4248-b216-a4cc992a43ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-20fff6f0-ecdb-452d-afa8-b155e6b19949,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-4d19348d-498c-4376-b30d-cf1234b0452d,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-41ed6416-40e1-40b6-9873-bd49af819f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-8d942967-234b-4d48-8d36-b3e5cb2060aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342829974-172.17.0.21-1597461716815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-d86d95d3-9143-46c7-a40f-8229f91ceded,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-8d64b336-e20c-49b8-a019-b515bc4756b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-ec832719-7ff8-4c01-8717-b7c0f9f9f358,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-0a2f2e7a-6d53-4cf7-bafd-0ee8e70f09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-049d583e-25cc-461a-913f-0738f1535827,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-8dcfd5f3-f6db-489d-9e5a-1e93a86538ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-4365e6f6-28af-4c55-a136-31ec363f9fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-35f17e61-af9d-48df-9082-dc7c74f8f2f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342829974-172.17.0.21-1597461716815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-d86d95d3-9143-46c7-a40f-8229f91ceded,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-8d64b336-e20c-49b8-a019-b515bc4756b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-ec832719-7ff8-4c01-8717-b7c0f9f9f358,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-0a2f2e7a-6d53-4cf7-bafd-0ee8e70f09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-049d583e-25cc-461a-913f-0738f1535827,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-8dcfd5f3-f6db-489d-9e5a-1e93a86538ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-4365e6f6-28af-4c55-a136-31ec363f9fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-35f17e61-af9d-48df-9082-dc7c74f8f2f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842481722-172.17.0.21-1597461808940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34392,DS-46615445-6a85-4e8b-95f5-afde2c9d9cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-772dc583-0ecb-4d7d-b82a-7d37ec765bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-e19b84b4-2c57-4027-ac38-5fbe248e78b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-1b013750-4da6-4ae0-864c-a5c9f058981d,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-cf905d65-d7e6-4874-b68d-825617fc7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-6ed5cf27-4a5b-4c59-846d-24d42d724c38,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-2c3e13d7-9d87-49bc-aff9-52a8ffd3ac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ce4107fb-06ed-452e-9548-59422f200e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842481722-172.17.0.21-1597461808940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34392,DS-46615445-6a85-4e8b-95f5-afde2c9d9cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-772dc583-0ecb-4d7d-b82a-7d37ec765bec,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-e19b84b4-2c57-4027-ac38-5fbe248e78b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-1b013750-4da6-4ae0-864c-a5c9f058981d,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-cf905d65-d7e6-4874-b68d-825617fc7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-6ed5cf27-4a5b-4c59-846d-24d42d724c38,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-2c3e13d7-9d87-49bc-aff9-52a8ffd3ac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ce4107fb-06ed-452e-9548-59422f200e7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65308947-172.17.0.21-1597462983810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-3c5bcf7e-fd16-4076-b0d9-4def2842cc25,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-7f26b755-3a34-419f-a9d9-75891792f174,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-0a918bf4-16da-4107-b462-22fcd27792b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-c1350da6-fc9d-4c6a-bdd5-1efa0ed61d40,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-28979881-cebd-496a-8ed3-5931ea27ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-37bd4b56-7fcd-4761-8b3c-85455237b7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-86c912a9-c7d2-484c-a23b-15ab33b7182d,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-aa3c5a0f-5dc3-420e-bdf3-513cc226db47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65308947-172.17.0.21-1597462983810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-3c5bcf7e-fd16-4076-b0d9-4def2842cc25,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-7f26b755-3a34-419f-a9d9-75891792f174,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-0a918bf4-16da-4107-b462-22fcd27792b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-c1350da6-fc9d-4c6a-bdd5-1efa0ed61d40,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-28979881-cebd-496a-8ed3-5931ea27ad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-37bd4b56-7fcd-4761-8b3c-85455237b7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-86c912a9-c7d2-484c-a23b-15ab33b7182d,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-aa3c5a0f-5dc3-420e-bdf3-513cc226db47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992873615-172.17.0.21-1597463026186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-a1e75eac-841c-4497-a545-326a643e6429,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-fe6f94e1-7d64-4f09-94c7-f9465d82f251,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-dc8b9554-0e0d-40b4-b34e-177b66a0ace3,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-251d655e-1264-470f-95c6-8849fe5ba7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-f773f983-cb3f-425b-861d-228d2cf703f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-c803f06e-7d83-4153-807b-1dff9589a3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-a2790783-a32f-414b-b3b7-cf6d0e514e41,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-c8f3ee0a-6435-496f-bb17-e68253a4a963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992873615-172.17.0.21-1597463026186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-a1e75eac-841c-4497-a545-326a643e6429,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-fe6f94e1-7d64-4f09-94c7-f9465d82f251,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-dc8b9554-0e0d-40b4-b34e-177b66a0ace3,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-251d655e-1264-470f-95c6-8849fe5ba7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-f773f983-cb3f-425b-861d-228d2cf703f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-c803f06e-7d83-4153-807b-1dff9589a3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-a2790783-a32f-414b-b3b7-cf6d0e514e41,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-c8f3ee0a-6435-496f-bb17-e68253a4a963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272161624-172.17.0.21-1597463442153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37995,DS-210c3367-25b5-4c75-8556-b9745a5ee146,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-df0ba799-6141-4c72-8bde-b7daa7eb8352,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8319474b-7e46-4713-a7e3-34b45c17c767,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-306a3e6b-f4ad-4553-ae3e-56eb5f0cce78,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-814e2ae5-b6cd-484d-9004-024720a76a25,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-83db0b98-7264-4ce4-aa2c-ad4b8478a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d73b7005-eb5c-4823-a9d4-40df2943331f,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-6c762d59-9f1c-45ca-8bcc-d39f560dd908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272161624-172.17.0.21-1597463442153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37995,DS-210c3367-25b5-4c75-8556-b9745a5ee146,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-df0ba799-6141-4c72-8bde-b7daa7eb8352,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-8319474b-7e46-4713-a7e3-34b45c17c767,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-306a3e6b-f4ad-4553-ae3e-56eb5f0cce78,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-814e2ae5-b6cd-484d-9004-024720a76a25,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-83db0b98-7264-4ce4-aa2c-ad4b8478a27c,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d73b7005-eb5c-4823-a9d4-40df2943331f,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-6c762d59-9f1c-45ca-8bcc-d39f560dd908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215752611-172.17.0.21-1597463936307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-23acd5bb-d226-40dd-adad-9c24faf9ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-054748e9-c98a-40d3-a6e2-a461a64138cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-d4af69e9-20ad-43bf-b6b5-d9631f050dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-76d7e2f0-f5fb-4a95-93f2-23af2179ba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-610b708a-4b8c-44d6-82d5-0e40a09a10f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-41f32ecc-3823-445c-a24d-3dd9b0684e98,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-95764392-fde5-4225-95ff-db37b72bd907,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-7703748b-abf4-45bb-8736-f373a1d804a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215752611-172.17.0.21-1597463936307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-23acd5bb-d226-40dd-adad-9c24faf9ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-054748e9-c98a-40d3-a6e2-a461a64138cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-d4af69e9-20ad-43bf-b6b5-d9631f050dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-76d7e2f0-f5fb-4a95-93f2-23af2179ba5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-610b708a-4b8c-44d6-82d5-0e40a09a10f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-41f32ecc-3823-445c-a24d-3dd9b0684e98,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-95764392-fde5-4225-95ff-db37b72bd907,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-7703748b-abf4-45bb-8736-f373a1d804a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765481839-172.17.0.21-1597464549262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-83523d87-6b6d-44eb-a69e-89649312fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-8b2b9551-f99c-4fce-83b8-04ef29897b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-0e8cbd67-0c2c-4ee4-b811-69a7921e92cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-1198148c-6c30-471f-8039-69502b79a176,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-f4e23ee9-2e7d-49cb-82eb-e58a4c66db8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-a6554e8c-2f74-4050-8e0e-49017074c327,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-25d0b681-2648-4fee-84af-e39a7a6300a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-9cb73d55-f606-43a1-8dd2-2fc245959fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765481839-172.17.0.21-1597464549262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-83523d87-6b6d-44eb-a69e-89649312fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-8b2b9551-f99c-4fce-83b8-04ef29897b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-0e8cbd67-0c2c-4ee4-b811-69a7921e92cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-1198148c-6c30-471f-8039-69502b79a176,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-f4e23ee9-2e7d-49cb-82eb-e58a4c66db8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-a6554e8c-2f74-4050-8e0e-49017074c327,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-25d0b681-2648-4fee-84af-e39a7a6300a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-9cb73d55-f606-43a1-8dd2-2fc245959fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790022193-172.17.0.21-1597465022949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-c3d7a1e3-f5ae-44ca-9ab4-ffb0a6cd3548,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-beb9304b-94e2-4eae-9857-2e401f866cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-2feabbf9-553d-44f1-a70f-85244f269a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-1ca2e985-38ee-4284-a5c0-357f02222263,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-55a1465e-5306-43ff-86c9-3a3a27a120a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-87919bc7-bfa9-4eb3-95a7-99cea47f44e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-0315939d-745d-43f4-965c-95d9f4e61353,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-4c0c6105-dd4d-4d49-858c-cd8cca9243bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790022193-172.17.0.21-1597465022949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-c3d7a1e3-f5ae-44ca-9ab4-ffb0a6cd3548,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-beb9304b-94e2-4eae-9857-2e401f866cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-2feabbf9-553d-44f1-a70f-85244f269a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-1ca2e985-38ee-4284-a5c0-357f02222263,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-55a1465e-5306-43ff-86c9-3a3a27a120a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-87919bc7-bfa9-4eb3-95a7-99cea47f44e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-0315939d-745d-43f4-965c-95d9f4e61353,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-4c0c6105-dd4d-4d49-858c-cd8cca9243bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11397750-172.17.0.21-1597465067455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38846,DS-60af0492-fe63-4722-9208-c79364119a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-a417757b-5d69-4de3-a9e5-68338d051e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-4fabb530-2809-4516-b627-9b024b884463,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-32720455-8308-4a79-8650-81d7e3268d21,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-99a4a0b1-f349-403e-b28f-f1897df246e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-c14d0450-4745-400d-b030-2b7689bc2431,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-4e3449f9-1fa4-48b4-aa2e-b7dcfb6129ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-b7beec8d-71d8-4e81-81ed-1ae793a02bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11397750-172.17.0.21-1597465067455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38846,DS-60af0492-fe63-4722-9208-c79364119a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-a417757b-5d69-4de3-a9e5-68338d051e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-4fabb530-2809-4516-b627-9b024b884463,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-32720455-8308-4a79-8650-81d7e3268d21,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-99a4a0b1-f349-403e-b28f-f1897df246e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-c14d0450-4745-400d-b030-2b7689bc2431,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-4e3449f9-1fa4-48b4-aa2e-b7dcfb6129ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-b7beec8d-71d8-4e81-81ed-1ae793a02bce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 7041
