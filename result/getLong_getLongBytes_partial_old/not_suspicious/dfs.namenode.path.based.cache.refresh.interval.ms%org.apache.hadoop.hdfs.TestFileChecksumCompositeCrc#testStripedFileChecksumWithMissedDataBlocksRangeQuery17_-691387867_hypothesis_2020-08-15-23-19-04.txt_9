reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386063629-172.17.0.16-1597533809120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-84813c5a-d76f-414d-8844-62a006e985c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-52075728-1a16-46c6-b20f-eb3e9266d2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-8fd47489-f74e-4d27-a868-d6e8b656e40e,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-e4935b3a-981f-4a3f-bc49-899bf718cf34,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-408b7029-650d-48f5-9bd6-e0d985558182,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-0f396089-1d75-4663-afc1-af8d134feb92,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-65073786-e8eb-41f1-814d-7c7a2a7fb5df,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-3d5124ff-f2b9-4ca7-9d8f-c6e15d94014e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386063629-172.17.0.16-1597533809120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-84813c5a-d76f-414d-8844-62a006e985c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-52075728-1a16-46c6-b20f-eb3e9266d2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-8fd47489-f74e-4d27-a868-d6e8b656e40e,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-e4935b3a-981f-4a3f-bc49-899bf718cf34,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-408b7029-650d-48f5-9bd6-e0d985558182,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-0f396089-1d75-4663-afc1-af8d134feb92,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-65073786-e8eb-41f1-814d-7c7a2a7fb5df,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-3d5124ff-f2b9-4ca7-9d8f-c6e15d94014e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170385950-172.17.0.16-1597534038880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33560,DS-26e939c8-9907-493f-9107-853bdaf23006,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-bc287c66-c088-47f2-9479-2c3806b327bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-b9de5d42-2219-4e18-89c2-26e98a8d9866,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-400a7dc4-eb0c-474a-be56-755e1c927b30,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-42216a87-939d-4054-922e-6bcdb09fd1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-1d2c3ae4-c8b0-4c55-b778-9e9bd6f02242,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-e82b1147-7e92-402a-acb0-16aa4d32d616,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-90fd40dd-6a77-431f-b2c9-784fdb3f572a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170385950-172.17.0.16-1597534038880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33560,DS-26e939c8-9907-493f-9107-853bdaf23006,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-bc287c66-c088-47f2-9479-2c3806b327bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-b9de5d42-2219-4e18-89c2-26e98a8d9866,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-400a7dc4-eb0c-474a-be56-755e1c927b30,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-42216a87-939d-4054-922e-6bcdb09fd1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-1d2c3ae4-c8b0-4c55-b778-9e9bd6f02242,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-e82b1147-7e92-402a-acb0-16aa4d32d616,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-90fd40dd-6a77-431f-b2c9-784fdb3f572a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217894390-172.17.0.16-1597534305339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-560d3632-e816-484a-8aaa-4823a15d7af5,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-0b82767b-5a85-4746-a84e-0b29f16241c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-ce84c6c9-7567-42f3-85c2-b9ee22980eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-672f32c1-e697-430a-bb89-70a9c27d39db,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-e576ad55-fa2b-47d1-b11a-c6a5fe53e468,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-8622bcbd-4b8c-4db1-a087-90f46f380275,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-e4bd84f4-d736-4869-816e-dfc72cb9152e,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-39defd03-73a9-4260-800a-83037b63ad4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217894390-172.17.0.16-1597534305339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-560d3632-e816-484a-8aaa-4823a15d7af5,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-0b82767b-5a85-4746-a84e-0b29f16241c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-ce84c6c9-7567-42f3-85c2-b9ee22980eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-672f32c1-e697-430a-bb89-70a9c27d39db,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-e576ad55-fa2b-47d1-b11a-c6a5fe53e468,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-8622bcbd-4b8c-4db1-a087-90f46f380275,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-e4bd84f4-d736-4869-816e-dfc72cb9152e,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-39defd03-73a9-4260-800a-83037b63ad4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135367533-172.17.0.16-1597536760552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-4f5243a9-656f-4269-967e-f8f72fec1907,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-c6219295-ae63-4452-961f-35f501af479a,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-a36ba11c-6466-48d4-a283-3e79b88e2867,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-2f8b9013-e0b0-4aee-8887-230e7502b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-77cac511-9337-4d87-b469-935d38adf5de,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-4cec1807-b84d-4cc1-863a-f8bbe237e935,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-7dfa7283-779c-49c9-8bda-dd86e97400c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-8cb5747e-1048-4cd8-a4b6-12cac423e604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135367533-172.17.0.16-1597536760552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-4f5243a9-656f-4269-967e-f8f72fec1907,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-c6219295-ae63-4452-961f-35f501af479a,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-a36ba11c-6466-48d4-a283-3e79b88e2867,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-2f8b9013-e0b0-4aee-8887-230e7502b7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-77cac511-9337-4d87-b469-935d38adf5de,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-4cec1807-b84d-4cc1-863a-f8bbe237e935,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-7dfa7283-779c-49c9-8bda-dd86e97400c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-8cb5747e-1048-4cd8-a4b6-12cac423e604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102029892-172.17.0.16-1597536905262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41271,DS-7b09212a-9bc1-4b1e-9ce0-92fea9c2113c,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-8a0aa1b1-d721-4fa2-a184-b30d223f961c,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-309bfd5d-f94f-4f51-b806-bd5bd2c43faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-1d18e8cf-2421-4004-a46b-c9cb23813cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-69f9389e-8faa-423d-ab57-dd96ad7c193c,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-ee356477-1545-4a38-b69a-1ff2d280e965,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-72e66256-0fe5-448c-89ea-986a3bec7bae,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-7c1db084-e79d-446d-902f-0c1b7acad3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102029892-172.17.0.16-1597536905262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41271,DS-7b09212a-9bc1-4b1e-9ce0-92fea9c2113c,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-8a0aa1b1-d721-4fa2-a184-b30d223f961c,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-309bfd5d-f94f-4f51-b806-bd5bd2c43faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-1d18e8cf-2421-4004-a46b-c9cb23813cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-69f9389e-8faa-423d-ab57-dd96ad7c193c,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-ee356477-1545-4a38-b69a-1ff2d280e965,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-72e66256-0fe5-448c-89ea-986a3bec7bae,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-7c1db084-e79d-446d-902f-0c1b7acad3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512130421-172.17.0.16-1597537546311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-17d18d2c-09b8-473d-af98-44692c43b192,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-4426c591-d2ee-49a5-8833-b7c7081863fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f7808341-bcc0-4a99-a205-35df07800c42,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-4351f22b-d5a7-4696-b420-243b22ca5674,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-fb489fec-9283-474b-8aee-e77c67269531,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-24f55bec-e1d0-4553-8c1a-92031ed75b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-b372109d-3aaf-4b7a-a943-0e0951dbcb75,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-cdc2ca85-8279-4c4f-b05a-41f4445ea58d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512130421-172.17.0.16-1597537546311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-17d18d2c-09b8-473d-af98-44692c43b192,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-4426c591-d2ee-49a5-8833-b7c7081863fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f7808341-bcc0-4a99-a205-35df07800c42,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-4351f22b-d5a7-4696-b420-243b22ca5674,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-fb489fec-9283-474b-8aee-e77c67269531,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-24f55bec-e1d0-4553-8c1a-92031ed75b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-b372109d-3aaf-4b7a-a943-0e0951dbcb75,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-cdc2ca85-8279-4c4f-b05a-41f4445ea58d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976381551-172.17.0.16-1597537580098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41216,DS-0ba30f9e-d05d-4dbd-b200-89d5829291a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-0fcc39e6-1271-4599-89fd-5330b731aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-3c84e503-ac22-40ff-9ed2-03126c5d2959,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-0e8ee19d-3dc9-4eab-9187-0c8605b8c6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-008dee49-2d78-4737-9f93-7e14f41b27ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-724ab67f-8723-4b57-b4ec-009d1d1249a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-f250442c-132f-4114-9a9a-5b1ca07c848d,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-4de3a5d3-3c0f-4c1a-8c1a-a1199f6dae39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976381551-172.17.0.16-1597537580098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41216,DS-0ba30f9e-d05d-4dbd-b200-89d5829291a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-0fcc39e6-1271-4599-89fd-5330b731aea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-3c84e503-ac22-40ff-9ed2-03126c5d2959,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-0e8ee19d-3dc9-4eab-9187-0c8605b8c6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-008dee49-2d78-4737-9f93-7e14f41b27ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-724ab67f-8723-4b57-b4ec-009d1d1249a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-f250442c-132f-4114-9a9a-5b1ca07c848d,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-4de3a5d3-3c0f-4c1a-8c1a-a1199f6dae39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930898748-172.17.0.16-1597539232255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-8fb0dc5b-20e8-4205-814a-571baa8e2abc,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-0b92a44c-8b1e-431f-8fe2-f8c5122d31ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-8c072bcd-68de-4ab8-b16d-832874daa8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-845203f7-0704-43b1-848f-e1aa219f7b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-31ef96c0-edc6-4b2d-bd1a-ce4a067eda24,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-a891ff18-f514-4d57-96f0-f95cf63d650c,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-12c2a148-2653-4df1-9267-0f9b2f70a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-fc83a4b4-56f0-4c5b-a74f-814579d7c8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930898748-172.17.0.16-1597539232255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-8fb0dc5b-20e8-4205-814a-571baa8e2abc,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-0b92a44c-8b1e-431f-8fe2-f8c5122d31ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-8c072bcd-68de-4ab8-b16d-832874daa8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-845203f7-0704-43b1-848f-e1aa219f7b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-31ef96c0-edc6-4b2d-bd1a-ce4a067eda24,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-a891ff18-f514-4d57-96f0-f95cf63d650c,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-12c2a148-2653-4df1-9267-0f9b2f70a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-fc83a4b4-56f0-4c5b-a74f-814579d7c8cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: false positive !!!
Total execution time in seconds : 5759
