reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85829560-172.17.0.6-1597569601498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-f9238b61-3a8c-4a57-ab46-096d6be9d102,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-bfca86f1-e0d0-4e70-87d4-866b1105994e,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-d3f40ef5-40fd-4aa0-ba69-cd95c1894c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-f9bc98a6-c452-4563-886a-7c643c8cbcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-a5efb614-160e-4215-b868-81b7cf44c899,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-2732b17e-f6c7-4807-9a81-cffcb437b7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-374db162-f023-4b06-beae-94a5609fba72,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-46a3f86c-c4e6-4810-9bbe-61aa67cfee8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85829560-172.17.0.6-1597569601498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-f9238b61-3a8c-4a57-ab46-096d6be9d102,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-bfca86f1-e0d0-4e70-87d4-866b1105994e,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-d3f40ef5-40fd-4aa0-ba69-cd95c1894c11,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-f9bc98a6-c452-4563-886a-7c643c8cbcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-a5efb614-160e-4215-b868-81b7cf44c899,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-2732b17e-f6c7-4807-9a81-cffcb437b7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-374db162-f023-4b06-beae-94a5609fba72,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-46a3f86c-c4e6-4810-9bbe-61aa67cfee8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272498112-172.17.0.6-1597569639238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-645584fa-a89d-466b-8baf-149e7c4644b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-42d5b81b-edb2-463a-a772-b05ca973b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-0becfe6e-08b8-4af7-9180-8be32770d765,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-fb06b1f8-0cd2-4b9b-bcac-ded82a25a35f,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-550e4a2a-1f04-465f-bc33-17b859dc9638,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-968b2391-bec1-49f1-a849-f9b3909911c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-4c353734-a03b-4b4b-b1b1-9201d79ee35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-ad6b0969-6293-491c-a8ba-030d321c3c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1272498112-172.17.0.6-1597569639238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-645584fa-a89d-466b-8baf-149e7c4644b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-42d5b81b-edb2-463a-a772-b05ca973b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-0becfe6e-08b8-4af7-9180-8be32770d765,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-fb06b1f8-0cd2-4b9b-bcac-ded82a25a35f,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-550e4a2a-1f04-465f-bc33-17b859dc9638,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-968b2391-bec1-49f1-a849-f9b3909911c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-4c353734-a03b-4b4b-b1b1-9201d79ee35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-ad6b0969-6293-491c-a8ba-030d321c3c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475515320-172.17.0.6-1597569717772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-f023ac8d-2d25-43b0-a761-4ccb9101f5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-3a39e874-570b-4c46-bb4b-b7f8bbfb573e,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-a6f3b17d-0657-4285-8113-5b04f8324a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-a45a9e00-a6ab-4fd6-8679-91b681bb0a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-282f90e9-2fb1-481d-8e9f-5580728aeccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-e220a451-54a4-485a-8f46-a38e0b4dab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-db73c4be-7910-4539-a9aa-b510254199cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-dae27de0-af9d-4bfd-9352-4de254954c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475515320-172.17.0.6-1597569717772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-f023ac8d-2d25-43b0-a761-4ccb9101f5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-3a39e874-570b-4c46-bb4b-b7f8bbfb573e,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-a6f3b17d-0657-4285-8113-5b04f8324a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-a45a9e00-a6ab-4fd6-8679-91b681bb0a96,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-282f90e9-2fb1-481d-8e9f-5580728aeccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-e220a451-54a4-485a-8f46-a38e0b4dab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-db73c4be-7910-4539-a9aa-b510254199cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-dae27de0-af9d-4bfd-9352-4de254954c14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383147527-172.17.0.6-1597569832480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-46703cb6-4d26-4b1e-955a-7a644ad4442a,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-353061a7-d67a-4cf9-868d-dd0fc5f3588e,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-9be16407-809b-456a-95af-3e582cd06a32,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-e1661af1-4b56-4215-b2c4-14642b107085,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-a94d0016-ad48-4db9-91f6-d8ced910cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-77f8f54d-84d2-4c51-b859-defd6ea48089,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-f98c4a4a-e17d-4a57-83c1-567fe454a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-ee4870d9-aae7-43ca-901c-37b397f446f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383147527-172.17.0.6-1597569832480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-46703cb6-4d26-4b1e-955a-7a644ad4442a,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-353061a7-d67a-4cf9-868d-dd0fc5f3588e,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-9be16407-809b-456a-95af-3e582cd06a32,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-e1661af1-4b56-4215-b2c4-14642b107085,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-a94d0016-ad48-4db9-91f6-d8ced910cf41,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-77f8f54d-84d2-4c51-b859-defd6ea48089,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-f98c4a4a-e17d-4a57-83c1-567fe454a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-ee4870d9-aae7-43ca-901c-37b397f446f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799421623-172.17.0.6-1597569872587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-8fa50aec-c03d-4c1d-8ab8-964d11a98aff,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-439294ce-41da-4f52-9a25-e81b0f71a4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-4513e968-63c2-427f-a131-59542bcbb851,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-bee5af69-feaf-4f50-8a3d-277f46b180aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-d010c1b9-8b39-4491-a8a9-0e7d8c03637b,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-6fbef194-d3cd-47a0-9559-bc70102e153c,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-5bfe7981-3d52-413f-bb16-166de1e000a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-e4c224dc-d7fd-4664-9f94-c307d5ca4768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799421623-172.17.0.6-1597569872587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-8fa50aec-c03d-4c1d-8ab8-964d11a98aff,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-439294ce-41da-4f52-9a25-e81b0f71a4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-4513e968-63c2-427f-a131-59542bcbb851,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-bee5af69-feaf-4f50-8a3d-277f46b180aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-d010c1b9-8b39-4491-a8a9-0e7d8c03637b,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-6fbef194-d3cd-47a0-9559-bc70102e153c,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-5bfe7981-3d52-413f-bb16-166de1e000a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-e4c224dc-d7fd-4664-9f94-c307d5ca4768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744899294-172.17.0.6-1597570258304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41125,DS-501dc29a-5827-4312-9722-8a302310b515,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-fc7879dd-fb53-4fa5-ac1d-63b41510f06b,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-e0c5228e-732a-4b6d-8903-c37149bb4ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-bb74db18-b440-4cac-9e16-1760b2f51a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-a3d4b6cf-df91-4c40-9977-25de99466522,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-5dc8184e-a71e-407b-9a62-1f7bf89ba783,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-c602b058-8673-491c-98d4-0f7f3f920f48,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-28d2a74a-5f86-404e-81b8-1157cc20fd57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744899294-172.17.0.6-1597570258304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41125,DS-501dc29a-5827-4312-9722-8a302310b515,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-fc7879dd-fb53-4fa5-ac1d-63b41510f06b,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-e0c5228e-732a-4b6d-8903-c37149bb4ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-bb74db18-b440-4cac-9e16-1760b2f51a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-a3d4b6cf-df91-4c40-9977-25de99466522,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-5dc8184e-a71e-407b-9a62-1f7bf89ba783,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-c602b058-8673-491c-98d4-0f7f3f920f48,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-28d2a74a-5f86-404e-81b8-1157cc20fd57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636747402-172.17.0.6-1597570419398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37645,DS-c720eed6-83a2-4b79-a86a-ed4e3e89999a,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-f4e53713-a71f-42ad-b8cb-062b4ce5ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-65f8b238-7325-436c-91b1-7cd66294a640,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-4a5a1450-54ef-47d0-86de-a4a8c05e12af,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-33c84fe2-c74c-45e9-a895-86aeb17bd36b,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-4ce68d82-31df-4da1-bd46-9285550a3815,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-9d039ea0-e122-4b76-bdef-cead07b43b02,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-c84ed8a2-a2ad-4591-a794-eb190fc81678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636747402-172.17.0.6-1597570419398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37645,DS-c720eed6-83a2-4b79-a86a-ed4e3e89999a,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-f4e53713-a71f-42ad-b8cb-062b4ce5ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-65f8b238-7325-436c-91b1-7cd66294a640,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-4a5a1450-54ef-47d0-86de-a4a8c05e12af,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-33c84fe2-c74c-45e9-a895-86aeb17bd36b,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-4ce68d82-31df-4da1-bd46-9285550a3815,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-9d039ea0-e122-4b76-bdef-cead07b43b02,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-c84ed8a2-a2ad-4591-a794-eb190fc81678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376959196-172.17.0.6-1597570538613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-803764c1-9e4b-4b1d-95eb-38cd3b7169d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-1d8ea756-befd-4e50-95b2-26e8b65fd535,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-dda9dbe2-4491-4e1b-8847-2e1303944b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-2181ef96-86f0-4668-a903-01a4be7ecbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-56ee9ce3-7eec-41ef-9b31-7f58f4c0314c,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-d246fcd1-ab28-4dc3-bfa9-f8a834814e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-53920ed2-900f-4c9e-b11a-5365e37a2396,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-417c10ee-9e47-4cc8-bc82-7e1f6b15fadf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376959196-172.17.0.6-1597570538613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-803764c1-9e4b-4b1d-95eb-38cd3b7169d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-1d8ea756-befd-4e50-95b2-26e8b65fd535,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-dda9dbe2-4491-4e1b-8847-2e1303944b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-2181ef96-86f0-4668-a903-01a4be7ecbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-56ee9ce3-7eec-41ef-9b31-7f58f4c0314c,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-d246fcd1-ab28-4dc3-bfa9-f8a834814e24,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-53920ed2-900f-4c9e-b11a-5365e37a2396,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-417c10ee-9e47-4cc8-bc82-7e1f6b15fadf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020892424-172.17.0.6-1597571243920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-2e369a6f-35b6-43c3-bd6e-c512369e3686,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-d8245bdb-bc46-431a-90f2-a5203f7a3197,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-e3272868-e6b6-4de0-bc53-5a59ac89ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-2e0fef99-4d4e-4922-a9de-0c1da7e2890a,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-57ebeb0d-8cae-44d5-830d-feea8ff3b8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-62a8aa6f-b59d-4330-a3e5-945e6065f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-8f773061-7394-4ae1-bd0f-b2c579106ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-dd972dbb-fd85-4db8-aaa5-6a3a732d72ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020892424-172.17.0.6-1597571243920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-2e369a6f-35b6-43c3-bd6e-c512369e3686,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-d8245bdb-bc46-431a-90f2-a5203f7a3197,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-e3272868-e6b6-4de0-bc53-5a59ac89ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-2e0fef99-4d4e-4922-a9de-0c1da7e2890a,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-57ebeb0d-8cae-44d5-830d-feea8ff3b8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-62a8aa6f-b59d-4330-a3e5-945e6065f3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-8f773061-7394-4ae1-bd0f-b2c579106ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-dd972dbb-fd85-4db8-aaa5-6a3a732d72ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096335250-172.17.0.6-1597571391589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40968,DS-0b508753-22ec-4c09-9d56-298f1f886d30,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-d14a4455-c214-4065-993d-d9cfb424aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-d29c3970-8928-4bf3-9b54-99975ef6b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-2be47351-6e60-4492-a666-0856d2bdceb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-7b803bf8-acb8-4dd8-b21b-493fd793cf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-c0a1e74f-116f-4864-8d00-ea831ef0ea70,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-268be4bd-4561-42b8-b2dc-4860646e9f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-bb075e41-d6ab-48fc-942e-251255e96f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096335250-172.17.0.6-1597571391589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40968,DS-0b508753-22ec-4c09-9d56-298f1f886d30,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-d14a4455-c214-4065-993d-d9cfb424aed4,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-d29c3970-8928-4bf3-9b54-99975ef6b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-2be47351-6e60-4492-a666-0856d2bdceb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-7b803bf8-acb8-4dd8-b21b-493fd793cf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-c0a1e74f-116f-4864-8d00-ea831ef0ea70,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-268be4bd-4561-42b8-b2dc-4860646e9f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-bb075e41-d6ab-48fc-942e-251255e96f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753554687-172.17.0.6-1597572601209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35958,DS-af349547-dc99-4604-9aa4-59cd7b1984a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-ee3b1e0e-2cf8-4dac-8c3b-6801eea21e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-41b748f8-16ca-4120-b68e-b659e271b7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-863ca2f2-42cb-4d36-82f1-46d254caa0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-1166d3b6-5ff1-4562-a7ec-e24fa115d210,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-d83ee94b-d102-4627-a170-8fe1c7519df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-7ad89bb8-e054-41d5-afed-717c6c846da7,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-2264b69a-35eb-4513-867b-f802f58b9932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753554687-172.17.0.6-1597572601209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35958,DS-af349547-dc99-4604-9aa4-59cd7b1984a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-ee3b1e0e-2cf8-4dac-8c3b-6801eea21e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-41b748f8-16ca-4120-b68e-b659e271b7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-863ca2f2-42cb-4d36-82f1-46d254caa0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-1166d3b6-5ff1-4562-a7ec-e24fa115d210,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-d83ee94b-d102-4627-a170-8fe1c7519df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-7ad89bb8-e054-41d5-afed-717c6c846da7,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-2264b69a-35eb-4513-867b-f802f58b9932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064185583-172.17.0.6-1597574050080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39830,DS-2a078af3-9b4d-4569-8d92-b28c03cda6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-ccce4f2d-304f-4a03-89fc-2af117b0050d,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-b4a741fc-a118-4261-9bb3-6e72d4385056,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-24c9280c-7732-4fac-925d-7936b3f8fd41,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-bb12929d-638d-48f2-be69-802e00bab047,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-6b507484-c352-4492-8f89-b0a62d98d711,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-b1c49a14-cf70-4b9c-86b3-8f005440221c,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-f2b29f84-f2bc-46be-95e9-e21f93188444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064185583-172.17.0.6-1597574050080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39830,DS-2a078af3-9b4d-4569-8d92-b28c03cda6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-ccce4f2d-304f-4a03-89fc-2af117b0050d,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-b4a741fc-a118-4261-9bb3-6e72d4385056,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-24c9280c-7732-4fac-925d-7936b3f8fd41,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-bb12929d-638d-48f2-be69-802e00bab047,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-6b507484-c352-4492-8f89-b0a62d98d711,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-b1c49a14-cf70-4b9c-86b3-8f005440221c,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-f2b29f84-f2bc-46be-95e9-e21f93188444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480496722-172.17.0.6-1597574200179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-f43d03bf-e2c4-4702-9d90-01039ca42807,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-6797a7be-a376-4643-b6ca-c4012ecf6fad,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-6e113ede-f4a3-4210-a4b4-131b10914f53,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-4662db1e-8a33-4456-96bb-f3c5f9d1f970,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-5b4968f6-f3d9-46fc-8e9a-0bfcbed7dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-213bdcd4-0100-4cc4-bdcf-b34eaab6537f,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-874a1798-88ea-495d-a3a4-e564c0d8ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-b3d2695c-fd91-428f-aea3-54e22ca0024c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480496722-172.17.0.6-1597574200179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-f43d03bf-e2c4-4702-9d90-01039ca42807,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-6797a7be-a376-4643-b6ca-c4012ecf6fad,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-6e113ede-f4a3-4210-a4b4-131b10914f53,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-4662db1e-8a33-4456-96bb-f3c5f9d1f970,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-5b4968f6-f3d9-46fc-8e9a-0bfcbed7dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-213bdcd4-0100-4cc4-bdcf-b34eaab6537f,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-874a1798-88ea-495d-a3a4-e564c0d8ae96,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-b3d2695c-fd91-428f-aea3-54e22ca0024c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5810
