reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823492382-172.17.0.2-1597563864732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-a34808b6-d882-425e-9b3e-374872bb6ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-8cc72f2d-8883-4d10-83c5-2205e3e3ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-d7e14cc6-f85f-4e33-89f2-82651cc39521,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-9d6ee9b2-d353-4939-be5d-7593e6661a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-902c6288-2bcc-4fb1-86f2-99804cb59e22,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-01aad3dc-d38b-43d1-86c9-28cf8dd88506,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-8b24a5b4-02f2-447e-96d0-c3abaa2c22cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-07750e44-38fb-4344-8525-3db23e4691ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823492382-172.17.0.2-1597563864732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-a34808b6-d882-425e-9b3e-374872bb6ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-8cc72f2d-8883-4d10-83c5-2205e3e3ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-d7e14cc6-f85f-4e33-89f2-82651cc39521,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-9d6ee9b2-d353-4939-be5d-7593e6661a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-902c6288-2bcc-4fb1-86f2-99804cb59e22,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-01aad3dc-d38b-43d1-86c9-28cf8dd88506,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-8b24a5b4-02f2-447e-96d0-c3abaa2c22cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-07750e44-38fb-4344-8525-3db23e4691ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059892989-172.17.0.2-1597563992140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-5ee8a998-5882-4e6a-ac4a-149ae709e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-739e2705-20d1-4fc2-851c-bc375da3f322,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-7dbe75f0-7ae4-49c5-b101-5c49f61e7a18,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-2947dcec-8f05-4ae4-a5f5-7ba509cdd5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-7f1a562a-66e5-45fa-a20a-cfb42b395ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-a380dd95-aec2-4b9a-a896-f794cf97bfda,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-110c9bcf-849f-4199-9f59-2e5253663c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-66c72ea2-843a-4609-9ae5-b75ecc419431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059892989-172.17.0.2-1597563992140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37284,DS-5ee8a998-5882-4e6a-ac4a-149ae709e3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-739e2705-20d1-4fc2-851c-bc375da3f322,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-7dbe75f0-7ae4-49c5-b101-5c49f61e7a18,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-2947dcec-8f05-4ae4-a5f5-7ba509cdd5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-7f1a562a-66e5-45fa-a20a-cfb42b395ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-a380dd95-aec2-4b9a-a896-f794cf97bfda,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-110c9bcf-849f-4199-9f59-2e5253663c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-66c72ea2-843a-4609-9ae5-b75ecc419431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948390146-172.17.0.2-1597564295942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35906,DS-24652771-ac74-473e-817d-b6f8f7ea107e,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-eea4dacd-2dd0-464f-a99c-0ddf7e644ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-442174b4-6f21-4881-ac6c-fa7093b04824,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-c41031c4-284a-416f-8ca3-c494e7fa500c,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-1b0b020d-6830-45d4-bf2a-70390086411b,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-577b6aeb-2ccf-46b4-aaa6-09b7a4c71884,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-435cdfea-7efd-488e-ac8b-758e4a927daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-2ce51343-4fcf-4f75-a186-1c76d3c78c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948390146-172.17.0.2-1597564295942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35906,DS-24652771-ac74-473e-817d-b6f8f7ea107e,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-eea4dacd-2dd0-464f-a99c-0ddf7e644ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-442174b4-6f21-4881-ac6c-fa7093b04824,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-c41031c4-284a-416f-8ca3-c494e7fa500c,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-1b0b020d-6830-45d4-bf2a-70390086411b,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-577b6aeb-2ccf-46b4-aaa6-09b7a4c71884,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-435cdfea-7efd-488e-ac8b-758e4a927daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-2ce51343-4fcf-4f75-a186-1c76d3c78c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808713068-172.17.0.2-1597565643421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44290,DS-b44ff12c-bc0a-472b-8025-71e6ce3feec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-bdd1d261-f9ba-4bfa-8e9a-734245fd7926,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-74a87720-721a-4136-b73b-b1836044275e,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-af9d0184-405d-4414-8580-66a9743cb71a,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-e532d7ae-e868-45ce-bf78-90fd85d1e72f,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-19623dbf-4786-4ab8-aee6-e13ff3e8dee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-f62616af-edd0-42ea-a06e-fc8f19e4f796,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-a8a30a40-c758-4852-a52f-71d7f76fb50b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808713068-172.17.0.2-1597565643421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44290,DS-b44ff12c-bc0a-472b-8025-71e6ce3feec6,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-bdd1d261-f9ba-4bfa-8e9a-734245fd7926,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-74a87720-721a-4136-b73b-b1836044275e,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-af9d0184-405d-4414-8580-66a9743cb71a,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-e532d7ae-e868-45ce-bf78-90fd85d1e72f,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-19623dbf-4786-4ab8-aee6-e13ff3e8dee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-f62616af-edd0-42ea-a06e-fc8f19e4f796,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-a8a30a40-c758-4852-a52f-71d7f76fb50b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980439499-172.17.0.2-1597565722001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43599,DS-9ca48cb3-9fc1-4500-8f09-4a9a7b834a55,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-f5116d68-f7ba-4178-9d7c-daa892f1ee03,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-bfd7fa66-fb4f-4d3d-8f30-6a7c934f8d31,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-50497ee1-4d27-4a80-9db5-d6675f7fb698,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-d80194f8-0c2e-4af0-8dac-0afcde90c831,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-85c8e7b3-4e11-496b-acb3-23eda967dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-95c81593-ea11-4fef-98a3-630c32d96391,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-9473110f-ef23-4a56-800b-baae963f4005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980439499-172.17.0.2-1597565722001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43599,DS-9ca48cb3-9fc1-4500-8f09-4a9a7b834a55,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-f5116d68-f7ba-4178-9d7c-daa892f1ee03,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-bfd7fa66-fb4f-4d3d-8f30-6a7c934f8d31,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-50497ee1-4d27-4a80-9db5-d6675f7fb698,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-d80194f8-0c2e-4af0-8dac-0afcde90c831,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-85c8e7b3-4e11-496b-acb3-23eda967dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-95c81593-ea11-4fef-98a3-630c32d96391,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-9473110f-ef23-4a56-800b-baae963f4005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897007734-172.17.0.2-1597566220439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42367,DS-1eeb6533-f5e4-489b-bd41-811bcbec5872,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-7f301913-9110-495f-84a8-746c9aba3b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-fe2aad12-2170-4333-b986-6460accb7697,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-0251cd5c-a98c-4b63-9b8f-fac4bfbc4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-293e0cec-1e7d-4026-b662-10c752943fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-fe9e9251-2e04-4f2e-a96e-39e8a0ef3c67,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-23861ec0-eafc-4581-8fb9-967ecdc63050,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-b548c3c7-8df2-47a3-9100-edf8193fd935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897007734-172.17.0.2-1597566220439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42367,DS-1eeb6533-f5e4-489b-bd41-811bcbec5872,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-7f301913-9110-495f-84a8-746c9aba3b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-fe2aad12-2170-4333-b986-6460accb7697,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-0251cd5c-a98c-4b63-9b8f-fac4bfbc4dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-293e0cec-1e7d-4026-b662-10c752943fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-fe9e9251-2e04-4f2e-a96e-39e8a0ef3c67,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-23861ec0-eafc-4581-8fb9-967ecdc63050,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-b548c3c7-8df2-47a3-9100-edf8193fd935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758382444-172.17.0.2-1597566255936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-eff64008-66d9-4f17-8505-2c3ab52bc4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-3c436025-12f1-474d-a5eb-87f878e53db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-f7c881a2-0cfd-479f-aaab-847aa9d221d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-f59106df-79d7-40a0-8460-493215b37890,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-0fc20028-b0e0-4459-a277-36f2babd51a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-0b1bfd52-7fd3-46f1-8da0-6e78ea4a7586,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-f53c5ca2-ea5e-46c3-9ef7-0a4f5f229bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-4f851bad-4d46-4c7b-a2fa-c1956c1cbb8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1758382444-172.17.0.2-1597566255936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-eff64008-66d9-4f17-8505-2c3ab52bc4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-3c436025-12f1-474d-a5eb-87f878e53db5,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-f7c881a2-0cfd-479f-aaab-847aa9d221d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-f59106df-79d7-40a0-8460-493215b37890,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-0fc20028-b0e0-4459-a277-36f2babd51a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-0b1bfd52-7fd3-46f1-8da0-6e78ea4a7586,DISK], DatanodeInfoWithStorage[127.0.0.1:44498,DS-f53c5ca2-ea5e-46c3-9ef7-0a4f5f229bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-4f851bad-4d46-4c7b-a2fa-c1956c1cbb8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135178750-172.17.0.2-1597566299132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-fb2190b6-c630-41e7-91a3-5028452e845c,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-4addf26f-43d3-4257-bb32-b53ab7018d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-a05a377e-6092-4946-9193-7396a7383a81,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-6e7de61b-95f0-4b55-8fd2-2d942e265e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-59d7bb93-b0b8-4d73-9906-91f7d54f27fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-93ad3964-de22-409a-af4a-cde8f72acd56,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-fb1fa582-f63b-4932-aaa1-77056f8bbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-f98b6514-a6ef-4e1a-9830-1d337c869239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135178750-172.17.0.2-1597566299132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-fb2190b6-c630-41e7-91a3-5028452e845c,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-4addf26f-43d3-4257-bb32-b53ab7018d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-a05a377e-6092-4946-9193-7396a7383a81,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-6e7de61b-95f0-4b55-8fd2-2d942e265e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-59d7bb93-b0b8-4d73-9906-91f7d54f27fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-93ad3964-de22-409a-af4a-cde8f72acd56,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-fb1fa582-f63b-4932-aaa1-77056f8bbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-f98b6514-a6ef-4e1a-9830-1d337c869239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909074680-172.17.0.2-1597566457985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-1148355a-94c2-44f8-bcd1-db47e5a357b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-397fecdc-21fb-475d-87ee-039ce68c0ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-69fa3d33-1f10-4b91-ae2d-839ac0b535fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-ae4d80e3-237d-4cd5-92c1-3443a1cc7bda,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-5496f266-cb12-46ea-91f6-b12cc520c3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-ec691db5-573a-43fc-9413-d060d76e8417,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-7419128d-c11f-4b53-b0b0-2ce428a20bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-9dfa2aed-fb8e-42b2-aab7-3439536fade9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909074680-172.17.0.2-1597566457985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-1148355a-94c2-44f8-bcd1-db47e5a357b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-397fecdc-21fb-475d-87ee-039ce68c0ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-69fa3d33-1f10-4b91-ae2d-839ac0b535fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-ae4d80e3-237d-4cd5-92c1-3443a1cc7bda,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-5496f266-cb12-46ea-91f6-b12cc520c3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-ec691db5-573a-43fc-9413-d060d76e8417,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-7419128d-c11f-4b53-b0b0-2ce428a20bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-9dfa2aed-fb8e-42b2-aab7-3439536fade9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363214282-172.17.0.2-1597566661452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37521,DS-0a748bc7-62f5-468a-9e8c-3b72fe210e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-abc8211f-18be-4897-8f34-8c1a89b93b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-1a5a99d4-f090-49ff-895b-1a2879fef1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-e892e81a-914e-4c75-b194-82cfe0c7a421,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-bcf5db68-2431-487c-a02d-79e594ba01d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-129c9333-9323-486e-87db-2190fe27b228,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-c9e24fe7-404a-4db8-bc36-ede6ec336303,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-d292a45f-cab1-443b-a551-b5ded4a989ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363214282-172.17.0.2-1597566661452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37521,DS-0a748bc7-62f5-468a-9e8c-3b72fe210e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-abc8211f-18be-4897-8f34-8c1a89b93b43,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-1a5a99d4-f090-49ff-895b-1a2879fef1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-e892e81a-914e-4c75-b194-82cfe0c7a421,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-bcf5db68-2431-487c-a02d-79e594ba01d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-129c9333-9323-486e-87db-2190fe27b228,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-c9e24fe7-404a-4db8-bc36-ede6ec336303,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-d292a45f-cab1-443b-a551-b5ded4a989ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102348485-172.17.0.2-1597567053624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-0b7fd52d-a002-4905-8511-c3a22756bdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-4104a99c-9087-4a88-991e-9b2a319b90e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-94bfd69e-797f-48fb-9dcb-447fc4411551,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-095f087e-db75-4e07-ad7a-10b276c3508a,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-fd542b43-edae-4424-8e18-cb052557844d,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ec162080-f087-4444-86f5-d717c306faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-3dfd5d14-58bf-4da3-b22f-270b5c2fbf90,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-8785051e-84e9-4563-983d-afb9dc0f8e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102348485-172.17.0.2-1597567053624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-0b7fd52d-a002-4905-8511-c3a22756bdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-4104a99c-9087-4a88-991e-9b2a319b90e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-94bfd69e-797f-48fb-9dcb-447fc4411551,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-095f087e-db75-4e07-ad7a-10b276c3508a,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-fd542b43-edae-4424-8e18-cb052557844d,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ec162080-f087-4444-86f5-d717c306faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-3dfd5d14-58bf-4da3-b22f-270b5c2fbf90,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-8785051e-84e9-4563-983d-afb9dc0f8e85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110800244-172.17.0.2-1597567365467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-345a0842-1bee-410b-9a49-26ace5034429,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-e9f9e1f6-8ca0-41c0-bd08-c28834790512,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-91a60980-ad72-48b1-adfd-8c36c98b6483,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-66a7e654-389b-402d-b7f4-0143299c6b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-3d141591-23f0-48d9-a9c7-364b4c71c2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-6fca8249-4f1e-4da1-985d-c6b362587f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-d20043c1-fe9c-4938-9259-e83b330c4f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-c5ebe694-7ccd-476a-89c3-133a4d798c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2110800244-172.17.0.2-1597567365467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-345a0842-1bee-410b-9a49-26ace5034429,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-e9f9e1f6-8ca0-41c0-bd08-c28834790512,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-91a60980-ad72-48b1-adfd-8c36c98b6483,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-66a7e654-389b-402d-b7f4-0143299c6b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-3d141591-23f0-48d9-a9c7-364b4c71c2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-6fca8249-4f1e-4da1-985d-c6b362587f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-d20043c1-fe9c-4938-9259-e83b330c4f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-c5ebe694-7ccd-476a-89c3-133a4d798c33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532676185-172.17.0.2-1597567804829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-5c0eb4df-1a14-4366-87f7-970c0f5d5a12,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-abb42dc0-d7b2-4705-b79c-5eb61d311b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-133d9d4c-3ac2-4d40-aee9-c36ad0d992e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-502ac89e-c9c5-4115-ad5a-053705c9a7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-da3023b6-cf12-4245-a1db-08d5c97a25c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-30a10147-4d04-459f-954b-fcb7ed9ba85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-53df8dcb-382f-4afd-9a76-edf79289b089,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-c7293cf0-64a7-43bd-9b89-58220c17c3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532676185-172.17.0.2-1597567804829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41020,DS-5c0eb4df-1a14-4366-87f7-970c0f5d5a12,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-abb42dc0-d7b2-4705-b79c-5eb61d311b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-133d9d4c-3ac2-4d40-aee9-c36ad0d992e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-502ac89e-c9c5-4115-ad5a-053705c9a7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-da3023b6-cf12-4245-a1db-08d5c97a25c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-30a10147-4d04-459f-954b-fcb7ed9ba85f,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-53df8dcb-382f-4afd-9a76-edf79289b089,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-c7293cf0-64a7-43bd-9b89-58220c17c3fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087083477-172.17.0.2-1597567956815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45529,DS-aa2f4bbb-c184-4476-824f-29502654b072,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-d41c6455-cb7e-40b8-9aac-adc4dbb02b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-2ba00866-1d4b-48b2-88b9-52d5e49a1fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-c7e50be4-19c5-40f2-9f29-5dc0be1c4e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-7f86491c-7554-47b7-93d4-4d2502361baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-7f560d42-2cd7-465c-b722-db04693a3227,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-ca95d7c5-2513-4670-9347-697abe8b127e,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-6355278c-1984-47ee-b4f6-07d4163f7538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087083477-172.17.0.2-1597567956815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45529,DS-aa2f4bbb-c184-4476-824f-29502654b072,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-d41c6455-cb7e-40b8-9aac-adc4dbb02b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-2ba00866-1d4b-48b2-88b9-52d5e49a1fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-c7e50be4-19c5-40f2-9f29-5dc0be1c4e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-7f86491c-7554-47b7-93d4-4d2502361baa,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-7f560d42-2cd7-465c-b722-db04693a3227,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-ca95d7c5-2513-4670-9347-697abe8b127e,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-6355278c-1984-47ee-b4f6-07d4163f7538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886572358-172.17.0.2-1597568198047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-14c0d37d-7c7d-4353-afdf-4fe7ec696ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-65813b3c-3144-4fa3-9408-d4fa38d722f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-7733e4f7-1910-49a6-8882-beba13b4f238,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-e8ddafbd-af12-470c-bed2-70df751cfc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-8de32437-480c-4980-bf6c-deac6567ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-03e520ed-a738-4963-86ab-f77a7a3b3d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-3afada36-eaf9-453b-ae33-689ae09ef0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-ab446a85-052e-4d1a-a1db-a56faf20f962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886572358-172.17.0.2-1597568198047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-14c0d37d-7c7d-4353-afdf-4fe7ec696ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-65813b3c-3144-4fa3-9408-d4fa38d722f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-7733e4f7-1910-49a6-8882-beba13b4f238,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-e8ddafbd-af12-470c-bed2-70df751cfc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-8de32437-480c-4980-bf6c-deac6567ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-03e520ed-a738-4963-86ab-f77a7a3b3d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-3afada36-eaf9-453b-ae33-689ae09ef0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-ab446a85-052e-4d1a-a1db-a56faf20f962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480923199-172.17.0.2-1597568280918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-814037af-19e4-4644-8fb0-763e286cf3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-d58e2361-1df3-4425-8796-68ffa42430a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-9f67a51d-9c04-42c3-9993-a3aabfb197f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-ab3dfaa2-7e7e-4c98-b484-535767db8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-6c184836-c410-430e-99ad-9c53a8a8b4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-93000bb8-9442-4713-b1ce-500a03e259c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-e8fea314-b77a-4848-9e17-e1fc7537c34b,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-76bbf20f-1422-44c2-a57a-116d686b317b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480923199-172.17.0.2-1597568280918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-814037af-19e4-4644-8fb0-763e286cf3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-d58e2361-1df3-4425-8796-68ffa42430a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-9f67a51d-9c04-42c3-9993-a3aabfb197f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-ab3dfaa2-7e7e-4c98-b484-535767db8e57,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-6c184836-c410-430e-99ad-9c53a8a8b4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-93000bb8-9442-4713-b1ce-500a03e259c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-e8fea314-b77a-4848-9e17-e1fc7537c34b,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-76bbf20f-1422-44c2-a57a-116d686b317b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503190245-172.17.0.2-1597568314433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-9cde733f-b11a-4902-a1ea-c51c1f66febb,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-fc48eb59-2441-4d8b-b0fd-608c71d6b360,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-81098cd2-717b-4507-b480-f6e839d45297,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-6c52f699-bb41-4eb0-9d6c-9f41e16b4820,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-5a8eec57-3a4f-4042-8a8f-493c5ba25189,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-5c55747f-d4ac-4e25-a676-e82f381d954e,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-346b25c3-005c-4ec8-8056-85f70e915d16,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-9e9d03f5-a90d-41ba-82e9-76183091ebdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503190245-172.17.0.2-1597568314433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-9cde733f-b11a-4902-a1ea-c51c1f66febb,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-fc48eb59-2441-4d8b-b0fd-608c71d6b360,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-81098cd2-717b-4507-b480-f6e839d45297,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-6c52f699-bb41-4eb0-9d6c-9f41e16b4820,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-5a8eec57-3a4f-4042-8a8f-493c5ba25189,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-5c55747f-d4ac-4e25-a676-e82f381d954e,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-346b25c3-005c-4ec8-8056-85f70e915d16,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-9e9d03f5-a90d-41ba-82e9-76183091ebdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229739552-172.17.0.2-1597568437347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-c470adb2-ca4e-4ded-b1f7-7f77cb3f6de1,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-b1b31a8a-6d36-4eb3-8d9b-99896bcf382c,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-b36535ef-5605-4693-a832-6ac4876caed8,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-09f09a97-bfed-4d04-bcf5-f700dc5e0d77,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-3ababf1d-1e79-4568-9b95-17a38b082849,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-7ab01bff-6c06-47d0-a810-4ab0a0569ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-9f3b78a1-cd4b-4e41-9b22-538ad31576b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-3b86836d-829b-4af5-8ef7-174d82821bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229739552-172.17.0.2-1597568437347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-c470adb2-ca4e-4ded-b1f7-7f77cb3f6de1,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-b1b31a8a-6d36-4eb3-8d9b-99896bcf382c,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-b36535ef-5605-4693-a832-6ac4876caed8,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-09f09a97-bfed-4d04-bcf5-f700dc5e0d77,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-3ababf1d-1e79-4568-9b95-17a38b082849,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-7ab01bff-6c06-47d0-a810-4ab0a0569ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-9f3b78a1-cd4b-4e41-9b22-538ad31576b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-3b86836d-829b-4af5-8ef7-174d82821bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649871295-172.17.0.2-1597568852489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35623,DS-912a0061-ab43-4586-be80-d72b6a669986,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-704a0af9-7db7-44e8-b430-ff3cf34de061,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-71816c45-fdd1-4f45-a1e7-3d961d6e621e,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-1064b88f-7a2d-44b5-b589-a284fdd235ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-76b95f92-4d78-408b-8477-c79b7745d644,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-14bcbd7b-2503-4a37-b410-d3fa0eaee8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-3b8c0ed6-010c-4465-bf0f-f397a7b90499,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-0ddca912-d9dc-47d2-9a84-770e12ce2d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649871295-172.17.0.2-1597568852489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35623,DS-912a0061-ab43-4586-be80-d72b6a669986,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-704a0af9-7db7-44e8-b430-ff3cf34de061,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-71816c45-fdd1-4f45-a1e7-3d961d6e621e,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-1064b88f-7a2d-44b5-b589-a284fdd235ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-76b95f92-4d78-408b-8477-c79b7745d644,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-14bcbd7b-2503-4a37-b410-d3fa0eaee8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-3b8c0ed6-010c-4465-bf0f-f397a7b90499,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-0ddca912-d9dc-47d2-9a84-770e12ce2d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794791319-172.17.0.2-1597568897346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43534,DS-bcee3fdc-238e-4b29-a89d-354c76c612d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-cba196e6-fe72-4bd6-9751-dead8101ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-a75727e5-d2ea-4c14-a21e-f1fa1eae3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-0e93b3f8-4207-4180-9f1b-596644341f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-6f9faaf2-0030-4e0c-a2c8-d513bc7ae08a,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-9a218d7b-56f1-441a-8662-7a4b98f3d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-089a3c9a-7a55-4d1d-8ffe-d4b3641cee04,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-ca31388b-4039-4787-9b23-98d5fc4b593d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794791319-172.17.0.2-1597568897346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43534,DS-bcee3fdc-238e-4b29-a89d-354c76c612d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-cba196e6-fe72-4bd6-9751-dead8101ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-a75727e5-d2ea-4c14-a21e-f1fa1eae3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-0e93b3f8-4207-4180-9f1b-596644341f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-6f9faaf2-0030-4e0c-a2c8-d513bc7ae08a,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-9a218d7b-56f1-441a-8662-7a4b98f3d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-089a3c9a-7a55-4d1d-8ffe-d4b3641cee04,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-ca31388b-4039-4787-9b23-98d5fc4b593d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5935
