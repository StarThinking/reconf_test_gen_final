reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092581321-172.17.0.17-1597604056431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-5d0aabb6-b09d-4fa0-bbfe-d13952668bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-4e1d4c18-327f-4e43-b3a1-082ef99b5262,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-aff0216a-7a31-4786-a40b-afc951546ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-8dde017d-86c8-4f5c-8ae6-c6909a23febe,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-615e360a-acee-409c-bd8d-2bc56698e537,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-71039aaf-ec11-4dbc-bed1-c017e6eb3b92,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-9d500532-4684-4c1d-90dd-270305be7418,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-f72a55f9-b8fd-4b20-96b1-28afdfdb5c7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092581321-172.17.0.17-1597604056431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-5d0aabb6-b09d-4fa0-bbfe-d13952668bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-4e1d4c18-327f-4e43-b3a1-082ef99b5262,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-aff0216a-7a31-4786-a40b-afc951546ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-8dde017d-86c8-4f5c-8ae6-c6909a23febe,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-615e360a-acee-409c-bd8d-2bc56698e537,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-71039aaf-ec11-4dbc-bed1-c017e6eb3b92,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-9d500532-4684-4c1d-90dd-270305be7418,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-f72a55f9-b8fd-4b20-96b1-28afdfdb5c7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570965422-172.17.0.17-1597604098836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36109,DS-75076763-37c0-4685-a6fe-5c9b5f639aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-45d17137-073a-4325-a47a-2b024cf3646b,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-65414238-c72c-4b29-accd-ed82931c6e37,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-28a53fa6-c7e5-4cf9-803c-8340fab8efa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-22eca81d-57c9-45f8-abb2-c7ca4ced557c,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-f60275a9-873f-496c-b1ab-cf3d23cf1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-bfbabb3f-240e-4588-a25c-c7f2df72f50b,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-313eb472-3908-4ae5-8a29-5441783df9be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570965422-172.17.0.17-1597604098836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36109,DS-75076763-37c0-4685-a6fe-5c9b5f639aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-45d17137-073a-4325-a47a-2b024cf3646b,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-65414238-c72c-4b29-accd-ed82931c6e37,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-28a53fa6-c7e5-4cf9-803c-8340fab8efa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-22eca81d-57c9-45f8-abb2-c7ca4ced557c,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-f60275a9-873f-496c-b1ab-cf3d23cf1d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-bfbabb3f-240e-4588-a25c-c7f2df72f50b,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-313eb472-3908-4ae5-8a29-5441783df9be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42352652-172.17.0.17-1597604640942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42470,DS-4db4cc15-1aa8-415c-beb3-174e039e8815,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-73c346ae-ef21-4ed0-82ea-4e0a47c4a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-35350e46-089f-42f3-ad1c-5f9a707dfb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-ff524cec-7c17-48a2-87fa-e007cd518149,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-49b2d6e3-f362-48c0-82e4-4d090eccc5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-ba0dc03c-3bbc-4dcd-bd68-94fcf38a42ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-c24d13e5-ace0-4657-980b-d5e22e738502,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-8fe6044f-5dcc-4ddb-80b4-01a7b62cecc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42352652-172.17.0.17-1597604640942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42470,DS-4db4cc15-1aa8-415c-beb3-174e039e8815,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-73c346ae-ef21-4ed0-82ea-4e0a47c4a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-35350e46-089f-42f3-ad1c-5f9a707dfb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-ff524cec-7c17-48a2-87fa-e007cd518149,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-49b2d6e3-f362-48c0-82e4-4d090eccc5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-ba0dc03c-3bbc-4dcd-bd68-94fcf38a42ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-c24d13e5-ace0-4657-980b-d5e22e738502,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-8fe6044f-5dcc-4ddb-80b4-01a7b62cecc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805078819-172.17.0.17-1597604940651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-b185b926-0c34-4111-9783-714b47575948,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-d0dff6c8-7560-4abe-86b4-21ea59831559,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-3c66d202-97a3-4b33-963d-d4f2827d064b,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-f0953e35-b028-41ef-ad81-36359b9ecf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-5b9a7f91-bf40-4f32-8cc0-86373e04ab3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-f99e1e34-24d6-4df0-bea9-ac1d88996f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-9c715a57-6a7a-475c-9316-6441f80f7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-1edcf871-5e75-4143-9015-3e967f834847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805078819-172.17.0.17-1597604940651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-b185b926-0c34-4111-9783-714b47575948,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-d0dff6c8-7560-4abe-86b4-21ea59831559,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-3c66d202-97a3-4b33-963d-d4f2827d064b,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-f0953e35-b028-41ef-ad81-36359b9ecf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-5b9a7f91-bf40-4f32-8cc0-86373e04ab3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-f99e1e34-24d6-4df0-bea9-ac1d88996f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-9c715a57-6a7a-475c-9316-6441f80f7b41,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-1edcf871-5e75-4143-9015-3e967f834847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654300383-172.17.0.17-1597605088057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36046,DS-08797ba6-6b9c-418c-aca5-542a690f3e84,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-9f45260a-447f-49c4-9d46-3c50b9d469cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-db6a3cbd-d0ec-4b1e-9916-e8e72929163e,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-c11f55b8-abd7-4043-a7d1-7ce18e0ce975,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-5e4c503e-d38d-4dda-9906-9233519fb0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-37b42281-4ccc-438c-816d-9ad1e0329720,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-609ae50f-ec6d-4d5c-9c8f-29407312224e,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-f6cc3627-4159-4ddf-8435-f3a94ff8f7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654300383-172.17.0.17-1597605088057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36046,DS-08797ba6-6b9c-418c-aca5-542a690f3e84,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-9f45260a-447f-49c4-9d46-3c50b9d469cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-db6a3cbd-d0ec-4b1e-9916-e8e72929163e,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-c11f55b8-abd7-4043-a7d1-7ce18e0ce975,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-5e4c503e-d38d-4dda-9906-9233519fb0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-37b42281-4ccc-438c-816d-9ad1e0329720,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-609ae50f-ec6d-4d5c-9c8f-29407312224e,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-f6cc3627-4159-4ddf-8435-f3a94ff8f7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223454403-172.17.0.17-1597605569450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-1b0493f1-3ace-4839-8833-f169831b90b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-bb8ea726-a432-4047-a2e9-18ab6f368660,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-9e0899b7-6ec1-44bf-915f-1ff334a961fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-714dc205-9fab-4882-91d2-3403aee28beb,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-b65cbc68-97b8-4e6d-bdb8-29b2b87fe44d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-0bd41f3c-9427-41c8-b657-d940299a24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-c4caac30-9a91-4d9b-a363-2ae6fdcc1269,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-8db903f2-7ab4-4e80-808b-3a36817c1fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223454403-172.17.0.17-1597605569450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-1b0493f1-3ace-4839-8833-f169831b90b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-bb8ea726-a432-4047-a2e9-18ab6f368660,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-9e0899b7-6ec1-44bf-915f-1ff334a961fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-714dc205-9fab-4882-91d2-3403aee28beb,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-b65cbc68-97b8-4e6d-bdb8-29b2b87fe44d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-0bd41f3c-9427-41c8-b657-d940299a24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-c4caac30-9a91-4d9b-a363-2ae6fdcc1269,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-8db903f2-7ab4-4e80-808b-3a36817c1fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328243083-172.17.0.17-1597605860142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-9438f2a5-79e3-4937-ba91-13e1d9b8ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-cdc66723-bc77-43d0-9c63-8c5071769718,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-498b5722-078d-4201-b2c7-acb9c46f2614,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-0572a82b-099f-4db6-9132-954483e79609,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-13814427-8256-483c-926b-cca80940ece4,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-c45d3a98-3099-41be-b6ce-dfc17c38b48e,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-a5854663-1a1e-49c2-ab49-bc2576f49f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-b22aec56-7b5f-4ddc-abd9-c3223f71eb1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328243083-172.17.0.17-1597605860142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-9438f2a5-79e3-4937-ba91-13e1d9b8ebf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-cdc66723-bc77-43d0-9c63-8c5071769718,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-498b5722-078d-4201-b2c7-acb9c46f2614,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-0572a82b-099f-4db6-9132-954483e79609,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-13814427-8256-483c-926b-cca80940ece4,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-c45d3a98-3099-41be-b6ce-dfc17c38b48e,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-a5854663-1a1e-49c2-ab49-bc2576f49f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-b22aec56-7b5f-4ddc-abd9-c3223f71eb1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766451653-172.17.0.17-1597606176577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-11b3b469-53dd-4e0d-a3c6-b17e7551ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-3f506b7c-a233-41bc-969a-d1c70ccf13ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-0372f97a-0731-43fe-aeaa-8eb358e232f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-ecae5065-5781-42a7-b04e-9c4c7a2659e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-d6b4f9eb-aedd-4b9f-94a0-afa76b1d8bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-f5df11da-f5c0-4c37-b6d5-b631f7eed268,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-643c88ff-c7cd-4a28-83af-7d79490ff6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-cd3030ee-aa10-4c9e-8093-5e970c9c65b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766451653-172.17.0.17-1597606176577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-11b3b469-53dd-4e0d-a3c6-b17e7551ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-3f506b7c-a233-41bc-969a-d1c70ccf13ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-0372f97a-0731-43fe-aeaa-8eb358e232f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-ecae5065-5781-42a7-b04e-9c4c7a2659e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-d6b4f9eb-aedd-4b9f-94a0-afa76b1d8bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-f5df11da-f5c0-4c37-b6d5-b631f7eed268,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-643c88ff-c7cd-4a28-83af-7d79490ff6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-cd3030ee-aa10-4c9e-8093-5e970c9c65b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405204594-172.17.0.17-1597606647686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-e908c3da-f3a7-44ac-ba8b-48ba2066756f,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-a4d05648-8b08-4615-84c4-17b065bf0567,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-6b3bae01-05e1-4703-9823-923b68b1bcac,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-bbad6eb0-0ca3-4ae9-bd67-ef7ebd77cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-7d9bf94c-1565-47f9-b58d-2575948b8124,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-2855e75a-2e6b-48c4-b9ba-845f50f12fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-f7cfc834-b9cb-487a-ba07-faf2f20b7c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-44932510-61b4-41d3-aeba-b67c654c0ed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405204594-172.17.0.17-1597606647686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-e908c3da-f3a7-44ac-ba8b-48ba2066756f,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-a4d05648-8b08-4615-84c4-17b065bf0567,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-6b3bae01-05e1-4703-9823-923b68b1bcac,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-bbad6eb0-0ca3-4ae9-bd67-ef7ebd77cff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-7d9bf94c-1565-47f9-b58d-2575948b8124,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-2855e75a-2e6b-48c4-b9ba-845f50f12fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-f7cfc834-b9cb-487a-ba07-faf2f20b7c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-44932510-61b4-41d3-aeba-b67c654c0ed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191720812-172.17.0.17-1597607471965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46061,DS-d901c7ab-7030-46c3-b9c6-bf98d89eb22e,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-4781584c-896d-41b3-82ed-424cc13a7c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-ae00df7c-f7a5-41ea-b75b-9f8d92c90b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-dec41dd2-589e-4c5e-9f2c-03d171f838eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-51040a0c-e78d-4642-8cbb-b421d58e5192,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-14675a9a-3ded-4c31-bd5c-d3df883d6a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-43c88eb4-af8a-4a6c-afb2-53fb76f79b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-ac187d98-f735-47a7-820d-2a9bef011cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191720812-172.17.0.17-1597607471965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46061,DS-d901c7ab-7030-46c3-b9c6-bf98d89eb22e,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-4781584c-896d-41b3-82ed-424cc13a7c81,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-ae00df7c-f7a5-41ea-b75b-9f8d92c90b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-dec41dd2-589e-4c5e-9f2c-03d171f838eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-51040a0c-e78d-4642-8cbb-b421d58e5192,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-14675a9a-3ded-4c31-bd5c-d3df883d6a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-43c88eb4-af8a-4a6c-afb2-53fb76f79b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-ac187d98-f735-47a7-820d-2a9bef011cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340148219-172.17.0.17-1597607712333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-a20142c6-c576-4d04-9885-8d8a00184f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-4cfbecfc-761e-4ed9-9c3b-00962841e588,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-bede61f6-c619-42e9-8755-457e5fdc8d61,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-b549b486-0435-49fe-93ab-e7d3a8f213ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-2c605fee-401f-4ee6-9ce8-488f1f92e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-d98dd4dd-9c94-4da8-9b93-2279bbb4a7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-0469ea1e-9f09-44e3-9c58-72bc70b10e16,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-5a2df876-e784-4a40-bf36-59a458564302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340148219-172.17.0.17-1597607712333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-a20142c6-c576-4d04-9885-8d8a00184f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-4cfbecfc-761e-4ed9-9c3b-00962841e588,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-bede61f6-c619-42e9-8755-457e5fdc8d61,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-b549b486-0435-49fe-93ab-e7d3a8f213ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-2c605fee-401f-4ee6-9ce8-488f1f92e2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-d98dd4dd-9c94-4da8-9b93-2279bbb4a7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-0469ea1e-9f09-44e3-9c58-72bc70b10e16,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-5a2df876-e784-4a40-bf36-59a458564302,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724423259-172.17.0.17-1597607790692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35855,DS-1a4f754c-0b32-45dc-baff-8859187224fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-5bce9223-5d6e-4774-aeae-09b4ea848616,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-5e078d7a-d481-4d0d-876b-6121beb4eca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-147a81ba-4f72-4afa-a634-ee4f4ca53567,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-593def27-73da-4a85-9b6e-cb688b44f397,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-475c2731-2d37-44e6-866a-d7045c7fee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-32eb8872-a7f4-4a48-8e40-b9ef116a5d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-e9f5d98b-a32a-4819-9012-1cb8afd82e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724423259-172.17.0.17-1597607790692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35855,DS-1a4f754c-0b32-45dc-baff-8859187224fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-5bce9223-5d6e-4774-aeae-09b4ea848616,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-5e078d7a-d481-4d0d-876b-6121beb4eca5,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-147a81ba-4f72-4afa-a634-ee4f4ca53567,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-593def27-73da-4a85-9b6e-cb688b44f397,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-475c2731-2d37-44e6-866a-d7045c7fee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-32eb8872-a7f4-4a48-8e40-b9ef116a5d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-e9f5d98b-a32a-4819-9012-1cb8afd82e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705610961-172.17.0.17-1597608822017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33326,DS-768fe0d5-9a05-4c81-882a-7a2b476fd267,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-f69abd85-4f1f-4e25-b5ee-c35835975a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-dfbba499-f8ad-48ea-b6dc-0663b85e1b15,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-93fb468b-4e4f-4270-a059-764ed154d404,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-f9728c4a-f4a0-49eb-bceb-4e59c12b2c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-0b510956-0503-449b-b017-9c18a55f6114,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-db911006-e38a-444c-962a-b30e560a4fda,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-a29079b0-0276-4434-8d23-2465408cd0f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705610961-172.17.0.17-1597608822017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33326,DS-768fe0d5-9a05-4c81-882a-7a2b476fd267,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-f69abd85-4f1f-4e25-b5ee-c35835975a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-dfbba499-f8ad-48ea-b6dc-0663b85e1b15,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-93fb468b-4e4f-4270-a059-764ed154d404,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-f9728c4a-f4a0-49eb-bceb-4e59c12b2c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-0b510956-0503-449b-b017-9c18a55f6114,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-db911006-e38a-444c-962a-b30e560a4fda,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-a29079b0-0276-4434-8d23-2465408cd0f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120134027-172.17.0.17-1597609214433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34854,DS-034d0040-0dfc-4261-b502-98818d266279,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-cb986197-3eee-4f34-9d76-c74549d662cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-a20f4599-0cb5-451a-ba88-111f4f0f565f,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-238929da-094f-4719-b235-02467cee3f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-f219e029-6806-45a5-ba17-64cf26defee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-cbaae98a-845e-4ad8-9d51-5c1f3ea1d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-5bda5210-534e-4f3b-b90d-647a3f7cec70,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-321fae50-07a0-43f6-9906-13a8105bac6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120134027-172.17.0.17-1597609214433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34854,DS-034d0040-0dfc-4261-b502-98818d266279,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-cb986197-3eee-4f34-9d76-c74549d662cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-a20f4599-0cb5-451a-ba88-111f4f0f565f,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-238929da-094f-4719-b235-02467cee3f05,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-f219e029-6806-45a5-ba17-64cf26defee9,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-cbaae98a-845e-4ad8-9d51-5c1f3ea1d40e,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-5bda5210-534e-4f3b-b90d-647a3f7cec70,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-321fae50-07a0-43f6-9906-13a8105bac6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323018982-172.17.0.17-1597609449852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43130,DS-04e0a777-0743-464b-b6d1-7a28a60d639d,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-2247d6f2-50ec-4f7f-91eb-d1804e00331d,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-78f10439-ef48-43dd-bc8e-2fa12b92b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-313b86eb-1563-4352-9141-bea8470304c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-dc977e51-d097-4d1a-9478-91f1c7c4e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-039f3c9f-f0d1-496f-9dfd-b19da0927c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-679f24c7-6d3e-4fed-accb-3c9c95a41a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-580b3eea-8281-4e49-b062-64f0654ba3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323018982-172.17.0.17-1597609449852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43130,DS-04e0a777-0743-464b-b6d1-7a28a60d639d,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-2247d6f2-50ec-4f7f-91eb-d1804e00331d,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-78f10439-ef48-43dd-bc8e-2fa12b92b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-313b86eb-1563-4352-9141-bea8470304c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-dc977e51-d097-4d1a-9478-91f1c7c4e7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-039f3c9f-f0d1-496f-9dfd-b19da0927c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-679f24c7-6d3e-4fed-accb-3c9c95a41a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-580b3eea-8281-4e49-b062-64f0654ba3df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168842122-172.17.0.17-1597609491301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-82329baa-fe9c-4fc3-89d8-515a1a598bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-6dbe86df-cf9a-4249-a721-41e1cae8b4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-76c6040e-084e-416d-a157-31c5a9df545f,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-9bf7ec43-d867-4a7a-8ccb-5a821735aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-a997783a-ff42-4ea6-a245-7f1c060404b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-9b6d195b-cc85-46a4-8a91-b5b88857b341,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-e52f7f63-e8b2-4098-8a54-38962cb99800,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-6d0a4d8e-ed93-42f9-a4f0-7722e76e6879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168842122-172.17.0.17-1597609491301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-82329baa-fe9c-4fc3-89d8-515a1a598bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-6dbe86df-cf9a-4249-a721-41e1cae8b4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-76c6040e-084e-416d-a157-31c5a9df545f,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-9bf7ec43-d867-4a7a-8ccb-5a821735aa16,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-a997783a-ff42-4ea6-a245-7f1c060404b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-9b6d195b-cc85-46a4-8a91-b5b88857b341,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-e52f7f63-e8b2-4098-8a54-38962cb99800,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-6d0a4d8e-ed93-42f9-a4f0-7722e76e6879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122577545-172.17.0.17-1597609592060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32937,DS-b579824e-d6d9-447d-9337-fa42b1f0d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-94dc279d-b0d8-4a3e-b1ef-e5f8991f0fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-8250ca05-129a-4b76-9424-c1ca767f9e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-643c103f-b7f9-4c00-b931-539a1b722279,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-6b0c212c-cb5d-4d5f-a3d9-9bb0a71da414,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-5cda30f3-d5f0-45f7-b8cd-016921ed38fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-8e01879b-18ba-460a-a38b-368e8d850518,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-55726923-6c50-4ade-a525-ff61124405ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122577545-172.17.0.17-1597609592060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32937,DS-b579824e-d6d9-447d-9337-fa42b1f0d25e,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-94dc279d-b0d8-4a3e-b1ef-e5f8991f0fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-8250ca05-129a-4b76-9424-c1ca767f9e48,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-643c103f-b7f9-4c00-b931-539a1b722279,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-6b0c212c-cb5d-4d5f-a3d9-9bb0a71da414,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-5cda30f3-d5f0-45f7-b8cd-016921ed38fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-8e01879b-18ba-460a-a38b-368e8d850518,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-55726923-6c50-4ade-a525-ff61124405ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890156436-172.17.0.17-1597609689289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-9875240e-519d-40b0-9627-2c636577c74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-ecfcdef5-01d8-4ce0-88d5-61c668314374,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-e16fd075-1160-404b-9e65-fe002746da60,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-b13585cc-6a80-414c-966b-13bf64c0b220,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-a078eea0-904d-43e6-9220-98be7891c608,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-4eef802d-e647-4856-9221-dd8ca7daeda1,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-95d7f9ed-5f2c-40a4-be61-e95cd055b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-b3d78803-169a-448e-9974-b7d6aef89e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890156436-172.17.0.17-1597609689289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-9875240e-519d-40b0-9627-2c636577c74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-ecfcdef5-01d8-4ce0-88d5-61c668314374,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-e16fd075-1160-404b-9e65-fe002746da60,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-b13585cc-6a80-414c-966b-13bf64c0b220,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-a078eea0-904d-43e6-9220-98be7891c608,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-4eef802d-e647-4856-9221-dd8ca7daeda1,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-95d7f9ed-5f2c-40a4-be61-e95cd055b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-b3d78803-169a-448e-9974-b7d6aef89e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006425114-172.17.0.17-1597609916346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-22eedbd3-4e4d-4708-99db-d7c2bb0fff52,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-b19d1cb9-a212-49e9-b69a-b767cac68c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-559e0941-cc84-4644-a008-cad3f7f6981d,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-566b6680-16bf-499a-9f9a-3a4bc3f14647,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-49a249ca-7636-4542-9eed-776d9cf8dc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-6f9a99fc-2254-4c3e-acd6-39dbda937e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-5de3f669-97a9-4ce3-982d-2eff6647894e,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-49fad2a3-9785-47ce-8468-2408b2b3d76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006425114-172.17.0.17-1597609916346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-22eedbd3-4e4d-4708-99db-d7c2bb0fff52,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-b19d1cb9-a212-49e9-b69a-b767cac68c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-559e0941-cc84-4644-a008-cad3f7f6981d,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-566b6680-16bf-499a-9f9a-3a4bc3f14647,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-49a249ca-7636-4542-9eed-776d9cf8dc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-6f9a99fc-2254-4c3e-acd6-39dbda937e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-5de3f669-97a9-4ce3-982d-2eff6647894e,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-49fad2a3-9785-47ce-8468-2408b2b3d76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428848375-172.17.0.17-1597610162059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33677,DS-362ca429-ea29-4fab-81c0-a59a6ff50b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-197ee0bb-0a32-41da-99de-7835358cb00b,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-dbe001f3-3b51-4284-97ea-8c97f738846d,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-53549b6c-754c-4bcd-88c4-3d0a7423a950,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-dae682e3-5b79-4c49-88da-318765f17223,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-ccf55059-2d2b-46f2-adca-5fca16ef8f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-87431cc4-891c-4c86-b364-dc13e802f202,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-dd6ce676-7468-46e4-9915-090da998bbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428848375-172.17.0.17-1597610162059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33677,DS-362ca429-ea29-4fab-81c0-a59a6ff50b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-197ee0bb-0a32-41da-99de-7835358cb00b,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-dbe001f3-3b51-4284-97ea-8c97f738846d,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-53549b6c-754c-4bcd-88c4-3d0a7423a950,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-dae682e3-5b79-4c49-88da-318765f17223,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-ccf55059-2d2b-46f2-adca-5fca16ef8f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-87431cc4-891c-4c86-b364-dc13e802f202,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-dd6ce676-7468-46e4-9915-090da998bbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49262912-172.17.0.17-1597610558491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41685,DS-35dc0606-631c-4647-a3b6-d2d4ad79109f,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-d1a5e3fd-f5cf-4a15-a2e6-7b00b9cc3145,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-2eae6007-bb35-4356-b8c3-0d31a12150df,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-8f48cfc9-f244-4707-86c9-a0ee1be3ca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-cec239f7-173d-4c8a-968f-7e1a61a3310d,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-448512b5-3fdd-44aa-9c7d-68ae5bc567bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b7480b2a-ae55-4818-b74a-e0cddf007cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-7d015e58-b5b3-48e3-976c-f76c82977653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49262912-172.17.0.17-1597610558491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41685,DS-35dc0606-631c-4647-a3b6-d2d4ad79109f,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-d1a5e3fd-f5cf-4a15-a2e6-7b00b9cc3145,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-2eae6007-bb35-4356-b8c3-0d31a12150df,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-8f48cfc9-f244-4707-86c9-a0ee1be3ca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-cec239f7-173d-4c8a-968f-7e1a61a3310d,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-448512b5-3fdd-44aa-9c7d-68ae5bc567bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b7480b2a-ae55-4818-b74a-e0cddf007cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-7d015e58-b5b3-48e3-976c-f76c82977653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815824542-172.17.0.17-1597611025430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36081,DS-6e00f8eb-028f-4b9d-baa4-756ca1b86c15,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-17e6df07-ec86-427d-9a8a-31608733e348,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-4375eba3-a7c9-4738-805f-217350ace964,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-63871df9-4b48-46a9-ada4-e12953d0ea22,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-5bbeefc7-443d-4e89-b53d-077197cbd010,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-91d3ae6e-b4ab-4b34-b452-7528dba48ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-f079c788-6e46-4f3f-9610-4192eac47701,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-ec1060ef-c469-4562-b456-6794a2622c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815824542-172.17.0.17-1597611025430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36081,DS-6e00f8eb-028f-4b9d-baa4-756ca1b86c15,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-17e6df07-ec86-427d-9a8a-31608733e348,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-4375eba3-a7c9-4738-805f-217350ace964,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-63871df9-4b48-46a9-ada4-e12953d0ea22,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-5bbeefc7-443d-4e89-b53d-077197cbd010,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-91d3ae6e-b4ab-4b34-b452-7528dba48ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-f079c788-6e46-4f3f-9610-4192eac47701,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-ec1060ef-c469-4562-b456-6794a2622c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239021192-172.17.0.17-1597611116560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-5375ad76-5f43-4613-bf93-c672dd610c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-96239792-585e-4309-9353-ad14e723b416,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-ff1ef19a-c9b5-47db-b83b-bea3d8726f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-89983e1f-d84c-4151-bd55-c3642496b627,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-a310fab2-41dd-476a-9184-b3299633d0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-720b3a35-f4ee-4611-aa7a-165195778868,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-c3bb56bc-a443-42b7-b0c2-7c312cf53493,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-cbc7fe23-141c-4c7b-b672-4be00bc635f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239021192-172.17.0.17-1597611116560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-5375ad76-5f43-4613-bf93-c672dd610c00,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-96239792-585e-4309-9353-ad14e723b416,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-ff1ef19a-c9b5-47db-b83b-bea3d8726f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-89983e1f-d84c-4151-bd55-c3642496b627,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-a310fab2-41dd-476a-9184-b3299633d0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-720b3a35-f4ee-4611-aa7a-165195778868,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-c3bb56bc-a443-42b7-b0c2-7c312cf53493,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-cbc7fe23-141c-4c7b-b672-4be00bc635f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 7153
