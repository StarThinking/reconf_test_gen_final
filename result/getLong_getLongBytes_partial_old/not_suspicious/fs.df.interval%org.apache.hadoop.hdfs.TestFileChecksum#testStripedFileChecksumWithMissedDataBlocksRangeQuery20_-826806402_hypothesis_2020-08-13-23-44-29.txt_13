reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506663189-172.17.0.21-1597362703043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-482fda93-2b03-448d-b940-c8e6b6952b31,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-5f0d16a6-5eb1-4607-aa0d-ec3191c9a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-ab7a726f-9822-42e3-b168-a98576443175,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b2d78ebb-a63e-4b70-af3e-0f142eb29229,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-475cd741-c6b1-4324-8eba-0a44ec324626,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-7433b3f5-a5d3-4b5e-8998-77c47a9f59bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-a258ee1b-2c07-46f5-afa2-dca08011e415,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-deb082a5-3dc8-414e-ad88-7d3ad1c04fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506663189-172.17.0.21-1597362703043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33548,DS-482fda93-2b03-448d-b940-c8e6b6952b31,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-5f0d16a6-5eb1-4607-aa0d-ec3191c9a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-ab7a726f-9822-42e3-b168-a98576443175,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b2d78ebb-a63e-4b70-af3e-0f142eb29229,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-475cd741-c6b1-4324-8eba-0a44ec324626,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-7433b3f5-a5d3-4b5e-8998-77c47a9f59bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-a258ee1b-2c07-46f5-afa2-dca08011e415,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-deb082a5-3dc8-414e-ad88-7d3ad1c04fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133277222-172.17.0.21-1597362920307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-060c8fdc-98b5-461d-b741-2a297009fe30,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-dbde06ad-b4d2-47d7-8ae0-b23425cf5a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-011d346d-64f2-40a0-b027-430db864d83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-f650bc6a-0397-4fcd-b63b-f9da81336d46,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-807033c7-53fe-42f0-9b0d-0678c3fcdb02,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-c1757332-bc3f-469e-8437-61d14daa62b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-bc681c0b-f969-451a-845d-44ec451bd93e,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-e8742175-9ac1-485c-8671-9aaa4f124d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133277222-172.17.0.21-1597362920307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-060c8fdc-98b5-461d-b741-2a297009fe30,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-dbde06ad-b4d2-47d7-8ae0-b23425cf5a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-011d346d-64f2-40a0-b027-430db864d83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-f650bc6a-0397-4fcd-b63b-f9da81336d46,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-807033c7-53fe-42f0-9b0d-0678c3fcdb02,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-c1757332-bc3f-469e-8437-61d14daa62b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-bc681c0b-f969-451a-845d-44ec451bd93e,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-e8742175-9ac1-485c-8671-9aaa4f124d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463448765-172.17.0.21-1597363221386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43928,DS-e3733fba-92d3-43ff-abb9-fc2a86e6bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-0eeaaf32-8b07-4dc8-8198-cab22ed57032,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-f2b23c3d-2252-461b-a6d4-cd4590bc388a,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-40492010-9db1-4431-92fb-1dd656ab7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-a90a71bc-7617-4a38-924f-f22edcbd5447,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-abc5940a-73e4-412b-acb2-758e7301454c,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-6d2e317a-809d-4d60-9850-c2644a952df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-d4e6cfd9-c4b5-4934-bdad-c4d820068671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463448765-172.17.0.21-1597363221386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43928,DS-e3733fba-92d3-43ff-abb9-fc2a86e6bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-0eeaaf32-8b07-4dc8-8198-cab22ed57032,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-f2b23c3d-2252-461b-a6d4-cd4590bc388a,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-40492010-9db1-4431-92fb-1dd656ab7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-a90a71bc-7617-4a38-924f-f22edcbd5447,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-abc5940a-73e4-412b-acb2-758e7301454c,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-6d2e317a-809d-4d60-9850-c2644a952df9,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-d4e6cfd9-c4b5-4934-bdad-c4d820068671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949734679-172.17.0.21-1597363749007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-1fa02b41-4297-498d-8dbb-a3948a6842bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-e7b292dc-ddb6-4c38-ad40-16d44ab50197,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-0462f071-48e0-48f2-9620-3e4ef6ff1926,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-b14a87da-a513-4d15-b26f-6233fd148fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-d568f2eb-19c8-419d-8487-648c6cb1b852,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-aea75a9d-1e05-4422-84f0-1ebcb1539773,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-5b19eba1-1474-4d2e-bb57-4cf56f69da61,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-4c9d2fc5-46f4-464c-b2a9-bda944e2577a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-949734679-172.17.0.21-1597363749007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-1fa02b41-4297-498d-8dbb-a3948a6842bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-e7b292dc-ddb6-4c38-ad40-16d44ab50197,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-0462f071-48e0-48f2-9620-3e4ef6ff1926,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-b14a87da-a513-4d15-b26f-6233fd148fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-d568f2eb-19c8-419d-8487-648c6cb1b852,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-aea75a9d-1e05-4422-84f0-1ebcb1539773,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-5b19eba1-1474-4d2e-bb57-4cf56f69da61,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-4c9d2fc5-46f4-464c-b2a9-bda944e2577a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246964803-172.17.0.21-1597364359419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37727,DS-559a64c6-7abe-494d-9faa-7fb409f0098a,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-ed751b0e-95d3-4b04-84f4-be773343ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-cabddfec-803c-4514-be5d-9dbb56264a91,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-4606bf40-2d65-4c3a-afef-b81ac755fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-43749c90-376c-46ea-8ea0-9c677fcbfc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-597c69dc-d5d4-4f94-87eb-bce56f153e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-1284757c-8c9b-4618-a3ac-fb7c55ae42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-d08ff11a-dac3-437d-b1ce-b8dabf38c261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246964803-172.17.0.21-1597364359419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37727,DS-559a64c6-7abe-494d-9faa-7fb409f0098a,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-ed751b0e-95d3-4b04-84f4-be773343ec35,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-cabddfec-803c-4514-be5d-9dbb56264a91,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-4606bf40-2d65-4c3a-afef-b81ac755fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-43749c90-376c-46ea-8ea0-9c677fcbfc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-597c69dc-d5d4-4f94-87eb-bce56f153e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-1284757c-8c9b-4618-a3ac-fb7c55ae42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-d08ff11a-dac3-437d-b1ce-b8dabf38c261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681775301-172.17.0.21-1597365153750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-7189a57b-a388-4273-8343-51944a0bf99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-76d4ddf6-26f9-46e6-a16d-140139dc3728,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-8e9b843d-70a1-40ac-a8b9-408ba7d79a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-4b844d95-c802-41b6-83a8-77f6b69a41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-fa0cadf8-018c-4f36-9691-b62beb748606,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-751a367d-6290-46cc-bbdb-8f96216d6e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-10362506-62c6-4cf5-a134-b5e5a6da51f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-65ab5854-ab39-4772-8d82-3f5de0bdbec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681775301-172.17.0.21-1597365153750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-7189a57b-a388-4273-8343-51944a0bf99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-76d4ddf6-26f9-46e6-a16d-140139dc3728,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-8e9b843d-70a1-40ac-a8b9-408ba7d79a47,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-4b844d95-c802-41b6-83a8-77f6b69a41ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-fa0cadf8-018c-4f36-9691-b62beb748606,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-751a367d-6290-46cc-bbdb-8f96216d6e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-10362506-62c6-4cf5-a134-b5e5a6da51f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-65ab5854-ab39-4772-8d82-3f5de0bdbec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512072437-172.17.0.21-1597365891120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-66ed160b-151d-4910-a797-484324c7840f,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-047ca35e-ed27-4445-b560-e6224e463a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-1207733f-e0c1-4352-8f17-b908a4e9f243,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-c137799f-989b-4bca-a8a9-35771cf02b44,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-af3bb2cd-51e7-4ca0-a907-33ba0ea3a627,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-1ee02526-5d69-4b33-a651-e27894ef9942,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-901901cf-811e-46dd-b88a-b282b722c5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-1af9e443-9ab5-40f6-b2f9-6eeb5d2ae95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512072437-172.17.0.21-1597365891120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-66ed160b-151d-4910-a797-484324c7840f,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-047ca35e-ed27-4445-b560-e6224e463a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-1207733f-e0c1-4352-8f17-b908a4e9f243,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-c137799f-989b-4bca-a8a9-35771cf02b44,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-af3bb2cd-51e7-4ca0-a907-33ba0ea3a627,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-1ee02526-5d69-4b33-a651-e27894ef9942,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-901901cf-811e-46dd-b88a-b282b722c5da,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-1af9e443-9ab5-40f6-b2f9-6eeb5d2ae95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668978280-172.17.0.21-1597366273684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-bd31aa85-cfff-4c7c-b0de-2405f4a05c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-3a48834d-fbb1-4756-b207-22f93d7a3350,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-7117f3da-76d1-4a4b-9cb0-4beb42c2ec38,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-eab78636-3588-4f55-99cf-2009de657567,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-43656cd0-3549-4864-bf46-b6a8769945ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-499d7889-5e93-4b08-80c7-2c1907d70982,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-1bcca1fc-ae75-4c72-814a-84bac6b3fe43,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-f66d55ea-874c-4788-9491-1ba44ea27955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668978280-172.17.0.21-1597366273684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-bd31aa85-cfff-4c7c-b0de-2405f4a05c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-3a48834d-fbb1-4756-b207-22f93d7a3350,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-7117f3da-76d1-4a4b-9cb0-4beb42c2ec38,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-eab78636-3588-4f55-99cf-2009de657567,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-43656cd0-3549-4864-bf46-b6a8769945ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-499d7889-5e93-4b08-80c7-2c1907d70982,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-1bcca1fc-ae75-4c72-814a-84bac6b3fe43,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-f66d55ea-874c-4788-9491-1ba44ea27955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432399867-172.17.0.21-1597366423808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-633ef0de-5968-4192-a1aa-69de7ee27c26,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-6f4e4cfd-5504-4d0b-b5f5-c5341a970f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-0166f30c-01c1-446f-a09b-c60357c5bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-8c9d6589-409b-4aab-9706-c3a125beace8,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-818a25f0-9261-4643-b0b6-94d65987aea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-723bfe3b-8748-4a86-9047-bb443fbc1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-11f1a9a6-f882-4dc6-9938-c2faa1465011,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-f4e35670-0a20-4b09-af07-8b03e56cb115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432399867-172.17.0.21-1597366423808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-633ef0de-5968-4192-a1aa-69de7ee27c26,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-6f4e4cfd-5504-4d0b-b5f5-c5341a970f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-0166f30c-01c1-446f-a09b-c60357c5bd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-8c9d6589-409b-4aab-9706-c3a125beace8,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-818a25f0-9261-4643-b0b6-94d65987aea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-723bfe3b-8748-4a86-9047-bb443fbc1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-11f1a9a6-f882-4dc6-9938-c2faa1465011,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-f4e35670-0a20-4b09-af07-8b03e56cb115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141025795-172.17.0.21-1597366509434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42805,DS-9035a02c-dd6d-448b-a202-c1290e4219fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-d4281502-8633-4dee-a663-bcfcc0156f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-75a40e05-db9c-4be9-bbf5-a1f83e1cfb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-a411ed68-d4ef-4d6d-a584-9cd42ada391e,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-ce95af3e-01c0-4642-bba3-eb16f4d1ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-ca16c9f2-42ef-4663-8da8-9eba7e76b8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-58d6bf1f-0165-4192-8192-4cde4eee7eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-87876983-2dd3-48fe-9738-de2c24c5ab74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141025795-172.17.0.21-1597366509434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42805,DS-9035a02c-dd6d-448b-a202-c1290e4219fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-d4281502-8633-4dee-a663-bcfcc0156f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-75a40e05-db9c-4be9-bbf5-a1f83e1cfb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-a411ed68-d4ef-4d6d-a584-9cd42ada391e,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-ce95af3e-01c0-4642-bba3-eb16f4d1ffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-ca16c9f2-42ef-4663-8da8-9eba7e76b8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-58d6bf1f-0165-4192-8192-4cde4eee7eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-87876983-2dd3-48fe-9738-de2c24c5ab74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398545503-172.17.0.21-1597366649100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40490,DS-c37cd5a6-b491-4c05-b241-7903b7719fad,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-0af3959c-b1e0-4c18-a2ab-e72774338c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-1750a3ef-2ac6-4cdc-b21f-e58f060525a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-e30396e4-734d-42ac-b698-96f9bd1048de,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-f7a440a1-2d4a-495c-bd3b-05dbcfb9cbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-1d23acaf-4d98-4a51-baa8-2b52eaab6563,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-c34606bc-603e-4761-84e7-722290e4815e,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-087bae49-58f9-46e5-9abf-a3848689a6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-398545503-172.17.0.21-1597366649100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40490,DS-c37cd5a6-b491-4c05-b241-7903b7719fad,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-0af3959c-b1e0-4c18-a2ab-e72774338c92,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-1750a3ef-2ac6-4cdc-b21f-e58f060525a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-e30396e4-734d-42ac-b698-96f9bd1048de,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-f7a440a1-2d4a-495c-bd3b-05dbcfb9cbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-1d23acaf-4d98-4a51-baa8-2b52eaab6563,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-c34606bc-603e-4761-84e7-722290e4815e,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-087bae49-58f9-46e5-9abf-a3848689a6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400975847-172.17.0.21-1597366681586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-d9938d37-8830-4e23-8b83-c08c9e45c990,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-2fe06b28-70da-46de-a793-c299d991ea82,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-0ae07e00-4501-470e-bb2b-4f8fbc2b9082,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-6237a57a-60da-454f-bfbd-ee6665245cba,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-6e45d621-8c65-4fa4-803f-5e854469e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-5e701b00-2af2-4cbc-93b3-e0e7ede70519,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-680e66f4-5569-46e8-a9ae-26a37c016c57,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-e4b5933d-dfd9-457f-a391-7d039dc0cb4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400975847-172.17.0.21-1597366681586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-d9938d37-8830-4e23-8b83-c08c9e45c990,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-2fe06b28-70da-46de-a793-c299d991ea82,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-0ae07e00-4501-470e-bb2b-4f8fbc2b9082,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-6237a57a-60da-454f-bfbd-ee6665245cba,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-6e45d621-8c65-4fa4-803f-5e854469e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-5e701b00-2af2-4cbc-93b3-e0e7ede70519,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-680e66f4-5569-46e8-a9ae-26a37c016c57,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-e4b5933d-dfd9-457f-a391-7d039dc0cb4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798505758-172.17.0.21-1597367157033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-1b3cc62f-1cb6-4af4-a39c-d9260d88f04e,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-f8139db1-dc3d-4353-9e8a-e91ca7c607cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-9b0160a0-3849-460c-9125-d03f786a19ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-5915cfbe-9dcb-47e4-8dd9-278418014f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e7d1e9ac-e46a-4507-8dc5-4176db8a9955,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-4f0b749a-33ed-4f95-9c50-b02e4621e986,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-51f31507-92c2-4f17-9d57-2a237f95399b,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-e2923eb2-3f21-467b-bbb5-4e7990aa71ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798505758-172.17.0.21-1597367157033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-1b3cc62f-1cb6-4af4-a39c-d9260d88f04e,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-f8139db1-dc3d-4353-9e8a-e91ca7c607cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-9b0160a0-3849-460c-9125-d03f786a19ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-5915cfbe-9dcb-47e4-8dd9-278418014f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e7d1e9ac-e46a-4507-8dc5-4176db8a9955,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-4f0b749a-33ed-4f95-9c50-b02e4621e986,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-51f31507-92c2-4f17-9d57-2a237f95399b,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-e2923eb2-3f21-467b-bbb5-4e7990aa71ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798364186-172.17.0.21-1597367238772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-85e65bfc-3754-4f1d-af75-4db76211f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-d974aa91-a85c-483d-b933-77ff1f296f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-efc3b4d3-5af9-4888-9561-4f6c7dc1df00,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-2e0bcda0-7de2-4534-89ad-72627d48084f,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-792c176a-c898-4138-9009-efdf96e15f80,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-dbaa08fb-543b-4aac-8e30-5ec83eaf610c,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-e9d63f78-c46a-4409-a0fc-649e8f7c11cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-e637cd3f-3a92-4694-bc80-59751e84e394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798364186-172.17.0.21-1597367238772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-85e65bfc-3754-4f1d-af75-4db76211f6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-d974aa91-a85c-483d-b933-77ff1f296f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-efc3b4d3-5af9-4888-9561-4f6c7dc1df00,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-2e0bcda0-7de2-4534-89ad-72627d48084f,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-792c176a-c898-4138-9009-efdf96e15f80,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-dbaa08fb-543b-4aac-8e30-5ec83eaf610c,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-e9d63f78-c46a-4409-a0fc-649e8f7c11cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-e637cd3f-3a92-4694-bc80-59751e84e394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120964736-172.17.0.21-1597367419996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-4a9b2e37-e6ac-4238-9c09-bc789d5941ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-62bb676c-64b6-4f53-a98f-bfc54763a019,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-ea092e5c-60cc-4771-8a26-fd404b803473,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-6fa1fe2f-2f42-42d9-b3ea-904c6f53900d,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-e0b05e22-f398-4f93-800b-e7951be70c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-4c62b55d-325a-4a69-8e94-ef17aaf5018a,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-37522bc2-781d-4ea4-a70a-2bf0c5504e24,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-3aeef53f-988f-4540-a7b7-fa194430b236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1120964736-172.17.0.21-1597367419996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-4a9b2e37-e6ac-4238-9c09-bc789d5941ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-62bb676c-64b6-4f53-a98f-bfc54763a019,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-ea092e5c-60cc-4771-8a26-fd404b803473,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-6fa1fe2f-2f42-42d9-b3ea-904c6f53900d,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-e0b05e22-f398-4f93-800b-e7951be70c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-4c62b55d-325a-4a69-8e94-ef17aaf5018a,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-37522bc2-781d-4ea4-a70a-2bf0c5504e24,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-3aeef53f-988f-4540-a7b7-fa194430b236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246689870-172.17.0.21-1597367505120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-7c7fa496-b1bd-4d59-a2de-86378f5a41dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-a500d85c-2553-4e2e-9794-8b3d5868b0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-5e1987e9-d46f-4d3f-8f67-4b3eddb3cbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-2521c785-6207-431a-bd8e-5f625b2f794b,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-583f7803-646c-47fc-9907-ad36456e6571,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-cd5c3389-76f1-4172-9e0e-241251895467,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-434c6ec0-3602-4cf7-a435-1981b81dae05,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-f8b580d0-b935-4008-9a43-4a24321889ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246689870-172.17.0.21-1597367505120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-7c7fa496-b1bd-4d59-a2de-86378f5a41dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-a500d85c-2553-4e2e-9794-8b3d5868b0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-5e1987e9-d46f-4d3f-8f67-4b3eddb3cbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-2521c785-6207-431a-bd8e-5f625b2f794b,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-583f7803-646c-47fc-9907-ad36456e6571,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-cd5c3389-76f1-4172-9e0e-241251895467,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-434c6ec0-3602-4cf7-a435-1981b81dae05,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-f8b580d0-b935-4008-9a43-4a24321889ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767341884-172.17.0.21-1597367578563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-12de78b5-642b-40ad-9985-7cd8ee2239f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-f0bef7b6-8942-4ea5-89f0-4781e803e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-ee6a4b56-5578-4955-9361-4711f1e69d41,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-3aee3eba-2823-4fd8-b6f9-2a4bcfa3fc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-8aa6f691-663d-4882-b3b7-b3f0358cf697,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-e32a8eb7-cf6c-428d-b2f1-67711fc3a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-90d36376-f39c-456b-82dc-5fd5dc04e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-7d2a4251-d5e5-482e-ae25-e84c5cb3a379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767341884-172.17.0.21-1597367578563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-12de78b5-642b-40ad-9985-7cd8ee2239f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-f0bef7b6-8942-4ea5-89f0-4781e803e0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-ee6a4b56-5578-4955-9361-4711f1e69d41,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-3aee3eba-2823-4fd8-b6f9-2a4bcfa3fc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-8aa6f691-663d-4882-b3b7-b3f0358cf697,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-e32a8eb7-cf6c-428d-b2f1-67711fc3a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-90d36376-f39c-456b-82dc-5fd5dc04e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-7d2a4251-d5e5-482e-ae25-e84c5cb3a379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465104155-172.17.0.21-1597367699632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-558fb806-0340-47ed-9bdf-f65cee6aa150,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-1aef6bcd-de67-4c89-b8cd-2d78c4de6363,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-dca4388c-d7ed-4780-b849-2b89e364757d,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-6d87fdaf-fd78-45a1-84d8-9fcc0f8c5311,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-7a836a93-70ed-476f-a450-2d878a895cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-56c02d03-0147-4cce-aa55-29b9f7b851b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-1b942c16-788c-4fd0-a476-2609ba32d4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-8313a002-a1ae-48ea-aff8-34eb10be6774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1465104155-172.17.0.21-1597367699632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39062,DS-558fb806-0340-47ed-9bdf-f65cee6aa150,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-1aef6bcd-de67-4c89-b8cd-2d78c4de6363,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-dca4388c-d7ed-4780-b849-2b89e364757d,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-6d87fdaf-fd78-45a1-84d8-9fcc0f8c5311,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-7a836a93-70ed-476f-a450-2d878a895cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-56c02d03-0147-4cce-aa55-29b9f7b851b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-1b942c16-788c-4fd0-a476-2609ba32d4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-8313a002-a1ae-48ea-aff8-34eb10be6774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5573
