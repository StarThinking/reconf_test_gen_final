reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569695447-172.17.0.7-1597502830816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35256,DS-aac66a60-1ea4-4c07-875f-439017f55ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-de710b58-9b2d-43f6-bf41-bab5c4ded039,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-b194f0b1-da92-4f16-b63a-846615eeee22,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-8e76f366-5c32-4a58-9485-28f66e0b027e,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-6463a00c-b8d9-423e-b325-f92e275b258e,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-ca20b7a4-c79b-4cd0-a113-4af6580a1c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-5c0610b0-6778-42d2-8c55-27fa07118657,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-18d706d1-0f8b-49d4-be0e-fc721c2edc7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1569695447-172.17.0.7-1597502830816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35256,DS-aac66a60-1ea4-4c07-875f-439017f55ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-de710b58-9b2d-43f6-bf41-bab5c4ded039,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-b194f0b1-da92-4f16-b63a-846615eeee22,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-8e76f366-5c32-4a58-9485-28f66e0b027e,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-6463a00c-b8d9-423e-b325-f92e275b258e,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-ca20b7a4-c79b-4cd0-a113-4af6580a1c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-5c0610b0-6778-42d2-8c55-27fa07118657,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-18d706d1-0f8b-49d4-be0e-fc721c2edc7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433660248-172.17.0.7-1597503145609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37618,DS-d51b051f-f2d2-40ed-ab97-e3cefd431fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-81d3cbbe-f107-41d2-a887-7226db04b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-e14c1fa0-c316-48ff-a6ef-c5a9392a2f99,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-09d32cfe-5580-4ee4-8ea6-d49e972359a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-7aacbf81-1629-48f8-9542-83fa1d4b21bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-26052cf4-7c6d-4b37-9685-60cacd69c5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-5ef17682-ce13-4ccc-8945-eaf9a5ae93f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-55295380-5a0c-44a5-a5bc-6d20a1b25f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433660248-172.17.0.7-1597503145609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37618,DS-d51b051f-f2d2-40ed-ab97-e3cefd431fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-81d3cbbe-f107-41d2-a887-7226db04b55b,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-e14c1fa0-c316-48ff-a6ef-c5a9392a2f99,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-09d32cfe-5580-4ee4-8ea6-d49e972359a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-7aacbf81-1629-48f8-9542-83fa1d4b21bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-26052cf4-7c6d-4b37-9685-60cacd69c5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-5ef17682-ce13-4ccc-8945-eaf9a5ae93f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-55295380-5a0c-44a5-a5bc-6d20a1b25f4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840081761-172.17.0.7-1597503516471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-92fc8723-97be-40d0-9694-29eeba6e4070,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-e2f4b72f-fff5-487b-ac27-3a1d38f46dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-209318fd-351c-4591-947f-f7f4ed035e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-9cfb5517-4dc5-4319-9e22-fcd5bd5713fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-58f26fbe-7146-4c93-948e-2da51437f5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-305af8d0-52f9-432c-989b-3460046ecfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-f48e2434-14bb-4d03-ab77-6d8c425b45de,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-f29cc0b4-05f5-4178-9e2a-e60e11983142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840081761-172.17.0.7-1597503516471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-92fc8723-97be-40d0-9694-29eeba6e4070,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-e2f4b72f-fff5-487b-ac27-3a1d38f46dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-209318fd-351c-4591-947f-f7f4ed035e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-9cfb5517-4dc5-4319-9e22-fcd5bd5713fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-58f26fbe-7146-4c93-948e-2da51437f5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-305af8d0-52f9-432c-989b-3460046ecfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-f48e2434-14bb-4d03-ab77-6d8c425b45de,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-f29cc0b4-05f5-4178-9e2a-e60e11983142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993643809-172.17.0.7-1597503663267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42984,DS-23c0eb54-3cd5-45f7-a7ed-b6d22cd935f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-4dff9cf6-1d9e-4177-a67a-e6cea3f034a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-1618e374-2b86-4745-9bbd-8116c8515389,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-b9281441-758d-4bf0-8758-a18bb1a39fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-735cbe26-c5f8-4c1e-9b1c-8d4e23618167,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-8de0eedd-911a-4bdf-9d32-de59ec261f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-0a82f792-e6da-43a8-b875-4b6e696c470a,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-a1a623f5-7a19-4910-8e8f-3e211ac3cff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993643809-172.17.0.7-1597503663267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42984,DS-23c0eb54-3cd5-45f7-a7ed-b6d22cd935f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-4dff9cf6-1d9e-4177-a67a-e6cea3f034a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-1618e374-2b86-4745-9bbd-8116c8515389,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-b9281441-758d-4bf0-8758-a18bb1a39fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-735cbe26-c5f8-4c1e-9b1c-8d4e23618167,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-8de0eedd-911a-4bdf-9d32-de59ec261f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-0a82f792-e6da-43a8-b875-4b6e696c470a,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-a1a623f5-7a19-4910-8e8f-3e211ac3cff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115288976-172.17.0.7-1597504421577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37838,DS-139ce148-3a84-42a0-a4c7-b8d9b6110238,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-2e1f8c67-f56f-45b0-9223-130bd5b9bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-503f3698-57a2-4a28-a01f-4e9a47a2d55b,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-41ce1793-9dd3-4e73-a42a-33def3492945,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-f161a5de-895a-4088-a0e0-6aa3603b85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-0a0d28cf-417f-4a33-b1b8-2947f3465c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-364d2498-1557-4f36-9ed9-52fe1d6192d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-f2e7c44f-8fe7-4db0-8af2-b232db1dde3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115288976-172.17.0.7-1597504421577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37838,DS-139ce148-3a84-42a0-a4c7-b8d9b6110238,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-2e1f8c67-f56f-45b0-9223-130bd5b9bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-503f3698-57a2-4a28-a01f-4e9a47a2d55b,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-41ce1793-9dd3-4e73-a42a-33def3492945,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-f161a5de-895a-4088-a0e0-6aa3603b85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-0a0d28cf-417f-4a33-b1b8-2947f3465c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-364d2498-1557-4f36-9ed9-52fe1d6192d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-f2e7c44f-8fe7-4db0-8af2-b232db1dde3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189481568-172.17.0.7-1597504783745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-a12fb551-791c-4441-ba69-aab48d0e4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-32ae9c6f-64e3-4ff9-a3b3-aa90bd4d73ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-cd34299c-67f8-476b-97cc-0577725ae780,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-8b169eb3-0849-48de-8b13-7ef19ac4ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-d99c19ab-6b85-4448-8fef-059d2c112158,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-b67896e2-74a5-4402-9d08-b000a3ee2b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-e45a9f1b-e079-4fe3-91df-1207532ad8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-2467ea49-462d-496d-a20b-5af25439ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189481568-172.17.0.7-1597504783745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36127,DS-a12fb551-791c-4441-ba69-aab48d0e4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-32ae9c6f-64e3-4ff9-a3b3-aa90bd4d73ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-cd34299c-67f8-476b-97cc-0577725ae780,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-8b169eb3-0849-48de-8b13-7ef19ac4ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-d99c19ab-6b85-4448-8fef-059d2c112158,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-b67896e2-74a5-4402-9d08-b000a3ee2b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-e45a9f1b-e079-4fe3-91df-1207532ad8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-2467ea49-462d-496d-a20b-5af25439ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510594630-172.17.0.7-1597504852456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43030,DS-5aa1c1e8-9fba-46ee-89b8-317723468ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-305c7f83-3d54-4250-80aa-026e8b9a2cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-f10b5dff-e9b0-412c-a178-09de70302fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-97329dff-c740-4947-a057-27365563d195,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-7ff27359-5ab4-42c9-b5f1-0ad1840d6850,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-29b83847-4cc5-4da1-9cf1-286a357f5099,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-21596ee3-8585-49e8-84a5-25be297b4eec,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-35ff8c2d-9b87-4a5e-a7d1-afba2ab58d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510594630-172.17.0.7-1597504852456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43030,DS-5aa1c1e8-9fba-46ee-89b8-317723468ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-305c7f83-3d54-4250-80aa-026e8b9a2cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-f10b5dff-e9b0-412c-a178-09de70302fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-97329dff-c740-4947-a057-27365563d195,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-7ff27359-5ab4-42c9-b5f1-0ad1840d6850,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-29b83847-4cc5-4da1-9cf1-286a357f5099,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-21596ee3-8585-49e8-84a5-25be297b4eec,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-35ff8c2d-9b87-4a5e-a7d1-afba2ab58d1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473137726-172.17.0.7-1597505034822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37338,DS-fd5119c7-a0d6-4925-a650-c8122398d08f,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-ceeeb1ad-9643-4756-8670-9a9b95630b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-d0c34dbe-0568-417a-9a70-f476605f52a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-327f1926-b3d1-4853-827b-2d27d88a024b,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-c0973c12-c2d9-4580-ab1b-56f226a26ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-40a50af7-a37c-4ba9-8649-c74f9d52cbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-13f86c96-5754-4de1-b7ca-f3a711881f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-f1cf459b-db57-47d9-901a-cfb4a710414f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473137726-172.17.0.7-1597505034822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37338,DS-fd5119c7-a0d6-4925-a650-c8122398d08f,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-ceeeb1ad-9643-4756-8670-9a9b95630b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-d0c34dbe-0568-417a-9a70-f476605f52a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-327f1926-b3d1-4853-827b-2d27d88a024b,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-c0973c12-c2d9-4580-ab1b-56f226a26ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-40a50af7-a37c-4ba9-8649-c74f9d52cbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-13f86c96-5754-4de1-b7ca-f3a711881f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-f1cf459b-db57-47d9-901a-cfb4a710414f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713256910-172.17.0.7-1597505379959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-f447b40b-d3dd-4dd3-bbd2-fcd1d31564fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-896df96f-b4c7-488d-b546-9c4eb7ab5bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-88d39fe2-cb37-404e-bd2d-362d077f356a,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-6545bdad-8f12-4b91-9dfb-7dac27c8b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-f7450a80-8c95-4d6e-b318-2f8be4d85ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-7e668b24-37c3-40f9-9609-90ffa5e74b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f0a14e6c-831c-4f93-a1b1-3638cad9476f,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-9e1ca6ba-c196-4e33-b683-a2b912c365e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713256910-172.17.0.7-1597505379959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-f447b40b-d3dd-4dd3-bbd2-fcd1d31564fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-896df96f-b4c7-488d-b546-9c4eb7ab5bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-88d39fe2-cb37-404e-bd2d-362d077f356a,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-6545bdad-8f12-4b91-9dfb-7dac27c8b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-f7450a80-8c95-4d6e-b318-2f8be4d85ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-7e668b24-37c3-40f9-9609-90ffa5e74b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f0a14e6c-831c-4f93-a1b1-3638cad9476f,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-9e1ca6ba-c196-4e33-b683-a2b912c365e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076837319-172.17.0.7-1597505622551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-5d62febd-d974-42ed-a238-62e02fc5c15a,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-abcaecaa-d66f-421c-b135-8859f9b96fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-89dee6eb-a7e3-4dd0-8845-63ff475f7068,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-35c2dda7-5efa-4520-8112-c4741ca459d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-93332e83-d2f8-496f-a3f4-4465ee071a76,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-58c41deb-151d-4cd0-98f6-d39f4af36039,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-d09c79ee-0585-482f-8a6c-075b06bff072,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-84a08747-424f-46af-acf1-0b466c86c3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076837319-172.17.0.7-1597505622551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-5d62febd-d974-42ed-a238-62e02fc5c15a,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-abcaecaa-d66f-421c-b135-8859f9b96fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-89dee6eb-a7e3-4dd0-8845-63ff475f7068,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-35c2dda7-5efa-4520-8112-c4741ca459d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-93332e83-d2f8-496f-a3f4-4465ee071a76,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-58c41deb-151d-4cd0-98f6-d39f4af36039,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-d09c79ee-0585-482f-8a6c-075b06bff072,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-84a08747-424f-46af-acf1-0b466c86c3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260912235-172.17.0.7-1597506079607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37096,DS-53b91321-16b6-419b-bef0-f59d9648c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-4218d0b9-668b-417b-8331-79acdbc418b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-86c907ed-5378-4e0f-aba3-e68f8be1740f,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-1f8ea981-66ac-4cd9-b835-25c7fc923693,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-a3bf3005-8f66-40c6-9f65-71e3393c36ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-9e87bdc6-dcdd-4f3a-8150-f4eb41c20822,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-060115d2-b898-457d-8d06-1f435eca91a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-8bdd390d-881c-4ecc-a74e-3b3e165cf53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-260912235-172.17.0.7-1597506079607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37096,DS-53b91321-16b6-419b-bef0-f59d9648c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-4218d0b9-668b-417b-8331-79acdbc418b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-86c907ed-5378-4e0f-aba3-e68f8be1740f,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-1f8ea981-66ac-4cd9-b835-25c7fc923693,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-a3bf3005-8f66-40c6-9f65-71e3393c36ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-9e87bdc6-dcdd-4f3a-8150-f4eb41c20822,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-060115d2-b898-457d-8d06-1f435eca91a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-8bdd390d-881c-4ecc-a74e-3b3e165cf53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272771746-172.17.0.7-1597506263600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35501,DS-c46b70d2-9539-46ba-b886-a9fa0c0f7277,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-c0b00eab-2539-45d0-b115-02765fbfdb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-c1d90f73-9112-4b66-a19e-268fbc654ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-446db2e3-7dd8-456e-91b6-aab34ef7bd18,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-3baf1209-5dee-4e74-82db-04a7e50bc884,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-2d7eaae7-2399-4527-9c00-dc5a744240fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-c804fd1c-0f88-4076-a137-d72f1439efee,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-7a0cbdcf-433d-4f3d-94ae-765795df910b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272771746-172.17.0.7-1597506263600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35501,DS-c46b70d2-9539-46ba-b886-a9fa0c0f7277,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-c0b00eab-2539-45d0-b115-02765fbfdb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-c1d90f73-9112-4b66-a19e-268fbc654ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-446db2e3-7dd8-456e-91b6-aab34ef7bd18,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-3baf1209-5dee-4e74-82db-04a7e50bc884,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-2d7eaae7-2399-4527-9c00-dc5a744240fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-c804fd1c-0f88-4076-a137-d72f1439efee,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-7a0cbdcf-433d-4f3d-94ae-765795df910b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822345929-172.17.0.7-1597506302602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40221,DS-207da6cf-84e6-4513-8b36-2fe873c0772f,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-c28c110c-f6d5-4d39-b737-e9a6aa215889,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-57e7088a-2495-4f0d-8425-d4b220660023,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-aceb45ff-7c45-47f8-8315-8f7389ffcdca,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-e3b0fd4a-eb66-43dc-9d3e-dae687c940b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-3ccb8d82-c4f0-4469-a03a-e3584742b42d,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-5e32566b-7b60-48f9-a9b6-85e040f33318,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-54903156-f7da-47a5-852f-211470962a8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822345929-172.17.0.7-1597506302602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40221,DS-207da6cf-84e6-4513-8b36-2fe873c0772f,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-c28c110c-f6d5-4d39-b737-e9a6aa215889,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-57e7088a-2495-4f0d-8425-d4b220660023,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-aceb45ff-7c45-47f8-8315-8f7389ffcdca,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-e3b0fd4a-eb66-43dc-9d3e-dae687c940b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-3ccb8d82-c4f0-4469-a03a-e3584742b42d,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-5e32566b-7b60-48f9-a9b6-85e040f33318,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-54903156-f7da-47a5-852f-211470962a8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333164411-172.17.0.7-1597506446997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44698,DS-6456c2f6-645d-42c4-8664-850ede1afb83,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-9d558690-24b5-4ae9-9434-6bb48014ea66,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-3895331b-4a77-4550-a6bc-bdae1aa0a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-7ff8bb9b-a2a8-46ba-adc8-41592b18a964,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-d0a5c605-09fc-4813-9197-e4153d08d093,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-4be87099-57d1-485a-bbf8-206eb209828c,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-4b074f23-6022-4800-bc3f-56cb3ec73208,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-b276293f-4eeb-48ad-9cf6-e36ac52cceba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333164411-172.17.0.7-1597506446997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44698,DS-6456c2f6-645d-42c4-8664-850ede1afb83,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-9d558690-24b5-4ae9-9434-6bb48014ea66,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-3895331b-4a77-4550-a6bc-bdae1aa0a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-7ff8bb9b-a2a8-46ba-adc8-41592b18a964,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-d0a5c605-09fc-4813-9197-e4153d08d093,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-4be87099-57d1-485a-bbf8-206eb209828c,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-4b074f23-6022-4800-bc3f-56cb3ec73208,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-b276293f-4eeb-48ad-9cf6-e36ac52cceba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594613050-172.17.0.7-1597506633306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33127,DS-a2087831-e72c-4f6f-b20a-6e99dd27808a,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-e39cc769-e885-4510-83ac-fffa02f0270b,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-ed14861b-7b1b-4883-8196-43031511c828,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-7df8cb4b-863f-42f5-a8a9-79e396224e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-971c2252-8e16-461b-8ba5-0bcb0431cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-b39baa91-da07-45f0-bc2d-4f7d27050a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-15fb786f-3ed1-4b25-bf4a-22ca36b105a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-99443524-35e5-4fd8-94e8-8f0accd7f44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594613050-172.17.0.7-1597506633306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33127,DS-a2087831-e72c-4f6f-b20a-6e99dd27808a,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-e39cc769-e885-4510-83ac-fffa02f0270b,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-ed14861b-7b1b-4883-8196-43031511c828,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-7df8cb4b-863f-42f5-a8a9-79e396224e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-971c2252-8e16-461b-8ba5-0bcb0431cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-b39baa91-da07-45f0-bc2d-4f7d27050a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-15fb786f-3ed1-4b25-bf4a-22ca36b105a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-99443524-35e5-4fd8-94e8-8f0accd7f44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358158342-172.17.0.7-1597506709542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40273,DS-f74020ce-ee04-4a56-8dfb-07933e1755f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-d3053a81-f30d-4d92-8edd-dce01d2f9b03,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-b17ac0b5-efeb-4d69-a977-672f2a153fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-70b4f8e8-515d-47de-9f94-d0fb816caa18,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-34c2dfd6-3785-43bf-a2a0-2e870ea9d30c,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-982ff854-a23c-4f48-aeeb-231f6c8d88bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-f299c567-d60a-45b0-a50c-7feb5f1b9bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-1e5450a3-72ed-4e6c-9298-30e6086544a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358158342-172.17.0.7-1597506709542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40273,DS-f74020ce-ee04-4a56-8dfb-07933e1755f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-d3053a81-f30d-4d92-8edd-dce01d2f9b03,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-b17ac0b5-efeb-4d69-a977-672f2a153fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-70b4f8e8-515d-47de-9f94-d0fb816caa18,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-34c2dfd6-3785-43bf-a2a0-2e870ea9d30c,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-982ff854-a23c-4f48-aeeb-231f6c8d88bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-f299c567-d60a-45b0-a50c-7feb5f1b9bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-1e5450a3-72ed-4e6c-9298-30e6086544a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766095806-172.17.0.7-1597506748338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42848,DS-8ee23791-260f-4bf2-ace1-d56f5a29ba47,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-e8b2400a-0c75-4c93-8b9d-dec9c1bc8fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-baa85b09-27fc-47e0-95d3-ae9b4b13db20,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-41da0b21-2243-4ddf-ba95-25919dbd3ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-4e6b67cf-0f2d-49e0-9807-9ab42afb6b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-b798d8db-b7e4-4ed3-a87a-450e0b6ebddc,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-0be74a88-2a9a-40a6-aa6f-fbf32c2cefcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-1d65c1d5-889e-4034-a3ae-cecbeabe4131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1766095806-172.17.0.7-1597506748338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42848,DS-8ee23791-260f-4bf2-ace1-d56f5a29ba47,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-e8b2400a-0c75-4c93-8b9d-dec9c1bc8fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-baa85b09-27fc-47e0-95d3-ae9b4b13db20,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-41da0b21-2243-4ddf-ba95-25919dbd3ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-4e6b67cf-0f2d-49e0-9807-9ab42afb6b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-b798d8db-b7e4-4ed3-a87a-450e0b6ebddc,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-0be74a88-2a9a-40a6-aa6f-fbf32c2cefcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-1d65c1d5-889e-4034-a3ae-cecbeabe4131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962434867-172.17.0.7-1597506894928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33643,DS-0a142ea1-f7c2-4325-8eab-622b46051f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-3780ebad-2413-4462-ae5d-978656e2cae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-90dd1b43-ba4f-403c-8e2e-c17a8ccd1b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-f992cb88-cc63-4ea3-a42a-697e4c3bf199,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-7968d5e7-c8a9-4083-919a-cc096b3df9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-33dbe522-fbfc-4d7a-8adc-b2d34630d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-2edfc3c2-607d-4aeb-8cb9-dc70fc173b12,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-a2ca090a-63f9-4f04-b941-3a7cf71cee09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962434867-172.17.0.7-1597506894928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33643,DS-0a142ea1-f7c2-4325-8eab-622b46051f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-3780ebad-2413-4462-ae5d-978656e2cae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-90dd1b43-ba4f-403c-8e2e-c17a8ccd1b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-f992cb88-cc63-4ea3-a42a-697e4c3bf199,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-7968d5e7-c8a9-4083-919a-cc096b3df9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-33dbe522-fbfc-4d7a-8adc-b2d34630d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-2edfc3c2-607d-4aeb-8cb9-dc70fc173b12,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-a2ca090a-63f9-4f04-b941-3a7cf71cee09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924288616-172.17.0.7-1597507627705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-a03d8982-dc74-41c0-92f3-ced8172e5913,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-62bfebf6-6763-46ad-ae80-9bc9ef1f5a84,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-69a76950-8f93-48e5-9cc1-b742f9ebd124,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-b0336954-223f-4eba-adb2-b53882a87409,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-bba1a72a-3ac8-4577-afbd-83596f671f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-c729d9ff-6e93-4501-93b4-bde5be694ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-a1d9b844-3428-43de-87d9-fa98f69a68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-7fedf169-aad4-48c4-baca-95c7af243e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924288616-172.17.0.7-1597507627705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-a03d8982-dc74-41c0-92f3-ced8172e5913,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-62bfebf6-6763-46ad-ae80-9bc9ef1f5a84,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-69a76950-8f93-48e5-9cc1-b742f9ebd124,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-b0336954-223f-4eba-adb2-b53882a87409,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-bba1a72a-3ac8-4577-afbd-83596f671f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-c729d9ff-6e93-4501-93b4-bde5be694ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-a1d9b844-3428-43de-87d9-fa98f69a68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-7fedf169-aad4-48c4-baca-95c7af243e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929659222-172.17.0.7-1597507763506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-7680a0ab-23bc-4f73-8aca-97a6e6e36e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-a3a890dc-29eb-410b-97eb-596a4dfbba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-50b1ba04-03f4-41fb-8f45-1ad8401b7d15,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-4ec8115f-e226-4140-98ee-e91ed3da75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-bf55c64a-18e6-423f-af1c-0be45d082426,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-13677956-99a5-42f4-87d3-6ec758ae6d41,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-8222d3d6-5314-4c39-86ff-2c9fd2eb23fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-791f9a37-186f-4658-a2c8-45cbc1eed870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1929659222-172.17.0.7-1597507763506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-7680a0ab-23bc-4f73-8aca-97a6e6e36e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-a3a890dc-29eb-410b-97eb-596a4dfbba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-50b1ba04-03f4-41fb-8f45-1ad8401b7d15,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-4ec8115f-e226-4140-98ee-e91ed3da75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-bf55c64a-18e6-423f-af1c-0be45d082426,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-13677956-99a5-42f4-87d3-6ec758ae6d41,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-8222d3d6-5314-4c39-86ff-2c9fd2eb23fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-791f9a37-186f-4658-a2c8-45cbc1eed870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928901292-172.17.0.7-1597507839821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-66333544-87ab-48ca-812a-3dd5c1891b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-d7cda17b-27a8-4868-8592-94089623e478,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-d9fe7b7c-32d8-40e9-b1f4-7eddc7912d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-0ad6a0ba-ef42-4feb-8acd-d0d986314cff,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-c8e7d07a-aa74-41fb-97f1-76fe274e066f,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-edaa0503-4d34-47e3-9207-b0ac7a0f2cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-6e262c29-99a3-4dce-90ba-5c34b13574bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-e998a84c-695b-4265-8dcc-71176332df01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928901292-172.17.0.7-1597507839821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-66333544-87ab-48ca-812a-3dd5c1891b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-d7cda17b-27a8-4868-8592-94089623e478,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-d9fe7b7c-32d8-40e9-b1f4-7eddc7912d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-0ad6a0ba-ef42-4feb-8acd-d0d986314cff,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-c8e7d07a-aa74-41fb-97f1-76fe274e066f,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-edaa0503-4d34-47e3-9207-b0ac7a0f2cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-6e262c29-99a3-4dce-90ba-5c34b13574bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-e998a84c-695b-4265-8dcc-71176332df01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5389
