reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977432040-172.17.0.11-1597400258804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-b84bc122-e681-44aa-9c49-ad128016859c,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-f1181dca-7bec-4cb0-9fe8-354c8cd04e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-edec5954-4194-469f-adb4-6ddf8f9fbe77,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-1eac605c-f8b1-4f48-a119-d95f414fc9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-b5b01561-a87b-447e-a7ba-ef839b050b99,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-12c53811-aff2-42fa-ad4a-f8b7730d4927,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-c080080b-14f1-4939-b179-e3f19a02f3db,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-27e4189b-be62-41f4-8a45-ae95ab521fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977432040-172.17.0.11-1597400258804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-b84bc122-e681-44aa-9c49-ad128016859c,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-f1181dca-7bec-4cb0-9fe8-354c8cd04e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-edec5954-4194-469f-adb4-6ddf8f9fbe77,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-1eac605c-f8b1-4f48-a119-d95f414fc9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-b5b01561-a87b-447e-a7ba-ef839b050b99,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-12c53811-aff2-42fa-ad4a-f8b7730d4927,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-c080080b-14f1-4939-b179-e3f19a02f3db,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-27e4189b-be62-41f4-8a45-ae95ab521fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259094881-172.17.0.11-1597400347172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46035,DS-d633be4c-db47-4884-a6e1-41cb070c3510,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-7d174e90-d035-41e9-b331-14b5bfcadc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-09af3946-0542-4275-97d1-a0504d92aa73,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-5c0873b9-593d-4bec-8e7a-8ac0e8fb56f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-c1435abd-8417-482e-ab9c-0e37124a6ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-97abb95d-416c-4952-a450-e24cc592b199,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-2eaf69d5-7964-4074-8c72-70ceed7e9394,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-48a529d1-fe6d-4220-a5a5-d3cea85908f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259094881-172.17.0.11-1597400347172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46035,DS-d633be4c-db47-4884-a6e1-41cb070c3510,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-7d174e90-d035-41e9-b331-14b5bfcadc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-09af3946-0542-4275-97d1-a0504d92aa73,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-5c0873b9-593d-4bec-8e7a-8ac0e8fb56f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-c1435abd-8417-482e-ab9c-0e37124a6ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-97abb95d-416c-4952-a450-e24cc592b199,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-2eaf69d5-7964-4074-8c72-70ceed7e9394,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-48a529d1-fe6d-4220-a5a5-d3cea85908f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257124975-172.17.0.11-1597400600714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-23e410f4-c7de-4a35-97aa-a0fea91c812f,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-ddec5964-e5ab-44d3-94bc-a385281b8da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-6cf389b1-5f88-4a85-a01a-6d86b6db8405,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-c3d9155c-95de-4114-ae13-6382d89c48ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-717fc818-1bff-46e0-b637-1ecea00028f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-96a4fab3-7f27-4023-98a3-5f4de2be4156,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-f22a6860-c528-46f1-8ce3-1ba518394cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-7c8ad406-f6c5-40c9-ac68-4b627226f013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257124975-172.17.0.11-1597400600714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-23e410f4-c7de-4a35-97aa-a0fea91c812f,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-ddec5964-e5ab-44d3-94bc-a385281b8da3,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-6cf389b1-5f88-4a85-a01a-6d86b6db8405,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-c3d9155c-95de-4114-ae13-6382d89c48ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-717fc818-1bff-46e0-b637-1ecea00028f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-96a4fab3-7f27-4023-98a3-5f4de2be4156,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-f22a6860-c528-46f1-8ce3-1ba518394cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-7c8ad406-f6c5-40c9-ac68-4b627226f013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6494511-172.17.0.11-1597400837081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-b4608ee3-75a5-498e-bc94-dc0b00777da2,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-132569de-7139-49b6-9024-9229872008c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-6ed66ec9-7b1d-4744-8419-04a42526a4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-406e0f65-31e6-4782-a67a-511858d256c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-cca7a501-bb91-452b-8e5f-cbac1e1bc6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1b6b3945-8080-4d5f-9243-7bb00ab8c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-94f208bb-3c3f-4232-bfe8-56570282fa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-e254a2b5-bc16-4192-8403-6c3719bc5e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6494511-172.17.0.11-1597400837081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-b4608ee3-75a5-498e-bc94-dc0b00777da2,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-132569de-7139-49b6-9024-9229872008c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-6ed66ec9-7b1d-4744-8419-04a42526a4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-406e0f65-31e6-4782-a67a-511858d256c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-cca7a501-bb91-452b-8e5f-cbac1e1bc6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1b6b3945-8080-4d5f-9243-7bb00ab8c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-94f208bb-3c3f-4232-bfe8-56570282fa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-e254a2b5-bc16-4192-8403-6c3719bc5e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89414472-172.17.0.11-1597401005701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38592,DS-e2505994-6017-4bc2-9a49-b2924bf4e105,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-d7c1a2e8-69e4-4cda-9426-95a8e600f221,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-e72cc9c1-1c23-4173-ac74-373b9ae0c218,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-d1ad6141-ce76-4a70-858d-2b5cc5d12a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-b9e51de5-0e05-4775-8b39-ab24e05dbdee,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-f255d825-0c65-44b6-9b13-a8616f238ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-d50a7aa3-5bf3-40d3-992a-2dd16650f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-c81cbe45-a218-4f85-8ede-53e2dcf38be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89414472-172.17.0.11-1597401005701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38592,DS-e2505994-6017-4bc2-9a49-b2924bf4e105,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-d7c1a2e8-69e4-4cda-9426-95a8e600f221,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-e72cc9c1-1c23-4173-ac74-373b9ae0c218,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-d1ad6141-ce76-4a70-858d-2b5cc5d12a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-b9e51de5-0e05-4775-8b39-ab24e05dbdee,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-f255d825-0c65-44b6-9b13-a8616f238ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-d50a7aa3-5bf3-40d3-992a-2dd16650f82a,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-c81cbe45-a218-4f85-8ede-53e2dcf38be8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587460452-172.17.0.11-1597401062336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-3ef1f327-e748-456b-9067-30b9b1b37dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-8f343f51-5e8b-4596-9155-bfed65d636f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-43b6e639-ab25-460c-80ce-509742c1f234,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-ddc3c305-7f3e-463e-8791-2a25472e41a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-e3f80c6f-7002-40b1-be01-cf81803d0dba,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-ba322e4a-e20f-41bf-9e46-fea43d218fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-5fdead1d-c263-44ea-9b10-3750d0f21fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-9ec88c68-4d41-4962-add0-452d7f5bb22e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587460452-172.17.0.11-1597401062336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-3ef1f327-e748-456b-9067-30b9b1b37dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-8f343f51-5e8b-4596-9155-bfed65d636f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-43b6e639-ab25-460c-80ce-509742c1f234,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-ddc3c305-7f3e-463e-8791-2a25472e41a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-e3f80c6f-7002-40b1-be01-cf81803d0dba,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-ba322e4a-e20f-41bf-9e46-fea43d218fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-5fdead1d-c263-44ea-9b10-3750d0f21fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-9ec88c68-4d41-4962-add0-452d7f5bb22e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913856173-172.17.0.11-1597401192761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-0c854c2d-6fae-4741-8087-940cc0cf4438,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-9bd7e7eb-738a-4395-8866-71246401732f,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-8a83e006-5735-4831-93d5-c355a1ab4b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-877872f1-397a-4baa-b6ec-71ede8da7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-2415c6a6-8a7a-40d9-bd3a-8efe80d8a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-9a541dfa-83ee-4890-84f4-4e3ea130ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-18a9c493-edb5-4488-96e4-fff124649c52,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-d772a9f3-4fda-4f54-9515-19e776c94f6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913856173-172.17.0.11-1597401192761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-0c854c2d-6fae-4741-8087-940cc0cf4438,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-9bd7e7eb-738a-4395-8866-71246401732f,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-8a83e006-5735-4831-93d5-c355a1ab4b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-877872f1-397a-4baa-b6ec-71ede8da7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-2415c6a6-8a7a-40d9-bd3a-8efe80d8a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-9a541dfa-83ee-4890-84f4-4e3ea130ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-18a9c493-edb5-4488-96e4-fff124649c52,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-d772a9f3-4fda-4f54-9515-19e776c94f6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207175063-172.17.0.11-1597402363029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-a094b184-dc89-4528-843f-2a1f05609661,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-e6631da2-8e32-4002-aad8-03c775c28d56,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-a6ed0c24-1af0-494b-95ea-94c68d3275b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-2de9df79-2224-4bb1-9eb6-9973e8ada7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-07e77eaf-572f-4da3-90f3-b6d1b9e82e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-ad544584-2703-4f61-9125-9dc038bb36a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-ee785a13-7198-47b7-9370-ccbd6d3bb23e,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-eb8ed29f-ac60-47b3-86db-a4be7c03affc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207175063-172.17.0.11-1597402363029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35586,DS-a094b184-dc89-4528-843f-2a1f05609661,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-e6631da2-8e32-4002-aad8-03c775c28d56,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-a6ed0c24-1af0-494b-95ea-94c68d3275b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-2de9df79-2224-4bb1-9eb6-9973e8ada7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-07e77eaf-572f-4da3-90f3-b6d1b9e82e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-ad544584-2703-4f61-9125-9dc038bb36a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-ee785a13-7198-47b7-9370-ccbd6d3bb23e,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-eb8ed29f-ac60-47b3-86db-a4be7c03affc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671620566-172.17.0.11-1597402977419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-a190dcb1-0890-4c33-975e-5169644e8544,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-78fed0f4-6d70-4f77-8409-1bd30d40aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-2fa16027-92f5-4744-94c3-3889409ff9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-6af78bb6-c5f9-450e-9bb5-d1a2a20498ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-8c5da60a-0c34-42db-abc9-1d73e8ef3910,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-fe3c2edc-e5ed-4e1f-880f-e4fad099a867,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-2beb2449-8969-4a63-aca4-cd74166af246,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-748e627e-ba4c-474c-ab38-40e44626c6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671620566-172.17.0.11-1597402977419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-a190dcb1-0890-4c33-975e-5169644e8544,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-78fed0f4-6d70-4f77-8409-1bd30d40aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-2fa16027-92f5-4744-94c3-3889409ff9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-6af78bb6-c5f9-450e-9bb5-d1a2a20498ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-8c5da60a-0c34-42db-abc9-1d73e8ef3910,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-fe3c2edc-e5ed-4e1f-880f-e4fad099a867,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-2beb2449-8969-4a63-aca4-cd74166af246,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-748e627e-ba4c-474c-ab38-40e44626c6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570319017-172.17.0.11-1597403029317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-ba918e3a-0cc7-4e43-be3c-b5ea2ffe8e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-9954f080-81f5-4c62-a732-905b67168e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-63854436-30bb-45aa-a50c-3863094ac71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-96a9f7f0-e2ec-44e3-b57e-782037ee9793,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-c569249c-d809-451b-86b7-7b4902c959d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-795c466c-1b03-473f-911c-7d88826bb456,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-d624fede-372e-4277-96c9-855e6a7656f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-d6ee2283-01d8-4e50-8857-4949b21d4461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570319017-172.17.0.11-1597403029317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-ba918e3a-0cc7-4e43-be3c-b5ea2ffe8e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-9954f080-81f5-4c62-a732-905b67168e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-63854436-30bb-45aa-a50c-3863094ac71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-96a9f7f0-e2ec-44e3-b57e-782037ee9793,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-c569249c-d809-451b-86b7-7b4902c959d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-795c466c-1b03-473f-911c-7d88826bb456,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-d624fede-372e-4277-96c9-855e6a7656f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-d6ee2283-01d8-4e50-8857-4949b21d4461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342688501-172.17.0.11-1597403120147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46250,DS-f06f505a-743f-4e12-9b87-cd4d51364a38,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-f8ac8d2b-db71-4485-9c36-f857fc7db033,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-f61ee93d-0217-49c5-b1b0-05d97885745c,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-3dcc3b35-ed0b-4577-8026-3e449169083e,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8919b12c-fbb0-4cfa-acb4-c0589b23e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-64d66986-0bfd-4777-b570-5aed3fe97e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-00baee6d-e9d4-48a9-b2e1-84cdc2422d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-7b4a5c5a-ca15-4f57-8242-4f6c6a2708f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342688501-172.17.0.11-1597403120147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46250,DS-f06f505a-743f-4e12-9b87-cd4d51364a38,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-f8ac8d2b-db71-4485-9c36-f857fc7db033,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-f61ee93d-0217-49c5-b1b0-05d97885745c,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-3dcc3b35-ed0b-4577-8026-3e449169083e,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8919b12c-fbb0-4cfa-acb4-c0589b23e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-64d66986-0bfd-4777-b570-5aed3fe97e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-00baee6d-e9d4-48a9-b2e1-84cdc2422d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-7b4a5c5a-ca15-4f57-8242-4f6c6a2708f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638505143-172.17.0.11-1597403643351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43901,DS-3037ae98-8168-4676-9f90-b9558bb32ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-e5d32956-7eee-4f74-bf81-a52a80a0782b,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8e446395-122d-4b5e-a429-f5815d76f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-9675c2dc-ddfe-44fc-b9b5-c5b1652fccce,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-543344b3-5376-4d5e-adde-9598655b212f,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-cc110701-3969-4a38-a98b-261c708e39a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-da7aead4-f402-415f-92da-f710463858a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-315e7632-4177-4ff4-b71d-f4e787c12421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638505143-172.17.0.11-1597403643351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43901,DS-3037ae98-8168-4676-9f90-b9558bb32ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-e5d32956-7eee-4f74-bf81-a52a80a0782b,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8e446395-122d-4b5e-a429-f5815d76f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-9675c2dc-ddfe-44fc-b9b5-c5b1652fccce,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-543344b3-5376-4d5e-adde-9598655b212f,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-cc110701-3969-4a38-a98b-261c708e39a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-da7aead4-f402-415f-92da-f710463858a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-315e7632-4177-4ff4-b71d-f4e787c12421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981752622-172.17.0.11-1597403687480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-e39d6897-b54d-48c6-99c8-04809bbd8845,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-b8b4cc00-889c-4836-9688-d5992bad2a38,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-7469c30e-a528-46d8-8798-e7b4db68f980,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-e79621f6-c4d8-410c-9189-bdcdf3311fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-46ab7c30-029f-412d-b18f-ed32fe26db8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-dcb2ac9f-a53a-415b-8d52-c1e598b51d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-f27ed102-c0d9-47f3-9a64-43ed38a0f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-243a6ae0-c730-464f-bb4c-a2bc840e33d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981752622-172.17.0.11-1597403687480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-e39d6897-b54d-48c6-99c8-04809bbd8845,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-b8b4cc00-889c-4836-9688-d5992bad2a38,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-7469c30e-a528-46d8-8798-e7b4db68f980,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-e79621f6-c4d8-410c-9189-bdcdf3311fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-46ab7c30-029f-412d-b18f-ed32fe26db8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-dcb2ac9f-a53a-415b-8d52-c1e598b51d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-f27ed102-c0d9-47f3-9a64-43ed38a0f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-243a6ae0-c730-464f-bb4c-a2bc840e33d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851561741-172.17.0.11-1597403780359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-479ba5ee-2d8a-4426-a5fb-ea639ac6e164,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-4bd5b1d7-5625-422a-a7f5-56635513b541,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-ddbec1fc-e15b-4d09-917b-f3f9639c2593,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-e7fdff8f-ea88-4f41-a366-6f530bdcedce,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-7aa5be25-a306-4adb-a668-7846715e0afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-e37eff2e-9d8a-4224-9130-712439a676bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-881d7ae4-2b92-417d-b79a-87efc9d5cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-11b83aa2-7ebe-41aa-a0a0-8c7db37186a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851561741-172.17.0.11-1597403780359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39652,DS-479ba5ee-2d8a-4426-a5fb-ea639ac6e164,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-4bd5b1d7-5625-422a-a7f5-56635513b541,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-ddbec1fc-e15b-4d09-917b-f3f9639c2593,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-e7fdff8f-ea88-4f41-a366-6f530bdcedce,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-7aa5be25-a306-4adb-a668-7846715e0afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-e37eff2e-9d8a-4224-9130-712439a676bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-881d7ae4-2b92-417d-b79a-87efc9d5cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-11b83aa2-7ebe-41aa-a0a0-8c7db37186a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122335135-172.17.0.11-1597404795891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43507,DS-e869ded2-dd62-4786-b0d6-e0dbbaad9b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-80e212e3-f677-41aa-9bcd-026e5560548a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-4ce57625-3ef3-4874-9241-c1731a1ee293,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-7c3a7955-4f7a-4b1b-809c-e5dce9076886,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-e11748f6-262a-4267-b961-6fad75e63b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-1d59fa18-6e92-4899-b7ef-ec375c7297dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-84e14892-cd59-4de2-bcc2-59b343376c93,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-198a0bfc-f94f-44ad-bf61-f0eb3ad0ac3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122335135-172.17.0.11-1597404795891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43507,DS-e869ded2-dd62-4786-b0d6-e0dbbaad9b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-80e212e3-f677-41aa-9bcd-026e5560548a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-4ce57625-3ef3-4874-9241-c1731a1ee293,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-7c3a7955-4f7a-4b1b-809c-e5dce9076886,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-e11748f6-262a-4267-b961-6fad75e63b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-1d59fa18-6e92-4899-b7ef-ec375c7297dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-84e14892-cd59-4de2-bcc2-59b343376c93,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-198a0bfc-f94f-44ad-bf61-f0eb3ad0ac3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334859553-172.17.0.11-1597405266445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-affc9489-e65f-4973-9eec-c5fc65a8d919,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-e5d926d3-516b-4de5-8f2d-b4fb732a148d,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-ad332cfb-4ac8-4f91-bed8-f1fa4508313c,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-1efbfbe4-073d-413a-9af6-3a155fd1d4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-5b129ca4-0eb8-45f5-ab04-3956fea7558d,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-f11d5a1f-6fa5-40ab-9e76-05e7f3134550,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-118b5110-8944-4536-a6e5-5083300699b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-3a2d723d-2fab-48ee-9d76-c5342f83873d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334859553-172.17.0.11-1597405266445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-affc9489-e65f-4973-9eec-c5fc65a8d919,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-e5d926d3-516b-4de5-8f2d-b4fb732a148d,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-ad332cfb-4ac8-4f91-bed8-f1fa4508313c,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-1efbfbe4-073d-413a-9af6-3a155fd1d4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-5b129ca4-0eb8-45f5-ab04-3956fea7558d,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-f11d5a1f-6fa5-40ab-9e76-05e7f3134550,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-118b5110-8944-4536-a6e5-5083300699b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-3a2d723d-2fab-48ee-9d76-c5342f83873d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052655152-172.17.0.11-1597405555586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-085f5dc2-2b6c-4695-a8bc-31660f11510c,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-a65bc0d8-6c32-4400-882d-692440479ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-ae1b1252-7b12-4519-92bd-53aa8b9737cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-88d3533e-c2f6-4a98-ace9-2ddb62278a82,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-94c54552-63a4-4335-941e-f9ed715d7291,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-6586a5de-122e-458e-8230-f6f634909019,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-c8df89aa-ffbf-4784-88b4-e0a5ce7892d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-134f827b-2548-4213-93b3-b974b284e6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052655152-172.17.0.11-1597405555586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-085f5dc2-2b6c-4695-a8bc-31660f11510c,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-a65bc0d8-6c32-4400-882d-692440479ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-ae1b1252-7b12-4519-92bd-53aa8b9737cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-88d3533e-c2f6-4a98-ace9-2ddb62278a82,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-94c54552-63a4-4335-941e-f9ed715d7291,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-6586a5de-122e-458e-8230-f6f634909019,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-c8df89aa-ffbf-4784-88b4-e0a5ce7892d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-134f827b-2548-4213-93b3-b974b284e6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.write-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535049369-172.17.0.11-1597406628207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-e43af176-7bbb-4e36-8bda-f38580c755cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-8454e224-9a5b-43c2-9d30-98337bc19586,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-16ef45d1-3fcb-46db-a9ce-b5a9d9c42e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-b4a92f7d-26b6-426e-8f10-eb6c9e4b2b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-859014fa-6764-45c9-b265-ca958740f72c,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-339a513e-6f8e-4803-87d6-8b81ed538579,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-b6a2c9fe-0656-4cfd-be7f-ee94ae9ec053,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-3a169827-2cab-4d3f-9b27-c696e933823c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535049369-172.17.0.11-1597406628207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36985,DS-e43af176-7bbb-4e36-8bda-f38580c755cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-8454e224-9a5b-43c2-9d30-98337bc19586,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-16ef45d1-3fcb-46db-a9ce-b5a9d9c42e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-b4a92f7d-26b6-426e-8f10-eb6c9e4b2b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-859014fa-6764-45c9-b265-ca958740f72c,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-339a513e-6f8e-4803-87d6-8b81ed538579,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-b6a2c9fe-0656-4cfd-be7f-ee94ae9ec053,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-3a169827-2cab-4d3f-9b27-c696e933823c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7104
