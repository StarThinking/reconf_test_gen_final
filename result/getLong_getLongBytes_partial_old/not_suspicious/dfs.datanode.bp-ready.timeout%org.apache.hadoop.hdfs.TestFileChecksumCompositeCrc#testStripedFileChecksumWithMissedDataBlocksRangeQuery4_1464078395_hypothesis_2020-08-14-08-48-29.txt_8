reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913316078-172.17.0.8-1597395653908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36419,DS-085bfd54-69b3-4e31-976a-50e2bfb6a010,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-6d5d09bd-8875-4f4a-b3e0-fc3ec7b1af43,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-c28941cc-43b1-4730-bd33-4fef6958472e,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-58f15d7b-9c75-4c88-bd71-c775f418406b,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-b29a04dc-0d17-4aed-8d21-d52e2676a612,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-b2da698e-3dc9-4ec2-9626-94ebbb9b98b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-9082ee48-5ac5-4da3-ab52-e9df941e1dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-439e53fa-06d8-4d31-a65e-9d43f8d8b404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913316078-172.17.0.8-1597395653908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36419,DS-085bfd54-69b3-4e31-976a-50e2bfb6a010,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-6d5d09bd-8875-4f4a-b3e0-fc3ec7b1af43,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-c28941cc-43b1-4730-bd33-4fef6958472e,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-58f15d7b-9c75-4c88-bd71-c775f418406b,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-b29a04dc-0d17-4aed-8d21-d52e2676a612,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-b2da698e-3dc9-4ec2-9626-94ebbb9b98b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-9082ee48-5ac5-4da3-ab52-e9df941e1dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-439e53fa-06d8-4d31-a65e-9d43f8d8b404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238374272-172.17.0.8-1597395921940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-ef3cf4c6-dd79-48b6-bfad-17531d0f6060,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-1504c41e-553e-4eaf-b3e5-2ee30e2828c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-63e52b1f-d2a1-40d0-b091-57af33e6f048,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-2743eec7-69c7-42f2-9860-f3dc6b8054bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-00929805-b552-4fee-ba06-aca11bb8bb88,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-35494048-b9ef-4423-ba12-e21ab1bf21c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-2184107d-ab9a-44e3-984e-ab8ad963c84c,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-81b8ddc5-9a9b-4099-83ac-07d9336bdc48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238374272-172.17.0.8-1597395921940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-ef3cf4c6-dd79-48b6-bfad-17531d0f6060,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-1504c41e-553e-4eaf-b3e5-2ee30e2828c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-63e52b1f-d2a1-40d0-b091-57af33e6f048,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-2743eec7-69c7-42f2-9860-f3dc6b8054bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-00929805-b552-4fee-ba06-aca11bb8bb88,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-35494048-b9ef-4423-ba12-e21ab1bf21c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-2184107d-ab9a-44e3-984e-ab8ad963c84c,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-81b8ddc5-9a9b-4099-83ac-07d9336bdc48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130419959-172.17.0.8-1597396077770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38664,DS-d7cae136-73d5-494f-84c4-879ab2031dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-7f0e9f7c-ca52-463c-bdee-fe3cc6e0cf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-cd6c2f39-da99-4179-b6af-971dd47115d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-fd15dad7-75db-46a9-a289-b56d6355e42e,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-ba049997-1cb1-4418-8c69-233c3d78a328,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-c37cc563-d92d-43e9-a3da-2323ad4a984a,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-9779308b-56aa-467e-88a7-1ac40e725671,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-d672fd96-0366-48e7-8232-1b0f6365443b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130419959-172.17.0.8-1597396077770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38664,DS-d7cae136-73d5-494f-84c4-879ab2031dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-7f0e9f7c-ca52-463c-bdee-fe3cc6e0cf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-cd6c2f39-da99-4179-b6af-971dd47115d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-fd15dad7-75db-46a9-a289-b56d6355e42e,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-ba049997-1cb1-4418-8c69-233c3d78a328,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-c37cc563-d92d-43e9-a3da-2323ad4a984a,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-9779308b-56aa-467e-88a7-1ac40e725671,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-d672fd96-0366-48e7-8232-1b0f6365443b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443381526-172.17.0.8-1597396488470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-e19f2120-5512-43a8-b18e-84ee88279352,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-36e5d7bf-a2f8-4dc6-b85d-49688fbb921b,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-cb4c7ecf-d6be-4683-83b3-9b37038fa656,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-530dae40-6c69-456e-96e2-53f931f85f21,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-49019630-d45e-41c9-b75a-d08b4ee02a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-c7599a42-3f71-4e2b-ac68-2fbe6ebae8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-56018078-0571-41a0-a85c-e043a1284aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-4ed0577b-4b96-44f9-ba20-855193ed25e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443381526-172.17.0.8-1597396488470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-e19f2120-5512-43a8-b18e-84ee88279352,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-36e5d7bf-a2f8-4dc6-b85d-49688fbb921b,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-cb4c7ecf-d6be-4683-83b3-9b37038fa656,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-530dae40-6c69-456e-96e2-53f931f85f21,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-49019630-d45e-41c9-b75a-d08b4ee02a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-c7599a42-3f71-4e2b-ac68-2fbe6ebae8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-56018078-0571-41a0-a85c-e043a1284aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-4ed0577b-4b96-44f9-ba20-855193ed25e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333821725-172.17.0.8-1597396649102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-211b3e14-0419-4dd5-b092-f985f92099c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-d916a7d9-2749-4b49-9f59-5790ec625d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-d52fb58a-e75c-4408-9563-b1f21d41f4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-678b11f7-4703-4f20-9031-293ee3f8be4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-37d586cf-9e40-4c9a-9384-f450342bfd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-4e68c3a6-aa9d-48a0-be83-ec487eb50404,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-f3a889dc-ac17-4822-a65b-7f257b640b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-c7814056-05c7-4145-8997-3e6a8333a96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333821725-172.17.0.8-1597396649102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-211b3e14-0419-4dd5-b092-f985f92099c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-d916a7d9-2749-4b49-9f59-5790ec625d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-d52fb58a-e75c-4408-9563-b1f21d41f4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-678b11f7-4703-4f20-9031-293ee3f8be4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-37d586cf-9e40-4c9a-9384-f450342bfd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-4e68c3a6-aa9d-48a0-be83-ec487eb50404,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-f3a889dc-ac17-4822-a65b-7f257b640b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-c7814056-05c7-4145-8997-3e6a8333a96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026751274-172.17.0.8-1597397145628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-4dd15447-c848-496a-9b8b-643053a85a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-0b3ba4b0-45a2-4ced-a80d-8f6e264dafcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-a93c6590-54d3-4908-a1ff-f43a3e9c6766,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-2046f62a-9920-4d57-bdd5-9d05b4256c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-5063101c-349b-45f7-973a-daa80b87d194,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-03ee6865-98bb-4bb2-9cdf-6a42b4277468,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-870f15c8-2161-43d4-83aa-10989b578aba,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-6d6b870b-80c8-4797-95f7-af88e699e0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026751274-172.17.0.8-1597397145628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-4dd15447-c848-496a-9b8b-643053a85a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-0b3ba4b0-45a2-4ced-a80d-8f6e264dafcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-a93c6590-54d3-4908-a1ff-f43a3e9c6766,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-2046f62a-9920-4d57-bdd5-9d05b4256c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-5063101c-349b-45f7-973a-daa80b87d194,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-03ee6865-98bb-4bb2-9cdf-6a42b4277468,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-870f15c8-2161-43d4-83aa-10989b578aba,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-6d6b870b-80c8-4797-95f7-af88e699e0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199824323-172.17.0.8-1597397184107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43211,DS-f9028bce-e1d4-43a6-b47f-dfb2a7ea2301,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-a720b4b5-1494-4dc1-a4dc-857440ea0708,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-6f5aeffa-0a6f-46d8-8ba5-8ee9ca7fbc07,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-e3346a1c-ed5e-42ad-b890-75f2564fdf77,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-e631451d-c655-435a-9088-e7794a53bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-06968fd4-4e0c-4cf0-8838-78271aa17d11,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-cd2e75cd-3844-4111-8a70-3df70fcb19be,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-985f7900-e544-4308-95cb-305af44c1b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199824323-172.17.0.8-1597397184107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43211,DS-f9028bce-e1d4-43a6-b47f-dfb2a7ea2301,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-a720b4b5-1494-4dc1-a4dc-857440ea0708,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-6f5aeffa-0a6f-46d8-8ba5-8ee9ca7fbc07,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-e3346a1c-ed5e-42ad-b890-75f2564fdf77,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-e631451d-c655-435a-9088-e7794a53bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-06968fd4-4e0c-4cf0-8838-78271aa17d11,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-cd2e75cd-3844-4111-8a70-3df70fcb19be,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-985f7900-e544-4308-95cb-305af44c1b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136517913-172.17.0.8-1597397507339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-4d0d9558-c666-442a-b049-c38450c0f14f,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-e328b65c-2e0f-406a-a075-82929d75673d,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-92eae2bf-4766-48a8-b14f-bae5ae2771d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-f9053f09-050a-4d18-bb9f-2433abfb12ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-5d72276c-fe97-4734-b6f4-f5c85a173ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-5bb5307f-fb6f-4f0d-b532-dc9caa562fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-d660a1c6-ca6e-437f-b291-bd0fe8cf94af,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-8bc10b97-e325-4097-8cba-da1b7ef02691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136517913-172.17.0.8-1597397507339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37883,DS-4d0d9558-c666-442a-b049-c38450c0f14f,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-e328b65c-2e0f-406a-a075-82929d75673d,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-92eae2bf-4766-48a8-b14f-bae5ae2771d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-f9053f09-050a-4d18-bb9f-2433abfb12ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-5d72276c-fe97-4734-b6f4-f5c85a173ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-5bb5307f-fb6f-4f0d-b532-dc9caa562fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-d660a1c6-ca6e-437f-b291-bd0fe8cf94af,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-8bc10b97-e325-4097-8cba-da1b7ef02691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819105164-172.17.0.8-1597397969234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-81c452f4-97c0-4cec-9491-41e7a661f2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-7ea68e93-b2a0-4d38-82c9-70a5b45b0d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-7c1cb3bc-3d96-484b-b109-3be4a1a41a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-e76f372e-896b-4a2d-88b9-1707de4b460a,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-46e71763-e43f-467e-9f0c-4a384f060c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-c3ccd684-718a-4ea6-a14a-b0defe5fe572,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-1310e232-9541-4fd0-9011-c7a75de1af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-68581d9b-da47-48dd-84aa-b26f7a7dc307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819105164-172.17.0.8-1597397969234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-81c452f4-97c0-4cec-9491-41e7a661f2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-7ea68e93-b2a0-4d38-82c9-70a5b45b0d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-7c1cb3bc-3d96-484b-b109-3be4a1a41a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-e76f372e-896b-4a2d-88b9-1707de4b460a,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-46e71763-e43f-467e-9f0c-4a384f060c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-c3ccd684-718a-4ea6-a14a-b0defe5fe572,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-1310e232-9541-4fd0-9011-c7a75de1af1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-68581d9b-da47-48dd-84aa-b26f7a7dc307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135660325-172.17.0.8-1597398326114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-98000f91-7b4b-42ed-be69-1cf8d37840b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-1cf2f6c6-d83c-46d9-9c8f-e3f13469b3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-37167021-2a62-4fee-8355-a32870421b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-4468c53d-147f-4698-8b3e-edb1814e25cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-93b049dc-0373-41c9-90b9-5b20e928ae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-44510156-37e8-452d-83fd-d185969fa579,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-6b769792-edd2-4ac3-bf74-a7de62cec3be,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-8c9af586-fa28-42b3-9ae7-a1487597614a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135660325-172.17.0.8-1597398326114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-98000f91-7b4b-42ed-be69-1cf8d37840b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-1cf2f6c6-d83c-46d9-9c8f-e3f13469b3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-37167021-2a62-4fee-8355-a32870421b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-4468c53d-147f-4698-8b3e-edb1814e25cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-93b049dc-0373-41c9-90b9-5b20e928ae6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-44510156-37e8-452d-83fd-d185969fa579,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-6b769792-edd2-4ac3-bf74-a7de62cec3be,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-8c9af586-fa28-42b3-9ae7-a1487597614a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273886103-172.17.0.8-1597398496522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39626,DS-8b079fca-98b3-4828-829b-8e8b6cdea8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-9ae42e13-c424-4542-acd5-90d1b6682d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-266269f8-f13b-4512-bc27-b8519e3e0e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-5a904b75-cd66-47df-8b8c-0f9dc63307f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-8dbd5748-1ff1-42cc-b64f-21b53a0a4030,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-34a69c01-b345-4fad-ba90-73b979be8764,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-0ac4d4c7-5a3c-4083-a94f-0bb2e058475a,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-20e90a6b-7ae7-4e64-8262-d574445f1958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273886103-172.17.0.8-1597398496522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39626,DS-8b079fca-98b3-4828-829b-8e8b6cdea8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-9ae42e13-c424-4542-acd5-90d1b6682d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-266269f8-f13b-4512-bc27-b8519e3e0e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-5a904b75-cd66-47df-8b8c-0f9dc63307f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-8dbd5748-1ff1-42cc-b64f-21b53a0a4030,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-34a69c01-b345-4fad-ba90-73b979be8764,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-0ac4d4c7-5a3c-4083-a94f-0bb2e058475a,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-20e90a6b-7ae7-4e64-8262-d574445f1958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809189037-172.17.0.8-1597398539636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33647,DS-cb756639-af2a-4212-adfb-aa30ec9f565a,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-1ffe7d59-a673-4d3d-bcc1-30ce9e25f07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-33fa42d7-a297-4ee0-b084-d4a6d01028bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-c4d3060e-fa90-4150-a988-ea541b8336fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-19a050f2-89bc-46db-8bd8-0f77eac21a89,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-66d06c5f-9315-4b70-aa38-76393ed2d756,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-2795af21-6e40-4b8c-aa77-2d236047ac70,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-5eb957b0-6217-4b54-9471-a65e61785d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809189037-172.17.0.8-1597398539636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33647,DS-cb756639-af2a-4212-adfb-aa30ec9f565a,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-1ffe7d59-a673-4d3d-bcc1-30ce9e25f07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-33fa42d7-a297-4ee0-b084-d4a6d01028bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-c4d3060e-fa90-4150-a988-ea541b8336fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-19a050f2-89bc-46db-8bd8-0f77eac21a89,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-66d06c5f-9315-4b70-aa38-76393ed2d756,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-2795af21-6e40-4b8c-aa77-2d236047ac70,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-5eb957b0-6217-4b54-9471-a65e61785d8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547804605-172.17.0.8-1597398926891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-df2ca22f-ec16-4cef-80ef-8b8a3aacfdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-c836e1ba-c22e-416e-9874-ea0a2c821fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-658738b5-43ec-43b1-a197-cf04b288063d,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-1e1d33ee-653d-456d-8d2e-0ffb750f296f,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-86c79070-651d-445b-a004-c78ea61b51d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-d01bfd75-e090-4161-b521-3dca53edcfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-3f364d5b-e512-4983-9dca-a90c57477cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-f8f131bf-264e-496d-93ba-79c2cb9a2799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547804605-172.17.0.8-1597398926891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46857,DS-df2ca22f-ec16-4cef-80ef-8b8a3aacfdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-c836e1ba-c22e-416e-9874-ea0a2c821fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-658738b5-43ec-43b1-a197-cf04b288063d,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-1e1d33ee-653d-456d-8d2e-0ffb750f296f,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-86c79070-651d-445b-a004-c78ea61b51d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-d01bfd75-e090-4161-b521-3dca53edcfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-3f364d5b-e512-4983-9dca-a90c57477cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-f8f131bf-264e-496d-93ba-79c2cb9a2799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215512733-172.17.0.8-1597399343969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40133,DS-22cdfebd-d423-4539-aa67-4f1f1b198c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-ade04a14-b7ca-4ad1-a033-8a1851163737,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-a45475db-01a9-4b65-a141-f008401285b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-c7ea0fd9-a5ca-4efc-83e7-f5fc23626717,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-a8c51f8b-1067-4cf7-b9aa-a9c44517aa98,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-e3b70b32-7db2-4da6-8b0a-94cf5d724020,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-e0884337-254e-4ea0-8e5d-3a37aef6d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-7b240245-37ca-40a5-884c-5f61b70f47e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215512733-172.17.0.8-1597399343969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40133,DS-22cdfebd-d423-4539-aa67-4f1f1b198c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-ade04a14-b7ca-4ad1-a033-8a1851163737,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-a45475db-01a9-4b65-a141-f008401285b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-c7ea0fd9-a5ca-4efc-83e7-f5fc23626717,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-a8c51f8b-1067-4cf7-b9aa-a9c44517aa98,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-e3b70b32-7db2-4da6-8b0a-94cf5d724020,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-e0884337-254e-4ea0-8e5d-3a37aef6d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-7b240245-37ca-40a5-884c-5f61b70f47e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431728141-172.17.0.8-1597399722514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-46508e5f-01d5-4500-a4ee-505d982e3aab,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-ec6224ce-f70c-480d-bc2e-902a4d195099,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2121fd4f-c2d5-4eef-a2c8-c145fcfe3600,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-b3c7c0d6-abc2-4e11-b74c-255c8fcb8673,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-b4791cab-39d4-42e5-bdc0-36c6312f466f,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-75e6e488-80c2-4190-94c6-92afb016d134,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-f0e491a4-113a-4261-9ca8-47679fdc284b,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-4a428089-d4da-40d3-b225-dbd66548c702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431728141-172.17.0.8-1597399722514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-46508e5f-01d5-4500-a4ee-505d982e3aab,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-ec6224ce-f70c-480d-bc2e-902a4d195099,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2121fd4f-c2d5-4eef-a2c8-c145fcfe3600,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-b3c7c0d6-abc2-4e11-b74c-255c8fcb8673,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-b4791cab-39d4-42e5-bdc0-36c6312f466f,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-75e6e488-80c2-4190-94c6-92afb016d134,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-f0e491a4-113a-4261-9ca8-47679fdc284b,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-4a428089-d4da-40d3-b225-dbd66548c702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712508209-172.17.0.8-1597400691500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-4da31650-bd98-495d-be8c-e62d53e540f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-1e336238-6e19-4649-b28e-1822e125cbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-4ac65301-639b-41bd-ab89-a14552dd8dce,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-0c5205b9-975c-463a-ad29-ae750cd0d2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-daa00179-4043-4e14-8f1d-d3f5e0ab5c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-7e713270-291a-4478-a72e-1967b4a8d87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-9385b8d5-af79-493c-a524-d91d405a5ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-2964b777-3fb6-43e7-9981-53d57a750980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712508209-172.17.0.8-1597400691500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-4da31650-bd98-495d-be8c-e62d53e540f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-1e336238-6e19-4649-b28e-1822e125cbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-4ac65301-639b-41bd-ab89-a14552dd8dce,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-0c5205b9-975c-463a-ad29-ae750cd0d2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-daa00179-4043-4e14-8f1d-d3f5e0ab5c29,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-7e713270-291a-4478-a72e-1967b4a8d87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-9385b8d5-af79-493c-a524-d91d405a5ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-2964b777-3fb6-43e7-9981-53d57a750980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705307891-172.17.0.8-1597400729227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-02c48a2d-adc1-4f97-a5bb-95c1ff3432f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-d3d36a56-a264-4a6e-81e9-501b9d31d638,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-202f19aa-148e-45bc-97a2-9e64942de400,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-7a8810c5-1495-4b4d-9ce1-d7e8c86b54fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-ff82c297-f9a7-4f50-9109-d061c625c868,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-9ee19be8-d139-44f0-baa2-30f498fe626b,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-72f5cb39-b27c-4bf2-95a0-1712da9d547a,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-c39f6e6c-b991-4d4c-ab5a-1a06522f8445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705307891-172.17.0.8-1597400729227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43077,DS-02c48a2d-adc1-4f97-a5bb-95c1ff3432f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-d3d36a56-a264-4a6e-81e9-501b9d31d638,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-202f19aa-148e-45bc-97a2-9e64942de400,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-7a8810c5-1495-4b4d-9ce1-d7e8c86b54fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-ff82c297-f9a7-4f50-9109-d061c625c868,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-9ee19be8-d139-44f0-baa2-30f498fe626b,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-72f5cb39-b27c-4bf2-95a0-1712da9d547a,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-c39f6e6c-b991-4d4c-ab5a-1a06522f8445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741836929-172.17.0.8-1597401040510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37244,DS-322867ae-5a95-4e52-a593-da9b9d2ca3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-7147eabf-7368-4478-bbee-5d94074fc350,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-c63ece35-4749-4dc1-9d1a-79d7ef6942df,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-1a5a5abf-bf02-4bc7-bfc8-000d720b2dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-a31f0b0a-1625-47d7-9c71-0e73f0b109df,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-3c07f105-f421-4b10-9055-c547d13b3ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-72a04aa4-93d8-46ca-bc17-45e3712b85a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-10ac398b-f543-41ed-ade7-cba349054300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1741836929-172.17.0.8-1597401040510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37244,DS-322867ae-5a95-4e52-a593-da9b9d2ca3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-7147eabf-7368-4478-bbee-5d94074fc350,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-c63ece35-4749-4dc1-9d1a-79d7ef6942df,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-1a5a5abf-bf02-4bc7-bfc8-000d720b2dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-a31f0b0a-1625-47d7-9c71-0e73f0b109df,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-3c07f105-f421-4b10-9055-c547d13b3ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-72a04aa4-93d8-46ca-bc17-45e3712b85a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-10ac398b-f543-41ed-ade7-cba349054300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6198
