reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169829645-172.17.0.12-1597355103014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-1f938c51-778b-4470-a3fa-1a5cede45a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-feeba803-c03d-4608-b0d3-e30562764b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-b413e24e-ecda-42a7-a069-a8763e6ac63f,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-10332978-eac8-4af4-bea0-66ba05402e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-e68b13c9-77b2-43d5-a377-2e1854408dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-54574d0b-6878-479b-9fda-0475df06fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-d9c9bb35-2ea1-47c2-be14-758df4a9a29e,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-fcb21265-ca39-4968-bc30-ef0d83f45ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169829645-172.17.0.12-1597355103014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37462,DS-1f938c51-778b-4470-a3fa-1a5cede45a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-feeba803-c03d-4608-b0d3-e30562764b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-b413e24e-ecda-42a7-a069-a8763e6ac63f,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-10332978-eac8-4af4-bea0-66ba05402e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-e68b13c9-77b2-43d5-a377-2e1854408dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-54574d0b-6878-479b-9fda-0475df06fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-d9c9bb35-2ea1-47c2-be14-758df4a9a29e,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-fcb21265-ca39-4968-bc30-ef0d83f45ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807639814-172.17.0.12-1597355869627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42327,DS-0a9496de-5f27-48a9-8b5a-c47e8f8345b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-fef3e6e8-b738-4a52-86cf-9beb19fa43b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-6480e60c-0e89-45a0-96ca-854666c4ff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-0568152c-cfee-45f5-8f21-83c32e9f2d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-79f240f5-133e-4d71-b523-f66a77423c61,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-0cfcd4c4-f94e-491a-8a40-58f68878da77,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-66902ae1-c713-4b5d-bae5-845edcd38573,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-8b038fc6-035e-4e8c-a4d3-6af86e24a10c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807639814-172.17.0.12-1597355869627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42327,DS-0a9496de-5f27-48a9-8b5a-c47e8f8345b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-fef3e6e8-b738-4a52-86cf-9beb19fa43b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-6480e60c-0e89-45a0-96ca-854666c4ff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-0568152c-cfee-45f5-8f21-83c32e9f2d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-79f240f5-133e-4d71-b523-f66a77423c61,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-0cfcd4c4-f94e-491a-8a40-58f68878da77,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-66902ae1-c713-4b5d-bae5-845edcd38573,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-8b038fc6-035e-4e8c-a4d3-6af86e24a10c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682410088-172.17.0.12-1597356219401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46257,DS-8abd92ef-0b6c-4981-a27c-743e5736d5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-ea64b5b5-2898-417c-ac51-7545f0df91b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-c14a779f-a081-40ad-97f4-d276f996caf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-ea49e1b5-0476-4d14-825d-de3d8621a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-0cf5d780-4ddb-4199-9f91-8bd26d31d070,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-41c01f44-fa19-4c9b-a65b-14705d5a6db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-fd28a507-09f3-4e43-a25f-dc5a566b92b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-0ea217f2-e5a5-42cd-9839-3c5caeee1e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682410088-172.17.0.12-1597356219401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46257,DS-8abd92ef-0b6c-4981-a27c-743e5736d5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-ea64b5b5-2898-417c-ac51-7545f0df91b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-c14a779f-a081-40ad-97f4-d276f996caf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-ea49e1b5-0476-4d14-825d-de3d8621a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-0cf5d780-4ddb-4199-9f91-8bd26d31d070,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-41c01f44-fa19-4c9b-a65b-14705d5a6db4,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-fd28a507-09f3-4e43-a25f-dc5a566b92b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-0ea217f2-e5a5-42cd-9839-3c5caeee1e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165865595-172.17.0.12-1597356601736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-a51c1333-bd3c-43b8-9d9b-373014f8077c,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-b0723286-1343-4349-8234-0a9ad287bc35,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-57ce17f2-dfa3-4acd-86d3-7457568382ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-9d00ade4-6883-488d-bd4d-101414dfe6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-ed3d5931-b65d-4288-9da6-545ff1d0796a,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-632a1e68-517b-446c-b5ef-3bdf3410823d,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-10a253ee-81b8-4d14-bbda-f2b5ebe6e753,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d5f96abb-8e19-44a8-8b3e-25812d8e3618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165865595-172.17.0.12-1597356601736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-a51c1333-bd3c-43b8-9d9b-373014f8077c,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-b0723286-1343-4349-8234-0a9ad287bc35,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-57ce17f2-dfa3-4acd-86d3-7457568382ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-9d00ade4-6883-488d-bd4d-101414dfe6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-ed3d5931-b65d-4288-9da6-545ff1d0796a,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-632a1e68-517b-446c-b5ef-3bdf3410823d,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-10a253ee-81b8-4d14-bbda-f2b5ebe6e753,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d5f96abb-8e19-44a8-8b3e-25812d8e3618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610963298-172.17.0.12-1597356847718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44182,DS-a5f05fa0-4736-4162-a11e-73fcba4255e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-6c456802-d7d2-48da-af1b-c3eef04856ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-5f9f24aa-50ad-401d-b1d0-fe6088fefc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-f731a1ae-2c6e-43a4-9508-5b21b905859f,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-38963b35-48ef-4a63-966a-507ee8809416,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-a22805b4-efd4-4c89-afa6-f1f9bceec685,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-bdffa26f-9504-4d29-acba-bc8f317a68f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-2245c49e-519d-48a3-bf75-a49d968d57a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610963298-172.17.0.12-1597356847718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44182,DS-a5f05fa0-4736-4162-a11e-73fcba4255e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-6c456802-d7d2-48da-af1b-c3eef04856ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-5f9f24aa-50ad-401d-b1d0-fe6088fefc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-f731a1ae-2c6e-43a4-9508-5b21b905859f,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-38963b35-48ef-4a63-966a-507ee8809416,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-a22805b4-efd4-4c89-afa6-f1f9bceec685,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-bdffa26f-9504-4d29-acba-bc8f317a68f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-2245c49e-519d-48a3-bf75-a49d968d57a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250687563-172.17.0.12-1597357172499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-37072a62-ccc4-4a84-b95a-58431a4b5a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-6daad88f-789c-40fe-ae72-ef8c3aaa9136,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-da11e48b-6f19-48d5-a4e3-e37980e69336,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-0353aa09-453c-4f10-b937-4931f3e7bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-b3c61342-a176-4f29-96e0-013203eaae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-3a3013ee-bd84-48d8-af68-48812cf67011,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-fe32ad25-939e-4b73-966f-c2c9016dee82,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-d5d8b6cf-9730-43f7-abd6-c795d058ee88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250687563-172.17.0.12-1597357172499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41557,DS-37072a62-ccc4-4a84-b95a-58431a4b5a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-6daad88f-789c-40fe-ae72-ef8c3aaa9136,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-da11e48b-6f19-48d5-a4e3-e37980e69336,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-0353aa09-453c-4f10-b937-4931f3e7bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-b3c61342-a176-4f29-96e0-013203eaae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-3a3013ee-bd84-48d8-af68-48812cf67011,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-fe32ad25-939e-4b73-966f-c2c9016dee82,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-d5d8b6cf-9730-43f7-abd6-c795d058ee88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799143184-172.17.0.12-1597358119836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38283,DS-702a57a1-d9e2-4fcd-9343-74ae70c93ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-ae9e8725-e98e-4cf2-8830-1a5c9258291d,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-52504bf6-8877-4123-b2ae-b9bffeb48a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-53b6228e-552b-4df6-b24b-fb3d41fcbf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-13accf0a-632c-4871-b60c-89988515a585,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-09f40374-2407-4003-8b0e-a4d30cc036ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-4e85c3d5-4020-4b92-8791-f07aeea43e92,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-cb7f17f8-7f63-4431-a453-5e0d3ef47adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799143184-172.17.0.12-1597358119836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38283,DS-702a57a1-d9e2-4fcd-9343-74ae70c93ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-ae9e8725-e98e-4cf2-8830-1a5c9258291d,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-52504bf6-8877-4123-b2ae-b9bffeb48a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-53b6228e-552b-4df6-b24b-fb3d41fcbf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-13accf0a-632c-4871-b60c-89988515a585,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-09f40374-2407-4003-8b0e-a4d30cc036ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-4e85c3d5-4020-4b92-8791-f07aeea43e92,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-cb7f17f8-7f63-4431-a453-5e0d3ef47adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530403603-172.17.0.12-1597358359661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35869,DS-47b5e35c-c966-456d-ad5b-f0826cea6e12,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-4c453dfa-552d-4ccf-958c-393d1dd64882,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-3c6e7db1-0ef2-482d-82bd-5dc6e4f8fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-62e27886-b791-45d3-9d8d-3389ef4c7f27,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-65f6d865-2e58-41fc-bfe3-ec607ac8de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-49bf7deb-9f0a-4a90-a1a5-6658c50f215c,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-c4696b89-09d3-4358-861a-d6c5c70356c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-734015a7-b147-4c60-bfd6-69ab6c241cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1530403603-172.17.0.12-1597358359661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35869,DS-47b5e35c-c966-456d-ad5b-f0826cea6e12,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-4c453dfa-552d-4ccf-958c-393d1dd64882,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-3c6e7db1-0ef2-482d-82bd-5dc6e4f8fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-62e27886-b791-45d3-9d8d-3389ef4c7f27,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-65f6d865-2e58-41fc-bfe3-ec607ac8de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-49bf7deb-9f0a-4a90-a1a5-6658c50f215c,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-c4696b89-09d3-4358-861a-d6c5c70356c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-734015a7-b147-4c60-bfd6-69ab6c241cdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717588891-172.17.0.12-1597358592179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44895,DS-9ee3c7ac-5bc0-4950-a9e1-4aede365dbff,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-12ad84fe-3473-4102-9665-dc13823be6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-d1ba48b8-0191-4fd9-a909-5e768cb8bea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-691283d1-c9a8-4139-8f91-ec5af70f1bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-750ef09c-1501-4ffe-ac15-70dc35215c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-8a4fbfff-d332-4a58-bc24-99a07b0d4e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-454c4cf1-2821-4091-bc62-c69f3f0dff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-e89bdc2a-8d4e-4d3d-a6d7-95852de5630c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717588891-172.17.0.12-1597358592179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44895,DS-9ee3c7ac-5bc0-4950-a9e1-4aede365dbff,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-12ad84fe-3473-4102-9665-dc13823be6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-d1ba48b8-0191-4fd9-a909-5e768cb8bea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-691283d1-c9a8-4139-8f91-ec5af70f1bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-750ef09c-1501-4ffe-ac15-70dc35215c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-8a4fbfff-d332-4a58-bc24-99a07b0d4e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-454c4cf1-2821-4091-bc62-c69f3f0dff9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-e89bdc2a-8d4e-4d3d-a6d7-95852de5630c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336774337-172.17.0.12-1597359740920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41010,DS-93829d6e-13f4-4fb3-b90a-c81fdc232232,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-620f9cf4-7d33-4ab1-aa80-018ef855a850,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-6c4c7dce-755b-4bf5-9a79-88a2d9dea21f,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-5bc1ce86-601d-4a7c-b326-fa6f7d89cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-339ba8e1-9961-48f7-b144-fd8d84848d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-e49247be-874e-466c-83ff-6085ff55b882,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-bc9c1921-149d-424e-9819-61a0cc2eae41,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-3a92bd94-aba1-463c-80e0-8425c0f4126c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336774337-172.17.0.12-1597359740920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41010,DS-93829d6e-13f4-4fb3-b90a-c81fdc232232,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-620f9cf4-7d33-4ab1-aa80-018ef855a850,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-6c4c7dce-755b-4bf5-9a79-88a2d9dea21f,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-5bc1ce86-601d-4a7c-b326-fa6f7d89cc11,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-339ba8e1-9961-48f7-b144-fd8d84848d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-e49247be-874e-466c-83ff-6085ff55b882,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-bc9c1921-149d-424e-9819-61a0cc2eae41,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-3a92bd94-aba1-463c-80e0-8425c0f4126c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628100802-172.17.0.12-1597359862106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43455,DS-f6ad3d44-1a8f-4d82-ad11-873ef71a6e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-e716efdb-8faf-4a30-9483-ee7010fb849b,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-7b84fa05-0518-40a8-8171-2c4ac8104f39,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-c4a8f18e-7417-4a9c-b8b6-558f4baa82f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-9d18c4e4-d887-46fb-b643-7f455d6ee34d,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-a89baefb-6f54-426e-91e0-e0af12d07099,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-48296821-ba9e-4917-b458-d361e4990e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-252e39d7-6033-4d92-b452-b4d2750e5190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628100802-172.17.0.12-1597359862106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43455,DS-f6ad3d44-1a8f-4d82-ad11-873ef71a6e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-e716efdb-8faf-4a30-9483-ee7010fb849b,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-7b84fa05-0518-40a8-8171-2c4ac8104f39,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-c4a8f18e-7417-4a9c-b8b6-558f4baa82f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-9d18c4e4-d887-46fb-b643-7f455d6ee34d,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-a89baefb-6f54-426e-91e0-e0af12d07099,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-48296821-ba9e-4917-b458-d361e4990e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-252e39d7-6033-4d92-b452-b4d2750e5190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974571862-172.17.0.12-1597360630846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44442,DS-9eb2ebd6-7143-483f-a9c5-4459926613f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-8a6984c7-ed66-4e4b-8191-fab1b9ec2874,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-2eff9c20-edc2-40ac-99ae-91c268f2321a,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-db4d30a4-ddbd-488f-afdb-e1ad042d00bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-94e84e5d-2992-4e00-ae08-e0ad6e760378,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-9534be88-6c28-48e7-806d-4dfd5ec17e16,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-c46385ab-4ed8-4e36-a686-0ce1207c6884,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-cab8807a-08cf-4d12-9b47-c4215937b2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974571862-172.17.0.12-1597360630846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44442,DS-9eb2ebd6-7143-483f-a9c5-4459926613f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-8a6984c7-ed66-4e4b-8191-fab1b9ec2874,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-2eff9c20-edc2-40ac-99ae-91c268f2321a,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-db4d30a4-ddbd-488f-afdb-e1ad042d00bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-94e84e5d-2992-4e00-ae08-e0ad6e760378,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-9534be88-6c28-48e7-806d-4dfd5ec17e16,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-c46385ab-4ed8-4e36-a686-0ce1207c6884,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-cab8807a-08cf-4d12-9b47-c4215937b2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456296705-172.17.0.12-1597360809066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-5aa36f10-3e9d-4a1c-888d-eaf883af7ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-3632527f-253b-4161-8567-715ae74182f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-a37288ac-2ef1-481e-b033-5789f74ae5be,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-1745c870-d9af-4573-adc3-fd400befe445,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-bb9c8bd8-d698-4361-b89a-92567fae9edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-59d53016-0189-414e-9dd0-deb84c376bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-eff805bc-5486-4871-b958-8447f021a994,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-a35b7e82-5992-4a12-9a84-112ca436c21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456296705-172.17.0.12-1597360809066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-5aa36f10-3e9d-4a1c-888d-eaf883af7ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-3632527f-253b-4161-8567-715ae74182f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-a37288ac-2ef1-481e-b033-5789f74ae5be,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-1745c870-d9af-4573-adc3-fd400befe445,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-bb9c8bd8-d698-4361-b89a-92567fae9edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-59d53016-0189-414e-9dd0-deb84c376bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-eff805bc-5486-4871-b958-8447f021a994,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-a35b7e82-5992-4a12-9a84-112ca436c21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 20
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185134571-172.17.0.12-1597361424391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-1cdf11cf-ccca-46a5-8153-aed18214a7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-c5e2f21b-fe08-4e83-bf58-430e82f52ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-9b26734b-cc5b-456e-befb-fc8f4de8e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-e1f64de3-f03d-4933-bbcd-ce0622643df3,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-1e5df7ca-1f45-41d0-a411-67ed3ba1bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-4e6d82a1-219e-44d0-b410-8b5985c5b7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-9a71d0e9-b395-4e08-80fe-b8901e85b72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-b7a8b8bf-bbba-48f0-9c8f-20d203ae1e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185134571-172.17.0.12-1597361424391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-1cdf11cf-ccca-46a5-8153-aed18214a7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-c5e2f21b-fe08-4e83-bf58-430e82f52ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-9b26734b-cc5b-456e-befb-fc8f4de8e98e,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-e1f64de3-f03d-4933-bbcd-ce0622643df3,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-1e5df7ca-1f45-41d0-a411-67ed3ba1bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-4e6d82a1-219e-44d0-b410-8b5985c5b7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-9a71d0e9-b395-4e08-80fe-b8901e85b72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-b7a8b8bf-bbba-48f0-9c8f-20d203ae1e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6867
