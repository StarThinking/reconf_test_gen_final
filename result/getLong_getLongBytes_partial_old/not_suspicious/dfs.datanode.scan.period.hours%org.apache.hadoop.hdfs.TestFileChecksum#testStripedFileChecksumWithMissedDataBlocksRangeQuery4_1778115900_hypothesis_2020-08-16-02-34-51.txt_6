reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075599964-172.17.0.7-1597546592375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-5c54ccd1-53dd-4985-8db4-7793f6d3bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-d70ebe8b-0c15-435e-b051-5ba32a814ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-02d252bd-30a0-49fd-97d1-05ebfd799aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-a92d87e5-c72e-4227-9599-303f67dd24f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-9e52fe2e-b203-416c-93f9-5f311be93196,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-ccb73faf-bc40-4ce0-8532-ae9a54bb7cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-aaeb2712-ec30-4b04-8a88-bd0190b74683,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-e5c5ce84-9d65-4acf-9731-59f2d2a28c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075599964-172.17.0.7-1597546592375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-5c54ccd1-53dd-4985-8db4-7793f6d3bbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-d70ebe8b-0c15-435e-b051-5ba32a814ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-02d252bd-30a0-49fd-97d1-05ebfd799aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-a92d87e5-c72e-4227-9599-303f67dd24f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-9e52fe2e-b203-416c-93f9-5f311be93196,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-ccb73faf-bc40-4ce0-8532-ae9a54bb7cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-aaeb2712-ec30-4b04-8a88-bd0190b74683,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-e5c5ce84-9d65-4acf-9731-59f2d2a28c77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618317340-172.17.0.7-1597546910410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-f6a91add-8023-4839-ab96-ae76ec36408f,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-3d995780-326a-4999-b0f0-dc366af80b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-9448c3a4-61cb-4f4c-91d4-07694f2217fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-3d06fd4e-b902-4be8-a6ad-8a9a3a5109b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-6b6c0697-746c-405e-bb71-a9432e538210,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-4e4f5c7d-1143-41c4-a623-af5863dbb2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-20b91b53-4ea9-4472-b96d-1ee88a94734d,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-1bde8d82-81dc-4300-8650-d5770cd3b881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618317340-172.17.0.7-1597546910410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-f6a91add-8023-4839-ab96-ae76ec36408f,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-3d995780-326a-4999-b0f0-dc366af80b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-9448c3a4-61cb-4f4c-91d4-07694f2217fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-3d06fd4e-b902-4be8-a6ad-8a9a3a5109b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-6b6c0697-746c-405e-bb71-a9432e538210,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-4e4f5c7d-1143-41c4-a623-af5863dbb2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-20b91b53-4ea9-4472-b96d-1ee88a94734d,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-1bde8d82-81dc-4300-8650-d5770cd3b881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568004755-172.17.0.7-1597547246638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-37236c2b-c4ed-42e7-8d69-93da5f437d81,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-cbbe2572-c060-4b33-bed6-789ec487d4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-66ea3a16-75fe-4fc2-976b-38dfca565220,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-d6e847a8-d164-4494-800b-4a8a05cc31f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-5ca47fc2-cc5c-4133-94c9-cc4472dcdcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-edc8aa25-12a8-4244-b061-ca1f4bd8bf98,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8068aed3-e2e0-437f-8cda-cbb3eb5d1759,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-d13099d5-313d-44f3-b1c6-1148b1378769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568004755-172.17.0.7-1597547246638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39230,DS-37236c2b-c4ed-42e7-8d69-93da5f437d81,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-cbbe2572-c060-4b33-bed6-789ec487d4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-66ea3a16-75fe-4fc2-976b-38dfca565220,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-d6e847a8-d164-4494-800b-4a8a05cc31f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-5ca47fc2-cc5c-4133-94c9-cc4472dcdcb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-edc8aa25-12a8-4244-b061-ca1f4bd8bf98,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8068aed3-e2e0-437f-8cda-cbb3eb5d1759,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-d13099d5-313d-44f3-b1c6-1148b1378769,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467491947-172.17.0.7-1597548265733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44375,DS-3ba9f1d9-69b4-4073-83e5-d97a60287587,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-d3ac6105-09bb-4b3b-bf00-2c1ffede12c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-ec159a9e-468f-4c61-8218-96aa633d67b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-8594cba1-c933-4316-bf66-954c870ecb63,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-3f55f9bd-829b-42b7-b16b-e17cc1d38cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-00bceda6-f72b-4387-a6a4-a84d00af1b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-8d822a5d-d7c9-4b2a-be20-bf281a584676,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-342b6d43-bc35-45ff-ba3b-a5926a402322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467491947-172.17.0.7-1597548265733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44375,DS-3ba9f1d9-69b4-4073-83e5-d97a60287587,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-d3ac6105-09bb-4b3b-bf00-2c1ffede12c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-ec159a9e-468f-4c61-8218-96aa633d67b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-8594cba1-c933-4316-bf66-954c870ecb63,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-3f55f9bd-829b-42b7-b16b-e17cc1d38cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-00bceda6-f72b-4387-a6a4-a84d00af1b73,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-8d822a5d-d7c9-4b2a-be20-bf281a584676,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-342b6d43-bc35-45ff-ba3b-a5926a402322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506845044-172.17.0.7-1597548343374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44736,DS-473c076a-64e4-45ae-98a9-641023d17484,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-4139f879-61f9-4e5e-93af-7a72121582aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-729e22e0-651e-4eae-b9f4-1cafacd8fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-4f4bc1eb-e06f-400f-8f37-d7ea8f5c1530,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-68b6fa7f-f607-4125-8093-e352ea46c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-29146c23-d1a4-4cfc-a9e6-95daec9f84be,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-d26ab51a-db47-4e12-a64e-d37a84ce0e66,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-efeb3313-efcb-40dc-93e9-4cdd35f2722c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506845044-172.17.0.7-1597548343374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44736,DS-473c076a-64e4-45ae-98a9-641023d17484,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-4139f879-61f9-4e5e-93af-7a72121582aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-729e22e0-651e-4eae-b9f4-1cafacd8fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-4f4bc1eb-e06f-400f-8f37-d7ea8f5c1530,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-68b6fa7f-f607-4125-8093-e352ea46c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-29146c23-d1a4-4cfc-a9e6-95daec9f84be,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-d26ab51a-db47-4e12-a64e-d37a84ce0e66,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-efeb3313-efcb-40dc-93e9-4cdd35f2722c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855171752-172.17.0.7-1597548418655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44858,DS-1c570ae6-1da6-47a2-a50e-a852e54f2805,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-87cd3e00-3910-4674-9c97-86af9e36f677,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-a372665d-7d42-4a9a-b8af-d583c8e54f02,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-9c497782-8878-4876-bcd1-340e35636fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-a8b1eb43-5105-4a41-b516-1186fd6da180,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-1a31ce04-4596-412c-955e-39c864e0b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-828203af-f445-433c-8c05-7cd5e1487950,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-6881c216-e130-40c3-87c4-16c790671cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855171752-172.17.0.7-1597548418655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44858,DS-1c570ae6-1da6-47a2-a50e-a852e54f2805,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-87cd3e00-3910-4674-9c97-86af9e36f677,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-a372665d-7d42-4a9a-b8af-d583c8e54f02,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-9c497782-8878-4876-bcd1-340e35636fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-a8b1eb43-5105-4a41-b516-1186fd6da180,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-1a31ce04-4596-412c-955e-39c864e0b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-828203af-f445-433c-8c05-7cd5e1487950,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-6881c216-e130-40c3-87c4-16c790671cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307712439-172.17.0.7-1597548875080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35693,DS-16814c89-5894-43f9-b978-163552bbcbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-5f9a3b06-42ff-4288-904c-a115797435f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-f79db37e-c41d-4179-94a7-5e090de6b9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-6072afdb-98fd-478e-b356-81f9f0051beb,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-d4db6ec1-abf1-4e57-ad06-bb287298c86f,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-aad56b0e-8add-4cf4-ab44-cf484b76c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-229e43b7-fc67-4cbc-a0e8-d289b3b24095,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9a2cdb58-8466-49a1-afb7-80a0ca2d775a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307712439-172.17.0.7-1597548875080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35693,DS-16814c89-5894-43f9-b978-163552bbcbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-5f9a3b06-42ff-4288-904c-a115797435f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-f79db37e-c41d-4179-94a7-5e090de6b9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-6072afdb-98fd-478e-b356-81f9f0051beb,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-d4db6ec1-abf1-4e57-ad06-bb287298c86f,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-aad56b0e-8add-4cf4-ab44-cf484b76c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-229e43b7-fc67-4cbc-a0e8-d289b3b24095,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-9a2cdb58-8466-49a1-afb7-80a0ca2d775a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366571283-172.17.0.7-1597548910466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44902,DS-e9bd12f4-3bde-4245-8f5c-7679a1076a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-69f5375c-c955-45da-8a40-ad50075197bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-20c69fe2-1233-4355-a777-e74ae8c5f711,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-39e2729d-2183-49f5-b892-0a9a534527d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-1bc8bce2-08e4-4cbf-954c-c5e65b98039f,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-03eacce5-3bf2-41ee-8dce-f7724eb49638,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-34163e2b-fdd2-49fd-90a5-56ecfb5801b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-7a4afca0-dec3-42e9-90b3-0ca07708e187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366571283-172.17.0.7-1597548910466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44902,DS-e9bd12f4-3bde-4245-8f5c-7679a1076a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-69f5375c-c955-45da-8a40-ad50075197bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-20c69fe2-1233-4355-a777-e74ae8c5f711,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-39e2729d-2183-49f5-b892-0a9a534527d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-1bc8bce2-08e4-4cbf-954c-c5e65b98039f,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-03eacce5-3bf2-41ee-8dce-f7724eb49638,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-34163e2b-fdd2-49fd-90a5-56ecfb5801b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-7a4afca0-dec3-42e9-90b3-0ca07708e187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325851908-172.17.0.7-1597549694522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-ad2fefa0-65b3-47cf-b428-5b17fe097f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-15e19cac-df7f-4825-8bc9-0038a8a9e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-316223d2-3fa1-4851-b4dc-2172be4e4b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-2b3c50aa-8419-4ed4-b347-5f6800de0104,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-42d112a8-3f24-47df-aea3-78b6fece18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-a06c2441-5208-4f85-8393-dcf8ec825c22,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-a24e82b8-2183-4a1d-9a59-89abfc19f13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-80dfa0ad-5023-4479-88bd-829cdadaaf76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325851908-172.17.0.7-1597549694522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-ad2fefa0-65b3-47cf-b428-5b17fe097f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-15e19cac-df7f-4825-8bc9-0038a8a9e4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-316223d2-3fa1-4851-b4dc-2172be4e4b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-2b3c50aa-8419-4ed4-b347-5f6800de0104,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-42d112a8-3f24-47df-aea3-78b6fece18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-a06c2441-5208-4f85-8393-dcf8ec825c22,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-a24e82b8-2183-4a1d-9a59-89abfc19f13f,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-80dfa0ad-5023-4479-88bd-829cdadaaf76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659100417-172.17.0.7-1597549998033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42449,DS-4f288b26-993f-4e14-aa7a-9f79abbf51a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-8007b551-e501-4972-844c-a29404f2c5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-e3c4a868-322e-4e70-aa47-330ea721e883,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-ba01d500-e2ca-4c58-bb68-9dba5cd25c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-3e57583b-de5d-4b7e-a0a2-5bfa02061e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-513bdd42-a5e5-4a87-b388-4c7a53461da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-277dba65-1b33-4136-966f-ed80294e6fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-6ea20263-f55b-474c-9e9f-95146439404c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659100417-172.17.0.7-1597549998033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42449,DS-4f288b26-993f-4e14-aa7a-9f79abbf51a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-8007b551-e501-4972-844c-a29404f2c5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-e3c4a868-322e-4e70-aa47-330ea721e883,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-ba01d500-e2ca-4c58-bb68-9dba5cd25c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-3e57583b-de5d-4b7e-a0a2-5bfa02061e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-513bdd42-a5e5-4a87-b388-4c7a53461da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-277dba65-1b33-4136-966f-ed80294e6fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-6ea20263-f55b-474c-9e9f-95146439404c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96232781-172.17.0.7-1597550149156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-75053fca-26e7-457e-87dc-10303a74d0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-21f90541-162b-4d46-b7ea-171bce1ddac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-4ea95f4c-2095-4e0d-a2d1-e41fc4e7380a,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-5a8be32e-303d-487b-ba18-fffea26648a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-4cf2ccd1-9679-46c3-859b-52b5915338df,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-88c58b64-4186-4bbd-a4f6-910c021b9b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-241f693e-dbf2-44fb-af30-12bbc4a9464b,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-52aa6e44-f98e-422a-a019-56c6baf1b51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96232781-172.17.0.7-1597550149156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-75053fca-26e7-457e-87dc-10303a74d0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-21f90541-162b-4d46-b7ea-171bce1ddac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-4ea95f4c-2095-4e0d-a2d1-e41fc4e7380a,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-5a8be32e-303d-487b-ba18-fffea26648a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-4cf2ccd1-9679-46c3-859b-52b5915338df,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-88c58b64-4186-4bbd-a4f6-910c021b9b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-241f693e-dbf2-44fb-af30-12bbc4a9464b,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-52aa6e44-f98e-422a-a019-56c6baf1b51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555669635-172.17.0.7-1597550448397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-5b12206c-9d2c-49b4-a7db-a455aed69a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-cc8959b2-489b-4c2b-b953-0f3adfe1d43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-c38f9ba7-382b-4087-b4c6-a5a38729b665,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-d5c6e1fe-2391-47db-a80a-d51b21886ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-2f3e2cb5-d577-43c0-92bd-0b8bb467e994,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-0b22ddbc-1637-447d-9bbc-ca9ebfbdf61b,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-e0626003-3d37-4328-87af-44207163f687,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-398eab61-e499-49ca-8a5b-e6b43f43f371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555669635-172.17.0.7-1597550448397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-5b12206c-9d2c-49b4-a7db-a455aed69a27,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-cc8959b2-489b-4c2b-b953-0f3adfe1d43c,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-c38f9ba7-382b-4087-b4c6-a5a38729b665,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-d5c6e1fe-2391-47db-a80a-d51b21886ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-2f3e2cb5-d577-43c0-92bd-0b8bb467e994,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-0b22ddbc-1637-447d-9bbc-ca9ebfbdf61b,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-e0626003-3d37-4328-87af-44207163f687,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-398eab61-e499-49ca-8a5b-e6b43f43f371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166686299-172.17.0.7-1597550488349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-69ce286f-c0bf-44ab-a41a-e2426bb74ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-7ffd94d1-e24a-4235-845d-0d89ed4e18de,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-80051ec5-0b4c-4043-9d5b-33f5217372da,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-ca5bd53c-8d4b-4745-8965-fb657084ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-a9da498a-259c-4c25-99fa-3352347a8b07,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-72ad7972-9119-4403-a07c-7f0313b96d48,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-26f9d45e-37b5-4996-b87c-1bb46277269d,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-2b09262e-a0e6-4b2d-bfb9-b972e9b63d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166686299-172.17.0.7-1597550488349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-69ce286f-c0bf-44ab-a41a-e2426bb74ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-7ffd94d1-e24a-4235-845d-0d89ed4e18de,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-80051ec5-0b4c-4043-9d5b-33f5217372da,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-ca5bd53c-8d4b-4745-8965-fb657084ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-a9da498a-259c-4c25-99fa-3352347a8b07,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-72ad7972-9119-4403-a07c-7f0313b96d48,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-26f9d45e-37b5-4996-b87c-1bb46277269d,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-2b09262e-a0e6-4b2d-bfb9-b972e9b63d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615150714-172.17.0.7-1597550661835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35773,DS-1b26b6d7-a55b-47c6-ada7-01d45c3156e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-65a48d56-4799-43a0-bbe3-0d8581c77e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-8040300f-a0a8-456c-b8c6-e78aa137d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-58a6611a-5fd4-4a6e-8224-1f2e793ff90e,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-51a9b295-66e5-4ec9-b367-7d735efe00b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-cebeb204-f082-4ab1-bfbf-511181575929,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-83dd3e49-1ab8-4d8f-8a94-dd0419b7a241,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-1a7ac5e9-58b7-46ab-b7a0-ca81da4c28e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615150714-172.17.0.7-1597550661835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35773,DS-1b26b6d7-a55b-47c6-ada7-01d45c3156e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-65a48d56-4799-43a0-bbe3-0d8581c77e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-8040300f-a0a8-456c-b8c6-e78aa137d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-58a6611a-5fd4-4a6e-8224-1f2e793ff90e,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-51a9b295-66e5-4ec9-b367-7d735efe00b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-cebeb204-f082-4ab1-bfbf-511181575929,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-83dd3e49-1ab8-4d8f-8a94-dd0419b7a241,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-1a7ac5e9-58b7-46ab-b7a0-ca81da4c28e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181234790-172.17.0.7-1597550882861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-2798f4bc-5bb3-4c86-af5f-45c9cc45170f,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-535d0013-dc0a-4638-9914-6b8af78e310f,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-e16480e5-f733-45b5-9e21-45ce7d1a4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-58fc3ed4-1b1b-4720-a67e-7dabd1b15454,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-8e5252b7-3344-48d1-adc2-aaf76f1426ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-cead5a40-ed2a-4c54-ba83-ccbd71775eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-ba580728-4ae8-447c-83bc-b8476532e571,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-e3cce326-b54f-495e-b896-ac33f0e12190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181234790-172.17.0.7-1597550882861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-2798f4bc-5bb3-4c86-af5f-45c9cc45170f,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-535d0013-dc0a-4638-9914-6b8af78e310f,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-e16480e5-f733-45b5-9e21-45ce7d1a4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-58fc3ed4-1b1b-4720-a67e-7dabd1b15454,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-8e5252b7-3344-48d1-adc2-aaf76f1426ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-cead5a40-ed2a-4c54-ba83-ccbd71775eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-ba580728-4ae8-447c-83bc-b8476532e571,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-e3cce326-b54f-495e-b896-ac33f0e12190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5811
