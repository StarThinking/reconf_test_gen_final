reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194541812-172.17.0.13-1597358115040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42309,DS-5f41e89b-ab9a-435f-a629-c2ed4e168af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-0efa86f8-7bd6-41e3-a90e-00c11023c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-cd6bf9da-9a00-4cda-bd53-89288ab8c2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-20abeb99-255b-4b16-b260-2ef6eceb6ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-9b5dc34e-4c83-4e12-854d-7c277a0d95fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-85115cf6-f9f5-4753-b09a-e0469e5dcbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-d416cd06-033b-4c44-a7fe-0aab2e3528b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-fdf8c9c5-bb40-4812-ba59-badde90409d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194541812-172.17.0.13-1597358115040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42309,DS-5f41e89b-ab9a-435f-a629-c2ed4e168af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-0efa86f8-7bd6-41e3-a90e-00c11023c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-cd6bf9da-9a00-4cda-bd53-89288ab8c2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-20abeb99-255b-4b16-b260-2ef6eceb6ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-9b5dc34e-4c83-4e12-854d-7c277a0d95fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-85115cf6-f9f5-4753-b09a-e0469e5dcbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-d416cd06-033b-4c44-a7fe-0aab2e3528b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-fdf8c9c5-bb40-4812-ba59-badde90409d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93515032-172.17.0.13-1597358406340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43731,DS-623bd8f1-104b-4e03-a5e5-777bb6330c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-909eddc9-37f0-432c-b014-4bcf7666c4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-7b0f4549-8700-4f26-b6e9-9e8da451533c,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-b0a5ff6d-526b-4337-81b1-e1160fb6c981,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-6d9e1497-f42c-4a62-ba62-73773351d567,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-03fd2287-39eb-4ed9-a02f-a9d05641b048,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-5716e5ff-99c7-41e2-8e33-839716f31dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-d1629f1a-8176-4ae7-b01e-6f58af1b88c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93515032-172.17.0.13-1597358406340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43731,DS-623bd8f1-104b-4e03-a5e5-777bb6330c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-909eddc9-37f0-432c-b014-4bcf7666c4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-7b0f4549-8700-4f26-b6e9-9e8da451533c,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-b0a5ff6d-526b-4337-81b1-e1160fb6c981,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-6d9e1497-f42c-4a62-ba62-73773351d567,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-03fd2287-39eb-4ed9-a02f-a9d05641b048,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-5716e5ff-99c7-41e2-8e33-839716f31dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-d1629f1a-8176-4ae7-b01e-6f58af1b88c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105997052-172.17.0.13-1597358537910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45667,DS-812c779b-2160-4238-9712-20f3179e1a34,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-1c897c5d-c65b-42c7-9134-dbb5281ebc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-fa4208e6-bf35-4e55-af88-65a04aba20d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-181aa072-4725-4a9a-a3a0-e7cbd700a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-421312df-34f0-494f-a85f-f5b3385b8e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-1bc336f8-7013-4e27-8f34-fabe602d276e,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-4490320d-198f-4ab1-8c99-4556aaa499df,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-08fdf8ab-10cf-4e37-b3ca-8b14a208e655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105997052-172.17.0.13-1597358537910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45667,DS-812c779b-2160-4238-9712-20f3179e1a34,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-1c897c5d-c65b-42c7-9134-dbb5281ebc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-fa4208e6-bf35-4e55-af88-65a04aba20d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-181aa072-4725-4a9a-a3a0-e7cbd700a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-421312df-34f0-494f-a85f-f5b3385b8e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-1bc336f8-7013-4e27-8f34-fabe602d276e,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-4490320d-198f-4ab1-8c99-4556aaa499df,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-08fdf8ab-10cf-4e37-b3ca-8b14a208e655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753544963-172.17.0.13-1597359071368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42770,DS-f6a97491-4800-4fee-a85c-36b4d253335b,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-8e0afc1f-7a0d-4208-bfb1-a45334bc77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-d9645caa-4b66-4e8d-b9ac-5758a01283ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-636a4acf-ed31-484e-92cd-448db0e0113d,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-27909a0f-0829-4527-b8cb-4eec6160cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-699fc7c1-f717-48c6-a599-38056e9f97c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-9dfd3f9a-172e-4353-92eb-dc7e2d960ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-9897758e-9e25-4524-97ec-3c5e75ba8939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753544963-172.17.0.13-1597359071368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42770,DS-f6a97491-4800-4fee-a85c-36b4d253335b,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-8e0afc1f-7a0d-4208-bfb1-a45334bc77fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-d9645caa-4b66-4e8d-b9ac-5758a01283ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-636a4acf-ed31-484e-92cd-448db0e0113d,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-27909a0f-0829-4527-b8cb-4eec6160cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-699fc7c1-f717-48c6-a599-38056e9f97c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-9dfd3f9a-172e-4353-92eb-dc7e2d960ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-9897758e-9e25-4524-97ec-3c5e75ba8939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906619769-172.17.0.13-1597359229767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34590,DS-6c0d049b-2cab-429a-a09d-80ae278b77bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-3898c0f6-53a2-4580-b850-31e70cbd5de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-99da1fda-a0bd-4d13-8521-6566f21eb8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-5cf8718d-bc0a-4bac-972c-599a3ef4f014,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-21b3a061-6a35-4be1-be77-57cdd4d10871,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-82ef8404-1f9b-4192-a0a4-bb99c8c64156,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-dd5c32d2-1375-456e-a046-880fb6e8b756,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-67406c5e-b9dd-42fb-b823-3ac00326daae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906619769-172.17.0.13-1597359229767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34590,DS-6c0d049b-2cab-429a-a09d-80ae278b77bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-3898c0f6-53a2-4580-b850-31e70cbd5de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-99da1fda-a0bd-4d13-8521-6566f21eb8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-5cf8718d-bc0a-4bac-972c-599a3ef4f014,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-21b3a061-6a35-4be1-be77-57cdd4d10871,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-82ef8404-1f9b-4192-a0a4-bb99c8c64156,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-dd5c32d2-1375-456e-a046-880fb6e8b756,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-67406c5e-b9dd-42fb-b823-3ac00326daae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352243209-172.17.0.13-1597359275753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39759,DS-b026a90a-07db-4bb6-b7bf-20dc6edb6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-5a5803f9-a242-4d81-b52e-101d77b16cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-27c84dec-2bf9-4df1-88e0-e510c1a4121b,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-817578c4-dc84-4d5e-97b4-f67abfc17fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-69d282bf-25ab-4eae-90bc-df470d591537,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-ad7fad1d-6b48-4cae-a42b-3ed67e936a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-36d31f1a-da9f-405d-8cc7-a1f6f16e3669,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-7776080b-b5ff-4865-962e-8437390de483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352243209-172.17.0.13-1597359275753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39759,DS-b026a90a-07db-4bb6-b7bf-20dc6edb6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-5a5803f9-a242-4d81-b52e-101d77b16cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-27c84dec-2bf9-4df1-88e0-e510c1a4121b,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-817578c4-dc84-4d5e-97b4-f67abfc17fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-69d282bf-25ab-4eae-90bc-df470d591537,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-ad7fad1d-6b48-4cae-a42b-3ed67e936a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-36d31f1a-da9f-405d-8cc7-a1f6f16e3669,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-7776080b-b5ff-4865-962e-8437390de483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616734546-172.17.0.13-1597359315868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-bc0954d5-361e-4360-b5bf-7ddf4b492b61,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-c37335ee-2f4c-4770-863a-cd9159e62e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-ce2dcb8f-d096-4b53-8962-61561dcd8d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-fe0797d2-dec0-425a-9b58-cdc954587d38,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-732fd0e3-0668-49b0-8020-a9a7d94d7bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-a17e07c0-f211-4d1c-92d5-c6572c1134b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-f1222374-d800-4bf2-b673-ff7e31520c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-82022ec3-4ef4-434d-8cbe-1765ce24bc3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616734546-172.17.0.13-1597359315868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39997,DS-bc0954d5-361e-4360-b5bf-7ddf4b492b61,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-c37335ee-2f4c-4770-863a-cd9159e62e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-ce2dcb8f-d096-4b53-8962-61561dcd8d05,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-fe0797d2-dec0-425a-9b58-cdc954587d38,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-732fd0e3-0668-49b0-8020-a9a7d94d7bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-a17e07c0-f211-4d1c-92d5-c6572c1134b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-f1222374-d800-4bf2-b673-ff7e31520c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-82022ec3-4ef4-434d-8cbe-1765ce24bc3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825008568-172.17.0.13-1597359412726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-39e361f6-0049-4b9c-b29e-496f0d315fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-63809b7d-3b1a-4fdb-8198-e1c11facad79,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-4b7eb249-2ac7-4f25-96aa-e1e46e8d01d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-559d66c8-c9dc-49f7-8349-6c509a240598,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-d64aa7aa-7c45-4857-9929-2069e4571045,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-555057c9-e59c-40f5-9568-79f2e2f37b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-52305308-038d-42e7-ba2e-fbf3670bcfca,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-72797207-7d36-4a2d-baee-62055087935d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825008568-172.17.0.13-1597359412726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-39e361f6-0049-4b9c-b29e-496f0d315fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-63809b7d-3b1a-4fdb-8198-e1c11facad79,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-4b7eb249-2ac7-4f25-96aa-e1e46e8d01d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-559d66c8-c9dc-49f7-8349-6c509a240598,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-d64aa7aa-7c45-4857-9929-2069e4571045,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-555057c9-e59c-40f5-9568-79f2e2f37b82,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-52305308-038d-42e7-ba2e-fbf3670bcfca,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-72797207-7d36-4a2d-baee-62055087935d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419972701-172.17.0.13-1597359697139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45825,DS-7c3992a9-e4e5-49d4-814a-e63d74bd8e82,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-558a8faf-f3d2-47ed-9a02-f4014002b683,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-a265b271-36cf-45c7-ae31-4c08b509e88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-d7f948f4-a55d-4501-9042-c553e7ccb47b,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-5bd47be0-297a-4e68-ba2c-bc5498d62844,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-b6e2e8e6-ad20-44e8-af3c-f8f969affd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-5d289982-42cc-4c25-bf64-448d2f29e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-7a789032-8b98-43cc-81bd-645a8f33f0a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419972701-172.17.0.13-1597359697139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45825,DS-7c3992a9-e4e5-49d4-814a-e63d74bd8e82,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-558a8faf-f3d2-47ed-9a02-f4014002b683,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-a265b271-36cf-45c7-ae31-4c08b509e88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-d7f948f4-a55d-4501-9042-c553e7ccb47b,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-5bd47be0-297a-4e68-ba2c-bc5498d62844,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-b6e2e8e6-ad20-44e8-af3c-f8f969affd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-5d289982-42cc-4c25-bf64-448d2f29e9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-7a789032-8b98-43cc-81bd-645a8f33f0a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458233130-172.17.0.13-1597359882121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-da5b40e4-17af-49de-8098-0df2cd8fef89,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-fa22ef09-9b0a-473e-88a7-fc8a9da21477,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-2b28ca45-bc36-4122-91bc-4e0fd54f7f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-5f7382c9-ac00-41ff-8519-c687f4d925e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-fbd14a86-3a0a-4d5c-82f4-df22bce483b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-423de3c5-830d-4de5-b4d2-047d44c221bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-15a125c1-6d48-4fc8-8242-338eb2a7c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-e60a2f1e-c6ba-4794-a75a-2cd8d76d44c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458233130-172.17.0.13-1597359882121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-da5b40e4-17af-49de-8098-0df2cd8fef89,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-fa22ef09-9b0a-473e-88a7-fc8a9da21477,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-2b28ca45-bc36-4122-91bc-4e0fd54f7f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-5f7382c9-ac00-41ff-8519-c687f4d925e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-fbd14a86-3a0a-4d5c-82f4-df22bce483b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-423de3c5-830d-4de5-b4d2-047d44c221bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-15a125c1-6d48-4fc8-8242-338eb2a7c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-e60a2f1e-c6ba-4794-a75a-2cd8d76d44c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400239254-172.17.0.13-1597360072955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40096,DS-3a1f480e-2971-4be5-bbc9-b456934d74ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-ca64dc40-4af2-46c0-be16-5c94653dd639,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-35750dc0-0fd4-4160-bfa0-cdda1d5bd8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-6d8ec56a-4624-4b10-9a04-936911778ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-5ea05c88-d2db-41d1-938b-164a3ddbd343,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-547f0fbb-845f-4fd7-aed3-d8e50953bfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-af6eb1e4-27e4-4d45-841c-b2aa9c273ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-4a32e6d0-e098-4eaf-b273-1f6743258505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400239254-172.17.0.13-1597360072955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40096,DS-3a1f480e-2971-4be5-bbc9-b456934d74ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-ca64dc40-4af2-46c0-be16-5c94653dd639,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-35750dc0-0fd4-4160-bfa0-cdda1d5bd8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-6d8ec56a-4624-4b10-9a04-936911778ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-5ea05c88-d2db-41d1-938b-164a3ddbd343,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-547f0fbb-845f-4fd7-aed3-d8e50953bfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-af6eb1e4-27e4-4d45-841c-b2aa9c273ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-4a32e6d0-e098-4eaf-b273-1f6743258505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877280392-172.17.0.13-1597360270602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-1cc7c5bb-a84a-4e32-854b-13e5768ddadb,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-827e45e4-3329-4f26-b0ca-4c6462ec3b49,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-22199519-b87b-4691-8e88-eb8030f4fb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-8c135d81-737c-4b6b-b76d-9618245565d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-bc7b051a-001b-4956-811a-56a69748e84c,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-a851a7b9-4a6a-40e0-9687-9f5d9a3d9697,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-bb84f5d6-f3d3-4d4e-a8c3-89a1787a3d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-7520aab9-bc4c-42bc-96d8-31c17a8d411c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877280392-172.17.0.13-1597360270602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34665,DS-1cc7c5bb-a84a-4e32-854b-13e5768ddadb,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-827e45e4-3329-4f26-b0ca-4c6462ec3b49,DISK], DatanodeInfoWithStorage[127.0.0.1:39630,DS-22199519-b87b-4691-8e88-eb8030f4fb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-8c135d81-737c-4b6b-b76d-9618245565d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-bc7b051a-001b-4956-811a-56a69748e84c,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-a851a7b9-4a6a-40e0-9687-9f5d9a3d9697,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-bb84f5d6-f3d3-4d4e-a8c3-89a1787a3d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-7520aab9-bc4c-42bc-96d8-31c17a8d411c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43803087-172.17.0.13-1597360758987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43934,DS-4b7e9eae-72bb-4efe-80cf-04b1f4ba4feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-fa4b2532-58c8-4b45-afb0-81e53dbd13d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-92f2b99e-827c-4469-9f91-3fe2eb1ea105,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-d07f4d71-df56-4990-ace6-a1581f2271e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-2c34b239-0d7b-4969-bb40-bfa0334d0e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-980003cb-8e39-4d96-b5b5-e758945b39ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-8e1e0bab-5578-4892-bd94-ecf9763c2b43,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-8f410f06-0e39-4aa0-ad3b-c64cdfd6ce59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43803087-172.17.0.13-1597360758987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43934,DS-4b7e9eae-72bb-4efe-80cf-04b1f4ba4feb,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-fa4b2532-58c8-4b45-afb0-81e53dbd13d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-92f2b99e-827c-4469-9f91-3fe2eb1ea105,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-d07f4d71-df56-4990-ace6-a1581f2271e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-2c34b239-0d7b-4969-bb40-bfa0334d0e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-980003cb-8e39-4d96-b5b5-e758945b39ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-8e1e0bab-5578-4892-bd94-ecf9763c2b43,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-8f410f06-0e39-4aa0-ad3b-c64cdfd6ce59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815243722-172.17.0.13-1597360992753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33484,DS-168885a7-da75-4c96-9741-086dbf2636db,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-cdedf03d-88f6-48a9-b700-8b8fb4018f10,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-c1fbe55f-b5be-4e84-bbd2-f1fe72facd62,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-1f052db2-d4c2-4de7-8425-1a5d7cc87f53,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-a6bfa553-5d82-45a7-bcf2-b8447321f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-5a8a18d7-a819-4e3a-9630-978498ae6681,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-d059511a-62af-43f8-b1c3-e6949c816693,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-091440b5-9dbb-467d-85a5-bf20f8b4173b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815243722-172.17.0.13-1597360992753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33484,DS-168885a7-da75-4c96-9741-086dbf2636db,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-cdedf03d-88f6-48a9-b700-8b8fb4018f10,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-c1fbe55f-b5be-4e84-bbd2-f1fe72facd62,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-1f052db2-d4c2-4de7-8425-1a5d7cc87f53,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-a6bfa553-5d82-45a7-bcf2-b8447321f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-5a8a18d7-a819-4e3a-9630-978498ae6681,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-d059511a-62af-43f8-b1c3-e6949c816693,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-091440b5-9dbb-467d-85a5-bf20f8b4173b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306494630-172.17.0.13-1597361720124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45885,DS-5337802b-3f48-4b24-bae4-2c9e078acc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-4431b194-045a-461c-bee5-d0e148b8993c,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-2057ff3e-94f3-42d4-8115-acfc10d186c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-e9c6ef8e-0b77-446f-a389-72a78245469f,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-b694d9a5-e486-41e1-a4a7-6375657e1413,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-7eb6da47-214a-4c5b-be12-c25b312142e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-1846be2e-f68f-4b28-989c-a33cf43f0714,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-f533d33f-560a-4462-aa72-25339237306c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306494630-172.17.0.13-1597361720124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45885,DS-5337802b-3f48-4b24-bae4-2c9e078acc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-4431b194-045a-461c-bee5-d0e148b8993c,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-2057ff3e-94f3-42d4-8115-acfc10d186c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-e9c6ef8e-0b77-446f-a389-72a78245469f,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-b694d9a5-e486-41e1-a4a7-6375657e1413,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-7eb6da47-214a-4c5b-be12-c25b312142e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-1846be2e-f68f-4b28-989c-a33cf43f0714,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-f533d33f-560a-4462-aa72-25339237306c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719498503-172.17.0.13-1597361804354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-25fd4bc1-d276-4ac3-8e01-5df8b47fa9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-8672fe57-7c21-48c3-b059-46192c92ca90,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-b96dc7a9-a2f0-4dcc-842f-230658d988eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-68b48e15-dc25-4b2f-9e0d-7687d9d8125d,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-99d8313d-1cbb-4962-801d-a2cc3cd83a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-a94456a5-1dde-4eff-9dc7-8dbab2260127,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-f7241b87-94cb-40d9-929f-f741ec76917c,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-6e2407e2-cf71-48ab-88d1-c9aaa915db76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719498503-172.17.0.13-1597361804354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-25fd4bc1-d276-4ac3-8e01-5df8b47fa9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-8672fe57-7c21-48c3-b059-46192c92ca90,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-b96dc7a9-a2f0-4dcc-842f-230658d988eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-68b48e15-dc25-4b2f-9e0d-7687d9d8125d,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-99d8313d-1cbb-4962-801d-a2cc3cd83a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-a94456a5-1dde-4eff-9dc7-8dbab2260127,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-f7241b87-94cb-40d9-929f-f741ec76917c,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-6e2407e2-cf71-48ab-88d1-c9aaa915db76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424425191-172.17.0.13-1597362143446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36382,DS-05a8ab8f-9787-44e1-be3f-c0b65b1e6e96,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-e9f2a3a2-4ecd-4902-afd2-1961a5b7bd81,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-f1710daf-ca31-4ca3-a1fc-f2578952d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-dbbe016d-8885-4746-91c3-2f0c78841bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-ea1bee22-1c7a-40cc-84c1-ae136d2ccd54,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8148f648-cb44-41ab-87a9-78ed36ba6490,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-0ecde202-ad5d-4c3c-9593-562b335bcf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-c0171111-c9db-4612-8d84-bc25a4d9a5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424425191-172.17.0.13-1597362143446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36382,DS-05a8ab8f-9787-44e1-be3f-c0b65b1e6e96,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-e9f2a3a2-4ecd-4902-afd2-1961a5b7bd81,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-f1710daf-ca31-4ca3-a1fc-f2578952d3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-dbbe016d-8885-4746-91c3-2f0c78841bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-ea1bee22-1c7a-40cc-84c1-ae136d2ccd54,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8148f648-cb44-41ab-87a9-78ed36ba6490,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-0ecde202-ad5d-4c3c-9593-562b335bcf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-c0171111-c9db-4612-8d84-bc25a4d9a5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888853822-172.17.0.13-1597362427689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33479,DS-2a9bc206-c017-4253-8c90-112056a7b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-e6006174-d99a-42e4-99e2-6f8c3380b54b,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-204da484-4e36-4050-a305-15afac3ca82e,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-d61fa0da-4856-419f-be55-7679f566052a,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-fb175198-39f7-4e03-8d1c-6f5f1cfaab82,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-082c3969-688f-4a66-8adf-2208a5e1c222,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-c6df31ac-d171-4269-b22a-2cab69cdaa63,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-7752fcfc-1adf-4628-812e-d796f0d95d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888853822-172.17.0.13-1597362427689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33479,DS-2a9bc206-c017-4253-8c90-112056a7b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-e6006174-d99a-42e4-99e2-6f8c3380b54b,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-204da484-4e36-4050-a305-15afac3ca82e,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-d61fa0da-4856-419f-be55-7679f566052a,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-fb175198-39f7-4e03-8d1c-6f5f1cfaab82,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-082c3969-688f-4a66-8adf-2208a5e1c222,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-c6df31ac-d171-4269-b22a-2cab69cdaa63,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-7752fcfc-1adf-4628-812e-d796f0d95d95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706319842-172.17.0.13-1597362569867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45506,DS-6310bc6e-f2ca-4ca3-90ef-0993bb49acb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-3fc6cdc8-4e66-4134-ae73-425356e522bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-de1a0a8c-e718-457a-bbe1-04dff9137857,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-f7635fea-a336-49b9-8a44-cfa78b91a13b,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-abe3cb20-2e51-4d6b-9218-85b48c2cd7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-d8ceeb4e-47db-4217-886a-352eb1016f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-2070b2ac-49ec-4bb3-a53a-1f64fab2a453,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-39f55d8b-bf36-46a2-99e1-ae9c43bd6a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706319842-172.17.0.13-1597362569867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45506,DS-6310bc6e-f2ca-4ca3-90ef-0993bb49acb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-3fc6cdc8-4e66-4134-ae73-425356e522bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-de1a0a8c-e718-457a-bbe1-04dff9137857,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-f7635fea-a336-49b9-8a44-cfa78b91a13b,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-abe3cb20-2e51-4d6b-9218-85b48c2cd7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-d8ceeb4e-47db-4217-886a-352eb1016f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-2070b2ac-49ec-4bb3-a53a-1f64fab2a453,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-39f55d8b-bf36-46a2-99e1-ae9c43bd6a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235627524-172.17.0.13-1597362666099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-738ea97a-a579-4248-9a7b-2c8169721d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-aa89477c-6cff-4ab3-9a0f-9796a94b6de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-8dcf0dc3-c52e-442a-8a3f-ec1f91752c12,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-8a7529b5-8609-4674-8931-aeb88248240b,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-a8e6087b-5237-4fa6-baaf-24d0346f6a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-0cedcda6-0acb-43a5-866a-c055ddefcb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-8fb2da77-acfe-4141-9e43-bbd1fd3fdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-54df851f-fcc9-4aaa-8c6d-61b88b183257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235627524-172.17.0.13-1597362666099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33925,DS-738ea97a-a579-4248-9a7b-2c8169721d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-aa89477c-6cff-4ab3-9a0f-9796a94b6de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-8dcf0dc3-c52e-442a-8a3f-ec1f91752c12,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-8a7529b5-8609-4674-8931-aeb88248240b,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-a8e6087b-5237-4fa6-baaf-24d0346f6a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-0cedcda6-0acb-43a5-866a-c055ddefcb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-8fb2da77-acfe-4141-9e43-bbd1fd3fdf44,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-54df851f-fcc9-4aaa-8c6d-61b88b183257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161047912-172.17.0.13-1597362949270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-6440d541-f7a4-43a4-b804-ffb9e3252cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-541668c1-3e77-47af-a8ef-b94ead75f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-0f04a591-229a-4255-b99c-a4cf6c5de3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-188000e4-5625-42ef-b8cc-8e39fb3ab158,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-152acca7-914f-4014-8c0b-bc1e0737546b,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-97c3a2e6-c134-493e-b88d-d20db2267e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-731c0de2-5d01-4512-9b5b-dca625311fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-b02e1358-0017-41c4-b3a6-64cb1ba4fa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161047912-172.17.0.13-1597362949270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40431,DS-6440d541-f7a4-43a4-b804-ffb9e3252cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-541668c1-3e77-47af-a8ef-b94ead75f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-0f04a591-229a-4255-b99c-a4cf6c5de3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-188000e4-5625-42ef-b8cc-8e39fb3ab158,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-152acca7-914f-4014-8c0b-bc1e0737546b,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-97c3a2e6-c134-493e-b88d-d20db2267e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-731c0de2-5d01-4512-9b5b-dca625311fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-b02e1358-0017-41c4-b3a6-64cb1ba4fa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881287072-172.17.0.13-1597363498207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42648,DS-57db366f-1bb8-4191-9905-55ff7e20c4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-f9a58380-8822-4fec-adcd-07731690a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-d0b89eba-c902-4ed7-b13d-f4619c26f143,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-999b8413-37ca-4687-adfc-925de88f6a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-8ab2aee5-2012-45d1-a3ee-832cc850c58d,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-636f047d-87f5-409b-bc07-8bbc99bbc390,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-040f256c-c0bd-4e11-8b91-2ce87420cde8,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-f8b13fce-54c5-4aad-9b92-0d87958f069d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881287072-172.17.0.13-1597363498207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42648,DS-57db366f-1bb8-4191-9905-55ff7e20c4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-f9a58380-8822-4fec-adcd-07731690a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-d0b89eba-c902-4ed7-b13d-f4619c26f143,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-999b8413-37ca-4687-adfc-925de88f6a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-8ab2aee5-2012-45d1-a3ee-832cc850c58d,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-636f047d-87f5-409b-bc07-8bbc99bbc390,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-040f256c-c0bd-4e11-8b91-2ce87420cde8,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-f8b13fce-54c5-4aad-9b92-0d87958f069d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330573240-172.17.0.13-1597364338609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-7eb2c684-60fe-4336-a8d4-3ac5c8e922e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-e9673875-d020-43f7-bdc8-76030a77758b,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-29ae6248-6f49-49a5-abc0-e62955d42319,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-51ef23cb-cf04-4a21-84da-bd81619d92f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-99486b8a-fb28-4d06-85e9-88abdf978e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-98de26b2-ff5d-44ac-8601-40ca4a7c3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-f6d02ef6-7526-4a06-8313-1b69a9ebbccc,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-080ff74b-9512-4355-86b3-7427c48e40ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330573240-172.17.0.13-1597364338609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36263,DS-7eb2c684-60fe-4336-a8d4-3ac5c8e922e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-e9673875-d020-43f7-bdc8-76030a77758b,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-29ae6248-6f49-49a5-abc0-e62955d42319,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-51ef23cb-cf04-4a21-84da-bd81619d92f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-99486b8a-fb28-4d06-85e9-88abdf978e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-98de26b2-ff5d-44ac-8601-40ca4a7c3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-f6d02ef6-7526-4a06-8313-1b69a9ebbccc,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-080ff74b-9512-4355-86b3-7427c48e40ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823582314-172.17.0.13-1597364429730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-356634b0-60bd-4b7f-8752-b272ffae929b,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-5cf41d41-557b-400d-9d3f-128591d9190b,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-a14ff289-9f2d-4605-9ffd-15f9a12ca03a,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-af9696da-9d14-47a7-aa1c-e10e89c045d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-9e465dc0-bd7f-4049-9e1c-dd66da436d91,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-0f90d3c6-6a2b-4ec2-a39f-cba618b02262,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-0df29304-6b3f-4d48-9bcc-b28aca4ef20b,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-4299df46-900c-45ba-bd4b-4e4974709144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823582314-172.17.0.13-1597364429730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41647,DS-356634b0-60bd-4b7f-8752-b272ffae929b,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-5cf41d41-557b-400d-9d3f-128591d9190b,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-a14ff289-9f2d-4605-9ffd-15f9a12ca03a,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-af9696da-9d14-47a7-aa1c-e10e89c045d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-9e465dc0-bd7f-4049-9e1c-dd66da436d91,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-0f90d3c6-6a2b-4ec2-a39f-cba618b02262,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-0df29304-6b3f-4d48-9bcc-b28aca4ef20b,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-4299df46-900c-45ba-bd4b-4e4974709144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126960476-172.17.0.13-1597364782079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-b0ded42d-ce93-41ca-a296-a63f80d865d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-2b90200a-290d-47a9-85af-508f88ccf557,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-921c673a-80ac-4414-bb85-4728c1c628a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-661e04d4-5e88-4234-8122-b0333cb16ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-f1f58e87-d4d4-4d84-83a6-99d63e2bcf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-67a4fde9-1e12-4f01-bb75-2900aff81bea,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-1ff29967-32c0-4906-b21f-72716be6771e,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-528107bb-4b16-46c4-83fa-98b128f6030b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126960476-172.17.0.13-1597364782079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-b0ded42d-ce93-41ca-a296-a63f80d865d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-2b90200a-290d-47a9-85af-508f88ccf557,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-921c673a-80ac-4414-bb85-4728c1c628a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-661e04d4-5e88-4234-8122-b0333cb16ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-f1f58e87-d4d4-4d84-83a6-99d63e2bcf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-67a4fde9-1e12-4f01-bb75-2900aff81bea,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-1ff29967-32c0-4906-b21f-72716be6771e,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-528107bb-4b16-46c4-83fa-98b128f6030b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 7138
