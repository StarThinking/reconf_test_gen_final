reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498142063-172.17.0.4-1597365729231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33173,DS-500b76bb-d5e5-48cc-83e7-abfd33369f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-1331b6f1-f6d8-467b-b937-446aa801d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-df13e68a-4fba-421f-8716-852f952b45f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-6fe496f3-6f26-4dd0-a655-4ce2863aa28c,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-c8cdc3e7-6c0d-4d22-bb8e-e58e2c62aaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-1208f0b3-baf1-422d-b263-7c105a6ddb53,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-e5b62b37-35fd-47ef-9fb6-5d1e14f38a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-945623c3-d93c-4f4c-a87d-addccf0a19a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498142063-172.17.0.4-1597365729231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33173,DS-500b76bb-d5e5-48cc-83e7-abfd33369f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-1331b6f1-f6d8-467b-b937-446aa801d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-df13e68a-4fba-421f-8716-852f952b45f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-6fe496f3-6f26-4dd0-a655-4ce2863aa28c,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-c8cdc3e7-6c0d-4d22-bb8e-e58e2c62aaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-1208f0b3-baf1-422d-b263-7c105a6ddb53,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-e5b62b37-35fd-47ef-9fb6-5d1e14f38a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-945623c3-d93c-4f4c-a87d-addccf0a19a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830211506-172.17.0.4-1597366664095:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40611,DS-5ddc6244-2536-419b-812c-8fbfb17a9ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-71d0a922-82df-44f1-8c91-b7d40cfc5b27,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-9facd27a-e646-4d11-b6ce-454f33e630d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-698ae168-2852-4cea-996e-3163c585f5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-32392f25-fd1e-49e3-a0ed-0a958163b311,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-d4bb4ead-0df6-4f46-a5b7-cc95912d3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-dc35b8fd-42df-44fd-b879-490622348bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-1533f379-e5f1-4a50-9d3a-79c753aa0cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830211506-172.17.0.4-1597366664095:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40611,DS-5ddc6244-2536-419b-812c-8fbfb17a9ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-71d0a922-82df-44f1-8c91-b7d40cfc5b27,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-9facd27a-e646-4d11-b6ce-454f33e630d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-698ae168-2852-4cea-996e-3163c585f5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-32392f25-fd1e-49e3-a0ed-0a958163b311,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-d4bb4ead-0df6-4f46-a5b7-cc95912d3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-dc35b8fd-42df-44fd-b879-490622348bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-1533f379-e5f1-4a50-9d3a-79c753aa0cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557196791-172.17.0.4-1597367299682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33192,DS-28ea091c-6e9c-4c3b-942c-0a087c776412,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-f99a55f4-1894-408b-bc32-5a46d376a0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-7e6fbcfc-4bcd-4f0c-9713-02bd1b9afa72,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-af91fbee-cf37-4529-8bc1-3577c75198b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-ebae928c-28ed-4f73-bbe0-15e1cc2ad1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-a0411e8e-927a-4397-8284-9ffd8d776f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-f15b4ad8-be70-4e68-98f8-3ab4aedc3048,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-7a496896-a0c1-434c-afb9-7772191be862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557196791-172.17.0.4-1597367299682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33192,DS-28ea091c-6e9c-4c3b-942c-0a087c776412,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-f99a55f4-1894-408b-bc32-5a46d376a0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-7e6fbcfc-4bcd-4f0c-9713-02bd1b9afa72,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-af91fbee-cf37-4529-8bc1-3577c75198b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-ebae928c-28ed-4f73-bbe0-15e1cc2ad1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-a0411e8e-927a-4397-8284-9ffd8d776f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-f15b4ad8-be70-4e68-98f8-3ab4aedc3048,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-7a496896-a0c1-434c-afb9-7772191be862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402646404-172.17.0.4-1597367445895:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-6f243638-5db2-4d69-a186-7a3b57aced48,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-6bf24a6c-e84f-40a7-ac46-e2f1f3f98a41,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-fde9fe14-7215-4634-956c-31f26b2d1e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-3c9176c4-c66a-4a4d-8fb3-c14869747efd,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-bb4ed20b-586b-417e-9018-8a19ff8a52e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-17f5fcb9-cc5d-4c7d-9a4f-aea34f9a95b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-7be32bb8-35c4-454d-80d7-0d5b3d62e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-bf80bb4f-41c6-4601-b412-44dc6c763891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402646404-172.17.0.4-1597367445895:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-6f243638-5db2-4d69-a186-7a3b57aced48,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-6bf24a6c-e84f-40a7-ac46-e2f1f3f98a41,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-fde9fe14-7215-4634-956c-31f26b2d1e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-3c9176c4-c66a-4a4d-8fb3-c14869747efd,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-bb4ed20b-586b-417e-9018-8a19ff8a52e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-17f5fcb9-cc5d-4c7d-9a4f-aea34f9a95b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-7be32bb8-35c4-454d-80d7-0d5b3d62e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-bf80bb4f-41c6-4601-b412-44dc6c763891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120327499-172.17.0.4-1597367555359:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-562bdfbc-c279-45e3-92e9-94203a09c67c,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-2f40cb8a-7a26-4a3e-a563-2626dcf35ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-1ff32599-d92c-4b83-9235-66770856fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-ba48b5f5-1fdd-4bf4-a830-cd920f4e9751,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-9dcb2c2b-d831-4a47-bb1a-9105ff673e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-d42a6f86-16a1-437f-b39a-c96475712329,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-a752a4d6-c048-4342-bfe5-11dd777d838c,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-bef31138-e391-403a-add5-b31cd3cdb654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120327499-172.17.0.4-1597367555359:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-562bdfbc-c279-45e3-92e9-94203a09c67c,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-2f40cb8a-7a26-4a3e-a563-2626dcf35ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-1ff32599-d92c-4b83-9235-66770856fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-ba48b5f5-1fdd-4bf4-a830-cd920f4e9751,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-9dcb2c2b-d831-4a47-bb1a-9105ff673e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-d42a6f86-16a1-437f-b39a-c96475712329,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-a752a4d6-c048-4342-bfe5-11dd777d838c,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-bef31138-e391-403a-add5-b31cd3cdb654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971214069-172.17.0.4-1597367759809:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-e87a9c1e-6d56-4783-9473-61207f96a7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-26233419-fcf1-4245-940d-d4c4aec6044b,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-a0ea9ced-72dd-447f-9ef7-f7230fd1d946,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-973bdef3-bab5-46b8-912b-118952ebd799,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a7254cbf-8a0a-4682-b435-7a3047ea5b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-c2b33494-93b0-4781-937f-72c1e7db121b,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-75ff2a4c-4d2a-4c7a-8552-67b93791d4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-5e8323e6-9460-45a5-8caa-2f74e4df3f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971214069-172.17.0.4-1597367759809:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33013,DS-e87a9c1e-6d56-4783-9473-61207f96a7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-26233419-fcf1-4245-940d-d4c4aec6044b,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-a0ea9ced-72dd-447f-9ef7-f7230fd1d946,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-973bdef3-bab5-46b8-912b-118952ebd799,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a7254cbf-8a0a-4682-b435-7a3047ea5b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-c2b33494-93b0-4781-937f-72c1e7db121b,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-75ff2a4c-4d2a-4c7a-8552-67b93791d4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-5e8323e6-9460-45a5-8caa-2f74e4df3f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743921970-172.17.0.4-1597368105065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-beb8db78-fd7c-4e5f-9dad-4e70e5401f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-d69acb90-7cd5-4def-8b56-aa4191c45e02,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-2f3d3f0d-a6b1-4921-aee6-64e1d26bc241,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-9adfd3bd-8a59-48e1-8117-d65999d19479,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-343441ae-5ac5-4e51-8707-c259498aff3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-64ff9120-7c90-46a3-b676-40629e89a8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-14ba5114-31ac-45b3-b525-32966ce74315,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-a39c00ce-bfb7-488e-b57f-493b84606e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743921970-172.17.0.4-1597368105065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-beb8db78-fd7c-4e5f-9dad-4e70e5401f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-d69acb90-7cd5-4def-8b56-aa4191c45e02,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-2f3d3f0d-a6b1-4921-aee6-64e1d26bc241,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-9adfd3bd-8a59-48e1-8117-d65999d19479,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-343441ae-5ac5-4e51-8707-c259498aff3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-64ff9120-7c90-46a3-b676-40629e89a8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-14ba5114-31ac-45b3-b525-32966ce74315,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-a39c00ce-bfb7-488e-b57f-493b84606e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656894295-172.17.0.4-1597368446208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38056,DS-64e085e4-7435-435b-b220-af720efe5c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-6f63a862-52eb-431b-876f-01da287c098c,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-77bc6c5f-77c6-4ecb-a2da-dfa7947f8a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-6aeb048c-6fc2-485b-a88a-b182b6d45538,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-6fdbced7-5781-47f5-b3d7-7b29735151b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-e5ce4903-8be8-491f-9d2c-f6e64a60c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-19b0d207-b13d-4115-8330-6dd998945b01,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-aedaec09-e390-4a9e-94b0-785001d8b924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656894295-172.17.0.4-1597368446208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38056,DS-64e085e4-7435-435b-b220-af720efe5c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-6f63a862-52eb-431b-876f-01da287c098c,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-77bc6c5f-77c6-4ecb-a2da-dfa7947f8a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-6aeb048c-6fc2-485b-a88a-b182b6d45538,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-6fdbced7-5781-47f5-b3d7-7b29735151b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-e5ce4903-8be8-491f-9d2c-f6e64a60c7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-19b0d207-b13d-4115-8330-6dd998945b01,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-aedaec09-e390-4a9e-94b0-785001d8b924,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165085762-172.17.0.4-1597369136247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-14fc3643-6ae1-4bf8-9fcb-b0e56fc36d94,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-a077f324-b0a0-4742-88aa-0f3e0a2ede8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-d529f72a-f759-42d2-b4fc-35d4dc4a5c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-98fbc5f7-8469-47ab-8d64-24d977587e29,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-2bd56570-649d-4ecb-8063-6d0b6e51bb58,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-e25a6067-de19-4a71-98a8-7a8dd38e0d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d89c5d71-03b5-4d0b-ac52-37a2238c0665,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-c5941be6-2959-491b-a25a-8a36dc42fc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165085762-172.17.0.4-1597369136247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-14fc3643-6ae1-4bf8-9fcb-b0e56fc36d94,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-a077f324-b0a0-4742-88aa-0f3e0a2ede8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-d529f72a-f759-42d2-b4fc-35d4dc4a5c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-98fbc5f7-8469-47ab-8d64-24d977587e29,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-2bd56570-649d-4ecb-8063-6d0b6e51bb58,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-e25a6067-de19-4a71-98a8-7a8dd38e0d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d89c5d71-03b5-4d0b-ac52-37a2238c0665,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-c5941be6-2959-491b-a25a-8a36dc42fc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15934800-172.17.0.4-1597369320868:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-536ad6ff-9ca9-4d9c-8c9d-130267bb3d18,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-96fef95b-66cf-477b-8194-4b075b0806bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-422051c7-0c39-493c-b7b8-745924124b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-bc979a22-6765-4f62-b543-c6752a3afe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-13af719f-9817-4743-83b9-b8ee30e97171,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-951eae80-cb16-4211-996d-7ac39994ca75,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-bc147c3b-341c-4318-ae10-9fe25162ce9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-e9e3785b-e99a-42c4-bede-e962e9b8a792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15934800-172.17.0.4-1597369320868:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-536ad6ff-9ca9-4d9c-8c9d-130267bb3d18,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-96fef95b-66cf-477b-8194-4b075b0806bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-422051c7-0c39-493c-b7b8-745924124b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-bc979a22-6765-4f62-b543-c6752a3afe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-13af719f-9817-4743-83b9-b8ee30e97171,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-951eae80-cb16-4211-996d-7ac39994ca75,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-bc147c3b-341c-4318-ae10-9fe25162ce9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-e9e3785b-e99a-42c4-bede-e962e9b8a792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590397106-172.17.0.4-1597369491541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45136,DS-e77a995e-9d35-46b3-93f8-f44750759e04,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-cdab2662-c179-4d46-8c2f-a4877ee743aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-145ca64d-3d2c-497d-a46e-dd621a3012de,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-bf081234-0632-498e-8d58-b442f0ce04e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-4c14cc90-e783-4fe9-8510-419321f0f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-26d8f995-0cc1-4a67-9b30-cdb0705d8832,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-d5323a03-365a-4064-8249-a56dc53489c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-fc91b161-557f-43f1-a75f-10d16a18f06a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590397106-172.17.0.4-1597369491541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45136,DS-e77a995e-9d35-46b3-93f8-f44750759e04,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-cdab2662-c179-4d46-8c2f-a4877ee743aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-145ca64d-3d2c-497d-a46e-dd621a3012de,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-bf081234-0632-498e-8d58-b442f0ce04e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-4c14cc90-e783-4fe9-8510-419321f0f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-26d8f995-0cc1-4a67-9b30-cdb0705d8832,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-d5323a03-365a-4064-8249-a56dc53489c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-fc91b161-557f-43f1-a75f-10d16a18f06a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538228565-172.17.0.4-1597369871890:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42059,DS-0152e1d5-3038-4535-b559-b97dc44e9663,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-6c6e241f-e9a1-4227-8ae9-d1e912c6fc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-25a3f986-749e-4a62-aee7-245a887f122c,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-a840318a-8481-470f-a7ca-7ec035a248ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-a8c29648-75b8-4dd2-82dc-328d98811806,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-7bbb2e36-5418-486f-91ff-1afd38f08ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-e8db0d81-2c21-4016-835d-0ea0bd66a98f,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-597dca18-a777-4dec-9e7b-9890c52d8a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-538228565-172.17.0.4-1597369871890:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42059,DS-0152e1d5-3038-4535-b559-b97dc44e9663,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-6c6e241f-e9a1-4227-8ae9-d1e912c6fc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-25a3f986-749e-4a62-aee7-245a887f122c,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-a840318a-8481-470f-a7ca-7ec035a248ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-a8c29648-75b8-4dd2-82dc-328d98811806,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-7bbb2e36-5418-486f-91ff-1afd38f08ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-e8db0d81-2c21-4016-835d-0ea0bd66a98f,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-597dca18-a777-4dec-9e7b-9890c52d8a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599102291-172.17.0.4-1597370138669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-708e0ffa-6101-40b6-a2be-ca19f7614307,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-53f34a1d-202b-42b7-b12c-11bf6e188034,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-4c71288b-c502-47bf-9fc8-6aead02f4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-40b4c0ab-d8dd-4d2f-9514-73cf1a37bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-753887d6-28aa-4fb4-94c1-ea2785338126,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-35b6c5f7-c449-4ca8-bc13-002ad759a9be,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-06a5fab1-29c3-4073-bf47-bf86be5c5af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-6e475092-0cd6-4eb7-8647-274f9fbe29a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599102291-172.17.0.4-1597370138669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45837,DS-708e0ffa-6101-40b6-a2be-ca19f7614307,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-53f34a1d-202b-42b7-b12c-11bf6e188034,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-4c71288b-c502-47bf-9fc8-6aead02f4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-40b4c0ab-d8dd-4d2f-9514-73cf1a37bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-753887d6-28aa-4fb4-94c1-ea2785338126,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-35b6c5f7-c449-4ca8-bc13-002ad759a9be,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-06a5fab1-29c3-4073-bf47-bf86be5c5af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-6e475092-0cd6-4eb7-8647-274f9fbe29a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206752329-172.17.0.4-1597370259145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-5418a0f1-ffb8-4c04-8bb8-90df0a50c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-008690b5-9b46-4365-9aa4-aab264e06905,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-eebd9c31-c9b3-4780-a3ba-4895f6cd814f,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-d485ce4a-cba4-4998-90d1-2bd1cdd0c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-d84533e6-ca4b-455f-85c0-2acd2370f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-cd58c7f5-ffdf-4a61-887b-4e20d92d242e,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-ac780878-f9b0-4cd7-bc12-1fcb823a684a,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-644aa5f8-11a4-43f5-9649-366d0ccefb52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206752329-172.17.0.4-1597370259145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44252,DS-5418a0f1-ffb8-4c04-8bb8-90df0a50c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-008690b5-9b46-4365-9aa4-aab264e06905,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-eebd9c31-c9b3-4780-a3ba-4895f6cd814f,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-d485ce4a-cba4-4998-90d1-2bd1cdd0c8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-d84533e6-ca4b-455f-85c0-2acd2370f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-cd58c7f5-ffdf-4a61-887b-4e20d92d242e,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-ac780878-f9b0-4cd7-bc12-1fcb823a684a,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-644aa5f8-11a4-43f5-9649-366d0ccefb52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222933390-172.17.0.4-1597370372206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35937,DS-6e96cd15-bc8c-4461-a76f-638f07997d18,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-7bc8d46e-eff8-4ee6-9e63-ac7e87e10f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-a8403026-7727-4296-85f5-da9635884fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-1443dbe1-edc1-47d8-b006-ee38a46ec001,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-d317ee80-cef3-415b-bd41-e6f6317fe996,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-d49f2c7b-8977-4a1a-9307-2eff04dd3215,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-eec08ea3-d156-49fa-b11f-fe19a695866d,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-590be7ff-f134-453c-b2e2-8dc5bd5c0ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1222933390-172.17.0.4-1597370372206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35937,DS-6e96cd15-bc8c-4461-a76f-638f07997d18,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-7bc8d46e-eff8-4ee6-9e63-ac7e87e10f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-a8403026-7727-4296-85f5-da9635884fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-1443dbe1-edc1-47d8-b006-ee38a46ec001,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-d317ee80-cef3-415b-bd41-e6f6317fe996,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-d49f2c7b-8977-4a1a-9307-2eff04dd3215,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-eec08ea3-d156-49fa-b11f-fe19a695866d,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-590be7ff-f134-453c-b2e2-8dc5bd5c0ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399594783-172.17.0.4-1597370490147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-abd9761a-bb31-4834-ae52-90703141e47f,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-d4053a5b-86aa-43fc-949b-7cd808fd5ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-dfc77f71-8eff-4064-ab85-1b309841d63e,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-aa852627-2fe0-450c-9a6c-0fd94b84e587,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-428f11d6-b7f4-4921-907d-2ae7077dcf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-1739a6d2-be2c-4fe5-b75d-05d61d01b093,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-6fd9c5a0-539d-4bbf-bf73-24811d62d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-a278a09b-7ac2-4d67-9419-fb4d066d05f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399594783-172.17.0.4-1597370490147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35508,DS-abd9761a-bb31-4834-ae52-90703141e47f,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-d4053a5b-86aa-43fc-949b-7cd808fd5ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-dfc77f71-8eff-4064-ab85-1b309841d63e,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-aa852627-2fe0-450c-9a6c-0fd94b84e587,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-428f11d6-b7f4-4921-907d-2ae7077dcf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-1739a6d2-be2c-4fe5-b75d-05d61d01b093,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-6fd9c5a0-539d-4bbf-bf73-24811d62d81f,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-a278a09b-7ac2-4d67-9419-fb4d066d05f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5586
