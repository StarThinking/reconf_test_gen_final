reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733185264-172.17.0.15-1597281137235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-9fbb4384-5501-42d4-9c00-574d11672344,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-2cf7352b-adce-4e5e-99ce-e83647a6dbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-2db5ee32-b3ca-48da-ac7a-79fe822bea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-830e9125-11f7-470e-b8aa-46d8f6ccc1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-a94f4612-2377-4dc0-9547-3ca808ffd2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-a5be0a61-106f-416c-aa54-d561ee333309,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-7e674b0d-b3d0-4159-99e0-eecdcf88f353,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-82b0d19b-584a-4cd8-aa9a-2d9716cac115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733185264-172.17.0.15-1597281137235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46092,DS-9fbb4384-5501-42d4-9c00-574d11672344,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-2cf7352b-adce-4e5e-99ce-e83647a6dbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-2db5ee32-b3ca-48da-ac7a-79fe822bea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-830e9125-11f7-470e-b8aa-46d8f6ccc1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-a94f4612-2377-4dc0-9547-3ca808ffd2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-a5be0a61-106f-416c-aa54-d561ee333309,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-7e674b0d-b3d0-4159-99e0-eecdcf88f353,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-82b0d19b-584a-4cd8-aa9a-2d9716cac115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073325938-172.17.0.15-1597281804214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35609,DS-7ec2ba4d-1256-4d6b-bff3-6b51097024bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-052942f1-589d-4080-ac6a-8831138dc93b,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-eeddc609-e316-43ab-8f49-19c2fbb921f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-cd44542f-31bb-49e3-96e0-d9b69f8aab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-a84da43d-68f8-48ac-9c7b-d97857beb872,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-09673b1f-0926-4137-9b8a-d2c2dfbdf6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-153e9f2c-0092-4ace-8025-c9c10402107a,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-76cb6414-0308-4ee5-ad2d-351d6dc49fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073325938-172.17.0.15-1597281804214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35609,DS-7ec2ba4d-1256-4d6b-bff3-6b51097024bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-052942f1-589d-4080-ac6a-8831138dc93b,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-eeddc609-e316-43ab-8f49-19c2fbb921f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-cd44542f-31bb-49e3-96e0-d9b69f8aab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-a84da43d-68f8-48ac-9c7b-d97857beb872,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-09673b1f-0926-4137-9b8a-d2c2dfbdf6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-153e9f2c-0092-4ace-8025-c9c10402107a,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-76cb6414-0308-4ee5-ad2d-351d6dc49fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151716009-172.17.0.15-1597281977203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-b20f898c-f8f3-4ddf-b1cf-be9f0513cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-c0932723-746c-4b58-ad13-25817a0629be,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-75421afe-df4f-4a91-be83-0b57a7968d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-01413935-7694-484f-a342-9f0f14630afd,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-ace7caed-3a81-49f6-a778-3803c97cfb08,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-bfd06753-49e8-472e-824e-b519d00ef661,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-a51192fe-6668-41ea-b02f-7682f154f3da,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-f1ae3d58-60da-49ac-99b6-e09c9d3b663a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151716009-172.17.0.15-1597281977203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-b20f898c-f8f3-4ddf-b1cf-be9f0513cf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-c0932723-746c-4b58-ad13-25817a0629be,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-75421afe-df4f-4a91-be83-0b57a7968d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-01413935-7694-484f-a342-9f0f14630afd,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-ace7caed-3a81-49f6-a778-3803c97cfb08,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-bfd06753-49e8-472e-824e-b519d00ef661,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-a51192fe-6668-41ea-b02f-7682f154f3da,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-f1ae3d58-60da-49ac-99b6-e09c9d3b663a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220990269-172.17.0.15-1597282268303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37847,DS-3f8881e4-0494-43c3-bb23-de9d8de1be05,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-8f3c9680-1287-4460-944c-8d8978a775c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-909c4bae-ba2a-4896-8f1d-5282a77dc5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-6f245f74-355f-449b-bbd5-b7962a10f58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-c287aa54-5099-457b-af7e-e6ed7eb89a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-818a33cd-21ab-4acc-84f6-7de96227470a,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-fba2341f-5cc4-4d82-a2d7-3e1d37bc2bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-c1924e10-1ce9-4785-bb17-14d6c94bcf13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220990269-172.17.0.15-1597282268303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37847,DS-3f8881e4-0494-43c3-bb23-de9d8de1be05,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-8f3c9680-1287-4460-944c-8d8978a775c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-909c4bae-ba2a-4896-8f1d-5282a77dc5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-6f245f74-355f-449b-bbd5-b7962a10f58a,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-c287aa54-5099-457b-af7e-e6ed7eb89a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-818a33cd-21ab-4acc-84f6-7de96227470a,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-fba2341f-5cc4-4d82-a2d7-3e1d37bc2bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-c1924e10-1ce9-4785-bb17-14d6c94bcf13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-268623492-172.17.0.15-1597282307913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-37dcd72e-c909-4cb7-94e0-dd94386b29ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-5015f2b4-9d50-461a-abcd-8cb95f627d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-a150f5b4-e601-4624-8c32-f49919ac6eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-cc62f7f9-ddf3-4cd1-ad41-9b513f44bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-b465a77c-1aa5-438f-b00d-6f06c369b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-e2421e55-cb58-4982-9522-e7c15c98b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-b83cc093-b4a8-4dff-af5e-c23268fb93a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-96d6505b-32d9-4215-b2c3-9c8d4cc35b6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-268623492-172.17.0.15-1597282307913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-37dcd72e-c909-4cb7-94e0-dd94386b29ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-5015f2b4-9d50-461a-abcd-8cb95f627d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-a150f5b4-e601-4624-8c32-f49919ac6eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-cc62f7f9-ddf3-4cd1-ad41-9b513f44bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-b465a77c-1aa5-438f-b00d-6f06c369b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-e2421e55-cb58-4982-9522-e7c15c98b1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-b83cc093-b4a8-4dff-af5e-c23268fb93a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-96d6505b-32d9-4215-b2c3-9c8d4cc35b6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587597609-172.17.0.15-1597282335652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-de761d08-8588-4f83-80da-c837e50bd7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-ee94085e-f36f-4f7e-b242-cd58bbb5f381,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-e96a4cb2-adef-4161-8606-beb606bdfe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-5ac6160e-9d89-4b53-9281-716449464114,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-730589a5-2ae9-40e4-a170-809e1fb7430f,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-a69e1f94-b9ac-4bbc-b81e-b629ab683c63,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-f77bc39c-e5fc-497c-a178-cac827d46c93,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-1c1b6917-b309-448a-b69f-d13c545a31f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587597609-172.17.0.15-1597282335652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-de761d08-8588-4f83-80da-c837e50bd7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-ee94085e-f36f-4f7e-b242-cd58bbb5f381,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-e96a4cb2-adef-4161-8606-beb606bdfe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-5ac6160e-9d89-4b53-9281-716449464114,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-730589a5-2ae9-40e4-a170-809e1fb7430f,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-a69e1f94-b9ac-4bbc-b81e-b629ab683c63,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-f77bc39c-e5fc-497c-a178-cac827d46c93,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-1c1b6917-b309-448a-b69f-d13c545a31f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770687754-172.17.0.15-1597282721379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-30f83c99-a928-4462-bae2-e6a0f537a5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-de10c3ce-52ec-4769-9053-b0b23fade708,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-60a7f483-9cd7-451e-84ed-b39360e6a4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-c3f87689-8191-4ca7-ba54-eea9e62e1fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-eb1735be-e302-4c39-9202-5e716c2a2b86,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-1712ebe2-f3c5-4d95-9704-8b7c8b690973,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-aa43da11-f294-4a50-bf05-ccc206365984,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-225a9965-3b91-4fe5-ac3d-f8ae41ef312b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770687754-172.17.0.15-1597282721379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-30f83c99-a928-4462-bae2-e6a0f537a5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-de10c3ce-52ec-4769-9053-b0b23fade708,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-60a7f483-9cd7-451e-84ed-b39360e6a4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-c3f87689-8191-4ca7-ba54-eea9e62e1fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-eb1735be-e302-4c39-9202-5e716c2a2b86,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-1712ebe2-f3c5-4d95-9704-8b7c8b690973,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-aa43da11-f294-4a50-bf05-ccc206365984,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-225a9965-3b91-4fe5-ac3d-f8ae41ef312b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604189852-172.17.0.15-1597282841560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-5043c653-db2f-435a-8670-01eed0b150c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-7e1b10db-0d22-47c7-8856-4f87bada3770,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-1e07fa17-f773-4c56-9232-e2ca37fd6a74,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-1d4b731a-a587-4a22-b4a3-8992e44076f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-9efe7b1b-80b8-4b77-946d-b40ed2581e78,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-b933f898-e4b5-460d-8406-d96d4b53cf62,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-9cce4898-9cfc-4f19-85bc-c0b14c2796dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-8c9943d4-3550-4171-8935-a33025baaca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1604189852-172.17.0.15-1597282841560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-5043c653-db2f-435a-8670-01eed0b150c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-7e1b10db-0d22-47c7-8856-4f87bada3770,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-1e07fa17-f773-4c56-9232-e2ca37fd6a74,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-1d4b731a-a587-4a22-b4a3-8992e44076f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-9efe7b1b-80b8-4b77-946d-b40ed2581e78,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-b933f898-e4b5-460d-8406-d96d4b53cf62,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-9cce4898-9cfc-4f19-85bc-c0b14c2796dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-8c9943d4-3550-4171-8935-a33025baaca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308183917-172.17.0.15-1597283184371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-c6120585-b382-4596-a368-483a1b336cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-8ded4286-9fad-4c55-ae39-d277c7fc5495,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-ea98c4d7-6cf5-4a80-9057-2a34d57307fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-1868799d-d101-4e0f-9849-7aef73fd09ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-56d9cd6f-8458-492e-82af-db150fa72f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-1c6175aa-fc76-4230-b418-60b98effc1af,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-07b47d73-1884-42a9-9c65-898e80398f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-4d5a7548-9d94-487e-b126-996d1103e479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308183917-172.17.0.15-1597283184371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-c6120585-b382-4596-a368-483a1b336cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-8ded4286-9fad-4c55-ae39-d277c7fc5495,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-ea98c4d7-6cf5-4a80-9057-2a34d57307fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-1868799d-d101-4e0f-9849-7aef73fd09ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-56d9cd6f-8458-492e-82af-db150fa72f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-1c6175aa-fc76-4230-b418-60b98effc1af,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-07b47d73-1884-42a9-9c65-898e80398f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-4d5a7548-9d94-487e-b126-996d1103e479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094207939-172.17.0.15-1597283291951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-7f3a98a6-e1db-4d11-8853-d6f65c8da482,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-d2170245-d96e-474d-8688-9294fd509c00,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-2acfbdad-f5c8-484d-9c74-a09a1b322f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-e763c4f6-ae76-454e-9f3d-f471d1260f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-65d7c1c7-ba4b-4830-91e6-f6ae70da73f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-758a40db-cc60-469b-8564-8c0df2c32ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-0057f5ac-59b4-4ab9-883b-9c32a3e0c639,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-fb9c9187-bc83-4296-a60b-22cb4035b77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094207939-172.17.0.15-1597283291951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-7f3a98a6-e1db-4d11-8853-d6f65c8da482,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-d2170245-d96e-474d-8688-9294fd509c00,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-2acfbdad-f5c8-484d-9c74-a09a1b322f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-e763c4f6-ae76-454e-9f3d-f471d1260f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-65d7c1c7-ba4b-4830-91e6-f6ae70da73f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-758a40db-cc60-469b-8564-8c0df2c32ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-0057f5ac-59b4-4ab9-883b-9c32a3e0c639,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-fb9c9187-bc83-4296-a60b-22cb4035b77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685393500-172.17.0.15-1597283328867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41675,DS-ca708a46-a3bc-4bfa-a541-71097cea63f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-23575dd3-7443-4e8c-9bd2-be21dff2d171,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-03eb5745-003f-4efd-94a7-ecbcb1dbfd79,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-8b574c35-9c4b-464e-98c4-f3257851441b,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-4b456f77-5e42-4e96-820e-d171811336d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-2be94340-6530-4eeb-bcd5-952978434dee,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-33d91085-8c31-4a99-8778-341418b7adae,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-6b59d62c-ffb2-4be0-b8b1-99ceb99ae569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685393500-172.17.0.15-1597283328867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41675,DS-ca708a46-a3bc-4bfa-a541-71097cea63f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-23575dd3-7443-4e8c-9bd2-be21dff2d171,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-03eb5745-003f-4efd-94a7-ecbcb1dbfd79,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-8b574c35-9c4b-464e-98c4-f3257851441b,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-4b456f77-5e42-4e96-820e-d171811336d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-2be94340-6530-4eeb-bcd5-952978434dee,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-33d91085-8c31-4a99-8778-341418b7adae,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-6b59d62c-ffb2-4be0-b8b1-99ceb99ae569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997343222-172.17.0.15-1597283824244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42784,DS-dcbd8c5e-75df-4301-8ef6-f7a3da069b50,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-8ef98023-5867-46e5-a718-21c811302a89,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-4ffba4b0-8869-49f6-81bc-6538a18391b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-22b3bfe4-c1b2-4e09-b4cf-537a251a43b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-26b2838e-622c-462c-8b8d-7bb9ae5e4c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-f4255319-1fe3-45d7-9dac-3ee10ecae8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-0aada6cb-aa9d-4aca-a87c-3527e880e709,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-33d45a23-2f32-49a0-b823-c07ba32a90cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-997343222-172.17.0.15-1597283824244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42784,DS-dcbd8c5e-75df-4301-8ef6-f7a3da069b50,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-8ef98023-5867-46e5-a718-21c811302a89,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-4ffba4b0-8869-49f6-81bc-6538a18391b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-22b3bfe4-c1b2-4e09-b4cf-537a251a43b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-26b2838e-622c-462c-8b8d-7bb9ae5e4c08,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-f4255319-1fe3-45d7-9dac-3ee10ecae8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-0aada6cb-aa9d-4aca-a87c-3527e880e709,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-33d45a23-2f32-49a0-b823-c07ba32a90cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279339216-172.17.0.15-1597283858536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35107,DS-f62b86a8-b3d5-4e16-9d55-b4db8a30a92f,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-6166a83f-8e02-4ad5-a619-b619528c6664,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-ffd5404c-7eba-462b-93b9-55ff731804d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-61061cf2-8438-4626-b53d-fa964f3c9cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-f7186c12-3a73-4130-ae0e-001326d73977,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-fb6e3419-8663-45a6-ba88-2dcd473db9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-df5c0c9c-2a6e-4294-ad7f-bc6bacc30faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-ebcd78e4-8a2c-4af0-83b1-54cfad0ed2d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279339216-172.17.0.15-1597283858536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35107,DS-f62b86a8-b3d5-4e16-9d55-b4db8a30a92f,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-6166a83f-8e02-4ad5-a619-b619528c6664,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-ffd5404c-7eba-462b-93b9-55ff731804d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-61061cf2-8438-4626-b53d-fa964f3c9cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-f7186c12-3a73-4130-ae0e-001326d73977,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-fb6e3419-8663-45a6-ba88-2dcd473db9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-df5c0c9c-2a6e-4294-ad7f-bc6bacc30faf,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-ebcd78e4-8a2c-4af0-83b1-54cfad0ed2d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880219050-172.17.0.15-1597283899505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40761,DS-b758268f-0507-4882-8302-8d41d3910a51,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-204c43d8-9596-4c96-bc35-2f93e01a5260,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-ca32f796-a01d-4846-b0ee-e7df322140c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-73cf9dde-f9d7-4d7f-bead-a75f7225e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-29f6b377-a4c2-4ba6-821a-157c53600fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-33bde471-2e06-4ea8-a75c-f7715735fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-fbb2bb24-d570-4de0-a25c-e85b81d30f32,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-c9946383-12ce-4347-a07d-56e0bb51cd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880219050-172.17.0.15-1597283899505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40761,DS-b758268f-0507-4882-8302-8d41d3910a51,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-204c43d8-9596-4c96-bc35-2f93e01a5260,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-ca32f796-a01d-4846-b0ee-e7df322140c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-73cf9dde-f9d7-4d7f-bead-a75f7225e74a,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-29f6b377-a4c2-4ba6-821a-157c53600fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-33bde471-2e06-4ea8-a75c-f7715735fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-fbb2bb24-d570-4de0-a25c-e85b81d30f32,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-c9946383-12ce-4347-a07d-56e0bb51cd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094723734-172.17.0.15-1597284565988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-928b18cc-1c1b-4e20-b72c-4f57ebc2728c,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-4060d98d-2fa8-49d2-8c45-527359f98ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-2bf264d7-a5a4-42bf-8644-95734ce99aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-9ea58e37-cce3-4f03-a77e-950f40fef184,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-5bf61c28-7e1b-425d-811c-c612b53f7372,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-99b01b22-fa5b-4d6e-b463-7506e331c92d,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-2d429fbc-0c32-44a4-a888-81653624a812,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-cddce5f8-8942-4972-b9f8-588b93c97593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094723734-172.17.0.15-1597284565988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-928b18cc-1c1b-4e20-b72c-4f57ebc2728c,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-4060d98d-2fa8-49d2-8c45-527359f98ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-2bf264d7-a5a4-42bf-8644-95734ce99aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-9ea58e37-cce3-4f03-a77e-950f40fef184,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-5bf61c28-7e1b-425d-811c-c612b53f7372,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-99b01b22-fa5b-4d6e-b463-7506e331c92d,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-2d429fbc-0c32-44a4-a888-81653624a812,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-cddce5f8-8942-4972-b9f8-588b93c97593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275284861-172.17.0.15-1597284635755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36022,DS-2422524a-7171-4578-977f-67208a0e86d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-3af6b487-18a1-42c8-a62f-84c869ad72f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-7608f7a7-c9eb-4e41-ac71-5040f4b45331,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-2fee2054-0dc3-414a-9982-77a9cadd89ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-84f225a3-6296-4ce7-9fe7-b49bae613e16,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-35b71db6-4841-4074-ae29-962ea7977ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-ec709918-705d-4754-8bf7-2277aaf3f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-1682d5ca-aaf8-4a22-a864-2bac33f0af36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275284861-172.17.0.15-1597284635755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36022,DS-2422524a-7171-4578-977f-67208a0e86d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-3af6b487-18a1-42c8-a62f-84c869ad72f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-7608f7a7-c9eb-4e41-ac71-5040f4b45331,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-2fee2054-0dc3-414a-9982-77a9cadd89ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-84f225a3-6296-4ce7-9fe7-b49bae613e16,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-35b71db6-4841-4074-ae29-962ea7977ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-ec709918-705d-4754-8bf7-2277aaf3f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-1682d5ca-aaf8-4a22-a864-2bac33f0af36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813007368-172.17.0.15-1597285319906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40198,DS-45ca2115-f8fd-4380-bb79-cda769939361,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-6613f2d1-eba0-4a06-81ac-544b16908b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-8400e68e-5ed3-4dce-8aee-297ebf79c63a,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-52b0d309-23cb-4380-ac3b-4ed1434778f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-33dfa713-074b-42b5-9acf-e7048f1f84ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-671f8aaf-a04b-40e5-803b-828cdea1ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-bd5491c0-4174-4c24-9abe-60f762ac594c,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-6151d1d0-4985-4b29-baed-f24bd5a68ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813007368-172.17.0.15-1597285319906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40198,DS-45ca2115-f8fd-4380-bb79-cda769939361,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-6613f2d1-eba0-4a06-81ac-544b16908b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-8400e68e-5ed3-4dce-8aee-297ebf79c63a,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-52b0d309-23cb-4380-ac3b-4ed1434778f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-33dfa713-074b-42b5-9acf-e7048f1f84ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-671f8aaf-a04b-40e5-803b-828cdea1ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-bd5491c0-4174-4c24-9abe-60f762ac594c,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-6151d1d0-4985-4b29-baed-f24bd5a68ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323117770-172.17.0.15-1597285486068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-638789fa-f640-49c1-af11-d4a705359088,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-c5d943f9-437c-41d6-a72b-1d72242aedac,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-349dab1a-257d-4356-ae6b-45048ecebcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a609f007-27f4-4c10-9b42-2c351ff375a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-7018df4e-d70c-4b31-8753-845076e8e52b,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-260375da-cd0d-48fd-89d4-aa811a94d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-1a8d55b3-6adf-4c6c-894c-f2c1f55d58a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-d84eed63-d7b5-48ec-9be3-a00c687fff90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323117770-172.17.0.15-1597285486068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-638789fa-f640-49c1-af11-d4a705359088,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-c5d943f9-437c-41d6-a72b-1d72242aedac,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-349dab1a-257d-4356-ae6b-45048ecebcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a609f007-27f4-4c10-9b42-2c351ff375a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-7018df4e-d70c-4b31-8753-845076e8e52b,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-260375da-cd0d-48fd-89d4-aa811a94d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-1a8d55b3-6adf-4c6c-894c-f2c1f55d58a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-d84eed63-d7b5-48ec-9be3-a00c687fff90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030003427-172.17.0.15-1597285524230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-fef19050-3255-46a2-98f2-5fdf4cbb8e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8867ac55-b86f-431f-a563-4a2aafe750f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-1b42595b-18d9-4fe1-95e0-b4537adfe8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-72f1ac77-02a9-4d41-8e3e-c1518436d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-097ee5f4-d45a-4263-9174-ee7060e2175d,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-44a0269b-3dec-44f6-9680-27c68a6a54e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-e4735e59-5d65-42cf-8544-eeb167638ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-b94128f7-2bb9-4371-a45c-2e3236de3d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030003427-172.17.0.15-1597285524230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35488,DS-fef19050-3255-46a2-98f2-5fdf4cbb8e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8867ac55-b86f-431f-a563-4a2aafe750f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-1b42595b-18d9-4fe1-95e0-b4537adfe8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-72f1ac77-02a9-4d41-8e3e-c1518436d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-097ee5f4-d45a-4263-9174-ee7060e2175d,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-44a0269b-3dec-44f6-9680-27c68a6a54e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-e4735e59-5d65-42cf-8544-eeb167638ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-b94128f7-2bb9-4371-a45c-2e3236de3d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-185782270-172.17.0.15-1597285708328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34160,DS-fb3eced0-3f71-41a6-b97e-da06885e8294,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-92132469-42d8-42d1-91e5-4e38416194f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-79c2f9d1-3137-440f-98c5-1f9fb5523c69,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-84124db6-b57a-4ee2-9936-969eb0c6b0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-60ca16f5-d112-4486-a7ad-cdb430b7f329,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-69580428-e9ae-4302-a4a3-89c6293a6f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-809069f7-9211-44a7-a805-518d49a1bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-f542b95e-5464-490a-81ad-53d8e050d665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-185782270-172.17.0.15-1597285708328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34160,DS-fb3eced0-3f71-41a6-b97e-da06885e8294,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-92132469-42d8-42d1-91e5-4e38416194f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-79c2f9d1-3137-440f-98c5-1f9fb5523c69,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-84124db6-b57a-4ee2-9936-969eb0c6b0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-60ca16f5-d112-4486-a7ad-cdb430b7f329,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-69580428-e9ae-4302-a4a3-89c6293a6f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-809069f7-9211-44a7-a805-518d49a1bf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-f542b95e-5464-490a-81ad-53d8e050d665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338288699-172.17.0.15-1597285782894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37692,DS-106aff2e-bd9f-43e8-ba77-2b6230ecbb81,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-7260f81e-6b66-4edc-bb94-4ad83743c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-78a4e257-1cfe-4b58-9c4d-e72a691060fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-eb43b2b0-3fd7-4fa8-86a9-d35d98e3c743,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-145f5430-a4ea-45d8-a739-b8e09760bfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-f58986e2-79d2-4882-9c5e-1752ca0ab305,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-c3e920af-a853-4682-b81e-999f276f4dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-c5bcf103-61d4-4d68-a1c3-f91eafac599d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1338288699-172.17.0.15-1597285782894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37692,DS-106aff2e-bd9f-43e8-ba77-2b6230ecbb81,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-7260f81e-6b66-4edc-bb94-4ad83743c4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-78a4e257-1cfe-4b58-9c4d-e72a691060fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-eb43b2b0-3fd7-4fa8-86a9-d35d98e3c743,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-145f5430-a4ea-45d8-a739-b8e09760bfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-f58986e2-79d2-4882-9c5e-1752ca0ab305,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-c3e920af-a853-4682-b81e-999f276f4dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-c5bcf103-61d4-4d68-a1c3-f91eafac599d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735879242-172.17.0.15-1597285820494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-bb3f0f5f-b2d8-4e26-8d29-c802dc447c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-54736874-f8be-4c64-95c9-394beee5b978,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-8c951a23-7bf2-40fc-ad11-855c98809357,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-e2476d0a-d2df-4acd-8cf1-137496cbd66f,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-371f1758-7ab5-4cd7-87d0-d89ed824aa80,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-0da9b753-feab-4b30-85a4-fe2c1ff0cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-93b9dde6-4ba1-4f7a-9fec-a919c36ac759,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-f37371dd-45ee-4af7-bdd1-d55149f0e167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735879242-172.17.0.15-1597285820494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-bb3f0f5f-b2d8-4e26-8d29-c802dc447c69,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-54736874-f8be-4c64-95c9-394beee5b978,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-8c951a23-7bf2-40fc-ad11-855c98809357,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-e2476d0a-d2df-4acd-8cf1-137496cbd66f,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-371f1758-7ab5-4cd7-87d0-d89ed824aa80,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-0da9b753-feab-4b30-85a4-fe2c1ff0cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-93b9dde6-4ba1-4f7a-9fec-a919c36ac759,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-f37371dd-45ee-4af7-bdd1-d55149f0e167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555450018-172.17.0.15-1597285852442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-5f80e0a0-8c0d-4514-8efc-dc99d139102d,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-b0233643-2013-42e5-b6a5-5e1c42c4158b,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-dd40ffb9-e79b-4685-b18e-342a2e377e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-6899c436-8c65-4151-9c28-29338a7c41f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-abe9f517-88b3-403c-ad6e-2102f7aa4037,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-2ea65736-e930-48b3-b82c-52dff24de9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-78f166ca-bdc0-48d9-9178-5ad4f9ead3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-443b2034-3fac-45ff-8772-a76d8d81d8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555450018-172.17.0.15-1597285852442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-5f80e0a0-8c0d-4514-8efc-dc99d139102d,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-b0233643-2013-42e5-b6a5-5e1c42c4158b,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-dd40ffb9-e79b-4685-b18e-342a2e377e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-6899c436-8c65-4151-9c28-29338a7c41f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-abe9f517-88b3-403c-ad6e-2102f7aa4037,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-2ea65736-e930-48b3-b82c-52dff24de9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-78f166ca-bdc0-48d9-9178-5ad4f9ead3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-443b2034-3fac-45ff-8772-a76d8d81d8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338398947-172.17.0.15-1597285886862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-79e6d5d2-c5f1-45ae-a12f-c30300079b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-e6318196-2329-47bb-95d0-1ae4989593c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-a8447749-ee30-4756-ad2c-6a86cb664ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-23e28b39-a961-4a7f-ba03-ac667581b5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-253952bc-9aa5-49bc-b22e-cea1bda217bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-1c660adf-eed8-4fb5-b4dd-0a755a2592af,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-fc7abb1e-a7d6-4a4e-af76-7e973e62b00c,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-158f56a7-cb67-439b-8f46-30a51f32ff00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338398947-172.17.0.15-1597285886862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-79e6d5d2-c5f1-45ae-a12f-c30300079b64,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-e6318196-2329-47bb-95d0-1ae4989593c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-a8447749-ee30-4756-ad2c-6a86cb664ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-23e28b39-a961-4a7f-ba03-ac667581b5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-253952bc-9aa5-49bc-b22e-cea1bda217bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-1c660adf-eed8-4fb5-b4dd-0a755a2592af,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-fc7abb1e-a7d6-4a4e-af76-7e973e62b00c,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-158f56a7-cb67-439b-8f46-30a51f32ff00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5591
