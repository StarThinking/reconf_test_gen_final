reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715921963-172.17.0.11-1597545779345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-09931736-602d-435e-8522-d0770a0a39e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-94346aca-6610-401b-9fa9-83014992b586,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-c4706aa4-5df4-44f1-9c77-4dfd2a82ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-28ee8383-b844-4e76-b54f-8a6df3e10ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-e5ed98db-6288-4c3a-9bd2-e2282d8bf0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-aab72f24-10ff-4cc7-aebc-64bda3042b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-73d475e4-be0f-4fee-87db-ef5bf71a6226,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-d0d51919-afbf-4978-a885-2ca6c903de52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715921963-172.17.0.11-1597545779345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-09931736-602d-435e-8522-d0770a0a39e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-94346aca-6610-401b-9fa9-83014992b586,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-c4706aa4-5df4-44f1-9c77-4dfd2a82ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-28ee8383-b844-4e76-b54f-8a6df3e10ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-e5ed98db-6288-4c3a-9bd2-e2282d8bf0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-aab72f24-10ff-4cc7-aebc-64bda3042b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-73d475e4-be0f-4fee-87db-ef5bf71a6226,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-d0d51919-afbf-4978-a885-2ca6c903de52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741373067-172.17.0.11-1597546060551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-3dde318d-a9dc-437f-9c8b-20af86520ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-6b272451-666d-45c0-8cc9-bcd553e6213e,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-44640fe0-ba4d-404e-8281-bb6b8a333b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-048548cb-2e12-40b2-bb68-5810a665afbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-51bf0b1a-1c48-494c-b364-3251766a6e19,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-dd5f77a6-1713-446e-938d-39eaf71a5aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-2137a72c-f238-45d7-8ab1-bcfb2d31cf26,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-a251b2f0-7ccd-4eaa-b042-ab896bc572fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741373067-172.17.0.11-1597546060551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-3dde318d-a9dc-437f-9c8b-20af86520ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-6b272451-666d-45c0-8cc9-bcd553e6213e,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-44640fe0-ba4d-404e-8281-bb6b8a333b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-048548cb-2e12-40b2-bb68-5810a665afbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-51bf0b1a-1c48-494c-b364-3251766a6e19,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-dd5f77a6-1713-446e-938d-39eaf71a5aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-2137a72c-f238-45d7-8ab1-bcfb2d31cf26,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-a251b2f0-7ccd-4eaa-b042-ab896bc572fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98850010-172.17.0.11-1597546247566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39928,DS-e5befb74-e95e-49f9-8cf2-c1d693f7c95e,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-1ec39a6f-0d54-4907-b606-0d1c947dc959,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-501201b5-d0ec-4782-b566-969a15703ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-28812639-f47e-449b-9639-50ace4b85096,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-705d663a-d3e2-40c7-b5ee-0abc3517bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-4602038b-12a2-48a8-8be9-37e7c551c3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-58d35c46-2a03-40b1-8011-be53abeca2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-4a3087bf-182e-4588-b8c2-d7d8bfbb6c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98850010-172.17.0.11-1597546247566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39928,DS-e5befb74-e95e-49f9-8cf2-c1d693f7c95e,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-1ec39a6f-0d54-4907-b606-0d1c947dc959,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-501201b5-d0ec-4782-b566-969a15703ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-28812639-f47e-449b-9639-50ace4b85096,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-705d663a-d3e2-40c7-b5ee-0abc3517bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-4602038b-12a2-48a8-8be9-37e7c551c3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-58d35c46-2a03-40b1-8011-be53abeca2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-4a3087bf-182e-4588-b8c2-d7d8bfbb6c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972717661-172.17.0.11-1597546533868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39331,DS-452a2414-4ae6-49dd-bb1b-ca35413aa369,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-9db15e3a-da78-4136-986e-44764141e1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-820bbb1e-b454-4f6b-a0fa-a3f5804fb92d,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-76a925f7-f96d-43a3-917d-9bcc64e13a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-9f802dd9-7370-4669-b57c-13b5cf78d518,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-070ddb5f-75c5-4b9a-a478-7fcb0b8eaef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-7d1d685c-6ef0-4ca0-8ab1-d453cf346cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-98d33e4b-1bee-4987-bbb8-ca1e2615d3dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972717661-172.17.0.11-1597546533868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39331,DS-452a2414-4ae6-49dd-bb1b-ca35413aa369,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-9db15e3a-da78-4136-986e-44764141e1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-820bbb1e-b454-4f6b-a0fa-a3f5804fb92d,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-76a925f7-f96d-43a3-917d-9bcc64e13a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-9f802dd9-7370-4669-b57c-13b5cf78d518,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-070ddb5f-75c5-4b9a-a478-7fcb0b8eaef4,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-7d1d685c-6ef0-4ca0-8ab1-d453cf346cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-98d33e4b-1bee-4987-bbb8-ca1e2615d3dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797209709-172.17.0.11-1597547155162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-b61ed54c-6067-4595-8196-158b9d4d0e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-3fc52208-8ce3-4fad-bf93-58af1fa4c7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-c52bea41-bebc-4122-a1c1-6bcb3f6a9ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-669732d7-4d7b-4075-b341-7bad6acb86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-3639975a-e120-4b03-8c83-c6ef716223bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-914cee32-8bc4-4c1d-a880-969475c2ed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-8d716520-8989-48e3-97d8-c4c5b756fce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-ff93c35b-90e2-4b51-bff5-2ad384fb4230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797209709-172.17.0.11-1597547155162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35636,DS-b61ed54c-6067-4595-8196-158b9d4d0e43,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-3fc52208-8ce3-4fad-bf93-58af1fa4c7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-c52bea41-bebc-4122-a1c1-6bcb3f6a9ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-669732d7-4d7b-4075-b341-7bad6acb86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-3639975a-e120-4b03-8c83-c6ef716223bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-914cee32-8bc4-4c1d-a880-969475c2ed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-8d716520-8989-48e3-97d8-c4c5b756fce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-ff93c35b-90e2-4b51-bff5-2ad384fb4230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110117182-172.17.0.11-1597547200439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40792,DS-f2bedb94-e93d-4e5d-bf31-16c09a1b5e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-24c08735-ed8c-4e38-883e-f53e1ba55be8,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-e0ad1a16-b35f-4d31-a067-3080e16a88b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-ad11eb65-32c3-4482-9513-78047c94623d,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-42cda9f2-730c-454a-9db9-d915a6f9ed25,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-df251e6a-d5b8-488a-870f-4b4ade61f9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-b5588b4c-ec3f-415e-b168-c41526c58885,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-ecb1abd6-41e1-4eec-ad20-3b74842b4be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110117182-172.17.0.11-1597547200439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40792,DS-f2bedb94-e93d-4e5d-bf31-16c09a1b5e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-24c08735-ed8c-4e38-883e-f53e1ba55be8,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-e0ad1a16-b35f-4d31-a067-3080e16a88b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-ad11eb65-32c3-4482-9513-78047c94623d,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-42cda9f2-730c-454a-9db9-d915a6f9ed25,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-df251e6a-d5b8-488a-870f-4b4ade61f9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-b5588b4c-ec3f-415e-b168-c41526c58885,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-ecb1abd6-41e1-4eec-ad20-3b74842b4be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579001111-172.17.0.11-1597547991239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-11daf660-c762-40fc-94bf-d450eaf50b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-694e842c-999d-44cf-8cd6-12d1d546429d,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-28e41360-3ca9-4253-ad0a-86506aeef2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-798ecacf-f2b4-433d-8cb2-c7c8483ce94a,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-2098b7b5-e113-4089-89ce-7130a491fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-86a96d7d-4160-4a2a-a81b-ffc3e1ef2b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5943e165-6e84-481d-9533-0e06697a5d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-4fe9bd04-a655-4b1e-8df9-e91060fccbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579001111-172.17.0.11-1597547991239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-11daf660-c762-40fc-94bf-d450eaf50b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-694e842c-999d-44cf-8cd6-12d1d546429d,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-28e41360-3ca9-4253-ad0a-86506aeef2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-798ecacf-f2b4-433d-8cb2-c7c8483ce94a,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-2098b7b5-e113-4089-89ce-7130a491fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-86a96d7d-4160-4a2a-a81b-ffc3e1ef2b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5943e165-6e84-481d-9533-0e06697a5d16,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-4fe9bd04-a655-4b1e-8df9-e91060fccbb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387049193-172.17.0.11-1597548700163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42009,DS-d9ad6544-2077-4ff3-91fb-8c1f48d585b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-e6eb51c5-3cd6-4ed4-83e4-ce906f51b8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-6f1bf260-edfb-4594-b889-fac675fa3132,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-69a3e8e4-047e-4c94-9602-ab2dba5d84c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-c8612d99-93da-4584-9fcf-e23164f63af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-97467e76-deab-4ee2-9d84-106dddc84849,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-a2acd657-b5d9-4033-8875-101b827bc444,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-2751466b-32bf-4ac7-8613-7b0e3e9d33ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387049193-172.17.0.11-1597548700163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42009,DS-d9ad6544-2077-4ff3-91fb-8c1f48d585b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-e6eb51c5-3cd6-4ed4-83e4-ce906f51b8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-6f1bf260-edfb-4594-b889-fac675fa3132,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-69a3e8e4-047e-4c94-9602-ab2dba5d84c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-c8612d99-93da-4584-9fcf-e23164f63af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-97467e76-deab-4ee2-9d84-106dddc84849,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-a2acd657-b5d9-4033-8875-101b827bc444,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-2751466b-32bf-4ac7-8613-7b0e3e9d33ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737695776-172.17.0.11-1597549138455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44638,DS-bde1aa1b-3f01-4b6f-8572-6ff8a0ff644a,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-e2407f04-d4e6-4810-a89c-1e45c3edf067,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-bfff1aa4-d935-4e4e-afcc-846286975310,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-f08e3daf-8d3f-468f-8078-94982c0eaf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-542c9259-2985-447c-8692-32bd7393dced,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-b86b68c5-0b8e-4eec-9023-3b58a3efcb67,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-61ba0617-fe4d-4539-a21a-69eb509c6210,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-aa8713ae-100a-4211-b193-08d976def4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737695776-172.17.0.11-1597549138455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44638,DS-bde1aa1b-3f01-4b6f-8572-6ff8a0ff644a,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-e2407f04-d4e6-4810-a89c-1e45c3edf067,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-bfff1aa4-d935-4e4e-afcc-846286975310,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-f08e3daf-8d3f-468f-8078-94982c0eaf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-542c9259-2985-447c-8692-32bd7393dced,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-b86b68c5-0b8e-4eec-9023-3b58a3efcb67,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-61ba0617-fe4d-4539-a21a-69eb509c6210,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-aa8713ae-100a-4211-b193-08d976def4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820436632-172.17.0.11-1597550254429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-8bece63e-b72c-4e9c-bb03-09721e4f6470,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-81abed27-cbc0-4c88-a1f3-80608dded9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-de736a60-39cc-4573-9fa9-69006b28c154,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-8a16e0cd-7cab-4330-a67a-1e857fb030ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-1b16955a-8d0f-4eb9-9c39-ec028dfb9a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-ae640225-c12c-4d3e-8ee3-95adda82b0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-22aebfcb-4fba-48e1-a37b-d8ee6fc0620c,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-5478261d-4237-45cd-952f-45232b0ad29c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820436632-172.17.0.11-1597550254429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-8bece63e-b72c-4e9c-bb03-09721e4f6470,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-81abed27-cbc0-4c88-a1f3-80608dded9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-de736a60-39cc-4573-9fa9-69006b28c154,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-8a16e0cd-7cab-4330-a67a-1e857fb030ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-1b16955a-8d0f-4eb9-9c39-ec028dfb9a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-ae640225-c12c-4d3e-8ee3-95adda82b0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-22aebfcb-4fba-48e1-a37b-d8ee6fc0620c,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-5478261d-4237-45cd-952f-45232b0ad29c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051385102-172.17.0.11-1597550529835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40884,DS-adeb8175-44b6-4dca-bf7b-d4c414757a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-3f9fa186-56d8-4cb1-98f6-924637f4fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-3217392a-8b58-4a90-beec-f57a13cfec08,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-4bfa36ce-83c8-4d9c-a5f9-9cfd7dc35a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-7bded221-5fc7-4f6f-bddd-01293ae6ebf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-a8891d48-72ca-4896-be9d-4d206b1b8b67,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-a8fefb21-b643-412e-8da4-bd7302b9a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-28f8a376-d47c-4e52-8524-46c4a525d671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051385102-172.17.0.11-1597550529835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40884,DS-adeb8175-44b6-4dca-bf7b-d4c414757a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-3f9fa186-56d8-4cb1-98f6-924637f4fee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-3217392a-8b58-4a90-beec-f57a13cfec08,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-4bfa36ce-83c8-4d9c-a5f9-9cfd7dc35a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-7bded221-5fc7-4f6f-bddd-01293ae6ebf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-a8891d48-72ca-4896-be9d-4d206b1b8b67,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-a8fefb21-b643-412e-8da4-bd7302b9a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-28f8a376-d47c-4e52-8524-46c4a525d671,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909795491-172.17.0.11-1597550688328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-08b698c8-7f01-4c3c-b946-f113334b7c31,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-8163c334-e0fc-4443-bf62-fd554cce6da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-9319e451-c4f7-41a9-a4c6-b56115668e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-d0f9faec-2342-41f6-af0d-51b342ff8e32,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-20ed2675-e8e6-4b7b-9d50-3b507045e0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-321bc0e0-14cc-43eb-8b18-65230708719d,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-d3b34543-8a6c-440a-b4ea-6b3e84d66fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-eed23f26-115f-4db2-b5d2-c0e9e50d32e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909795491-172.17.0.11-1597550688328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-08b698c8-7f01-4c3c-b946-f113334b7c31,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-8163c334-e0fc-4443-bf62-fd554cce6da6,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-9319e451-c4f7-41a9-a4c6-b56115668e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-d0f9faec-2342-41f6-af0d-51b342ff8e32,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-20ed2675-e8e6-4b7b-9d50-3b507045e0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-321bc0e0-14cc-43eb-8b18-65230708719d,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-d3b34543-8a6c-440a-b4ea-6b3e84d66fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-eed23f26-115f-4db2-b5d2-c0e9e50d32e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606197855-172.17.0.11-1597550766466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38067,DS-8adfd495-f160-437f-ba52-7390d3a52e16,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-c90f4944-cea3-4d3e-a385-64e158e6bc06,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-4e1b780f-54c4-418c-9713-1fdce5047b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-59752492-a66f-4bbf-bfb6-959f99e5b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-ac2c1427-05ad-4242-89ee-e5854581d800,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-cc3a7712-4780-43a4-8289-3478e98b5266,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-24a872cd-8b9a-4368-ba6a-006087eba013,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-210cfa13-3aa7-40d2-9c8b-0ee3ba52529e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606197855-172.17.0.11-1597550766466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38067,DS-8adfd495-f160-437f-ba52-7390d3a52e16,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-c90f4944-cea3-4d3e-a385-64e158e6bc06,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-4e1b780f-54c4-418c-9713-1fdce5047b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-59752492-a66f-4bbf-bfb6-959f99e5b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-ac2c1427-05ad-4242-89ee-e5854581d800,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-cc3a7712-4780-43a4-8289-3478e98b5266,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-24a872cd-8b9a-4368-ba6a-006087eba013,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-210cfa13-3aa7-40d2-9c8b-0ee3ba52529e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 200s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459058721-172.17.0.11-1597551235729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-b7d584e6-bdbf-4e69-a2b3-336de8d88714,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-7964e0c3-3876-47ab-901e-3d3c36b20046,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-8f313a18-cf2d-4b85-9d67-8e82b0608141,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-55fd8df2-2195-4a75-a957-ce3ad46cf90e,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-2cc3417c-4b95-44b4-a569-77747c6628c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-9b473b2f-c372-4d98-a9bf-f86d1d21ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-b4c9814a-85a1-425a-88fb-7afdbc62a565,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-04a548c9-7f87-42ed-b91d-363b19ceca49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459058721-172.17.0.11-1597551235729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35393,DS-b7d584e6-bdbf-4e69-a2b3-336de8d88714,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-7964e0c3-3876-47ab-901e-3d3c36b20046,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-8f313a18-cf2d-4b85-9d67-8e82b0608141,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-55fd8df2-2195-4a75-a957-ce3ad46cf90e,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-2cc3417c-4b95-44b4-a569-77747c6628c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-9b473b2f-c372-4d98-a9bf-f86d1d21ea7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-b4c9814a-85a1-425a-88fb-7afdbc62a565,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-04a548c9-7f87-42ed-b91d-363b19ceca49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5813
