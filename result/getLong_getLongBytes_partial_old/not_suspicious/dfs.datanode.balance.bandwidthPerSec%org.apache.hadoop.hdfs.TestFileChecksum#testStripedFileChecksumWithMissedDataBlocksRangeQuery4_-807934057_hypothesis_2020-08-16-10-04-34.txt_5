reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250834136-172.17.0.20-1597575249286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-36b87032-9a72-43a4-938e-84adfae6f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-9881d8fb-3360-436c-a940-b204aef3d775,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-f7aaf841-64fc-45d5-bfbd-c7677c919e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-747967d8-e223-4adf-a8b4-87e7707ab200,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-a41b60bd-c0d9-4cc2-baae-a65c8ba497f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-6534cc3a-35be-4395-b4cc-33b7302e2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-1cf3de63-6aea-4cd9-a84a-59a607039d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-c77e015f-6878-4f50-b2bb-0e4b71271ada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250834136-172.17.0.20-1597575249286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-36b87032-9a72-43a4-938e-84adfae6f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-9881d8fb-3360-436c-a940-b204aef3d775,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-f7aaf841-64fc-45d5-bfbd-c7677c919e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-747967d8-e223-4adf-a8b4-87e7707ab200,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-a41b60bd-c0d9-4cc2-baae-a65c8ba497f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-6534cc3a-35be-4395-b4cc-33b7302e2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-1cf3de63-6aea-4cd9-a84a-59a607039d11,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-c77e015f-6878-4f50-b2bb-0e4b71271ada,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593834716-172.17.0.20-1597575762971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-0dfae87b-21da-4388-aa22-dd53a4c63daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-400977b9-5f83-4775-bb1d-f44b48f82713,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-22f1c164-8555-4ebe-91ea-9b172185e136,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-378f6b14-6469-4190-a7ac-596ce3f5189e,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-22f01772-10b9-4a50-ac40-0553235eae79,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-27a85f65-d791-48bb-a97e-09c3ff632166,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-a8d0a23f-1530-4d51-912f-a86c2c8c2323,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-672b5080-a1cd-4363-9fd3-2b2828c2dd5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593834716-172.17.0.20-1597575762971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-0dfae87b-21da-4388-aa22-dd53a4c63daf,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-400977b9-5f83-4775-bb1d-f44b48f82713,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-22f1c164-8555-4ebe-91ea-9b172185e136,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-378f6b14-6469-4190-a7ac-596ce3f5189e,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-22f01772-10b9-4a50-ac40-0553235eae79,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-27a85f65-d791-48bb-a97e-09c3ff632166,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-a8d0a23f-1530-4d51-912f-a86c2c8c2323,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-672b5080-a1cd-4363-9fd3-2b2828c2dd5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311858716-172.17.0.20-1597576201911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-ed0958c8-e140-4f9b-9550-ae16eea22529,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-5bc284f9-b386-4a47-8093-42e552dbd1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-acbdd085-3c89-4fe7-9237-96e66ba8d98b,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-b0c226d8-5895-4987-b478-125e2ef68efd,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-c4896036-62ec-4659-840d-a5c774155779,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-02a0d133-672a-4503-a225-4c5040f78b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-9f8fe231-a7bb-478c-be3d-fad4eac70369,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-8e8e69ab-e7de-47c8-82db-6362742b1037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311858716-172.17.0.20-1597576201911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-ed0958c8-e140-4f9b-9550-ae16eea22529,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-5bc284f9-b386-4a47-8093-42e552dbd1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-acbdd085-3c89-4fe7-9237-96e66ba8d98b,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-b0c226d8-5895-4987-b478-125e2ef68efd,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-c4896036-62ec-4659-840d-a5c774155779,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-02a0d133-672a-4503-a225-4c5040f78b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-9f8fe231-a7bb-478c-be3d-fad4eac70369,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-8e8e69ab-e7de-47c8-82db-6362742b1037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162904041-172.17.0.20-1597577091303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38261,DS-1b3f49ce-1bfb-4cb3-abe7-5b4f305d25a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-0461df64-f9bc-4b66-90cc-ef20bfaf7768,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-2ebe6f7a-8739-4c8e-bada-5364086ca0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-1f7ab805-a51b-414f-b2fa-0fec334bdb61,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-c1a511d2-0512-41db-aa6d-bf06584f1c16,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-a0a91a96-5ed4-4a58-b138-3bdbc4222535,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-b87637b9-7e07-47e1-bf95-37410b21f624,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-459b0d49-7855-4329-8fad-5550cf907fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162904041-172.17.0.20-1597577091303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38261,DS-1b3f49ce-1bfb-4cb3-abe7-5b4f305d25a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-0461df64-f9bc-4b66-90cc-ef20bfaf7768,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-2ebe6f7a-8739-4c8e-bada-5364086ca0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-1f7ab805-a51b-414f-b2fa-0fec334bdb61,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-c1a511d2-0512-41db-aa6d-bf06584f1c16,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-a0a91a96-5ed4-4a58-b138-3bdbc4222535,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-b87637b9-7e07-47e1-bf95-37410b21f624,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-459b0d49-7855-4329-8fad-5550cf907fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537175962-172.17.0.20-1597577144440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39165,DS-0c10b87b-e0bb-498c-928a-599e5dc62fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-8c1b0dac-4672-41b1-b866-28858cb10bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-161e1952-7cfe-44e0-831b-05092cb8fb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-58148736-0f90-4c9b-a809-6be9f4d60092,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-b7f9a9e3-3b39-4adc-82aa-5ed4c0f7b8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-3b9895c7-b69a-430c-8ac9-76f7b24caca0,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-5f8962c7-bdf8-4620-81ab-33c2c5984753,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-c05c85bb-82ca-4f83-98fd-1efed24a254e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537175962-172.17.0.20-1597577144440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39165,DS-0c10b87b-e0bb-498c-928a-599e5dc62fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-8c1b0dac-4672-41b1-b866-28858cb10bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-161e1952-7cfe-44e0-831b-05092cb8fb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-58148736-0f90-4c9b-a809-6be9f4d60092,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-b7f9a9e3-3b39-4adc-82aa-5ed4c0f7b8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-3b9895c7-b69a-430c-8ac9-76f7b24caca0,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-5f8962c7-bdf8-4620-81ab-33c2c5984753,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-c05c85bb-82ca-4f83-98fd-1efed24a254e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639033988-172.17.0.20-1597577731466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-a068eff4-5abb-4c4f-bbb6-ac8c5ac1947b,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-e17d5c8a-5828-4cb6-b8c3-81d14d174900,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-a4386589-9755-4054-bf74-4d240786bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-0df1c27c-36ab-40b6-8da7-6ce95e99ef86,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-57e5ef19-082b-49ef-aadd-f5a3e093956c,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-d4649e1d-9115-40e6-8a86-dda7d1aaa35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-f41d1719-0086-49a3-9ab3-f177dceb0dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-ab43fb09-419c-4b4a-bbe3-ba5d1041642d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639033988-172.17.0.20-1597577731466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40416,DS-a068eff4-5abb-4c4f-bbb6-ac8c5ac1947b,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-e17d5c8a-5828-4cb6-b8c3-81d14d174900,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-a4386589-9755-4054-bf74-4d240786bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-0df1c27c-36ab-40b6-8da7-6ce95e99ef86,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-57e5ef19-082b-49ef-aadd-f5a3e093956c,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-d4649e1d-9115-40e6-8a86-dda7d1aaa35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-f41d1719-0086-49a3-9ab3-f177dceb0dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-ab43fb09-419c-4b4a-bbe3-ba5d1041642d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565537088-172.17.0.20-1597578060808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-26c5986b-061f-447c-a3d5-147dad95a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-853fc798-3374-48d6-965f-f3558781fef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-a2290089-a4ff-47c2-993c-0da6b3b411af,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-9a6babc0-ce39-4c18-9229-cfe7b825539d,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-c55549f9-b8a3-4d85-bbae-44644f1ca8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-787cec78-2c50-4239-8e65-14746ce8c375,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-5eb2bdb0-eb5d-4d99-b5b6-89026043a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-5f3c7bbe-bfe9-4eae-9d1b-2fac7883638b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565537088-172.17.0.20-1597578060808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-26c5986b-061f-447c-a3d5-147dad95a69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-853fc798-3374-48d6-965f-f3558781fef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-a2290089-a4ff-47c2-993c-0da6b3b411af,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-9a6babc0-ce39-4c18-9229-cfe7b825539d,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-c55549f9-b8a3-4d85-bbae-44644f1ca8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-787cec78-2c50-4239-8e65-14746ce8c375,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-5eb2bdb0-eb5d-4d99-b5b6-89026043a5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-5f3c7bbe-bfe9-4eae-9d1b-2fac7883638b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722002869-172.17.0.20-1597578635207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-1c58244c-ac32-4c1c-b012-0f0a2b6eed96,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-1c3c5fbb-833c-473e-9614-a1399daffd39,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-3b3a01b2-5dcd-4b11-93c1-0f491cf65963,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-a21de126-32af-4c06-8402-c02918f1cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-6d871364-27b3-4765-88d0-30f00fe200fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-b2945a5e-4874-4867-9720-a4224e97d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-a469b4b9-fa91-46b9-a6e1-99bd7c1ea619,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-47c17f94-9473-4d10-9e51-9e1c29f4dc38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722002869-172.17.0.20-1597578635207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-1c58244c-ac32-4c1c-b012-0f0a2b6eed96,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-1c3c5fbb-833c-473e-9614-a1399daffd39,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-3b3a01b2-5dcd-4b11-93c1-0f491cf65963,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-a21de126-32af-4c06-8402-c02918f1cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-6d871364-27b3-4765-88d0-30f00fe200fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-b2945a5e-4874-4867-9720-a4224e97d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-a469b4b9-fa91-46b9-a6e1-99bd7c1ea619,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-47c17f94-9473-4d10-9e51-9e1c29f4dc38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 100m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804578624-172.17.0.20-1597578971265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40761,DS-4135a2a1-9ba7-4954-ac7c-10b708fe0df6,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-1e9c4440-a97e-43e3-bbb8-edb6d803c43e,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-1f181103-b6ec-40ba-bf76-f197012912d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-e96c820c-37ed-4cb4-ac7a-4ef5d5bb1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-33c9be2d-3f4d-48fa-b0cb-cc8d42dc4ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-2578c37e-5f8c-4426-bce2-f81794684792,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-6e1c2df0-da59-4d21-81f8-4ba2ebbaadf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-d2d57cfc-f466-41e2-98dc-f5a17e904540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804578624-172.17.0.20-1597578971265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40761,DS-4135a2a1-9ba7-4954-ac7c-10b708fe0df6,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-1e9c4440-a97e-43e3-bbb8-edb6d803c43e,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-1f181103-b6ec-40ba-bf76-f197012912d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-e96c820c-37ed-4cb4-ac7a-4ef5d5bb1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-33c9be2d-3f4d-48fa-b0cb-cc8d42dc4ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-2578c37e-5f8c-4426-bce2-f81794684792,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-6e1c2df0-da59-4d21-81f8-4ba2ebbaadf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-d2d57cfc-f466-41e2-98dc-f5a17e904540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 7129
