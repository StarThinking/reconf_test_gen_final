reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432834677-172.17.0.9-1597344875755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36052,DS-f7ceb8d3-91e6-4c51-8930-a4cb0a16f692,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-3c3f5e7f-e069-428a-8a0f-433e4e270d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-1310b826-57d7-48f9-950f-70c04b8cb2df,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-58232773-72d6-495b-8b1a-824301e11f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-ec1116a9-82af-43eb-97b1-293d3af1f019,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-f594a45d-d967-47fa-b5d4-1c52d5f705be,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-0463ce35-9deb-4c51-8fc0-f638d99bc509,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-af914d12-a0df-48b1-95e6-f92a0ea8e533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432834677-172.17.0.9-1597344875755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36052,DS-f7ceb8d3-91e6-4c51-8930-a4cb0a16f692,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-3c3f5e7f-e069-428a-8a0f-433e4e270d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-1310b826-57d7-48f9-950f-70c04b8cb2df,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-58232773-72d6-495b-8b1a-824301e11f48,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-ec1116a9-82af-43eb-97b1-293d3af1f019,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-f594a45d-d967-47fa-b5d4-1c52d5f705be,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-0463ce35-9deb-4c51-8fc0-f638d99bc509,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-af914d12-a0df-48b1-95e6-f92a0ea8e533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382084039-172.17.0.9-1597345136227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38926,DS-ae0baabe-5c21-426f-aca1-606021412be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-d07cdc00-6c8d-485d-b449-31cbe3fb083d,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-ab6f34cc-4930-444e-8591-6041f6891e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-014bfa59-a6da-4e7b-911b-8de0d3390705,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-4417ded4-6ea1-4540-b490-f852fceb3139,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-e31e63c3-c52c-4783-8db9-4c472e5e61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-994378d9-5737-4543-9b6a-2b334eeda75b,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-1f1eb92a-54c2-46a8-9fec-81ede5c3dfd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382084039-172.17.0.9-1597345136227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38926,DS-ae0baabe-5c21-426f-aca1-606021412be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-d07cdc00-6c8d-485d-b449-31cbe3fb083d,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-ab6f34cc-4930-444e-8591-6041f6891e49,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-014bfa59-a6da-4e7b-911b-8de0d3390705,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-4417ded4-6ea1-4540-b490-f852fceb3139,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-e31e63c3-c52c-4783-8db9-4c472e5e61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-994378d9-5737-4543-9b6a-2b334eeda75b,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-1f1eb92a-54c2-46a8-9fec-81ede5c3dfd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243255636-172.17.0.9-1597345817248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45207,DS-7236e863-c6b9-4327-bdb8-6c222a01bf24,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-cd7a2cd6-2fdf-4c8b-82a3-1cad9d5e530c,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-2b25e16f-e219-4426-834d-ed000682e342,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-de96cfd3-9436-4a57-9a37-19f222f63cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-682f69f7-48e6-4b37-86e4-c524398b9d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-419d66cb-1ed3-4c69-931a-620b4b4a3b55,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-ef5c64ca-447f-4a89-8d95-ec33ca686750,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-0ede26de-05c2-4a73-b444-50408865bb4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243255636-172.17.0.9-1597345817248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45207,DS-7236e863-c6b9-4327-bdb8-6c222a01bf24,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-cd7a2cd6-2fdf-4c8b-82a3-1cad9d5e530c,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-2b25e16f-e219-4426-834d-ed000682e342,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-de96cfd3-9436-4a57-9a37-19f222f63cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-682f69f7-48e6-4b37-86e4-c524398b9d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-419d66cb-1ed3-4c69-931a-620b4b4a3b55,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-ef5c64ca-447f-4a89-8d95-ec33ca686750,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-0ede26de-05c2-4a73-b444-50408865bb4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56991644-172.17.0.9-1597345979091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43130,DS-716e3a4b-a5a3-4375-a9c6-7e2797cdcd63,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-8f29eede-7027-48de-b7ef-918f2450b8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-dd64afb6-6181-4d95-9faf-6e70d98d1c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-b96d3fd2-ca6a-4be9-b0b0-c2c20af66769,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-e63b6721-2a71-4365-b81e-ee48a0b75987,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-b8cc8ab4-9181-4388-b00e-81f08c4ddd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-bd5b9d5c-56fd-402e-9d15-9837d8c6e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-1b4e9a91-1dc8-4b0a-83aa-10a81abf1e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56991644-172.17.0.9-1597345979091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43130,DS-716e3a4b-a5a3-4375-a9c6-7e2797cdcd63,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-8f29eede-7027-48de-b7ef-918f2450b8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-dd64afb6-6181-4d95-9faf-6e70d98d1c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-b96d3fd2-ca6a-4be9-b0b0-c2c20af66769,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-e63b6721-2a71-4365-b81e-ee48a0b75987,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-b8cc8ab4-9181-4388-b00e-81f08c4ddd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-bd5b9d5c-56fd-402e-9d15-9837d8c6e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-1b4e9a91-1dc8-4b0a-83aa-10a81abf1e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636952660-172.17.0.9-1597346057366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37335,DS-4dc9ab5f-130e-4630-93b7-e541aa046fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-a533946e-0570-4a92-b9c2-720fdb8047e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-7e1105a0-8100-40f9-b853-b73d76cbf3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-34f750e4-0c4d-4c11-8320-df2b8224c9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-ae49718a-d9f7-4ebd-8b30-cba4f70cb3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-12ea9720-eedd-4b43-b238-acef3852f32c,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-83183021-0680-4994-b0c8-f96086eec834,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-c8d150f9-009f-49e1-bb42-7ae64b9f0b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636952660-172.17.0.9-1597346057366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37335,DS-4dc9ab5f-130e-4630-93b7-e541aa046fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-a533946e-0570-4a92-b9c2-720fdb8047e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-7e1105a0-8100-40f9-b853-b73d76cbf3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-34f750e4-0c4d-4c11-8320-df2b8224c9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-ae49718a-d9f7-4ebd-8b30-cba4f70cb3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-12ea9720-eedd-4b43-b238-acef3852f32c,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-83183021-0680-4994-b0c8-f96086eec834,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-c8d150f9-009f-49e1-bb42-7ae64b9f0b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716238075-172.17.0.9-1597346140440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36674,DS-d1b97481-2e59-4e3a-958f-4d30e0ac134c,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-a919dc0a-312c-4e63-9ba2-081406978a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-6138e684-30a9-406b-9e7a-02a454ee61ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-8fad44a4-9652-4281-b724-95563e906f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-6429667a-ded0-4d20-8c12-b22040a070a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-a80f0b4c-aae8-4adf-931b-081297f297b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-a49fd188-8d19-41d4-aa06-b0332b43f738,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-7997c404-fab3-447d-973a-bc95ce2e83a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716238075-172.17.0.9-1597346140440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36674,DS-d1b97481-2e59-4e3a-958f-4d30e0ac134c,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-a919dc0a-312c-4e63-9ba2-081406978a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-6138e684-30a9-406b-9e7a-02a454ee61ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-8fad44a4-9652-4281-b724-95563e906f94,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-6429667a-ded0-4d20-8c12-b22040a070a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-a80f0b4c-aae8-4adf-931b-081297f297b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-a49fd188-8d19-41d4-aa06-b0332b43f738,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-7997c404-fab3-447d-973a-bc95ce2e83a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056400752-172.17.0.9-1597346212124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-f6ea4ca5-0f62-4bc8-bd76-dc02b9410e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-61cc953c-f717-45c8-a1b8-4b065461d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4df759e9-790a-4349-b72e-76774c132c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-4ddba92d-11a5-48ca-836c-0a8af6f93147,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-850bdbdb-5fd2-4c43-a7ea-8ad7c6880a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-4afdc716-e537-4f07-9851-8b776f6377ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-76fd96be-ae6a-4afc-9f4b-53ab813021b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-a306c388-c7dc-4241-bbba-c010e43d71ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056400752-172.17.0.9-1597346212124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-f6ea4ca5-0f62-4bc8-bd76-dc02b9410e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-61cc953c-f717-45c8-a1b8-4b065461d23c,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-4df759e9-790a-4349-b72e-76774c132c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-4ddba92d-11a5-48ca-836c-0a8af6f93147,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-850bdbdb-5fd2-4c43-a7ea-8ad7c6880a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-4afdc716-e537-4f07-9851-8b776f6377ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-76fd96be-ae6a-4afc-9f4b-53ab813021b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-a306c388-c7dc-4241-bbba-c010e43d71ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309054087-172.17.0.9-1597346293482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-83c5379f-03e2-4a13-85b8-193ed1379fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-1d9ca997-3e90-42c7-8cad-9fe060ce6345,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-3f7a5613-a3e1-43f4-bfa5-0c1bbac45bda,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-3638179d-e851-4403-b62f-1ab5c83af655,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-8701f415-9073-49ed-9fef-e0e7e2f0184d,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-fc1be3e3-6340-4c5f-9683-5a73016ac7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-2a4ac2b0-2a6d-472e-bd1f-ecb7ca3b662b,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-00942144-a705-4774-b071-fe5d036d3399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309054087-172.17.0.9-1597346293482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-83c5379f-03e2-4a13-85b8-193ed1379fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-1d9ca997-3e90-42c7-8cad-9fe060ce6345,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-3f7a5613-a3e1-43f4-bfa5-0c1bbac45bda,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-3638179d-e851-4403-b62f-1ab5c83af655,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-8701f415-9073-49ed-9fef-e0e7e2f0184d,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-fc1be3e3-6340-4c5f-9683-5a73016ac7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-2a4ac2b0-2a6d-472e-bd1f-ecb7ca3b662b,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-00942144-a705-4774-b071-fe5d036d3399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475094289-172.17.0.9-1597346410230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-5067e8fc-2d46-439f-83e3-7f306cb75bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-d91ae6dc-77eb-41c8-a9c3-8beac46357ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-4efd23c4-0aac-4b6b-91ec-54fe81c8a456,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-a7feecd9-4e50-43fe-88cb-f3cbe03f678b,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-732e9c75-a38c-48e6-bf85-c7ea9e233e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-bee50ce7-d10d-4bc8-93db-0b892c7808d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-573c647b-e1dc-4710-adcc-444d21244d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-15583a20-c80b-484b-93a3-9ff63d841965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475094289-172.17.0.9-1597346410230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-5067e8fc-2d46-439f-83e3-7f306cb75bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-d91ae6dc-77eb-41c8-a9c3-8beac46357ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-4efd23c4-0aac-4b6b-91ec-54fe81c8a456,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-a7feecd9-4e50-43fe-88cb-f3cbe03f678b,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-732e9c75-a38c-48e6-bf85-c7ea9e233e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-bee50ce7-d10d-4bc8-93db-0b892c7808d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-573c647b-e1dc-4710-adcc-444d21244d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-15583a20-c80b-484b-93a3-9ff63d841965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172442995-172.17.0.9-1597348727783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44557,DS-531ed4cb-935a-43e7-bb3c-c8e0fa196810,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-143255c9-11b3-4439-a672-6fdff4afb504,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-439e5a9a-719a-4ff1-9a2f-0311d9c2bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-d37b6a95-668b-4f50-90c8-d70ff06ba49d,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-e6d68877-3612-408e-8286-08b606ab12f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-7ba70387-4f42-4505-9018-03233c369c10,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-5b2d8b22-2dc5-460d-ac11-a5b307612605,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-a4916ae4-39d1-46ac-b36d-c35f55795506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172442995-172.17.0.9-1597348727783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44557,DS-531ed4cb-935a-43e7-bb3c-c8e0fa196810,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-143255c9-11b3-4439-a672-6fdff4afb504,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-439e5a9a-719a-4ff1-9a2f-0311d9c2bebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-d37b6a95-668b-4f50-90c8-d70ff06ba49d,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-e6d68877-3612-408e-8286-08b606ab12f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-7ba70387-4f42-4505-9018-03233c369c10,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-5b2d8b22-2dc5-460d-ac11-a5b307612605,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-a4916ae4-39d1-46ac-b36d-c35f55795506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805480675-172.17.0.9-1597349284898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34098,DS-28cb1d3e-8f15-4391-b9ce-7b519dc01991,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-ef2fecb3-0f37-47a7-a6af-a68ab4dadff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-01a5be23-38d9-4006-8e02-0a52a9a68a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-3ce0acac-08bc-4235-b5ec-b2c0d89af72a,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-e0ee7f5a-b70a-4efc-8d02-874bf5721abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-02b61fbe-337b-44a4-95f6-ba059683bb03,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-a4c2a91c-48d7-4a45-ab45-68fd4a77a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-af9e41d3-aa20-40c4-abcd-f607137d0462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805480675-172.17.0.9-1597349284898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34098,DS-28cb1d3e-8f15-4391-b9ce-7b519dc01991,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-ef2fecb3-0f37-47a7-a6af-a68ab4dadff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-01a5be23-38d9-4006-8e02-0a52a9a68a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-3ce0acac-08bc-4235-b5ec-b2c0d89af72a,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-e0ee7f5a-b70a-4efc-8d02-874bf5721abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-02b61fbe-337b-44a4-95f6-ba059683bb03,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-a4c2a91c-48d7-4a45-ab45-68fd4a77a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-af9e41d3-aa20-40c4-abcd-f607137d0462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430243395-172.17.0.9-1597349475132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-26334b2d-c5a4-49f1-b3fc-69c8afb2a575,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-4be89624-b7c2-4c01-8ebe-a27d558ffd47,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-3326b59c-0fed-42de-80a1-927b123cfa94,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-8bd8fa9b-5d8f-492c-ac32-ca8710ec89bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-e0022f87-027c-4362-9c6c-b2e450a5e792,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-279d69fb-3ac7-43d5-80a1-ade8ab0b8781,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-af3f955e-9aa9-48af-98a7-30906d465f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-a52be02f-8aed-4ed9-b9fd-7943833fb6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430243395-172.17.0.9-1597349475132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40433,DS-26334b2d-c5a4-49f1-b3fc-69c8afb2a575,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-4be89624-b7c2-4c01-8ebe-a27d558ffd47,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-3326b59c-0fed-42de-80a1-927b123cfa94,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-8bd8fa9b-5d8f-492c-ac32-ca8710ec89bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-e0022f87-027c-4362-9c6c-b2e450a5e792,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-279d69fb-3ac7-43d5-80a1-ade8ab0b8781,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-af3f955e-9aa9-48af-98a7-30906d465f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-a52be02f-8aed-4ed9-b9fd-7943833fb6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711853921-172.17.0.9-1597349683171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33908,DS-aaafd1b6-ce0a-41e3-aea1-fdc627d5e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-743a06e7-3f7c-4670-8e45-1fef31db7d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-9df95b96-17a7-488c-888c-49c3c9bc228e,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-9616dc56-c030-4a66-9853-0928025641fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-a7cc7e53-a5f8-4ea3-ae2f-93e5f33f5fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-495e81cd-7e3c-4bd6-b3ae-f9e8442b76ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-f5142a4d-7a13-495e-93b5-69f2129fa54a,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-41b3b633-f531-4dbe-b097-5db4eec494df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711853921-172.17.0.9-1597349683171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33908,DS-aaafd1b6-ce0a-41e3-aea1-fdc627d5e67e,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-743a06e7-3f7c-4670-8e45-1fef31db7d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-9df95b96-17a7-488c-888c-49c3c9bc228e,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-9616dc56-c030-4a66-9853-0928025641fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-a7cc7e53-a5f8-4ea3-ae2f-93e5f33f5fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-495e81cd-7e3c-4bd6-b3ae-f9e8442b76ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-f5142a4d-7a13-495e-93b5-69f2129fa54a,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-41b3b633-f531-4dbe-b097-5db4eec494df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719774586-172.17.0.9-1597349991274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-4b74bc75-cafe-45b0-8144-5b7ae3bfd642,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-07d96e4b-d0c8-462b-b8bb-549c4d8940cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-f897f299-a420-4fac-9939-86d362c99264,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-894accf1-489b-464f-a337-394cde69fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-9a7f9f64-f899-4b75-b62d-83dde6cc4fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-1ee7d8ed-db48-4699-b31f-cde73807ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-9ca9e62a-89ae-4ba7-8b08-5d5fd6121f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-1e809376-74ba-49ed-b40a-9956d9854f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719774586-172.17.0.9-1597349991274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-4b74bc75-cafe-45b0-8144-5b7ae3bfd642,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-07d96e4b-d0c8-462b-b8bb-549c4d8940cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-f897f299-a420-4fac-9939-86d362c99264,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-894accf1-489b-464f-a337-394cde69fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-9a7f9f64-f899-4b75-b62d-83dde6cc4fae,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-1ee7d8ed-db48-4699-b31f-cde73807ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-9ca9e62a-89ae-4ba7-8b08-5d5fd6121f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-1e809376-74ba-49ed-b40a-9956d9854f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183702392-172.17.0.9-1597350334285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-f0d10047-77b9-4c51-ac2d-3e397b10dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-07a9b426-362e-41e0-ac07-bd7a11e5dd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-c9af0e57-dc13-4edb-802e-1cc8cbc7bb09,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-016c94d7-54bb-40a3-9f6d-0b13c4b2cd43,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-33e39358-c945-4a86-96a5-210101ab8386,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-9c96c95f-09ec-4279-9d71-53104015bfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-12de70a3-3fe8-423c-a77f-950e0f5cee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-cb3ac4dd-d4b6-4078-917f-9141ea0cc98f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183702392-172.17.0.9-1597350334285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-f0d10047-77b9-4c51-ac2d-3e397b10dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-07a9b426-362e-41e0-ac07-bd7a11e5dd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-c9af0e57-dc13-4edb-802e-1cc8cbc7bb09,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-016c94d7-54bb-40a3-9f6d-0b13c4b2cd43,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-33e39358-c945-4a86-96a5-210101ab8386,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-9c96c95f-09ec-4279-9d71-53104015bfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-12de70a3-3fe8-423c-a77f-950e0f5cee3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-cb3ac4dd-d4b6-4078-917f-9141ea0cc98f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670157502-172.17.0.9-1597350635907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-54fc99dc-8c54-4987-81cd-3865eab5fa14,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-291789d2-dce7-4fae-8d69-d4b491d61562,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-73ac8d55-f4b8-403e-9f69-b1b14ce2cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-8b599d4a-9089-4de8-999e-d3105c860605,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-2eb6d636-f95d-40a3-af08-09452cb5b99f,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-6daaaec2-7cb5-43ab-9b7e-72ab344f7bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-b06d805d-2e3e-4419-9ff5-46b3f5aace5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-a54700df-0d61-4fbf-9746-bcc88841d273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670157502-172.17.0.9-1597350635907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-54fc99dc-8c54-4987-81cd-3865eab5fa14,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-291789d2-dce7-4fae-8d69-d4b491d61562,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-73ac8d55-f4b8-403e-9f69-b1b14ce2cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-8b599d4a-9089-4de8-999e-d3105c860605,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-2eb6d636-f95d-40a3-af08-09452cb5b99f,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-6daaaec2-7cb5-43ab-9b7e-72ab344f7bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-b06d805d-2e3e-4419-9ff5-46b3f5aace5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-a54700df-0d61-4fbf-9746-bcc88841d273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5874
