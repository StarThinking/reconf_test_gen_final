reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823757678-172.17.0.13-1597518730848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-ecb62736-8d79-4492-a9dd-e38d2143f439,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-a7dc0d95-bd50-4dc3-bd1c-e78592c2c880,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-81b2413a-ef94-4051-b2a7-8dcb3e22efdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-c5e5b4bf-7481-4544-b938-6471a7d89dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-1f688904-bc8b-4042-b6cd-8d7b04aec6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-97d76eb3-7679-45a8-bf2e-fae7303bce58,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-8b796166-cc64-4571-b81a-dadcad39c823,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-5a41f381-13dd-4211-8607-db1bcf6815fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823757678-172.17.0.13-1597518730848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-ecb62736-8d79-4492-a9dd-e38d2143f439,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-a7dc0d95-bd50-4dc3-bd1c-e78592c2c880,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-81b2413a-ef94-4051-b2a7-8dcb3e22efdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-c5e5b4bf-7481-4544-b938-6471a7d89dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-1f688904-bc8b-4042-b6cd-8d7b04aec6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-97d76eb3-7679-45a8-bf2e-fae7303bce58,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-8b796166-cc64-4571-b81a-dadcad39c823,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-5a41f381-13dd-4211-8607-db1bcf6815fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814410250-172.17.0.13-1597518926594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-3fee4c83-91e6-4226-ba18-938eefb0c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-9dabf3e9-0b4f-421a-adf7-0346ee82a856,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-89d03dd7-938b-4b0b-aab6-1c523d8d19c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-7f06e6ac-0b88-4fa3-bfb0-62d0fed8bc61,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-08e7587a-849d-4e47-9599-48c60bcb579b,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-f66c3b1e-ef4e-437c-8779-5578e2123662,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-223708a3-06ee-4822-8e6b-f62cc415a9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-4ad4cbc6-5846-4748-a3ff-579cffc8b468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-814410250-172.17.0.13-1597518926594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-3fee4c83-91e6-4226-ba18-938eefb0c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-9dabf3e9-0b4f-421a-adf7-0346ee82a856,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-89d03dd7-938b-4b0b-aab6-1c523d8d19c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-7f06e6ac-0b88-4fa3-bfb0-62d0fed8bc61,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-08e7587a-849d-4e47-9599-48c60bcb579b,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-f66c3b1e-ef4e-437c-8779-5578e2123662,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-223708a3-06ee-4822-8e6b-f62cc415a9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-4ad4cbc6-5846-4748-a3ff-579cffc8b468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026354361-172.17.0.13-1597518972319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45520,DS-002ceb37-b450-4cf7-b89c-b00a4e0a1e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-96fa3ce0-ec22-4034-b3a9-c1479191a91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-34c377fc-c26e-4b45-9bdf-1b6c86d118ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-e2f1e77b-0891-4392-aa72-67cfd056718c,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-c8db0473-722f-4166-903f-093c38b5187a,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-f8c291bc-9843-4e92-91a1-f91a96002167,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-7c3197eb-5043-482f-9b4e-62e964a1ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-9df20498-4c90-48a1-92a7-829ffa6328e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026354361-172.17.0.13-1597518972319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45520,DS-002ceb37-b450-4cf7-b89c-b00a4e0a1e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-96fa3ce0-ec22-4034-b3a9-c1479191a91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-34c377fc-c26e-4b45-9bdf-1b6c86d118ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-e2f1e77b-0891-4392-aa72-67cfd056718c,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-c8db0473-722f-4166-903f-093c38b5187a,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-f8c291bc-9843-4e92-91a1-f91a96002167,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-7c3197eb-5043-482f-9b4e-62e964a1ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-9df20498-4c90-48a1-92a7-829ffa6328e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782744013-172.17.0.13-1597519547508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-3d5ed2d6-8719-4284-a92b-fa4d3ac62ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-76dd16ba-ab3a-4d79-beb7-93c3cd9818c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-ecee7511-0a53-4b26-9cf7-9df7f18d1121,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-869058d8-6804-4677-a154-f6e2c11b20a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-b4fe09f0-218a-4aab-8164-f1dd05859621,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-b4c9a842-34c7-4279-bede-231732c78097,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-a45df320-328e-4b0c-bdd6-d75b31003d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-3bf12357-5f16-4f51-a667-af4758623a9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782744013-172.17.0.13-1597519547508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-3d5ed2d6-8719-4284-a92b-fa4d3ac62ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-76dd16ba-ab3a-4d79-beb7-93c3cd9818c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-ecee7511-0a53-4b26-9cf7-9df7f18d1121,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-869058d8-6804-4677-a154-f6e2c11b20a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-b4fe09f0-218a-4aab-8164-f1dd05859621,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-b4c9a842-34c7-4279-bede-231732c78097,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-a45df320-328e-4b0c-bdd6-d75b31003d29,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-3bf12357-5f16-4f51-a667-af4758623a9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642799229-172.17.0.13-1597519955772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-0fc3c032-93d5-494b-9baf-e52cbf72ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-a28cee15-729b-4921-b2da-20f1e32da8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-2bc77b07-478f-4a1d-b481-c4c55f663d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-7a243898-1475-4294-a4be-300fd71243f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-202a9ae0-9f9f-4874-b686-e68f1b29c573,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-57409f92-a603-4c88-bf5c-498bb9d3a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-173d6ac2-07af-4593-bb8a-a336c425e24d,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-ce6b8fd2-811e-4e53-8be3-8ce1f72a9b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642799229-172.17.0.13-1597519955772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-0fc3c032-93d5-494b-9baf-e52cbf72ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-a28cee15-729b-4921-b2da-20f1e32da8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-2bc77b07-478f-4a1d-b481-c4c55f663d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-7a243898-1475-4294-a4be-300fd71243f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-202a9ae0-9f9f-4874-b686-e68f1b29c573,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-57409f92-a603-4c88-bf5c-498bb9d3a58f,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-173d6ac2-07af-4593-bb8a-a336c425e24d,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-ce6b8fd2-811e-4e53-8be3-8ce1f72a9b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868527864-172.17.0.13-1597520350676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38519,DS-4a5d369c-8a71-4f97-a068-a4d5c001ec08,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-b6ebd0e0-57a8-47e3-946e-33f191fd405c,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-75ef582d-1864-417b-9f5b-3bb45846bfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-e65c1dbb-c33a-4845-85e0-709db7cebb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-530479f0-ebf1-4401-85c5-21febd91b445,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-e91ccd76-fa29-4f4c-818d-0ac8443e86f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-176c88a2-4dce-4e52-ad83-476bff18306f,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-f4a29176-5a78-41d6-bfb7-2183d24492ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868527864-172.17.0.13-1597520350676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38519,DS-4a5d369c-8a71-4f97-a068-a4d5c001ec08,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-b6ebd0e0-57a8-47e3-946e-33f191fd405c,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-75ef582d-1864-417b-9f5b-3bb45846bfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-e65c1dbb-c33a-4845-85e0-709db7cebb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-530479f0-ebf1-4401-85c5-21febd91b445,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-e91ccd76-fa29-4f4c-818d-0ac8443e86f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-176c88a2-4dce-4e52-ad83-476bff18306f,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-f4a29176-5a78-41d6-bfb7-2183d24492ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608529180-172.17.0.13-1597520399561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-219d72ff-91d6-4756-a1a4-20437482cbde,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-9aa90396-cdfa-43f4-aa9f-53a53a8ebb08,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-7c1cc322-2708-4c78-bc76-17c3ba5a89df,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-946868b9-4a6e-48e5-804d-155311478b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-4dda5a1e-1321-4c52-a08a-89a34349b98d,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-75bdda97-768b-4687-a383-86c2c649af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-cfafb27d-3e88-43e1-987f-6fd7fe2c6dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-53147767-6700-4d9e-994a-d2d7b979425e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608529180-172.17.0.13-1597520399561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38120,DS-219d72ff-91d6-4756-a1a4-20437482cbde,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-9aa90396-cdfa-43f4-aa9f-53a53a8ebb08,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-7c1cc322-2708-4c78-bc76-17c3ba5a89df,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-946868b9-4a6e-48e5-804d-155311478b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-4dda5a1e-1321-4c52-a08a-89a34349b98d,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-75bdda97-768b-4687-a383-86c2c649af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-cfafb27d-3e88-43e1-987f-6fd7fe2c6dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-53147767-6700-4d9e-994a-d2d7b979425e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411437925-172.17.0.13-1597520806903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-e108cdf2-6db8-400b-b164-dd8494fe3e83,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-003ca153-30c4-42e2-9579-7e6ccc0e88c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-4c57c52a-fed6-4734-a847-5321be1c46a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-fdd5acfd-8ced-44f1-be05-820af33607e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-a54d7dfb-a193-44a7-b592-5edac2ae755c,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-bba4218f-e3e6-49c2-a2f1-deea0bd4d4be,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-e8927d4b-52f1-45e9-b202-6c3cff372131,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-8e370d13-e9a0-49b4-8580-b395bf349241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411437925-172.17.0.13-1597520806903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45352,DS-e108cdf2-6db8-400b-b164-dd8494fe3e83,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-003ca153-30c4-42e2-9579-7e6ccc0e88c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-4c57c52a-fed6-4734-a847-5321be1c46a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-fdd5acfd-8ced-44f1-be05-820af33607e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-a54d7dfb-a193-44a7-b592-5edac2ae755c,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-bba4218f-e3e6-49c2-a2f1-deea0bd4d4be,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-e8927d4b-52f1-45e9-b202-6c3cff372131,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-8e370d13-e9a0-49b4-8580-b395bf349241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321786979-172.17.0.13-1597521041572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42261,DS-7e71d10c-9484-4932-b49a-9101752778f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-45578948-087e-4a9d-911a-f5f6873d21e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-a5b048c8-d22d-4798-81ae-9b5370eacbef,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-c2e8be1f-8a6d-4113-a20d-745bbdd9d80c,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-eed59a91-fce0-45e9-95e2-c44adddbe773,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-ef5f01ae-b9ba-48ac-8d34-befd023f271b,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-56d18942-82b5-47c4-a0eb-196c7ccc935a,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-fb996c83-6657-4ca0-b324-e41a454fe941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321786979-172.17.0.13-1597521041572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42261,DS-7e71d10c-9484-4932-b49a-9101752778f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-45578948-087e-4a9d-911a-f5f6873d21e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-a5b048c8-d22d-4798-81ae-9b5370eacbef,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-c2e8be1f-8a6d-4113-a20d-745bbdd9d80c,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-eed59a91-fce0-45e9-95e2-c44adddbe773,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-ef5f01ae-b9ba-48ac-8d34-befd023f271b,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-56d18942-82b5-47c4-a0eb-196c7ccc935a,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-fb996c83-6657-4ca0-b324-e41a454fe941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077878975-172.17.0.13-1597521182908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-204f66c9-7cbe-419e-a9b1-f1aee473be78,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-fe55a55f-2baa-4e8e-9030-17f23bd7bf48,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-3b11fe1e-9e98-4e59-aad0-a753462ac8da,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-ceb3cfc8-0f53-4085-9c39-ce415ab99014,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-5fe1e146-826c-4d8a-a8a5-6010b3d5559d,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-01a217f0-dbd2-4361-b1b2-f7536cfd6b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-4ce38173-4017-4afe-8746-e8817764af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-5ff20127-8d10-4e20-8a2b-9968c8d50eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077878975-172.17.0.13-1597521182908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-204f66c9-7cbe-419e-a9b1-f1aee473be78,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-fe55a55f-2baa-4e8e-9030-17f23bd7bf48,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-3b11fe1e-9e98-4e59-aad0-a753462ac8da,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-ceb3cfc8-0f53-4085-9c39-ce415ab99014,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-5fe1e146-826c-4d8a-a8a5-6010b3d5559d,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-01a217f0-dbd2-4361-b1b2-f7536cfd6b18,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-4ce38173-4017-4afe-8746-e8817764af6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-5ff20127-8d10-4e20-8a2b-9968c8d50eee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793496246-172.17.0.13-1597521280124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38846,DS-b768b0c2-8027-45f1-aef4-9f2d5fc5d521,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-128a7bc3-1d99-4244-8d2a-e0e08e969dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-c78a0641-3c02-40db-afb6-e802d2009617,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-2fe75c33-7f7d-4254-ad1f-6741967c1366,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-b4b66b6e-b5b9-4e0c-8509-97410e52231b,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-ef7885b8-948c-475a-a0a1-e535659520ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-b08c3be8-243c-4ac0-9f22-3b4f7e5d25bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-83155ad3-e896-42ea-800b-cfa06116ad86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793496246-172.17.0.13-1597521280124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38846,DS-b768b0c2-8027-45f1-aef4-9f2d5fc5d521,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-128a7bc3-1d99-4244-8d2a-e0e08e969dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-c78a0641-3c02-40db-afb6-e802d2009617,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-2fe75c33-7f7d-4254-ad1f-6741967c1366,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-b4b66b6e-b5b9-4e0c-8509-97410e52231b,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-ef7885b8-948c-475a-a0a1-e535659520ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-b08c3be8-243c-4ac0-9f22-3b4f7e5d25bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-83155ad3-e896-42ea-800b-cfa06116ad86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845275929-172.17.0.13-1597521454034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-687fc29e-b80c-4bda-a0ea-ded3e14dc550,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-c03a5267-167e-4508-8e3d-60d599b6a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-188c5055-cab9-4090-9196-713de1975d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-a4983973-97b3-43a5-a2e9-dfce59f4bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-c9b0063e-4837-4cf3-9945-53501aede614,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-020464ca-07b1-4678-bf22-6674a26c5785,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-2a09df18-163e-4c05-95ba-ba78c9af2ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-6367e6ec-1f38-41f4-974c-fe5986f47800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845275929-172.17.0.13-1597521454034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-687fc29e-b80c-4bda-a0ea-ded3e14dc550,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-c03a5267-167e-4508-8e3d-60d599b6a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-188c5055-cab9-4090-9196-713de1975d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-a4983973-97b3-43a5-a2e9-dfce59f4bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-c9b0063e-4837-4cf3-9945-53501aede614,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-020464ca-07b1-4678-bf22-6674a26c5785,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-2a09df18-163e-4c05-95ba-ba78c9af2ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-6367e6ec-1f38-41f4-974c-fe5986f47800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110835874-172.17.0.13-1597522088893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42771,DS-0c7a3c3a-5aa5-4b72-bd3c-332b457382f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-c4a07a02-218d-4315-a5cf-60ec2c54a1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-38418cd0-1b04-4c95-8d6e-23f1d6f75e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-4556c045-db3b-437c-843a-2afc040bcc80,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-9d7096e0-45f1-4c4f-aa45-09f15e9608e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-5fd2ba29-b26b-40f4-8819-57bd7a1d52d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-d247afab-69c7-466d-8e6a-e539e8a6973c,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-b8ac3583-efd5-47c1-b1cd-f16839c477dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110835874-172.17.0.13-1597522088893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42771,DS-0c7a3c3a-5aa5-4b72-bd3c-332b457382f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-c4a07a02-218d-4315-a5cf-60ec2c54a1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-38418cd0-1b04-4c95-8d6e-23f1d6f75e21,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-4556c045-db3b-437c-843a-2afc040bcc80,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-9d7096e0-45f1-4c4f-aa45-09f15e9608e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-5fd2ba29-b26b-40f4-8819-57bd7a1d52d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-d247afab-69c7-466d-8e6a-e539e8a6973c,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-b8ac3583-efd5-47c1-b1cd-f16839c477dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570979454-172.17.0.13-1597522729885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41832,DS-ea61f1fd-0478-42df-a36d-2a9faceb3935,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-c71784f5-755a-4ae1-af04-7de74126135e,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-caa4ee58-6cb9-46f3-b71b-8253b21d3cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-bbbb41e3-1f2e-4be3-a715-51ec46224965,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-3e9b995c-ed9b-4059-bf95-2e8914aa4051,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-f5a55901-317a-43cb-bb60-2985f12a17e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-3041e3bf-bb82-4141-bb32-2816db1810b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-55ab560d-049e-4dd4-87c7-76f9dbd2d423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570979454-172.17.0.13-1597522729885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41832,DS-ea61f1fd-0478-42df-a36d-2a9faceb3935,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-c71784f5-755a-4ae1-af04-7de74126135e,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-caa4ee58-6cb9-46f3-b71b-8253b21d3cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-bbbb41e3-1f2e-4be3-a715-51ec46224965,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-3e9b995c-ed9b-4059-bf95-2e8914aa4051,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-f5a55901-317a-43cb-bb60-2985f12a17e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-3041e3bf-bb82-4141-bb32-2816db1810b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-55ab560d-049e-4dd4-87c7-76f9dbd2d423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218002262-172.17.0.13-1597523524992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-84ebb235-3562-4f7d-8996-9d84639ae951,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-f76f6efd-7ab8-4229-bf95-a16e96da69c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-b38b9536-a35f-4fce-9e06-0c8d8e292469,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-5e19cebb-3944-4473-99b6-2f07ede74dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-eaf5ee95-aa7f-4627-a82b-cbb2088207fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-e3e04bd2-8f20-452a-bd27-e2a45bb76a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-4fad7aa8-d6e1-417f-ab53-bb39f6f288a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-0273da61-de70-41d2-9978-8da855f3aa50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218002262-172.17.0.13-1597523524992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-84ebb235-3562-4f7d-8996-9d84639ae951,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-f76f6efd-7ab8-4229-bf95-a16e96da69c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-b38b9536-a35f-4fce-9e06-0c8d8e292469,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-5e19cebb-3944-4473-99b6-2f07ede74dda,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-eaf5ee95-aa7f-4627-a82b-cbb2088207fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-e3e04bd2-8f20-452a-bd27-e2a45bb76a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-4fad7aa8-d6e1-417f-ab53-bb39f6f288a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-0273da61-de70-41d2-9978-8da855f3aa50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113752813-172.17.0.13-1597523660776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39786,DS-9abdf3a6-88a8-49bf-842f-ebe04f3ffbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-b4fccfbe-fc4c-498d-b8d5-16ebe56337b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-de07c0b1-6802-45b8-8296-8cc9a44c04b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-ff7c8751-169b-4321-a91e-c7cf8a2b3fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-717dca42-b74f-483e-9071-8ed0cd415f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-46978bd2-1bf3-4701-96a3-098a60374f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-1f1f4187-a717-4f30-8dfe-a3dc020e00fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-3261241e-97e2-47b7-ac6e-aaa11c24636f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113752813-172.17.0.13-1597523660776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39786,DS-9abdf3a6-88a8-49bf-842f-ebe04f3ffbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-b4fccfbe-fc4c-498d-b8d5-16ebe56337b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-de07c0b1-6802-45b8-8296-8cc9a44c04b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-ff7c8751-169b-4321-a91e-c7cf8a2b3fea,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-717dca42-b74f-483e-9071-8ed0cd415f86,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-46978bd2-1bf3-4701-96a3-098a60374f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-1f1f4187-a717-4f30-8dfe-a3dc020e00fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-3261241e-97e2-47b7-ac6e-aaa11c24636f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508796341-172.17.0.13-1597524612777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41126,DS-f86428a7-bb20-4a85-b609-b03b404a5aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-1d86c96c-c70a-439b-b27f-8774a4fe05eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-67a7dd6e-c9ec-4325-95b2-51d255c848fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-5b654ece-c2fe-4502-bd37-686e5c01a3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-edea4d14-24fa-49d3-a5b8-4c12e9a9274e,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-ddce976a-4a07-4a63-9887-bc0bb0931ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-8401c390-e620-4e7e-8f51-7e71c66398fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-844ae8bc-9d16-4c5d-b54c-0f0b6764855a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508796341-172.17.0.13-1597524612777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41126,DS-f86428a7-bb20-4a85-b609-b03b404a5aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-1d86c96c-c70a-439b-b27f-8774a4fe05eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-67a7dd6e-c9ec-4325-95b2-51d255c848fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-5b654ece-c2fe-4502-bd37-686e5c01a3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-edea4d14-24fa-49d3-a5b8-4c12e9a9274e,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-ddce976a-4a07-4a63-9887-bc0bb0931ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-8401c390-e620-4e7e-8f51-7e71c66398fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-844ae8bc-9d16-4c5d-b54c-0f0b6764855a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428952229-172.17.0.13-1597524948353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41180,DS-3b28bcce-0b7d-4074-bf9b-8d4e498b3c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-61a90206-ced8-45b5-b651-ca4a688a6969,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-2e67c194-9a87-474d-a9e2-79adfa907487,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-eaad82b7-a88b-480d-a6c1-cf7338069578,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-f5441bbb-96f5-48d4-bcb6-711ae629f1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-55415705-eb95-4a8f-8487-5330148a8bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-3e3b6ed0-3715-4a20-bd09-f8e53d1f3ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-5c6b6b5b-2037-430e-9663-53d3bd4f6fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428952229-172.17.0.13-1597524948353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41180,DS-3b28bcce-0b7d-4074-bf9b-8d4e498b3c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-61a90206-ced8-45b5-b651-ca4a688a6969,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-2e67c194-9a87-474d-a9e2-79adfa907487,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-eaad82b7-a88b-480d-a6c1-cf7338069578,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-f5441bbb-96f5-48d4-bcb6-711ae629f1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-55415705-eb95-4a8f-8487-5330148a8bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-3e3b6ed0-3715-4a20-bd09-f8e53d1f3ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-5c6b6b5b-2037-430e-9663-53d3bd4f6fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700103113-172.17.0.13-1597525129340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-10304122-99bd-4858-97bf-d25fbfb47755,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-0eabbcf6-5f04-48a6-b5eb-4454aa123799,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-5a523f4d-a1b0-433e-af39-11021dcbd036,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-200f7d08-ade9-4238-a157-9f7e1575bebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-7115dab3-7fe1-4622-b759-c5e348946731,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-c0be33c0-8efc-4152-93eb-8b6a6537030e,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-5ebf8c70-7fcf-4cc6-a382-2536b1353d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-c485ef36-e897-4dc6-914b-ec14137ab79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700103113-172.17.0.13-1597525129340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36752,DS-10304122-99bd-4858-97bf-d25fbfb47755,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-0eabbcf6-5f04-48a6-b5eb-4454aa123799,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-5a523f4d-a1b0-433e-af39-11021dcbd036,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-200f7d08-ade9-4238-a157-9f7e1575bebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-7115dab3-7fe1-4622-b759-c5e348946731,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-c0be33c0-8efc-4152-93eb-8b6a6537030e,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-5ebf8c70-7fcf-4cc6-a382-2536b1353d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-c485ef36-e897-4dc6-914b-ec14137ab79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6922
