reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998167404-172.17.0.3-1597297863649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37732,DS-55e66ebf-e904-4ca7-81e5-c12c7d659045,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-55819868-37d5-401a-a87c-407c76f741f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-a9e017af-9040-429b-a986-e0af8a4b5962,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-5c5c1796-bd50-477a-9cf5-5e11f32701e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-0d4cdbc6-b031-4c50-aedc-253d464bb91e,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-8222845f-c515-4d17-bf31-53ed4a2c5b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-0aa72b44-01f3-436b-8016-75fefa5600f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-e536e83b-97e5-4449-9cab-623afab916c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998167404-172.17.0.3-1597297863649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37732,DS-55e66ebf-e904-4ca7-81e5-c12c7d659045,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-55819868-37d5-401a-a87c-407c76f741f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-a9e017af-9040-429b-a986-e0af8a4b5962,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-5c5c1796-bd50-477a-9cf5-5e11f32701e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-0d4cdbc6-b031-4c50-aedc-253d464bb91e,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-8222845f-c515-4d17-bf31-53ed4a2c5b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-0aa72b44-01f3-436b-8016-75fefa5600f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-e536e83b-97e5-4449-9cab-623afab916c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487398607-172.17.0.3-1597298086019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-2b15f384-e2f0-438f-8aed-cf64914a464a,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-066f2d3e-121f-4c79-863d-ec61eb3f0208,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-29c7452a-5898-490f-a17c-b70ff3bffe38,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-71b501ec-9ffd-43b9-bba9-2c8023b8271d,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-cff1fdc0-ebc4-4e9d-9226-f87f4b64cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-4c6b59f5-bc2f-4bb6-b7b5-2f155eb1d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-65bc7ecb-f0dd-4800-ae45-838d047f5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-40dd412f-2524-4492-8192-a5158786695e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487398607-172.17.0.3-1597298086019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41335,DS-2b15f384-e2f0-438f-8aed-cf64914a464a,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-066f2d3e-121f-4c79-863d-ec61eb3f0208,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-29c7452a-5898-490f-a17c-b70ff3bffe38,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-71b501ec-9ffd-43b9-bba9-2c8023b8271d,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-cff1fdc0-ebc4-4e9d-9226-f87f4b64cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-4c6b59f5-bc2f-4bb6-b7b5-2f155eb1d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-65bc7ecb-f0dd-4800-ae45-838d047f5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-40dd412f-2524-4492-8192-a5158786695e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029355240-172.17.0.3-1597298465218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-91941531-90e2-4bd1-be8f-a6e66fcb364c,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-c113a3ae-2282-49dc-a5c2-768d3bb7958e,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-719d5126-369b-4ddf-aa82-4913be7dc1da,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-abd8b734-2b1f-4d11-a75b-d2b7d7275dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-22dd4058-40c8-41b1-80bd-58655545b3df,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-a420fa53-dce5-4e36-9ce0-c46c11e25f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-c8360066-7f54-44a4-8787-70a07f176e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-2d6aab5b-1beb-46de-b680-be2a2f26038d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029355240-172.17.0.3-1597298465218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-91941531-90e2-4bd1-be8f-a6e66fcb364c,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-c113a3ae-2282-49dc-a5c2-768d3bb7958e,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-719d5126-369b-4ddf-aa82-4913be7dc1da,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-abd8b734-2b1f-4d11-a75b-d2b7d7275dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-22dd4058-40c8-41b1-80bd-58655545b3df,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-a420fa53-dce5-4e36-9ce0-c46c11e25f08,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-c8360066-7f54-44a4-8787-70a07f176e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-2d6aab5b-1beb-46de-b680-be2a2f26038d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668163268-172.17.0.3-1597299018154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45094,DS-3f9a4ad1-1252-4c89-aef5-7fd078578b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-1cd38630-ac10-4aae-86a3-2a4066df41b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-66e08e56-c7ce-4e62-8503-d658fc83467d,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-247bedf9-e162-480e-a00d-a007df8d48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-34300404-e817-473d-94be-b580087bd810,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-e1f52139-4c81-496d-946e-3e565f60b622,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-8803ae17-a226-433c-950b-717f610f2e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-1267a532-bcd2-4562-bbcc-2c370c9a68ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668163268-172.17.0.3-1597299018154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45094,DS-3f9a4ad1-1252-4c89-aef5-7fd078578b67,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-1cd38630-ac10-4aae-86a3-2a4066df41b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-66e08e56-c7ce-4e62-8503-d658fc83467d,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-247bedf9-e162-480e-a00d-a007df8d48a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-34300404-e817-473d-94be-b580087bd810,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-e1f52139-4c81-496d-946e-3e565f60b622,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-8803ae17-a226-433c-950b-717f610f2e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-1267a532-bcd2-4562-bbcc-2c370c9a68ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011090764-172.17.0.3-1597299427058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46709,DS-8e601719-f0e2-4060-81db-531bc6ddf70b,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-b870e5ae-b1eb-48c3-bd9c-92b2f7609c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-0c8b6f89-c411-4e03-9444-258c06b13c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-c319d24a-f428-4868-8348-80d3023c34b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-7a420e92-4629-4fdc-a97f-77143ac59ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-227ede91-7b61-4681-80c1-31abdc927deb,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-145def8d-2baf-4795-b1dd-7159687762fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-4abfcccc-7482-462f-9e1f-b9b8ddd6297f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011090764-172.17.0.3-1597299427058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46709,DS-8e601719-f0e2-4060-81db-531bc6ddf70b,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-b870e5ae-b1eb-48c3-bd9c-92b2f7609c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-0c8b6f89-c411-4e03-9444-258c06b13c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-c319d24a-f428-4868-8348-80d3023c34b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-7a420e92-4629-4fdc-a97f-77143ac59ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-227ede91-7b61-4681-80c1-31abdc927deb,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-145def8d-2baf-4795-b1dd-7159687762fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-4abfcccc-7482-462f-9e1f-b9b8ddd6297f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792240943-172.17.0.3-1597299691111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-d70187f9-c1a1-47f6-928c-51c64a768299,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-71b3bdb8-ee45-4509-a589-7f03e6b3af13,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-2fd69df5-04b8-474d-8e82-c93f6d5202a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-2cd2250f-be7d-4885-ae5c-8079fcef1344,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-d8512eb0-ce9c-4e25-84b6-0c8c78048ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-b049ed42-3e69-4c71-9635-08207c1774ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-74b9c161-cf56-4fc7-94d4-9ba78c6706d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-0a541f1b-bdcb-4bc2-95af-7881c72b70dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792240943-172.17.0.3-1597299691111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-d70187f9-c1a1-47f6-928c-51c64a768299,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-71b3bdb8-ee45-4509-a589-7f03e6b3af13,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-2fd69df5-04b8-474d-8e82-c93f6d5202a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-2cd2250f-be7d-4885-ae5c-8079fcef1344,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-d8512eb0-ce9c-4e25-84b6-0c8c78048ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-b049ed42-3e69-4c71-9635-08207c1774ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-74b9c161-cf56-4fc7-94d4-9ba78c6706d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-0a541f1b-bdcb-4bc2-95af-7881c72b70dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672902857-172.17.0.3-1597300233652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45703,DS-291bb374-32c4-4ec6-b613-88c8788b3ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-3dc61bf5-2e86-4ae2-b1f0-c5a8a2a7c397,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-eb2d19c5-120b-4cdb-826b-57e4c42b5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-7a770eaa-6a40-4edb-9559-f4550c05184c,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-57ca748b-bec1-43bf-b253-e89df86f2dce,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-22245e9b-616c-41c1-be06-309814fa902a,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-cf2f5534-78b5-4d59-a853-0313a12fff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-a504331b-c3e0-48ed-8d47-9e62bca20297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672902857-172.17.0.3-1597300233652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45703,DS-291bb374-32c4-4ec6-b613-88c8788b3ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-3dc61bf5-2e86-4ae2-b1f0-c5a8a2a7c397,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-eb2d19c5-120b-4cdb-826b-57e4c42b5f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-7a770eaa-6a40-4edb-9559-f4550c05184c,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-57ca748b-bec1-43bf-b253-e89df86f2dce,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-22245e9b-616c-41c1-be06-309814fa902a,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-cf2f5534-78b5-4d59-a853-0313a12fff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-a504331b-c3e0-48ed-8d47-9e62bca20297,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454870317-172.17.0.3-1597300386456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35835,DS-48016f77-4631-465c-94ad-95d07e50ad0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-7a405ee7-c0eb-464d-93b9-467023ff3cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-201ae3fa-0a22-4597-8cf4-32642fcb50eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-4ca09578-62b1-4257-b100-0f1d7f628eea,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-e495c4f0-053a-4cb1-b58f-cdebb1e8a6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-56908a6f-69d9-4d8a-b184-02e1a37669ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-e3ec7154-12b9-46cb-bc1b-1f7d8dba1392,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-7784ee0b-2abb-437b-ad86-1bc5929321ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454870317-172.17.0.3-1597300386456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35835,DS-48016f77-4631-465c-94ad-95d07e50ad0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-7a405ee7-c0eb-464d-93b9-467023ff3cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-201ae3fa-0a22-4597-8cf4-32642fcb50eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-4ca09578-62b1-4257-b100-0f1d7f628eea,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-e495c4f0-053a-4cb1-b58f-cdebb1e8a6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-56908a6f-69d9-4d8a-b184-02e1a37669ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-e3ec7154-12b9-46cb-bc1b-1f7d8dba1392,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-7784ee0b-2abb-437b-ad86-1bc5929321ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923264327-172.17.0.3-1597301534084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-f6304905-2e41-4a75-83fc-9f59d4efdd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-d94d4683-ffa4-42a0-b37e-b7b7889b8010,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-e0f9d5df-e675-4ee3-9820-85cbdf37498c,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-b8e7b324-4cec-431d-9ff2-9f9c2a5b8c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-9a4a71fc-83bb-41bd-926c-60b78564a7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-a4e8ad41-b8bc-4a4c-a9ee-a0a1bc3beb07,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-0bd4fc2f-33b9-4599-8541-857ecbd51222,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-a4e9ac64-8ef3-4c99-9f64-9a51e7cd631b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923264327-172.17.0.3-1597301534084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45132,DS-f6304905-2e41-4a75-83fc-9f59d4efdd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-d94d4683-ffa4-42a0-b37e-b7b7889b8010,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-e0f9d5df-e675-4ee3-9820-85cbdf37498c,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-b8e7b324-4cec-431d-9ff2-9f9c2a5b8c67,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-9a4a71fc-83bb-41bd-926c-60b78564a7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-a4e8ad41-b8bc-4a4c-a9ee-a0a1bc3beb07,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-0bd4fc2f-33b9-4599-8541-857ecbd51222,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-a4e9ac64-8ef3-4c99-9f64-9a51e7cd631b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190759006-172.17.0.3-1597301714478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-ee8e9cf4-65fd-442f-a800-596e02071534,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-b17bce66-a95f-4a60-87d6-88f33815ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-f19c7865-558b-40f8-b83e-88c144b27314,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-3817eeff-cf61-41a2-ae30-34175948d115,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-2510051d-611b-4ce7-a81a-d2fc52be49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-900fb06e-b118-4a79-b3b1-d33128a668f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-a6958dfc-e6a0-4be4-91ba-5279e95f3acf,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-c48910a6-f4e4-4b5a-8286-3b45d3d37ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190759006-172.17.0.3-1597301714478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39411,DS-ee8e9cf4-65fd-442f-a800-596e02071534,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-b17bce66-a95f-4a60-87d6-88f33815ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-f19c7865-558b-40f8-b83e-88c144b27314,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-3817eeff-cf61-41a2-ae30-34175948d115,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-2510051d-611b-4ce7-a81a-d2fc52be49f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-900fb06e-b118-4a79-b3b1-d33128a668f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-a6958dfc-e6a0-4be4-91ba-5279e95f3acf,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-c48910a6-f4e4-4b5a-8286-3b45d3d37ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337983018-172.17.0.3-1597302216753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44429,DS-7cebf87b-59c8-4e68-8956-b77b5d22fc57,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-1ef2f9f9-47bc-4358-9977-2ebaadd7e878,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-196ed0d1-91ba-4322-ae01-b5554ac4baff,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-f6a17c0e-9620-4da5-b4bc-19eb6b3bcbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-4c768150-8934-45fe-af8c-87ac2515f455,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-baabdaa2-a931-4589-b0f1-c4840ef064c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-de291532-9f5f-4fdd-914f-42a3acf592cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-0375f110-c432-4797-8edb-7ed222a8bbbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337983018-172.17.0.3-1597302216753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44429,DS-7cebf87b-59c8-4e68-8956-b77b5d22fc57,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-1ef2f9f9-47bc-4358-9977-2ebaadd7e878,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-196ed0d1-91ba-4322-ae01-b5554ac4baff,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-f6a17c0e-9620-4da5-b4bc-19eb6b3bcbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-4c768150-8934-45fe-af8c-87ac2515f455,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-baabdaa2-a931-4589-b0f1-c4840ef064c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-de291532-9f5f-4fdd-914f-42a3acf592cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-0375f110-c432-4797-8edb-7ed222a8bbbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5574
