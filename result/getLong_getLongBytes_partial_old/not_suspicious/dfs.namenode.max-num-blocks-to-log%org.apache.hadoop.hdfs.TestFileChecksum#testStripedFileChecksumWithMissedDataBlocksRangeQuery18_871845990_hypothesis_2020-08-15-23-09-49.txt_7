reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281688175-172.17.0.14-1597534538609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46776,DS-edaa32f2-6b2d-4c80-b786-dfdca5bcf9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-0cb5aa6a-e500-41c7-b78f-58d9f2ef5567,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-2f270e18-27b6-448d-be6c-cc3a9f2e5ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-4293578c-f443-452c-b71e-0ec4bee9d110,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-ab6ce40a-7cce-4fee-9479-ec9a6bf5645c,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-a9d5f93f-e587-4c5c-988f-feae1994ffa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-0f6b0410-985e-4eba-b1b8-a87ff52fbaff,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-73dabf0c-05fd-4ced-afb2-d38cf4b27d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281688175-172.17.0.14-1597534538609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46776,DS-edaa32f2-6b2d-4c80-b786-dfdca5bcf9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-0cb5aa6a-e500-41c7-b78f-58d9f2ef5567,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-2f270e18-27b6-448d-be6c-cc3a9f2e5ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-4293578c-f443-452c-b71e-0ec4bee9d110,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-ab6ce40a-7cce-4fee-9479-ec9a6bf5645c,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-a9d5f93f-e587-4c5c-988f-feae1994ffa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-0f6b0410-985e-4eba-b1b8-a87ff52fbaff,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-73dabf0c-05fd-4ced-afb2-d38cf4b27d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923359282-172.17.0.14-1597535055961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45277,DS-722c1fe8-435f-4239-889e-12a65abd7c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-908049ae-15ef-4119-9f20-8ff8a27a41bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-e2d861a0-bfbb-4445-9866-118b2cf39651,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-b9048cb4-26b8-4a39-812d-a4421ae955b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-962137b4-ddeb-49a3-a9f3-ae68216650c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-bb51863e-3ec3-40c7-ba73-7cb27c388337,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-47f05ce2-cd5c-4237-a090-d465276819c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-acb41d1e-b18a-4370-b076-e8a7083b1a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923359282-172.17.0.14-1597535055961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45277,DS-722c1fe8-435f-4239-889e-12a65abd7c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-908049ae-15ef-4119-9f20-8ff8a27a41bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-e2d861a0-bfbb-4445-9866-118b2cf39651,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-b9048cb4-26b8-4a39-812d-a4421ae955b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-962137b4-ddeb-49a3-a9f3-ae68216650c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-bb51863e-3ec3-40c7-ba73-7cb27c388337,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-47f05ce2-cd5c-4237-a090-d465276819c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-acb41d1e-b18a-4370-b076-e8a7083b1a12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903400519-172.17.0.14-1597535099538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-78777786-65bf-45cd-a8d3-9ef46cc883bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-ac8fb06f-d638-4b6c-8498-4abdf9dae780,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-79c8aab1-571d-4fd3-ac49-fd1400bf1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-7cb20483-6efe-405c-b86b-7532a2c7b469,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-fefebca5-e979-4b51-990f-73ceef4db687,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-b077cd97-0826-47f1-b7e2-16e78456adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-d6e3e670-b37c-4be1-8b22-48109baf9185,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-09407b2e-5b7d-4761-b1c5-dbdd684962a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903400519-172.17.0.14-1597535099538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-78777786-65bf-45cd-a8d3-9ef46cc883bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-ac8fb06f-d638-4b6c-8498-4abdf9dae780,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-79c8aab1-571d-4fd3-ac49-fd1400bf1dba,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-7cb20483-6efe-405c-b86b-7532a2c7b469,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-fefebca5-e979-4b51-990f-73ceef4db687,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-b077cd97-0826-47f1-b7e2-16e78456adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-d6e3e670-b37c-4be1-8b22-48109baf9185,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-09407b2e-5b7d-4761-b1c5-dbdd684962a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776899194-172.17.0.14-1597535330685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42846,DS-5f7abc91-cdf4-4bf9-871e-a3eed0d0054c,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-414fa3c6-3c1e-4ea8-9b52-9a17784bfcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-7116f0ec-cb4b-47d2-8f0f-68b501fe58f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-7c55426d-4a7c-475c-a48a-307a1ae1a949,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-ef7531a8-a2e4-4c45-a750-3c5368b0d4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-11fb2e8b-ffb8-4c90-a79c-4a2227618f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-79ba327c-ef83-46e4-b297-c44440dc716c,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-ce0cbc14-93a1-46f2-bfb9-76a709fef1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776899194-172.17.0.14-1597535330685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42846,DS-5f7abc91-cdf4-4bf9-871e-a3eed0d0054c,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-414fa3c6-3c1e-4ea8-9b52-9a17784bfcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-7116f0ec-cb4b-47d2-8f0f-68b501fe58f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-7c55426d-4a7c-475c-a48a-307a1ae1a949,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-ef7531a8-a2e4-4c45-a750-3c5368b0d4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-11fb2e8b-ffb8-4c90-a79c-4a2227618f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-79ba327c-ef83-46e4-b297-c44440dc716c,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-ce0cbc14-93a1-46f2-bfb9-76a709fef1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428103420-172.17.0.14-1597535400887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44654,DS-947a79fb-5c0c-43a0-8631-dba40920ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-3bf0bf8e-b954-4663-aeb6-e9d5023dbc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-0c36f909-1a9c-451e-8660-cc87bdd9540a,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-7d75d244-c1ff-438c-9a58-1c73c07b7785,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-21010283-eb38-43e1-b2a4-91cd563400f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-909a88bc-df76-416c-aaf7-460884a8cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-1cfa6cfd-f678-4e86-bd3d-7059d8e88548,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-5b2c1b15-8f59-4ac3-bd56-cda10edfaed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428103420-172.17.0.14-1597535400887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44654,DS-947a79fb-5c0c-43a0-8631-dba40920ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-3bf0bf8e-b954-4663-aeb6-e9d5023dbc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-0c36f909-1a9c-451e-8660-cc87bdd9540a,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-7d75d244-c1ff-438c-9a58-1c73c07b7785,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-21010283-eb38-43e1-b2a4-91cd563400f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-909a88bc-df76-416c-aaf7-460884a8cb54,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-1cfa6cfd-f678-4e86-bd3d-7059d8e88548,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-5b2c1b15-8f59-4ac3-bd56-cda10edfaed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063170590-172.17.0.14-1597535669359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44819,DS-63d3b349-cbec-4ce3-9676-0f0826a1e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-4e89a4d7-d7a2-4a70-956d-97da5939d333,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-501c55b9-ea25-4049-89bb-f01b00415bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-0c3c94f3-72d5-483d-9aa1-b460a703f748,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-9a9b14f6-6234-43b7-8d6d-35012b343f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-8888cd86-4d60-4f90-8b70-593b7f6627df,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-d521b3c4-cccf-4759-97ee-9766542f81b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-83fafa95-13e2-4f9d-8645-519830a1e2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063170590-172.17.0.14-1597535669359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44819,DS-63d3b349-cbec-4ce3-9676-0f0826a1e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-4e89a4d7-d7a2-4a70-956d-97da5939d333,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-501c55b9-ea25-4049-89bb-f01b00415bff,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-0c3c94f3-72d5-483d-9aa1-b460a703f748,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-9a9b14f6-6234-43b7-8d6d-35012b343f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-8888cd86-4d60-4f90-8b70-593b7f6627df,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-d521b3c4-cccf-4759-97ee-9766542f81b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-83fafa95-13e2-4f9d-8645-519830a1e2fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009525317-172.17.0.14-1597535937907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-d12bb154-28db-46c7-8292-ee34b140e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-62507bf2-905a-4d48-9356-a7ff7f17b1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-13e835f9-cadc-4f60-81f6-4055eaaa6900,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-cd279c2b-cf37-4418-bbe3-6dbcce64dea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-f1a1a8ca-028a-4b7b-8b3a-00c2003de0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-4dbd4f27-4d15-438b-9fb1-ffacc1d9b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-8cdf9f95-ef45-4712-b55f-712698f2daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-57db642f-9d8c-4f10-a709-894d0b9f416c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009525317-172.17.0.14-1597535937907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-d12bb154-28db-46c7-8292-ee34b140e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-62507bf2-905a-4d48-9356-a7ff7f17b1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-13e835f9-cadc-4f60-81f6-4055eaaa6900,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-cd279c2b-cf37-4418-bbe3-6dbcce64dea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-f1a1a8ca-028a-4b7b-8b3a-00c2003de0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-4dbd4f27-4d15-438b-9fb1-ffacc1d9b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-8cdf9f95-ef45-4712-b55f-712698f2daf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-57db642f-9d8c-4f10-a709-894d0b9f416c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134039930-172.17.0.14-1597536066923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38048,DS-5f3f9c1b-9fcf-49aa-bf82-7c728e7fd0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-db7ea5eb-ce74-43f6-82a5-3ba098142f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-c1507ac7-5c0e-447b-834f-6630b299ee85,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-0612fc5e-7fd3-4690-91dc-5864188f349d,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-ab4d57a2-f539-4ea4-80c5-4cc16744cbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-e43517f4-ea1f-4138-8400-5914769afb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-c2b8e03f-2b39-4c56-b2d9-534638cd70c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-136d7709-78fa-40f1-85a6-ec58adc1dfba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-134039930-172.17.0.14-1597536066923:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38048,DS-5f3f9c1b-9fcf-49aa-bf82-7c728e7fd0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-db7ea5eb-ce74-43f6-82a5-3ba098142f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-c1507ac7-5c0e-447b-834f-6630b299ee85,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-0612fc5e-7fd3-4690-91dc-5864188f349d,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-ab4d57a2-f539-4ea4-80c5-4cc16744cbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-e43517f4-ea1f-4138-8400-5914769afb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-c2b8e03f-2b39-4c56-b2d9-534638cd70c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-136d7709-78fa-40f1-85a6-ec58adc1dfba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901466771-172.17.0.14-1597536694813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39624,DS-18118621-8b06-4b4f-a938-283d56b2d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-e99c2f9e-767f-4b07-8d9a-74b8c19ccfac,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-27ec0ac0-c7ba-42cd-87c7-0163136043c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-62013a0f-e57f-41cf-8c5c-ee6055693f06,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-f2c4e274-edca-47a6-94ed-707a7802ccda,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-11027ce4-06cd-4c4c-a2c7-daaadfad48d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-204b34c4-98e0-4ea1-8a16-b302cb747728,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-72224e53-3253-4a94-a34a-9377d21ab9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901466771-172.17.0.14-1597536694813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39624,DS-18118621-8b06-4b4f-a938-283d56b2d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-e99c2f9e-767f-4b07-8d9a-74b8c19ccfac,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-27ec0ac0-c7ba-42cd-87c7-0163136043c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-62013a0f-e57f-41cf-8c5c-ee6055693f06,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-f2c4e274-edca-47a6-94ed-707a7802ccda,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-11027ce4-06cd-4c4c-a2c7-daaadfad48d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-204b34c4-98e0-4ea1-8a16-b302cb747728,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-72224e53-3253-4a94-a34a-9377d21ab9c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256252732-172.17.0.14-1597537104541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39579,DS-25cf61bf-c806-4483-8930-0d95587ef850,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-6d1c89f7-21b8-455b-8b2e-a96f8b31cb94,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-13a0a33a-5354-48e5-9fce-cc862637669d,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-343d4718-8487-4a6a-a3e8-9a88a03a471c,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-1e4a2356-8ba5-461e-8113-c068203c1a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-e0544b47-c773-4e84-b552-be8d1d2b9ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-7a11aa6a-dc53-4075-9f9f-e33a5ee62052,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-4ed75e7c-3845-470f-9c27-5575deea2c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256252732-172.17.0.14-1597537104541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39579,DS-25cf61bf-c806-4483-8930-0d95587ef850,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-6d1c89f7-21b8-455b-8b2e-a96f8b31cb94,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-13a0a33a-5354-48e5-9fce-cc862637669d,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-343d4718-8487-4a6a-a3e8-9a88a03a471c,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-1e4a2356-8ba5-461e-8113-c068203c1a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-e0544b47-c773-4e84-b552-be8d1d2b9ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-7a11aa6a-dc53-4075-9f9f-e33a5ee62052,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-4ed75e7c-3845-470f-9c27-5575deea2c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864115094-172.17.0.14-1597537180562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34923,DS-6c65ca25-ec1d-426f-a255-c9d579a6846f,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-4b11ae77-ccc5-4f1d-aa3e-1820138291b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-4a4ad2b4-9ad0-494f-9e63-507b040560a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-3e92d16c-dc17-44c1-a883-c30419c5b041,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-6da0a6b5-5aad-4490-bbec-f7d32be1340b,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-a3f9d4ba-4ada-44a5-bcca-21668d8c4f19,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-f68069de-bb97-4550-a116-e745b1bbca17,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-f808a99b-90c1-4673-a7a2-0a5365ff31c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864115094-172.17.0.14-1597537180562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34923,DS-6c65ca25-ec1d-426f-a255-c9d579a6846f,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-4b11ae77-ccc5-4f1d-aa3e-1820138291b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-4a4ad2b4-9ad0-494f-9e63-507b040560a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-3e92d16c-dc17-44c1-a883-c30419c5b041,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-6da0a6b5-5aad-4490-bbec-f7d32be1340b,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-a3f9d4ba-4ada-44a5-bcca-21668d8c4f19,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-f68069de-bb97-4550-a116-e745b1bbca17,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-f808a99b-90c1-4673-a7a2-0a5365ff31c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791445445-172.17.0.14-1597537944371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-9146468b-34dd-4d6f-962d-b105b44d719c,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-66105e2c-67b4-4715-8fc5-e72a973c560b,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-7e015452-308d-46d8-a099-7a99b7da466a,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6ede3d71-e878-44f0-8766-0eeb56fa2aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-508b64d4-f6d5-498f-a8c6-31b0e5456dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-7fd688cf-1e8d-4db5-ae28-9b6bf768358d,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-4738bc0f-3162-4ff5-a0ed-a6fef253a9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-1fd9a6cd-ad7f-4b5e-8e14-8917f355f4a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791445445-172.17.0.14-1597537944371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-9146468b-34dd-4d6f-962d-b105b44d719c,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-66105e2c-67b4-4715-8fc5-e72a973c560b,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-7e015452-308d-46d8-a099-7a99b7da466a,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6ede3d71-e878-44f0-8766-0eeb56fa2aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-508b64d4-f6d5-498f-a8c6-31b0e5456dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-7fd688cf-1e8d-4db5-ae28-9b6bf768358d,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-4738bc0f-3162-4ff5-a0ed-a6fef253a9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-1fd9a6cd-ad7f-4b5e-8e14-8917f355f4a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642781168-172.17.0.14-1597538408566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36681,DS-1c37b02c-716f-47e2-ab31-c7712297ad9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-6193b4a3-9760-434c-9d08-5db98123ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-95bf22f3-ba93-4603-b1f2-308a1756cc62,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-4618916f-0fbf-4913-9498-48259a560c47,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-669ee39d-74a5-4078-b9f0-460cff3c2411,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-fa3540c4-f20b-4582-9089-09345e54e69d,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-e182e6f8-7004-40cd-8316-fa4d65f71160,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-a9825590-3cf6-4cd7-af43-493361b1196a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642781168-172.17.0.14-1597538408566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36681,DS-1c37b02c-716f-47e2-ab31-c7712297ad9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-6193b4a3-9760-434c-9d08-5db98123ee78,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-95bf22f3-ba93-4603-b1f2-308a1756cc62,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-4618916f-0fbf-4913-9498-48259a560c47,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-669ee39d-74a5-4078-b9f0-460cff3c2411,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-fa3540c4-f20b-4582-9089-09345e54e69d,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-e182e6f8-7004-40cd-8316-fa4d65f71160,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-a9825590-3cf6-4cd7-af43-493361b1196a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5813
