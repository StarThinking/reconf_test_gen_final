reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956513757-172.17.0.10-1597508082029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44061,DS-5f4399f3-f780-4d9c-9b9f-91d2519d0995,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-8b6a59f9-d4f9-420a-a3cc-84e70c534852,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-712154e6-a21c-4a9e-a356-a08d42b0b29a,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-6b5ad448-ba91-490a-bec6-bb0e31105d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-48a44a55-61da-48ea-9b2c-095e38a2a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-a1b41471-3adc-4106-8e46-0e132f5cac56,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-2bf5d6dc-3a41-4a29-8dda-e60be6ea4c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-de129d87-71ec-46a8-8598-58170cebdef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956513757-172.17.0.10-1597508082029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44061,DS-5f4399f3-f780-4d9c-9b9f-91d2519d0995,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-8b6a59f9-d4f9-420a-a3cc-84e70c534852,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-712154e6-a21c-4a9e-a356-a08d42b0b29a,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-6b5ad448-ba91-490a-bec6-bb0e31105d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-48a44a55-61da-48ea-9b2c-095e38a2a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-a1b41471-3adc-4106-8e46-0e132f5cac56,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-2bf5d6dc-3a41-4a29-8dda-e60be6ea4c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-de129d87-71ec-46a8-8598-58170cebdef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719078783-172.17.0.10-1597508185618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-1ef8713c-fe3a-47d1-a34a-ba00cadb3455,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-6bd0e157-1b12-4f84-a3a7-6569e4172e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-c78300de-519d-4507-a82c-6fa9d76f67e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-daa5d610-c839-47c7-95be-3af9c4b1e58e,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-337fa098-d085-4299-9eae-2518dda33984,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-e50e889c-0d7e-4169-b7c3-1738fb385a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-8203dcb2-1cd4-4a3e-8b03-55f7cd20586e,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-d1450479-0724-48ef-ab46-2b21864dec7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719078783-172.17.0.10-1597508185618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-1ef8713c-fe3a-47d1-a34a-ba00cadb3455,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-6bd0e157-1b12-4f84-a3a7-6569e4172e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-c78300de-519d-4507-a82c-6fa9d76f67e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-daa5d610-c839-47c7-95be-3af9c4b1e58e,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-337fa098-d085-4299-9eae-2518dda33984,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-e50e889c-0d7e-4169-b7c3-1738fb385a83,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-8203dcb2-1cd4-4a3e-8b03-55f7cd20586e,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-d1450479-0724-48ef-ab46-2b21864dec7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551284392-172.17.0.10-1597508703060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-f2330c4a-67fc-435f-817a-6e6607215a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-bbf2059b-c035-4fb5-a81c-bc07eaf49c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-11a0b2a4-b8b9-4767-a504-a62588d68aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-e73d031f-ef6b-4d60-b1d7-599915f2b584,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-5a8d57a5-0603-454c-b800-be16888681ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-f9cfd9f5-61b1-46b6-b1d4-88b135fff58e,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-9283b641-f1b9-4365-bac4-132864b0ae50,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-e9674cec-dd89-444b-9832-baeb18890c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551284392-172.17.0.10-1597508703060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-f2330c4a-67fc-435f-817a-6e6607215a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-bbf2059b-c035-4fb5-a81c-bc07eaf49c17,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-11a0b2a4-b8b9-4767-a504-a62588d68aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-e73d031f-ef6b-4d60-b1d7-599915f2b584,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-5a8d57a5-0603-454c-b800-be16888681ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-f9cfd9f5-61b1-46b6-b1d4-88b135fff58e,DISK], DatanodeInfoWithStorage[127.0.0.1:34073,DS-9283b641-f1b9-4365-bac4-132864b0ae50,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-e9674cec-dd89-444b-9832-baeb18890c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127398313-172.17.0.10-1597509120395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45037,DS-13f2eebd-ebfb-48ef-b51d-9d5a420bdcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-a72c3de5-f8d6-4b7f-9fe6-0f1dc63dc417,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-86f21bb0-4941-42ef-8ec8-255206f57f93,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-ffe87b20-9a2d-4463-8620-dce4ad74d967,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-4f7c8938-adbd-49f9-9727-9de7faa0190a,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-22c082c1-e83f-4e3a-9dbf-26dbd301a17f,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-f149f06a-03bd-4f3d-8a7f-ff841d9d8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-fde88ff6-c2a8-45de-9c9f-d4657d484fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127398313-172.17.0.10-1597509120395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45037,DS-13f2eebd-ebfb-48ef-b51d-9d5a420bdcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-a72c3de5-f8d6-4b7f-9fe6-0f1dc63dc417,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-86f21bb0-4941-42ef-8ec8-255206f57f93,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-ffe87b20-9a2d-4463-8620-dce4ad74d967,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-4f7c8938-adbd-49f9-9727-9de7faa0190a,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-22c082c1-e83f-4e3a-9dbf-26dbd301a17f,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-f149f06a-03bd-4f3d-8a7f-ff841d9d8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-fde88ff6-c2a8-45de-9c9f-d4657d484fbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424292138-172.17.0.10-1597509351612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-c810a19f-c225-46f1-84ff-efd148a2c0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-59bce04e-233a-421a-bcf4-bdc7197cddf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-163c1b0a-4c26-48f9-b9f6-9ad2488466c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-698c592c-d059-4779-a912-8384a400c455,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-614d8720-2097-4a1e-aaa5-fca88a7c7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-d0aebba8-14b2-4e9a-a83f-46da8d1be848,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-04563705-af24-467e-bf1a-12ae5a5b32f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-6bbe25ce-ae87-4be4-9281-b09cde5c597a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424292138-172.17.0.10-1597509351612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-c810a19f-c225-46f1-84ff-efd148a2c0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-59bce04e-233a-421a-bcf4-bdc7197cddf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-163c1b0a-4c26-48f9-b9f6-9ad2488466c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-698c592c-d059-4779-a912-8384a400c455,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-614d8720-2097-4a1e-aaa5-fca88a7c7e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-d0aebba8-14b2-4e9a-a83f-46da8d1be848,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-04563705-af24-467e-bf1a-12ae5a5b32f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-6bbe25ce-ae87-4be4-9281-b09cde5c597a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511456763-172.17.0.10-1597509424702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43155,DS-39949ce5-bf52-41c4-83cc-8dbc0b28fe57,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-0040f87a-5932-49a6-8606-ebc16a208670,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-75d9c228-f861-46bb-acd3-c1c612d87cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-a63056cb-9637-4a04-9534-acef3eadc4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-4bb04233-9fea-4912-874b-be013e375ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-243c6afb-ec8a-443e-b811-628f43c941ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-56739368-f3fd-4e81-9b97-d09c45367c91,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-6fe8cb23-049f-45d6-88e4-7280bef1ce93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-511456763-172.17.0.10-1597509424702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43155,DS-39949ce5-bf52-41c4-83cc-8dbc0b28fe57,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-0040f87a-5932-49a6-8606-ebc16a208670,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-75d9c228-f861-46bb-acd3-c1c612d87cce,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-a63056cb-9637-4a04-9534-acef3eadc4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-4bb04233-9fea-4912-874b-be013e375ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-243c6afb-ec8a-443e-b811-628f43c941ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-56739368-f3fd-4e81-9b97-d09c45367c91,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-6fe8cb23-049f-45d6-88e4-7280bef1ce93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999974344-172.17.0.10-1597509710595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-ee8c9a0b-c611-4cdc-a21c-98febab31af1,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-26d00f4e-caa7-4c08-bb86-a6ba64006970,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-6c25363d-b6f8-454f-b5c2-b4e065b46a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-c6cc5ecb-c2b7-455a-b3dd-124e6b2d9545,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-8baab24e-dbd3-4f92-aa9e-9ea41ba1bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-a59a1d14-1b42-45ab-8be3-13a19107eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-57ada9e1-6c58-4d80-afc8-e09fe462b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-4628b5fd-54a4-410d-a79c-ed51ff1b6a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999974344-172.17.0.10-1597509710595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-ee8c9a0b-c611-4cdc-a21c-98febab31af1,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-26d00f4e-caa7-4c08-bb86-a6ba64006970,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-6c25363d-b6f8-454f-b5c2-b4e065b46a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-c6cc5ecb-c2b7-455a-b3dd-124e6b2d9545,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-8baab24e-dbd3-4f92-aa9e-9ea41ba1bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-a59a1d14-1b42-45ab-8be3-13a19107eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-57ada9e1-6c58-4d80-afc8-e09fe462b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-4628b5fd-54a4-410d-a79c-ed51ff1b6a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253746456-172.17.0.10-1597509992113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-aae3e0eb-8717-4ef0-a602-4f5402053f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-b5f1705b-79a0-45f7-8b42-06f91a0a56a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-cbe29834-f0ab-4ffd-aa45-31eba8213ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-5f1575a1-7b87-4b8d-92fe-d63600901803,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-23de66ae-ca86-48f8-b958-35126384bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-6fa6cbc2-84a8-4241-acad-36d404778993,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-4218ef75-9abf-4e5b-90d5-199c9eaae515,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-327c4434-ef4a-4383-9032-b9dc458adf55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253746456-172.17.0.10-1597509992113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-aae3e0eb-8717-4ef0-a602-4f5402053f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-b5f1705b-79a0-45f7-8b42-06f91a0a56a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-cbe29834-f0ab-4ffd-aa45-31eba8213ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-5f1575a1-7b87-4b8d-92fe-d63600901803,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-23de66ae-ca86-48f8-b958-35126384bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-6fa6cbc2-84a8-4241-acad-36d404778993,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-4218ef75-9abf-4e5b-90d5-199c9eaae515,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-327c4434-ef4a-4383-9032-b9dc458adf55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966139702-172.17.0.10-1597510915999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32806,DS-165b5beb-d32d-4920-961f-82945a1eea09,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-8ea1efcc-d8b5-46ca-90ab-9ba69f2a4322,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-61e0e7da-3d8a-4283-8595-4032da71efc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-5e77f72d-6a45-4a48-abdc-e3cfa0c11663,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-8e3660f6-850d-4789-a592-310efb01d2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-ea5519b0-10fc-448d-bf33-98dbfabcff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-a7fc5124-3fa3-42ca-9985-6ed4d360dfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-1f1cac57-b698-4832-9211-0e0276f66fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966139702-172.17.0.10-1597510915999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32806,DS-165b5beb-d32d-4920-961f-82945a1eea09,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-8ea1efcc-d8b5-46ca-90ab-9ba69f2a4322,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-61e0e7da-3d8a-4283-8595-4032da71efc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-5e77f72d-6a45-4a48-abdc-e3cfa0c11663,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-8e3660f6-850d-4789-a592-310efb01d2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-ea5519b0-10fc-448d-bf33-98dbfabcff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-a7fc5124-3fa3-42ca-9985-6ed4d360dfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-1f1cac57-b698-4832-9211-0e0276f66fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679553211-172.17.0.10-1597511523454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32771,DS-0e2eada8-0770-4f36-9c71-e097259d9873,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-a696e08f-e19d-45d2-8406-083e90f5d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-9af79822-fe6f-423c-b9f0-08b82a0ad254,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-b412d4c3-e77b-4218-bf26-2f1046ff8dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-fa8574c2-f10f-42f4-82da-1fa1382641ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-0edaf5b8-1698-4a85-b66f-f50f1ebb569d,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-5cc20a99-1a6e-4517-a98c-47fda13b8a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-8ea92b3f-7a30-443b-b59a-4043e6fe58b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679553211-172.17.0.10-1597511523454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32771,DS-0e2eada8-0770-4f36-9c71-e097259d9873,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-a696e08f-e19d-45d2-8406-083e90f5d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-9af79822-fe6f-423c-b9f0-08b82a0ad254,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-b412d4c3-e77b-4218-bf26-2f1046ff8dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-fa8574c2-f10f-42f4-82da-1fa1382641ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-0edaf5b8-1698-4a85-b66f-f50f1ebb569d,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-5cc20a99-1a6e-4517-a98c-47fda13b8a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-8ea92b3f-7a30-443b-b59a-4043e6fe58b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744632847-172.17.0.10-1597511704614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-3400a197-cec3-4594-bee6-281ee1899bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-f1ebee8a-13e7-4a13-9eae-9f0efac5f657,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-a19a17a9-dd6e-443a-a47f-827c7d182220,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-d02fed8f-c0ef-415f-a454-b15438472fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-9bf3d1cf-daeb-4262-aae3-469a98466c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-e812c251-1c20-428f-8f6e-c23352a95a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-7623f501-63bc-47e9-ac0c-c38e58a57518,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-60175409-4781-4e16-8d13-2c2bbc8131aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744632847-172.17.0.10-1597511704614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40622,DS-3400a197-cec3-4594-bee6-281ee1899bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-f1ebee8a-13e7-4a13-9eae-9f0efac5f657,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-a19a17a9-dd6e-443a-a47f-827c7d182220,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-d02fed8f-c0ef-415f-a454-b15438472fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-9bf3d1cf-daeb-4262-aae3-469a98466c05,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-e812c251-1c20-428f-8f6e-c23352a95a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-7623f501-63bc-47e9-ac0c-c38e58a57518,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-60175409-4781-4e16-8d13-2c2bbc8131aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381229100-172.17.0.10-1597511784969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43400,DS-4b129a7e-35c3-4a02-b7bf-d7ef1cb0b66d,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-a4e592ad-369b-493e-a695-3fbcae95c065,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-23d59836-3a72-4be0-a60d-22e10f6ac4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-009cb4b1-a9cf-476d-803a-45f32b31f1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-d36e5051-e4dc-47df-a6ce-3c93d818b374,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-1dd46498-3441-4da6-b110-d79394c7dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-efc65c35-8232-4471-967e-bde9de37ad21,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-bf44856d-8dab-45ab-9c0d-fbdd90e3a1ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381229100-172.17.0.10-1597511784969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43400,DS-4b129a7e-35c3-4a02-b7bf-d7ef1cb0b66d,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-a4e592ad-369b-493e-a695-3fbcae95c065,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-23d59836-3a72-4be0-a60d-22e10f6ac4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-009cb4b1-a9cf-476d-803a-45f32b31f1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-d36e5051-e4dc-47df-a6ce-3c93d818b374,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-1dd46498-3441-4da6-b110-d79394c7dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-efc65c35-8232-4471-967e-bde9de37ad21,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-bf44856d-8dab-45ab-9c0d-fbdd90e3a1ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-399139997-172.17.0.10-1597511939067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41453,DS-bf93bd9c-1c10-4e72-8a16-3e37c87db68f,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-61998dcc-c135-45a7-b69e-b9ceba87c4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-2b5a6fce-9e84-44be-9c2f-12eac705aacb,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-a011d328-19ac-4c27-960a-e14d7d6e2b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-3ffaee30-e058-43ba-a4d6-c6da11a2e248,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-d6a774f5-1d7e-4c7c-b822-2d5e5042878e,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-964fd39b-6e75-450f-b462-82751a2645b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-71e4100a-c4cd-4234-a006-93a69514ec0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-399139997-172.17.0.10-1597511939067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41453,DS-bf93bd9c-1c10-4e72-8a16-3e37c87db68f,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-61998dcc-c135-45a7-b69e-b9ceba87c4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-2b5a6fce-9e84-44be-9c2f-12eac705aacb,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-a011d328-19ac-4c27-960a-e14d7d6e2b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-3ffaee30-e058-43ba-a4d6-c6da11a2e248,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-d6a774f5-1d7e-4c7c-b822-2d5e5042878e,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-964fd39b-6e75-450f-b462-82751a2645b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-71e4100a-c4cd-4234-a006-93a69514ec0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277623528-172.17.0.10-1597512364615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40971,DS-da064e32-579d-4963-a85d-9326eb0920aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-84c3c2f6-f24c-44d6-9848-1bce20034ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-ec80e33f-7378-44f9-b8da-5f2dda145359,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-091237c0-b1f6-48e3-998e-f4044a21c0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-0fe14131-9062-4568-aa93-7e62bbb68594,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-0d2ccb45-e0ee-4bac-bb1d-564a76fe8f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-38088802-2b14-4fd8-99cd-108531deb5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-1e0c190f-703b-4db7-8d23-97cf909ddd49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277623528-172.17.0.10-1597512364615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40971,DS-da064e32-579d-4963-a85d-9326eb0920aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-84c3c2f6-f24c-44d6-9848-1bce20034ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-ec80e33f-7378-44f9-b8da-5f2dda145359,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-091237c0-b1f6-48e3-998e-f4044a21c0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-0fe14131-9062-4568-aa93-7e62bbb68594,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-0d2ccb45-e0ee-4bac-bb1d-564a76fe8f07,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-38088802-2b14-4fd8-99cd-108531deb5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-1e0c190f-703b-4db7-8d23-97cf909ddd49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146124956-172.17.0.10-1597513597028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39199,DS-694ed13d-6829-432e-83e2-e7a609988b17,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-fcc58612-4fc0-4905-b44d-3acfae904bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-958602a8-5c15-4612-96a7-b11d49c69e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-768d0e54-e8a8-4de2-919d-9409ca94746a,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-36942de7-6775-44b6-a0f3-4d892888ab72,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-fd019019-1ff5-45f5-9f7f-6d6fa1f1ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-5cd63c2d-964c-4777-9c25-387787fdd9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-8aa9cd27-5c13-4d28-9761-d7e96d71eb34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146124956-172.17.0.10-1597513597028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39199,DS-694ed13d-6829-432e-83e2-e7a609988b17,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-fcc58612-4fc0-4905-b44d-3acfae904bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-958602a8-5c15-4612-96a7-b11d49c69e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-768d0e54-e8a8-4de2-919d-9409ca94746a,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-36942de7-6775-44b6-a0f3-4d892888ab72,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-fd019019-1ff5-45f5-9f7f-6d6fa1f1ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-5cd63c2d-964c-4777-9c25-387787fdd9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-8aa9cd27-5c13-4d28-9761-d7e96d71eb34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422799238-172.17.0.10-1597513849839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-fb1fef74-41a2-47a0-b06a-4a5d3b512a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ac6d0c11-c291-40d1-bd14-a5c894d8bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-657669a0-55b8-4f39-a2d4-a73f718e16ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-704155d0-b3bb-472b-91de-903514475150,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-5ed7b2d1-93d4-4afb-b5cc-159cbbe91006,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-5cdfd895-23c8-477e-9b17-100fe000deea,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-7da38998-8c79-4a33-a8ed-681255454938,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-86a8e342-f929-4d46-970d-a570f1552ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422799238-172.17.0.10-1597513849839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-fb1fef74-41a2-47a0-b06a-4a5d3b512a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ac6d0c11-c291-40d1-bd14-a5c894d8bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-657669a0-55b8-4f39-a2d4-a73f718e16ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-704155d0-b3bb-472b-91de-903514475150,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-5ed7b2d1-93d4-4afb-b5cc-159cbbe91006,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-5cdfd895-23c8-477e-9b17-100fe000deea,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-7da38998-8c79-4a33-a8ed-681255454938,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-86a8e342-f929-4d46-970d-a570f1552ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726530824-172.17.0.10-1597514553986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-169bf916-627c-4d41-a3d3-b5708afcce90,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-8ea22667-232d-46a1-9988-c75c77292eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-a3278e94-ec8a-40f6-93be-a2b49595f4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-01d54623-28ad-4238-9021-e48dfae8f384,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-22ebaf93-474d-4080-9742-d55e0bb578b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-778b1b4a-0b6c-4321-aa7a-8b2e6da28648,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-d5a25e27-d538-47c8-a030-7eca4db9ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-bc02be86-7b7f-4e19-874a-e60d103d25f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726530824-172.17.0.10-1597514553986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-169bf916-627c-4d41-a3d3-b5708afcce90,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-8ea22667-232d-46a1-9988-c75c77292eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-a3278e94-ec8a-40f6-93be-a2b49595f4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-01d54623-28ad-4238-9021-e48dfae8f384,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-22ebaf93-474d-4080-9742-d55e0bb578b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-778b1b4a-0b6c-4321-aa7a-8b2e6da28648,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-d5a25e27-d538-47c8-a030-7eca4db9ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-bc02be86-7b7f-4e19-874a-e60d103d25f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328358198-172.17.0.10-1597514697148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36730,DS-66dde5dc-f358-4620-bba5-95fc0bc419a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-03358ff7-a1c1-46e0-865d-8b18b7473899,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-f01829a2-e50b-4fea-9954-fcfc753eae84,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-a3e9b2ec-2528-4001-9613-2d99af84b13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-2a63ce83-6865-4e73-9718-9e78702960b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-e9a00a15-0983-48d4-96a2-aed479d03dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-0b19b484-cadf-41ba-9f5a-fa407e648e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-9d95f455-25cd-4b31-a80b-c211a4ad140a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328358198-172.17.0.10-1597514697148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36730,DS-66dde5dc-f358-4620-bba5-95fc0bc419a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-03358ff7-a1c1-46e0-865d-8b18b7473899,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-f01829a2-e50b-4fea-9954-fcfc753eae84,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-a3e9b2ec-2528-4001-9613-2d99af84b13e,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-2a63ce83-6865-4e73-9718-9e78702960b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-e9a00a15-0983-48d4-96a2-aed479d03dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-0b19b484-cadf-41ba-9f5a-fa407e648e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-9d95f455-25cd-4b31-a80b-c211a4ad140a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369311101-172.17.0.10-1597514905626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-bfe7756d-5914-49fe-9273-cde62871b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-f03804ff-78c3-4f58-a951-50c7df979d30,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-83536102-3c4a-4724-9836-4e6441dd8ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-27f1a0ed-c5ac-44fe-b56d-1cc90022a58b,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-d48b28e4-d73b-4e70-949e-0094d33a14e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-9d26539a-7feb-436d-a634-cd2082c8ac11,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-756c4a9b-9fb1-451d-b923-dddac46b2aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-09e03d9f-ebe6-4102-832d-b0bc4ebed74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369311101-172.17.0.10-1597514905626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-bfe7756d-5914-49fe-9273-cde62871b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-f03804ff-78c3-4f58-a951-50c7df979d30,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-83536102-3c4a-4724-9836-4e6441dd8ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-27f1a0ed-c5ac-44fe-b56d-1cc90022a58b,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-d48b28e4-d73b-4e70-949e-0094d33a14e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-9d26539a-7feb-436d-a634-cd2082c8ac11,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-756c4a9b-9fb1-451d-b923-dddac46b2aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-09e03d9f-ebe6-4102-832d-b0bc4ebed74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 7117
