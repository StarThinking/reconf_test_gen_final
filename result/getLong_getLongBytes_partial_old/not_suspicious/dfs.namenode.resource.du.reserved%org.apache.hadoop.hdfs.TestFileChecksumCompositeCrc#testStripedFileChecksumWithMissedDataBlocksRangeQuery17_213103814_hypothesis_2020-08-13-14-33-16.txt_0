reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196996754-172.17.0.13-1597329827040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-51965d50-66c7-4796-8f2c-c0914c122bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-60ff8d20-5bf4-4082-b975-f814e7131e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-29241f1e-80be-4759-9e0c-31e4461a2758,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-ad06e0b7-24b0-4a5f-bb6d-0c69e6d3213a,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7b91ce5f-29b2-49ac-8403-c29c9ac72725,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-d2d1ef62-9f43-4e80-9c42-e82cbddcf8da,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-5b73c7f0-e3e0-46a3-bb87-51849dce5e46,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-0d5515bd-0bcc-4bc3-8dde-acdb6b59714b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196996754-172.17.0.13-1597329827040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35642,DS-51965d50-66c7-4796-8f2c-c0914c122bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-60ff8d20-5bf4-4082-b975-f814e7131e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-29241f1e-80be-4759-9e0c-31e4461a2758,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-ad06e0b7-24b0-4a5f-bb6d-0c69e6d3213a,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-7b91ce5f-29b2-49ac-8403-c29c9ac72725,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-d2d1ef62-9f43-4e80-9c42-e82cbddcf8da,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-5b73c7f0-e3e0-46a3-bb87-51849dce5e46,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-0d5515bd-0bcc-4bc3-8dde-acdb6b59714b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805064100-172.17.0.13-1597330058130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-824a3700-029e-4e03-95d4-006656fb469c,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-2a2cf848-0edb-4666-a6d3-3d551ac7b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-f793c37c-9a1e-4347-9805-9aded6a1647b,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-bca6289e-e6a8-4297-822c-dff2e455cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-7b0c1f43-6f18-4df3-bd41-40203964966e,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-9de36056-fb44-4711-b113-57ba57b58a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-8aabf192-8f34-4b06-b854-cb1c5a851ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-33dd97cd-ed03-45fc-9d9b-08a60166e124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-805064100-172.17.0.13-1597330058130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-824a3700-029e-4e03-95d4-006656fb469c,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-2a2cf848-0edb-4666-a6d3-3d551ac7b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-f793c37c-9a1e-4347-9805-9aded6a1647b,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-bca6289e-e6a8-4297-822c-dff2e455cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-7b0c1f43-6f18-4df3-bd41-40203964966e,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-9de36056-fb44-4711-b113-57ba57b58a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-8aabf192-8f34-4b06-b854-cb1c5a851ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-33dd97cd-ed03-45fc-9d9b-08a60166e124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945178945-172.17.0.13-1597330450247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35799,DS-515bcf2c-8565-4f57-9060-b43ef586d039,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-bbc6c9bf-4842-41f1-8246-4d1c3b8eb373,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-5cc08e50-bcfb-477c-b58a-0c2da85d3181,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-763cab4b-59d8-4113-8413-5ed575917fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-c7ecb25d-f4ce-4e34-9924-43b8cdc7df94,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-c2ae74f4-2ad6-42a0-b3a0-f49d01fbabe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-ee62873b-5594-4c92-bffa-9c537e038f01,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-55f4757e-6c1f-4fa3-b53a-e6e7a7838766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945178945-172.17.0.13-1597330450247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35799,DS-515bcf2c-8565-4f57-9060-b43ef586d039,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-bbc6c9bf-4842-41f1-8246-4d1c3b8eb373,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-5cc08e50-bcfb-477c-b58a-0c2da85d3181,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-763cab4b-59d8-4113-8413-5ed575917fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-c7ecb25d-f4ce-4e34-9924-43b8cdc7df94,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-c2ae74f4-2ad6-42a0-b3a0-f49d01fbabe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-ee62873b-5594-4c92-bffa-9c537e038f01,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-55f4757e-6c1f-4fa3-b53a-e6e7a7838766,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818659159-172.17.0.13-1597330757844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43022,DS-73e880ce-a329-46b8-85e6-9c3ff91bf229,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-904eab5c-a57c-4c1a-84ad-d6bca401ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-080e9680-01fa-4caa-a2ae-a9f4b05a8614,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-5ffd5cf7-c937-486b-9a56-f743f3943608,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-abc25f3a-255f-48a5-a10f-e36f24378bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-f9dea929-57f7-4f63-98de-76a956fb900c,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-1e5f54a9-9e55-4322-aef6-77b237ea509b,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-0febcf28-0f39-4a34-9adf-ecd55ab29d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818659159-172.17.0.13-1597330757844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43022,DS-73e880ce-a329-46b8-85e6-9c3ff91bf229,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-904eab5c-a57c-4c1a-84ad-d6bca401ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-080e9680-01fa-4caa-a2ae-a9f4b05a8614,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-5ffd5cf7-c937-486b-9a56-f743f3943608,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-abc25f3a-255f-48a5-a10f-e36f24378bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-f9dea929-57f7-4f63-98de-76a956fb900c,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-1e5f54a9-9e55-4322-aef6-77b237ea509b,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-0febcf28-0f39-4a34-9adf-ecd55ab29d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98369563-172.17.0.13-1597331854176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-9fbbbabb-6062-4116-93ad-cc5c2723d88b,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-7aac9ce8-78a4-442a-a983-cb9681237f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-8b3438a2-c2e6-46e8-94df-8f68ef535af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-ae38fe7c-4a01-4322-94f6-f6bb07092f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-43de81e1-a181-4ef2-ab23-8402bf723b99,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-b53da2c2-8d02-4eab-9ad9-1421ae411d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-8d9f7c83-a843-4c9f-9b90-9dc7b3c001a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-6d3a3529-7a73-436f-9c80-638bf8257bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98369563-172.17.0.13-1597331854176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33122,DS-9fbbbabb-6062-4116-93ad-cc5c2723d88b,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-7aac9ce8-78a4-442a-a983-cb9681237f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-8b3438a2-c2e6-46e8-94df-8f68ef535af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-ae38fe7c-4a01-4322-94f6-f6bb07092f95,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-43de81e1-a181-4ef2-ab23-8402bf723b99,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-b53da2c2-8d02-4eab-9ad9-1421ae411d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-8d9f7c83-a843-4c9f-9b90-9dc7b3c001a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-6d3a3529-7a73-436f-9c80-638bf8257bf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8246008-172.17.0.13-1597332878069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36689,DS-e57df051-69d1-4ce3-a5cf-b783c457fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-860d4a73-1d09-4150-98d3-8d38d7c6c337,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-c05f0022-52db-47a1-9c22-083272a3c60f,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-5e25afb8-f0b2-4c8a-96b6-90ae7a9ae2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-fbc15ea6-5280-4f0c-aec1-6db289644aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-ef9415a6-f3c7-4c24-acfd-687c0e11dd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-10eb3b4a-eb65-40ad-97d4-6abcee6e9ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-4d0ec238-3f7d-4d8b-a17c-7467b310c481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8246008-172.17.0.13-1597332878069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36689,DS-e57df051-69d1-4ce3-a5cf-b783c457fe76,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-860d4a73-1d09-4150-98d3-8d38d7c6c337,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-c05f0022-52db-47a1-9c22-083272a3c60f,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-5e25afb8-f0b2-4c8a-96b6-90ae7a9ae2df,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-fbc15ea6-5280-4f0c-aec1-6db289644aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-ef9415a6-f3c7-4c24-acfd-687c0e11dd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-10eb3b4a-eb65-40ad-97d4-6abcee6e9ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-4d0ec238-3f7d-4d8b-a17c-7467b310c481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639005278-172.17.0.13-1597333673265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-4004b9d9-0ad3-42a1-a9c0-94842d518c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-57891953-82c9-412c-ae6d-887e114a056b,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-afdf0c5e-9728-419e-b524-a7d5e6ba01c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-6d2f8a8e-8ee2-4874-923d-57c184546fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-2e1f161a-0807-4dec-87a3-1439642ddb29,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-90fd01ad-82f8-4b5d-9e91-3462d9c5db3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-66e38eae-000a-4325-afe3-f81057557b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-817e9376-98c4-4c1e-aa59-e48bb5855751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639005278-172.17.0.13-1597333673265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33753,DS-4004b9d9-0ad3-42a1-a9c0-94842d518c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-57891953-82c9-412c-ae6d-887e114a056b,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-afdf0c5e-9728-419e-b524-a7d5e6ba01c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-6d2f8a8e-8ee2-4874-923d-57c184546fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-2e1f161a-0807-4dec-87a3-1439642ddb29,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-90fd01ad-82f8-4b5d-9e91-3462d9c5db3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-66e38eae-000a-4325-afe3-f81057557b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-817e9376-98c4-4c1e-aa59-e48bb5855751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199318267-172.17.0.13-1597334440421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-20d6dd71-4edf-4fba-907a-e94b4529b787,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-b58f1374-94f1-4d31-af51-07a6a510ab4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-416efd0a-da19-4d02-bbdd-2c209eaa7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-80736dfc-6b63-4825-a362-dbb54b589c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-19241031-3018-4846-bc04-3748937a9f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-1a4e60d3-b4aa-4250-8a9b-c2ea1d451e04,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-1c9f04a6-f614-412d-acf1-2a7be74d00bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-1839bca6-0fe3-4893-8d93-bf6a489b1194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199318267-172.17.0.13-1597334440421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46314,DS-20d6dd71-4edf-4fba-907a-e94b4529b787,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-b58f1374-94f1-4d31-af51-07a6a510ab4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-416efd0a-da19-4d02-bbdd-2c209eaa7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-80736dfc-6b63-4825-a362-dbb54b589c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-19241031-3018-4846-bc04-3748937a9f18,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-1a4e60d3-b4aa-4250-8a9b-c2ea1d451e04,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-1c9f04a6-f614-412d-acf1-2a7be74d00bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-1839bca6-0fe3-4893-8d93-bf6a489b1194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883107353-172.17.0.13-1597334481263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34396,DS-5631aa23-84cb-4438-834c-e5e707f55fac,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-562aa7f4-4a39-4089-a0bc-19e6d71d45f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-84c4de83-f6e6-4fca-9233-f511065497c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-abbaeac3-1629-4381-92a3-42d2901c532b,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-d97a4885-2e43-4353-ba35-363cfdfd7f42,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-79c4c40e-a088-487a-aac0-bda7e5a203e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-67ee78fa-c698-49f6-8cb4-b368f9005e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-b1508ed2-0a0b-44f0-af72-03cdcae40afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883107353-172.17.0.13-1597334481263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34396,DS-5631aa23-84cb-4438-834c-e5e707f55fac,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-562aa7f4-4a39-4089-a0bc-19e6d71d45f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-84c4de83-f6e6-4fca-9233-f511065497c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-abbaeac3-1629-4381-92a3-42d2901c532b,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-d97a4885-2e43-4353-ba35-363cfdfd7f42,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-79c4c40e-a088-487a-aac0-bda7e5a203e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-67ee78fa-c698-49f6-8cb4-b368f9005e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-b1508ed2-0a0b-44f0-af72-03cdcae40afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 104857600
v2: 1677721600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938770874-172.17.0.13-1597335681837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35221,DS-366f2b5f-fc51-496c-8151-ca0545f27dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-b52c27a3-c4a6-4a21-b91c-3a097b776288,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-a6d364b4-bd23-4c72-be3a-968f77937ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-fb29fcca-cfb2-4eaa-a3d2-455afd471d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-9f1b89af-e499-481f-bac2-8fdd66c92a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-1d232eb5-576e-44dc-a568-94dda84e2742,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-103d2684-e9fb-4cc3-ab7a-43626846e685,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-9a0aa560-1c49-49bb-a2de-7b9c591f32fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938770874-172.17.0.13-1597335681837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35221,DS-366f2b5f-fc51-496c-8151-ca0545f27dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-b52c27a3-c4a6-4a21-b91c-3a097b776288,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-a6d364b4-bd23-4c72-be3a-968f77937ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-fb29fcca-cfb2-4eaa-a3d2-455afd471d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-9f1b89af-e499-481f-bac2-8fdd66c92a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-1d232eb5-576e-44dc-a568-94dda84e2742,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-103d2684-e9fb-4cc3-ab7a-43626846e685,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-9a0aa560-1c49-49bb-a2de-7b9c591f32fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 7024
