reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224758585-172.17.0.7-1597513256564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-cdded54a-fa65-423f-9d66-13bd61088311,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-b64380e5-16ce-4793-bdc5-8c32e8058bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-d31904e5-f691-4f26-b168-6a538dc9165c,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-55454170-2f10-4324-a97e-0d026edc7039,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-df5ebc8a-9b8b-4c7b-967d-c6624001a612,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-762aa066-fd38-48f9-b05e-ef7cf5717e99,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-255ac5a7-bdb3-48aa-bdb8-436ab0ffab90,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-d471879f-3f39-4cc2-adb4-3324f204ec40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224758585-172.17.0.7-1597513256564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-cdded54a-fa65-423f-9d66-13bd61088311,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-b64380e5-16ce-4793-bdc5-8c32e8058bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-d31904e5-f691-4f26-b168-6a538dc9165c,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-55454170-2f10-4324-a97e-0d026edc7039,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-df5ebc8a-9b8b-4c7b-967d-c6624001a612,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-762aa066-fd38-48f9-b05e-ef7cf5717e99,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-255ac5a7-bdb3-48aa-bdb8-436ab0ffab90,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-d471879f-3f39-4cc2-adb4-3324f204ec40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519021143-172.17.0.7-1597513374172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43225,DS-fb184e13-2d04-41ce-9f7b-8cfa8a6cbfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-794b2f57-8663-4af4-937d-726a418052d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-454935bb-c2ea-4ccc-b935-bc8dd43c60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-8f4fea91-45e2-40cb-ad32-a41da810a87d,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-796f1cb0-cfd8-4d2e-a537-7bc930faafbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-f68fc3f4-8b66-45b9-9fb5-1bc19fe40d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-39405088-9184-46ec-94f3-18e855544e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-68f9d17c-ba4a-4bdd-a881-b688282d72cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519021143-172.17.0.7-1597513374172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43225,DS-fb184e13-2d04-41ce-9f7b-8cfa8a6cbfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-794b2f57-8663-4af4-937d-726a418052d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-454935bb-c2ea-4ccc-b935-bc8dd43c60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-8f4fea91-45e2-40cb-ad32-a41da810a87d,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-796f1cb0-cfd8-4d2e-a537-7bc930faafbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-f68fc3f4-8b66-45b9-9fb5-1bc19fe40d86,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-39405088-9184-46ec-94f3-18e855544e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-68f9d17c-ba4a-4bdd-a881-b688282d72cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719823555-172.17.0.7-1597513458680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-c9c2e8ae-6dc4-4447-8402-bcbd2bdce4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-367068d2-5f02-4193-bd4d-7e642cdb3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-d264a82b-7fdf-480d-8e5f-cd3d2817a67d,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-668b3282-6735-4f3c-8fcf-0ec21055fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-045b4f8c-7440-4c58-b84a-044e4e20d790,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-9422bf62-df17-4f6a-a61f-02790465c488,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-5a69b83e-5969-484a-be55-6d0c279a2bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-430a3d08-a9e3-43ae-9ce4-44af1396dac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719823555-172.17.0.7-1597513458680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-c9c2e8ae-6dc4-4447-8402-bcbd2bdce4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-367068d2-5f02-4193-bd4d-7e642cdb3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-d264a82b-7fdf-480d-8e5f-cd3d2817a67d,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-668b3282-6735-4f3c-8fcf-0ec21055fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-045b4f8c-7440-4c58-b84a-044e4e20d790,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-9422bf62-df17-4f6a-a61f-02790465c488,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-5a69b83e-5969-484a-be55-6d0c279a2bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-430a3d08-a9e3-43ae-9ce4-44af1396dac6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437983684-172.17.0.7-1597513650866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-6438c63b-2208-4cf9-90cf-ef4ed779ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-fc2377ab-fbc4-4ea9-8ea3-4a5b288acbde,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-2e47a521-9b97-4610-9154-a057954e1a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-5c1d0b4f-a2c1-448a-8e93-ed5f03bc9201,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-23f72959-0dbf-47d8-ae10-edbd98a3463b,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-4cc21f91-8b92-49da-b2a6-ad4afb270442,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-28ff0e14-6dd3-42f1-adf9-83baac7815b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-e7b287d9-b0f4-41fb-a5e0-3ecb5066943c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437983684-172.17.0.7-1597513650866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-6438c63b-2208-4cf9-90cf-ef4ed779ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-fc2377ab-fbc4-4ea9-8ea3-4a5b288acbde,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-2e47a521-9b97-4610-9154-a057954e1a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-5c1d0b4f-a2c1-448a-8e93-ed5f03bc9201,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-23f72959-0dbf-47d8-ae10-edbd98a3463b,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-4cc21f91-8b92-49da-b2a6-ad4afb270442,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-28ff0e14-6dd3-42f1-adf9-83baac7815b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-e7b287d9-b0f4-41fb-a5e0-3ecb5066943c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799639582-172.17.0.7-1597514229907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-e1124551-2e7e-4809-8fb2-2a74f144c2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-c0686157-358e-455f-808b-8e3a2281cb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-e396b400-4295-4454-908d-77ca532d0a84,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-0956db1a-d96f-4535-ad25-b0032f006fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-1deee013-2f33-4e08-b21a-687c4a328970,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-2b02c39d-b7e6-4da8-82b1-62e3bcd593b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-0f231d19-f2ff-4909-b393-29330e5854ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-9cd8674d-fa97-453f-8ec1-55aea074c4e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799639582-172.17.0.7-1597514229907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-e1124551-2e7e-4809-8fb2-2a74f144c2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-c0686157-358e-455f-808b-8e3a2281cb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-e396b400-4295-4454-908d-77ca532d0a84,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-0956db1a-d96f-4535-ad25-b0032f006fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-1deee013-2f33-4e08-b21a-687c4a328970,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-2b02c39d-b7e6-4da8-82b1-62e3bcd593b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-0f231d19-f2ff-4909-b393-29330e5854ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-9cd8674d-fa97-453f-8ec1-55aea074c4e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813893045-172.17.0.7-1597514304712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-3e86a7d5-fd2f-41f0-80b0-bcee105acb55,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-4e08c311-f37e-4bca-95af-488fd5976108,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-098d2757-1b74-4dad-91bf-89a19b4f7d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-aac106af-c815-4a98-9f8b-9bde2bd96a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-9936071d-38af-44f5-8121-d85735b43ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-5a4366b0-4503-43cc-87dd-7e85daaf309d,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-af538757-d61c-4899-89db-85d5c02826a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-686c2c5e-2c46-40e0-ad2a-8fdfdf604126,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813893045-172.17.0.7-1597514304712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-3e86a7d5-fd2f-41f0-80b0-bcee105acb55,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-4e08c311-f37e-4bca-95af-488fd5976108,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-098d2757-1b74-4dad-91bf-89a19b4f7d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-aac106af-c815-4a98-9f8b-9bde2bd96a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-9936071d-38af-44f5-8121-d85735b43ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-5a4366b0-4503-43cc-87dd-7e85daaf309d,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-af538757-d61c-4899-89db-85d5c02826a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-686c2c5e-2c46-40e0-ad2a-8fdfdf604126,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652391195-172.17.0.7-1597514414357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-a8645c78-4206-4aa3-9cbb-7dd5d4d44757,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-e15fe94c-90c2-46bd-8639-a667361631f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-59875874-dace-482c-b03e-e8d21a5b2446,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-ef45a7b6-edf3-44f7-9bbb-0b21faa8f6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-50c0c226-f37a-4db4-8b60-4efe93a6b1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-db0f9744-355a-4491-9cfc-6445e80cf34e,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-f26e76a0-acb0-4d79-a500-1b926368efc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-51228064-824b-42ae-a046-960478e8a913,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652391195-172.17.0.7-1597514414357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-a8645c78-4206-4aa3-9cbb-7dd5d4d44757,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-e15fe94c-90c2-46bd-8639-a667361631f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-59875874-dace-482c-b03e-e8d21a5b2446,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-ef45a7b6-edf3-44f7-9bbb-0b21faa8f6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-50c0c226-f37a-4db4-8b60-4efe93a6b1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-db0f9744-355a-4491-9cfc-6445e80cf34e,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-f26e76a0-acb0-4d79-a500-1b926368efc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-51228064-824b-42ae-a046-960478e8a913,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776711102-172.17.0.7-1597514961625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34972,DS-43d9076e-3cc0-4f97-9fed-ab82cddd7583,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-efffb223-f533-48d8-ab87-26d696ecf741,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-080e10d6-8986-40d0-b30c-57d883329f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-7adf3d84-f003-4094-9a23-991fc0f8f436,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-03149630-ccc3-43b8-97cd-fd0f6d3998ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-a26e35b6-a886-4c39-b4a2-d2010e21e665,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-552cda5d-b6ab-4d20-9593-0b771439ea36,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-02bff1a6-e828-4e84-86f4-849526b0272f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776711102-172.17.0.7-1597514961625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34972,DS-43d9076e-3cc0-4f97-9fed-ab82cddd7583,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-efffb223-f533-48d8-ab87-26d696ecf741,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-080e10d6-8986-40d0-b30c-57d883329f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-7adf3d84-f003-4094-9a23-991fc0f8f436,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-03149630-ccc3-43b8-97cd-fd0f6d3998ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-a26e35b6-a886-4c39-b4a2-d2010e21e665,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-552cda5d-b6ab-4d20-9593-0b771439ea36,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-02bff1a6-e828-4e84-86f4-849526b0272f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520783927-172.17.0.7-1597514996340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-4990c32e-7805-4f62-af57-d4cfa8e414c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-1dbfbb6a-4fef-40df-94a6-17c30dd69495,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-133c5d64-04f0-482f-87ab-bfd18d75bbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-0b70ae25-a5a7-491c-a6c0-2b7a83bff0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-37dc9ebc-a2b9-498c-9cdb-eab29333d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-f65fd22b-4b9c-4e96-a0da-c7ea92e4506c,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-f559e015-0e6d-49b6-8575-37a1fbf619f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-530163a8-2951-485a-84e3-bdf134dd9280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520783927-172.17.0.7-1597514996340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-4990c32e-7805-4f62-af57-d4cfa8e414c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-1dbfbb6a-4fef-40df-94a6-17c30dd69495,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-133c5d64-04f0-482f-87ab-bfd18d75bbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-0b70ae25-a5a7-491c-a6c0-2b7a83bff0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-37dc9ebc-a2b9-498c-9cdb-eab29333d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-f65fd22b-4b9c-4e96-a0da-c7ea92e4506c,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-f559e015-0e6d-49b6-8575-37a1fbf619f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-530163a8-2951-485a-84e3-bdf134dd9280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555082932-172.17.0.7-1597515109172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41068,DS-9b66bcf9-beba-4584-baf7-01085766f786,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-7d27da36-1f2a-4416-b0b0-d85293ae58ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-09e7f6a2-bc4b-447f-b8d2-7206c9ec40db,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-92c70c49-4831-447c-8e46-5aab1dd197ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-8db672ca-924f-4b31-82cd-d7c3442bef1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-56dda063-76a7-4980-ba89-447e4a0a54d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-10adef18-0976-4ac5-9ff4-d3b83ee9f297,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-8e655469-6f19-4a6a-b988-8fd00145ab70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555082932-172.17.0.7-1597515109172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41068,DS-9b66bcf9-beba-4584-baf7-01085766f786,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-7d27da36-1f2a-4416-b0b0-d85293ae58ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-09e7f6a2-bc4b-447f-b8d2-7206c9ec40db,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-92c70c49-4831-447c-8e46-5aab1dd197ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-8db672ca-924f-4b31-82cd-d7c3442bef1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-56dda063-76a7-4980-ba89-447e4a0a54d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-10adef18-0976-4ac5-9ff4-d3b83ee9f297,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-8e655469-6f19-4a6a-b988-8fd00145ab70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21149519-172.17.0.7-1597515137448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-b5e5a72f-a2c5-4b9f-8d27-0b5fd87b26d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-4b97167f-35ef-49ec-8c04-f5d07705d367,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-20516539-fe2f-4ea6-8d85-285c81dd21c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-20ac01f1-b898-42ab-a14b-9d0120a4056a,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d532dfb4-d3bb-458b-867f-112c6f0e412f,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-97232861-f7bb-4a69-be5d-02af02f937fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-41fe2da1-ebd9-4bf1-b3b2-2daf404c549e,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-ea235040-40c0-46ea-9118-db2c5d4eedb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21149519-172.17.0.7-1597515137448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36138,DS-b5e5a72f-a2c5-4b9f-8d27-0b5fd87b26d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-4b97167f-35ef-49ec-8c04-f5d07705d367,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-20516539-fe2f-4ea6-8d85-285c81dd21c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-20ac01f1-b898-42ab-a14b-9d0120a4056a,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d532dfb4-d3bb-458b-867f-112c6f0e412f,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-97232861-f7bb-4a69-be5d-02af02f937fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-41fe2da1-ebd9-4bf1-b3b2-2daf404c549e,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-ea235040-40c0-46ea-9118-db2c5d4eedb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274951045-172.17.0.7-1597515321719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-a67db93f-7ce3-4224-9654-899a6c7f10e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-2b507d4f-d676-45ed-96d7-a69c9580ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-4d2cc417-e6a6-4f0f-8561-64387127f6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-edaea3e6-3c71-43d6-be78-a62ad9f6428a,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-589066b1-0f30-4718-881e-714b92c6b6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-28acc3d0-342d-42d6-93fc-f439c9745986,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-f5a27cd3-3c49-4c0b-b952-c8428498ff3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-5e4d23b5-4809-47b2-80af-6f840d640cfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274951045-172.17.0.7-1597515321719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-a67db93f-7ce3-4224-9654-899a6c7f10e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-2b507d4f-d676-45ed-96d7-a69c9580ca0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-4d2cc417-e6a6-4f0f-8561-64387127f6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-edaea3e6-3c71-43d6-be78-a62ad9f6428a,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-589066b1-0f30-4718-881e-714b92c6b6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-28acc3d0-342d-42d6-93fc-f439c9745986,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-f5a27cd3-3c49-4c0b-b952-c8428498ff3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-5e4d23b5-4809-47b2-80af-6f840d640cfc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065113143-172.17.0.7-1597515572506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45168,DS-1a4aafa7-eac6-442f-984e-8d10cdf488b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-d596892b-404c-47e3-953f-a23dc4be7503,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-6effb9e0-aff1-4f9e-a8b2-b2b4cb7b1d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-90c0499b-e749-484f-903e-476a0ecfeaef,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-b171a617-3324-43f6-aac9-fc66414bd330,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-dd83abbd-0b15-4bf6-ba3a-e5c408f6f337,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-c2fd8cf7-f7f9-46f2-8b36-93494d65e69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-baa26ede-73d8-406c-96c8-def26c270ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065113143-172.17.0.7-1597515572506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45168,DS-1a4aafa7-eac6-442f-984e-8d10cdf488b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-d596892b-404c-47e3-953f-a23dc4be7503,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-6effb9e0-aff1-4f9e-a8b2-b2b4cb7b1d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-90c0499b-e749-484f-903e-476a0ecfeaef,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-b171a617-3324-43f6-aac9-fc66414bd330,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-dd83abbd-0b15-4bf6-ba3a-e5c408f6f337,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-c2fd8cf7-f7f9-46f2-8b36-93494d65e69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-baa26ede-73d8-406c-96c8-def26c270ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759683465-172.17.0.7-1597515606673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-575148e5-dcab-4459-be50-33001748f57c,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-e3c1364c-3252-44bf-bcc6-572f9fbc449e,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-1b57794c-4a57-404e-a966-a353ba23e563,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-04ef6b5b-ed6e-438f-bcd4-672bc390068b,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-ec7de692-2518-4903-80f7-69804d53d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-03653921-0523-4cc6-bf18-aee1a2a613a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-eea361de-c50e-4a71-adfd-f6eb0973439a,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-a68b85f9-f7ba-4a38-bb59-6e202819a0a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759683465-172.17.0.7-1597515606673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-575148e5-dcab-4459-be50-33001748f57c,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-e3c1364c-3252-44bf-bcc6-572f9fbc449e,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-1b57794c-4a57-404e-a966-a353ba23e563,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-04ef6b5b-ed6e-438f-bcd4-672bc390068b,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-ec7de692-2518-4903-80f7-69804d53d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-03653921-0523-4cc6-bf18-aee1a2a613a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-eea361de-c50e-4a71-adfd-f6eb0973439a,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-a68b85f9-f7ba-4a38-bb59-6e202819a0a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488823504-172.17.0.7-1597515677423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46837,DS-963b6a96-34e4-4b00-ac0e-6244eed69edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-19e884b6-f95a-4c63-94f0-1126a6bd2192,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-22179387-a02e-4e1b-bade-e96bf78cb6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-cad22dc5-187d-42f9-bf37-ba6ac36659b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-79fbe3ab-12ec-4e82-860d-bfae9d5de897,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-27daa2d2-9378-4a8d-88d0-789af0c20202,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-5c2bcbac-4b83-4c59-a765-79ca5a8fe2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-af85bef5-bd3a-4c57-9bfb-d290813b739a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488823504-172.17.0.7-1597515677423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46837,DS-963b6a96-34e4-4b00-ac0e-6244eed69edb,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-19e884b6-f95a-4c63-94f0-1126a6bd2192,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-22179387-a02e-4e1b-bade-e96bf78cb6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-cad22dc5-187d-42f9-bf37-ba6ac36659b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-79fbe3ab-12ec-4e82-860d-bfae9d5de897,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-27daa2d2-9378-4a8d-88d0-789af0c20202,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-5c2bcbac-4b83-4c59-a765-79ca5a8fe2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-af85bef5-bd3a-4c57-9bfb-d290813b739a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782753745-172.17.0.7-1597515721053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-bc168e70-3944-413b-af08-20aee60ead48,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-727048bb-5cc4-48f6-9806-4976d8ce41b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-8b7ff3b5-75c4-477b-aff6-0d0bc5b12128,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-ccdf63f2-ff63-4d1d-a297-0fef244fade9,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-050b76cc-ad56-4f32-ba6a-3ee92c2861ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-0ef3f8da-c970-464d-aadc-2d7c011ce775,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-75a2c7c2-ea0a-401a-9308-7e11ae98e30d,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-ecac540a-2d7f-4476-bd02-34980abf43d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-782753745-172.17.0.7-1597515721053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-bc168e70-3944-413b-af08-20aee60ead48,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-727048bb-5cc4-48f6-9806-4976d8ce41b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-8b7ff3b5-75c4-477b-aff6-0d0bc5b12128,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-ccdf63f2-ff63-4d1d-a297-0fef244fade9,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-050b76cc-ad56-4f32-ba6a-3ee92c2861ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-0ef3f8da-c970-464d-aadc-2d7c011ce775,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-75a2c7c2-ea0a-401a-9308-7e11ae98e30d,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-ecac540a-2d7f-4476-bd02-34980abf43d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479020995-172.17.0.7-1597515790843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43553,DS-32f72401-2e72-4204-b358-845911dd2606,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-30c8de51-0daf-42ba-9694-5102123db0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-3f049431-3594-4709-9f6d-58478a1e3245,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-c372fc87-9018-41ec-865b-8bfd85fb1b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-832a68b0-df8d-4328-a72d-aa4bfbe71707,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-ddb0d0cd-024f-4852-a9f7-8531563b146c,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-8105e5e6-abfc-48b9-91bb-324743dcc3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-647493b6-d913-4d9b-8551-e4519871922c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479020995-172.17.0.7-1597515790843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43553,DS-32f72401-2e72-4204-b358-845911dd2606,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-30c8de51-0daf-42ba-9694-5102123db0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-3f049431-3594-4709-9f6d-58478a1e3245,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-c372fc87-9018-41ec-865b-8bfd85fb1b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-832a68b0-df8d-4328-a72d-aa4bfbe71707,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-ddb0d0cd-024f-4852-a9f7-8531563b146c,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-8105e5e6-abfc-48b9-91bb-324743dcc3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-647493b6-d913-4d9b-8551-e4519871922c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604392898-172.17.0.7-1597515831536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37322,DS-aeb3baf2-4c68-44d4-a64c-6379d98e3eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-98efa42d-ea0c-400b-84b7-259629a8c320,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-2d6077b3-bf8c-4e86-a493-b8787a653318,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-3b8a40e0-fa03-4bec-9bfc-55e419ac07a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-1d029521-6007-4fd1-a542-35a62860a4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-a004f1fa-a330-4394-898c-c8a044b0d666,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-b200ffa5-bedf-4237-8a16-aab3da10f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-444903f7-96ac-4771-b323-6a05eff40c9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604392898-172.17.0.7-1597515831536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37322,DS-aeb3baf2-4c68-44d4-a64c-6379d98e3eed,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-98efa42d-ea0c-400b-84b7-259629a8c320,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-2d6077b3-bf8c-4e86-a493-b8787a653318,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-3b8a40e0-fa03-4bec-9bfc-55e419ac07a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-1d029521-6007-4fd1-a542-35a62860a4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-a004f1fa-a330-4394-898c-c8a044b0d666,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-b200ffa5-bedf-4237-8a16-aab3da10f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-444903f7-96ac-4771-b323-6a05eff40c9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061514523-172.17.0.7-1597516026582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-01273439-8b76-4290-a746-4bf8002c3827,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-ba0e0a9a-8975-4dba-a3cb-bb980f6769e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-18bd0bc3-8d74-46d1-8d75-3488ee7915ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-2d8d56d3-690c-42a0-99de-45a748df80eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-a2dd8eca-8c54-4bfa-bda7-4d01959c1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-bbdd22ae-4ac5-480f-9b8b-896bf57c4b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-35db507b-ddfa-41ca-9250-a7cc5eb4cb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-2c714395-e3ac-42f4-a753-193daa582226,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061514523-172.17.0.7-1597516026582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-01273439-8b76-4290-a746-4bf8002c3827,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-ba0e0a9a-8975-4dba-a3cb-bb980f6769e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-18bd0bc3-8d74-46d1-8d75-3488ee7915ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-2d8d56d3-690c-42a0-99de-45a748df80eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-a2dd8eca-8c54-4bfa-bda7-4d01959c1afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-bbdd22ae-4ac5-480f-9b8b-896bf57c4b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-35db507b-ddfa-41ca-9250-a7cc5eb4cb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-2c714395-e3ac-42f4-a753-193daa582226,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378322293-172.17.0.7-1597516176102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-6ad8c9f0-64da-48b6-8acb-c57047f82771,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-6be26c64-e607-41ae-b75d-435390c9fdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-5edcf56b-bdf9-4420-9d06-fe8a0865573d,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-fb8ed260-59fe-43d7-8689-831cbe90071a,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-64b01fa0-f00d-4e8b-9097-9f266e49a09d,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-2882b75b-8b38-42d7-93e7-28239edf0112,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-736c0301-49e7-4909-8953-0f918d59d060,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-e041a64a-c768-45bb-88fe-a2e5a098906c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378322293-172.17.0.7-1597516176102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39225,DS-6ad8c9f0-64da-48b6-8acb-c57047f82771,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-6be26c64-e607-41ae-b75d-435390c9fdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-5edcf56b-bdf9-4420-9d06-fe8a0865573d,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-fb8ed260-59fe-43d7-8689-831cbe90071a,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-64b01fa0-f00d-4e8b-9097-9f266e49a09d,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-2882b75b-8b38-42d7-93e7-28239edf0112,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-736c0301-49e7-4909-8953-0f918d59d060,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-e041a64a-c768-45bb-88fe-a2e5a098906c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092921694-172.17.0.7-1597516579171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-169c8076-bb0c-46f9-8ddf-5d4d61fa0c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-c7142004-71e1-4413-a936-d8d394febd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-27014f78-24ca-4f2f-8c14-8ebe5571abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-66cb8eb6-9868-4a45-b8a4-82a2104d4914,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-dec3e83e-13ba-4cfe-9fe1-6c0633501fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-3eb2e80f-62c0-41b0-8cab-f9b012f5ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-c5585024-51a3-48ef-9188-413025869afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-ac923314-36fb-4797-8272-b589748c17a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092921694-172.17.0.7-1597516579171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-169c8076-bb0c-46f9-8ddf-5d4d61fa0c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-c7142004-71e1-4413-a936-d8d394febd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-27014f78-24ca-4f2f-8c14-8ebe5571abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-66cb8eb6-9868-4a45-b8a4-82a2104d4914,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-dec3e83e-13ba-4cfe-9fe1-6c0633501fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-3eb2e80f-62c0-41b0-8cab-f9b012f5ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-c5585024-51a3-48ef-9188-413025869afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-ac923314-36fb-4797-8272-b589748c17a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672939666-172.17.0.7-1597516676038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-2fbf28a0-5d75-499e-89cf-9d3ddeee0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-30a02462-ffeb-4a37-ba08-55311d10b972,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-925476c5-164f-44a7-9604-da0297b54a09,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-5946155f-a415-4fed-b489-e7b0d5e44a85,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-ec115dab-240a-405e-9055-ba3a4f065130,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-bef78aa5-c9f0-4fbd-be98-40aba26604b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-89af132c-04d0-425c-9261-ca82a3a5790e,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-224b95c1-d297-4574-9316-5deefd3258e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672939666-172.17.0.7-1597516676038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-2fbf28a0-5d75-499e-89cf-9d3ddeee0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-30a02462-ffeb-4a37-ba08-55311d10b972,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-925476c5-164f-44a7-9604-da0297b54a09,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-5946155f-a415-4fed-b489-e7b0d5e44a85,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-ec115dab-240a-405e-9055-ba3a4f065130,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-bef78aa5-c9f0-4fbd-be98-40aba26604b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-89af132c-04d0-425c-9261-ca82a3a5790e,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-224b95c1-d297-4574-9316-5deefd3258e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478806244-172.17.0.7-1597516711845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-75a0e4ba-12b7-41c1-b5ec-6a4771d40e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-ac8cdf48-3eb3-42db-adfa-63bd5667fb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-263c4fab-1490-42e2-9158-067b333ac2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-d3010cea-8d0a-4306-945d-48a8cc917256,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-40ac5b21-3013-4ecd-a8f3-9f7107aaf22b,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-cfac2f92-c34a-4a44-b2f2-e205b1482cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-59230c3e-315c-4cce-a792-9805820009a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-a2e44ab8-b260-4d6b-8bb2-616ebdb25533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478806244-172.17.0.7-1597516711845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-75a0e4ba-12b7-41c1-b5ec-6a4771d40e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-ac8cdf48-3eb3-42db-adfa-63bd5667fb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-263c4fab-1490-42e2-9158-067b333ac2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-d3010cea-8d0a-4306-945d-48a8cc917256,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-40ac5b21-3013-4ecd-a8f3-9f7107aaf22b,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-cfac2f92-c34a-4a44-b2f2-e205b1482cad,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-59230c3e-315c-4cce-a792-9805820009a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-a2e44ab8-b260-4d6b-8bb2-616ebdb25533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781460487-172.17.0.7-1597516783344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34028,DS-2e9267a7-8f86-4f3b-90a1-9a90da694cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-b69664af-ec97-4982-884c-1d89b9f4c6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-84cdf754-5228-4cfb-8f6a-aa0dcdee4991,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-e26369f4-6a57-409f-b8fc-d041ede8f5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-efe9f3d2-2bb9-488e-bf54-7afaa60c6966,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-3cdc205e-15ca-410d-a745-51b1bbd97d45,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-ecb544db-8cc1-46cf-84a8-8c630e20a515,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-1b76c846-d356-40ea-8d39-b8e14210ea38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781460487-172.17.0.7-1597516783344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34028,DS-2e9267a7-8f86-4f3b-90a1-9a90da694cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-b69664af-ec97-4982-884c-1d89b9f4c6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-84cdf754-5228-4cfb-8f6a-aa0dcdee4991,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-e26369f4-6a57-409f-b8fc-d041ede8f5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-efe9f3d2-2bb9-488e-bf54-7afaa60c6966,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-3cdc205e-15ca-410d-a745-51b1bbd97d45,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-ecb544db-8cc1-46cf-84a8-8c630e20a515,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-1b76c846-d356-40ea-8d39-b8e14210ea38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123884805-172.17.0.7-1597516922274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43571,DS-52121aac-41fa-4ef1-8ff1-509fad1565e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-7878ba93-bc4e-4b7d-b82c-1d05536f7206,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-6e16941e-b0f6-45f4-8063-8d78b2303af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-292a9cc8-c8c7-4e4c-8f14-f95a205ff3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-20d109aa-b90f-4b27-b798-9cf446b101f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-e9539ca9-ae58-49c2-82da-392cc28bcb99,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-6be94c1a-d5d6-412a-903d-d5f5a78287b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-c243359f-ba95-4c45-935c-66016dbbc137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123884805-172.17.0.7-1597516922274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43571,DS-52121aac-41fa-4ef1-8ff1-509fad1565e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-7878ba93-bc4e-4b7d-b82c-1d05536f7206,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-6e16941e-b0f6-45f4-8063-8d78b2303af6,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-292a9cc8-c8c7-4e4c-8f14-f95a205ff3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-20d109aa-b90f-4b27-b798-9cf446b101f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-e9539ca9-ae58-49c2-82da-392cc28bcb99,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-6be94c1a-d5d6-412a-903d-d5f5a78287b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-c243359f-ba95-4c45-935c-66016dbbc137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524136898-172.17.0.7-1597517024886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-110f9540-3fe2-4f13-acdc-ef19ab372c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-dc067dd2-685e-4000-af22-7a5b6eba16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-5b2643ff-1934-4b5b-ad50-5c53b88e5df7,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-2f289d56-14a2-4931-bb8c-10cabf47cc14,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-9d0f3b21-458c-487c-9b1d-aabae0c318ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-5d314e69-b6c4-41d0-9398-298ff8a86c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-ad593bc3-4cd4-407c-b036-17afee5478d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-47246a92-dc08-45c5-b5b8-5021054cb20f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524136898-172.17.0.7-1597517024886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-110f9540-3fe2-4f13-acdc-ef19ab372c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-dc067dd2-685e-4000-af22-7a5b6eba16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-5b2643ff-1934-4b5b-ad50-5c53b88e5df7,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-2f289d56-14a2-4931-bb8c-10cabf47cc14,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-9d0f3b21-458c-487c-9b1d-aabae0c318ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-5d314e69-b6c4-41d0-9398-298ff8a86c96,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-ad593bc3-4cd4-407c-b036-17afee5478d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-47246a92-dc08-45c5-b5b8-5021054cb20f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596215626-172.17.0.7-1597517060071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-9c7d2b1d-c384-45d4-af3a-7debd994ceca,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-7142dfac-3eab-43d4-be62-6719c076a73c,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-4e73cfff-274d-4650-ab09-493ed05636bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-5c0bcf71-fdbc-4601-a299-a22f4b376f33,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-e80201a6-8e8f-4306-afc1-701e7a590f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-57507f0f-008d-4958-9479-104de59fd307,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-0cdc0144-a1ff-4398-a1fa-cb3507934754,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-1a400ec4-f0f0-4afe-8a5b-6208e7ae60a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596215626-172.17.0.7-1597517060071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43310,DS-9c7d2b1d-c384-45d4-af3a-7debd994ceca,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-7142dfac-3eab-43d4-be62-6719c076a73c,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-4e73cfff-274d-4650-ab09-493ed05636bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-5c0bcf71-fdbc-4601-a299-a22f4b376f33,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-e80201a6-8e8f-4306-afc1-701e7a590f38,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-57507f0f-008d-4958-9479-104de59fd307,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-0cdc0144-a1ff-4398-a1fa-cb3507934754,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-1a400ec4-f0f0-4afe-8a5b-6208e7ae60a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046501285-172.17.0.7-1597517108044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35768,DS-32fbb3bb-f940-4d89-a244-ab48213152c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-f88dfdd9-dc4c-422f-a2d4-33a1c15d14b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-eab762f5-3cce-470a-97ae-197bfc9acdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-c18b5390-d0f6-43ea-b4df-5bd1b3b2f8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-4d13f90a-1b22-450e-aa80-e33267831871,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-2f4abc57-34c1-48d6-af21-9e5c9aea1b95,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-7f7d2b06-0b15-4182-8652-ccebe53d7af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-b943bd86-3449-4d35-9eb0-178e810e8717,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046501285-172.17.0.7-1597517108044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35768,DS-32fbb3bb-f940-4d89-a244-ab48213152c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-f88dfdd9-dc4c-422f-a2d4-33a1c15d14b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-eab762f5-3cce-470a-97ae-197bfc9acdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-c18b5390-d0f6-43ea-b4df-5bd1b3b2f8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-4d13f90a-1b22-450e-aa80-e33267831871,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-2f4abc57-34c1-48d6-af21-9e5c9aea1b95,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-7f7d2b06-0b15-4182-8652-ccebe53d7af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-b943bd86-3449-4d35-9eb0-178e810e8717,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123812331-172.17.0.7-1597517143589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37412,DS-5f91bdda-5e3c-4dc4-8544-ce16fe343ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-9c5229e6-292a-4d7c-83c4-bdd3742425c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-3abda83f-df2c-4604-8060-93dacf9d335b,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-d3e979fd-c966-4ae7-8f60-e73cb9fbd4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-9a18a2b0-7f29-4005-9520-a622d7ac5adb,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-25a52755-93c9-4027-a658-8977c9d7f17c,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-15797720-7f37-4039-94e0-2eec7f08304f,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-d2bfd9cc-3501-46c4-b91a-0bbff7c862a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123812331-172.17.0.7-1597517143589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37412,DS-5f91bdda-5e3c-4dc4-8544-ce16fe343ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-9c5229e6-292a-4d7c-83c4-bdd3742425c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-3abda83f-df2c-4604-8060-93dacf9d335b,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-d3e979fd-c966-4ae7-8f60-e73cb9fbd4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-9a18a2b0-7f29-4005-9520-a622d7ac5adb,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-25a52755-93c9-4027-a658-8977c9d7f17c,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-15797720-7f37-4039-94e0-2eec7f08304f,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-d2bfd9cc-3501-46c4-b91a-0bbff7c862a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456018911-172.17.0.7-1597517253989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39445,DS-41439c09-ade3-4ff7-b43d-8a8445cfa1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-75fee263-0aa1-4578-bfc1-de8bb9929d94,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-af69e51b-436b-4dac-bcca-b83413e359d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-db608578-aa1d-4988-918c-c7897a1710e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-e00e7fb3-ed20-4899-af98-41165cfb6c42,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-e2796939-8f59-41d2-93ae-692dd90d5561,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-69434cec-d7a1-4234-b1fd-90b95a5316be,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-86000a67-81ce-4da5-9320-28bfbc5e3b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456018911-172.17.0.7-1597517253989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39445,DS-41439c09-ade3-4ff7-b43d-8a8445cfa1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-75fee263-0aa1-4578-bfc1-de8bb9929d94,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-af69e51b-436b-4dac-bcca-b83413e359d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-db608578-aa1d-4988-918c-c7897a1710e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-e00e7fb3-ed20-4899-af98-41165cfb6c42,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-e2796939-8f59-41d2-93ae-692dd90d5561,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-69434cec-d7a1-4234-b1fd-90b95a5316be,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-86000a67-81ce-4da5-9320-28bfbc5e3b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666758340-172.17.0.7-1597517325475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41294,DS-a4dca853-fd42-4f96-b3db-5400ff3c87f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-d9cf0273-4ea6-4aaf-a268-0e8a50b015b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-484b6dfb-4b00-4c5c-a318-ed7f10a183c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-e98ff6a7-0cbc-4e91-9d27-02293e94a015,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-40b62be6-2b5c-45d5-91f6-0fa6b92fb4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-17aaa171-c740-4fa1-b555-4cc5165009f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-d729f7b6-3fcc-4d61-b87a-8f0177a5c4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-4fed9eb0-7a5e-4bd5-80a2-ef6bfbe6010c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666758340-172.17.0.7-1597517325475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41294,DS-a4dca853-fd42-4f96-b3db-5400ff3c87f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-d9cf0273-4ea6-4aaf-a268-0e8a50b015b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-484b6dfb-4b00-4c5c-a318-ed7f10a183c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-e98ff6a7-0cbc-4e91-9d27-02293e94a015,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-40b62be6-2b5c-45d5-91f6-0fa6b92fb4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-17aaa171-c740-4fa1-b555-4cc5165009f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-d729f7b6-3fcc-4d61-b87a-8f0177a5c4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-4fed9eb0-7a5e-4bd5-80a2-ef6bfbe6010c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219082201-172.17.0.7-1597517636560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36203,DS-990aa778-85f1-4697-bc71-af45ca1f82df,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-e9be739e-e403-4c9d-922e-c062a69380c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-29ebcbdb-d15d-4903-adb3-380ef6eacecd,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-8093bae0-ce15-43a9-b82c-c0bbda284448,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-fc57af21-d7a2-44a7-b189-0a459e7a08d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-3135fb54-b5df-4822-9dc3-5b31639a6d53,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-0802e225-8618-473c-8442-a75118f0ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-8724e41f-d025-4278-94c8-c3253c929d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219082201-172.17.0.7-1597517636560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36203,DS-990aa778-85f1-4697-bc71-af45ca1f82df,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-e9be739e-e403-4c9d-922e-c062a69380c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-29ebcbdb-d15d-4903-adb3-380ef6eacecd,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-8093bae0-ce15-43a9-b82c-c0bbda284448,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-fc57af21-d7a2-44a7-b189-0a459e7a08d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-3135fb54-b5df-4822-9dc3-5b31639a6d53,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-0802e225-8618-473c-8442-a75118f0ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-8724e41f-d025-4278-94c8-c3253c929d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718445002-172.17.0.7-1597517674982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46088,DS-638bef28-1a44-4243-af00-51ce31fa2b15,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-faefeea0-ff25-46bb-b040-948f21bd8c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-836cf46a-f76f-4df7-b576-658f202a9c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-f305bdef-7619-4cae-bb37-10b5e68395d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-5aa3a521-41bb-4583-a493-0c6a47f578d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-12d74e01-5cd2-4979-a929-e46e2889cd87,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-d11a71f7-7110-4f5a-9211-dcc940bdf3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-7381018e-3913-4200-b311-6cd4d116ef27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718445002-172.17.0.7-1597517674982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46088,DS-638bef28-1a44-4243-af00-51ce31fa2b15,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-faefeea0-ff25-46bb-b040-948f21bd8c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-836cf46a-f76f-4df7-b576-658f202a9c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-f305bdef-7619-4cae-bb37-10b5e68395d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-5aa3a521-41bb-4583-a493-0c6a47f578d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-12d74e01-5cd2-4979-a929-e46e2889cd87,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-d11a71f7-7110-4f5a-9211-dcc940bdf3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-7381018e-3913-4200-b311-6cd4d116ef27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107726738-172.17.0.7-1597517716413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44303,DS-bb8f497a-9a50-41c6-ba51-ee7b1c6c2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-5aa1fc12-62f5-4db1-b0dd-5eca2cceeaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-25e100a6-7334-4a6b-b81c-035a155b98ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-35bc32a0-1c39-4742-94e6-29e3cf72081e,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-d7ba7f2c-d54b-42b8-8931-54e7b2bb5c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-06a9cef9-d109-4318-ac40-0c3f155b360f,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-01e3663d-92ad-4804-8a80-0b03c2f6c90d,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-d7b9bdd3-3570-4e20-9e1f-68fb634a470b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107726738-172.17.0.7-1597517716413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44303,DS-bb8f497a-9a50-41c6-ba51-ee7b1c6c2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-5aa1fc12-62f5-4db1-b0dd-5eca2cceeaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-25e100a6-7334-4a6b-b81c-035a155b98ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-35bc32a0-1c39-4742-94e6-29e3cf72081e,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-d7ba7f2c-d54b-42b8-8931-54e7b2bb5c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-06a9cef9-d109-4318-ac40-0c3f155b360f,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-01e3663d-92ad-4804-8a80-0b03c2f6c90d,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-d7b9bdd3-3570-4e20-9e1f-68fb634a470b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088619244-172.17.0.7-1597517828444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-36063534-472d-42bf-997f-55acc73e0296,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-2cd4c3c9-66e7-46b8-b972-34ef7ac7a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-32ebf396-8e75-4111-b6d7-885b36186ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-849399a2-03e3-4c1d-b3b0-956a8132de12,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-d33c556e-0755-4ff3-962e-623cbb372bee,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-7c732376-d3c8-4abe-9796-cee20b6f15f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-7f4909fa-efb8-4f17-95b7-24127cb7c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-9bd35b72-088f-4171-9f30-d45cd2f68ffc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088619244-172.17.0.7-1597517828444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41998,DS-36063534-472d-42bf-997f-55acc73e0296,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-2cd4c3c9-66e7-46b8-b972-34ef7ac7a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-32ebf396-8e75-4111-b6d7-885b36186ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-849399a2-03e3-4c1d-b3b0-956a8132de12,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-d33c556e-0755-4ff3-962e-623cbb372bee,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-7c732376-d3c8-4abe-9796-cee20b6f15f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-7f4909fa-efb8-4f17-95b7-24127cb7c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-9bd35b72-088f-4171-9f30-d45cd2f68ffc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625072596-172.17.0.7-1597518127666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-a67add3b-5955-4b77-bb07-bc9c6e49aa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-3e2a6d25-f07b-456b-9b70-cb9813cdfe45,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-b21299be-8572-4cd6-a46f-df76b1cfeb24,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-8cfec3f4-1d45-45da-b014-7e3704897793,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-7dac1701-c068-4d3f-8d4b-51bb91dbcc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-ebbb6288-ee5f-415b-8ca6-38eea7f3b191,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-d2330954-0e4e-4dcc-92f6-da2a3bf44bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-57a884fc-0c2a-4ace-8e3d-e66386c60455,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625072596-172.17.0.7-1597518127666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-a67add3b-5955-4b77-bb07-bc9c6e49aa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-3e2a6d25-f07b-456b-9b70-cb9813cdfe45,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-b21299be-8572-4cd6-a46f-df76b1cfeb24,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-8cfec3f4-1d45-45da-b014-7e3704897793,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-7dac1701-c068-4d3f-8d4b-51bb91dbcc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-ebbb6288-ee5f-415b-8ca6-38eea7f3b191,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-d2330954-0e4e-4dcc-92f6-da2a3bf44bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-57a884fc-0c2a-4ace-8e3d-e66386c60455,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173420011-172.17.0.7-1597518241255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-8a1ce523-0253-4079-b9b7-90d1dbe2166c,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-2d8a62a4-d4a3-4a73-b9b8-ecd100d6c959,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-68c9032a-0432-4268-99c4-62a8935dc54a,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-038a7a0c-424b-4a4a-905c-92da8c9bcbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-5cea2fc7-81dc-45f1-be81-f44e3abf4a95,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-19c99ef8-db12-4d16-97b7-8f7d78199839,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-9ae72179-6a54-4bd9-b614-700e79826d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-612977a6-3b47-4c78-bff5-bbada47ee01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173420011-172.17.0.7-1597518241255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-8a1ce523-0253-4079-b9b7-90d1dbe2166c,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-2d8a62a4-d4a3-4a73-b9b8-ecd100d6c959,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-68c9032a-0432-4268-99c4-62a8935dc54a,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-038a7a0c-424b-4a4a-905c-92da8c9bcbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-5cea2fc7-81dc-45f1-be81-f44e3abf4a95,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-19c99ef8-db12-4d16-97b7-8f7d78199839,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-9ae72179-6a54-4bd9-b614-700e79826d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-612977a6-3b47-4c78-bff5-bbada47ee01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221109474-172.17.0.7-1597518510813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-fa09514c-bf9e-40b5-a24a-82c53fd6fc13,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-f9f5e34b-f6fe-445e-8431-530266afe3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-e90b52ff-093e-4632-b220-f2c0c37d90c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-674c6244-c114-4a56-8f2c-787ab7ea306d,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-74416562-8410-46cb-9729-a789d3e4027c,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-cb4b7817-33ba-40ab-9f47-1776fd91b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-a175a882-5981-43e0-a371-c8db6bc50277,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-fece5a7c-0581-41bc-b02b-5482a5b35203,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221109474-172.17.0.7-1597518510813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46809,DS-fa09514c-bf9e-40b5-a24a-82c53fd6fc13,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-f9f5e34b-f6fe-445e-8431-530266afe3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-e90b52ff-093e-4632-b220-f2c0c37d90c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-674c6244-c114-4a56-8f2c-787ab7ea306d,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-74416562-8410-46cb-9729-a789d3e4027c,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-cb4b7817-33ba-40ab-9f47-1776fd91b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-a175a882-5981-43e0-a371-c8db6bc50277,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-fece5a7c-0581-41bc-b02b-5482a5b35203,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 27 out of 50
result: false positive !!!
Total execution time in seconds : 5558
