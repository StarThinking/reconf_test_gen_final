reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592866012-172.17.0.11-1597461763546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44168,DS-d2990488-6432-46fe-b675-83b8ac041eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-f31c59e2-a801-4539-81c2-bbafbcdbd682,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-f529b787-a9b3-41ab-aa7b-975bf9c3c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-971a7f1b-c9d7-4545-beb5-2efe6ec7b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-3a660ed2-f1a5-422e-bdcb-b8dfb101f923,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-c1347d4f-4456-4a13-b954-5c2aa2466475,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-6537b29b-78f8-43d7-ac4e-c22a74923e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-3f5bdaec-a0f8-4761-9a95-2478b6bb3cfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592866012-172.17.0.11-1597461763546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44168,DS-d2990488-6432-46fe-b675-83b8ac041eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-f31c59e2-a801-4539-81c2-bbafbcdbd682,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-f529b787-a9b3-41ab-aa7b-975bf9c3c72a,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-971a7f1b-c9d7-4545-beb5-2efe6ec7b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-3a660ed2-f1a5-422e-bdcb-b8dfb101f923,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-c1347d4f-4456-4a13-b954-5c2aa2466475,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-6537b29b-78f8-43d7-ac4e-c22a74923e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-3f5bdaec-a0f8-4761-9a95-2478b6bb3cfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788810698-172.17.0.11-1597462625028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41307,DS-c374bc12-e7e3-400a-afaa-e94113af9fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-10d6497f-0859-4c96-82a3-05141ab0c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-3f283914-31ea-419f-b3e2-cbf1abaccf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-f2f8eb88-3ec1-401e-a904-abbd64f34f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-64fd98c3-09aa-4711-ba88-5d256230303e,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-371a45c8-6467-4ea3-802c-ba2b30f94a63,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-a0cfd0c9-672c-4f23-bd1f-09f2c825b316,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-9d6d3da8-bea6-4e10-9e73-0cf3805929f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788810698-172.17.0.11-1597462625028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41307,DS-c374bc12-e7e3-400a-afaa-e94113af9fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-10d6497f-0859-4c96-82a3-05141ab0c75a,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-3f283914-31ea-419f-b3e2-cbf1abaccf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-f2f8eb88-3ec1-401e-a904-abbd64f34f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-64fd98c3-09aa-4711-ba88-5d256230303e,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-371a45c8-6467-4ea3-802c-ba2b30f94a63,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-a0cfd0c9-672c-4f23-bd1f-09f2c825b316,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-9d6d3da8-bea6-4e10-9e73-0cf3805929f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906795754-172.17.0.11-1597462700244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-754eeebe-1936-4081-a0ff-ea0463f81b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-cf0c7a03-97ce-482c-96eb-79c168707ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-0a7c992a-cee2-42a9-8df1-a10e1327f66a,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-128cbc87-c641-4225-9284-85b6ad04abff,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-123e2282-71c1-448f-8188-31d93ec77df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-2bad3bf0-9748-4b31-ba7d-ce66e7c270b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-f17d39d0-eaf8-4801-b3ad-07e9e472e093,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-2d869fb1-592b-40fd-bd89-0c68f7244681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906795754-172.17.0.11-1597462700244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34108,DS-754eeebe-1936-4081-a0ff-ea0463f81b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-cf0c7a03-97ce-482c-96eb-79c168707ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-0a7c992a-cee2-42a9-8df1-a10e1327f66a,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-128cbc87-c641-4225-9284-85b6ad04abff,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-123e2282-71c1-448f-8188-31d93ec77df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-2bad3bf0-9748-4b31-ba7d-ce66e7c270b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-f17d39d0-eaf8-4801-b3ad-07e9e472e093,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-2d869fb1-592b-40fd-bd89-0c68f7244681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658697856-172.17.0.11-1597462884794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-0b7f2640-12f1-4a5e-a6f5-a8834e9b18db,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-0fca2927-1e2b-4781-8a02-f100a22f9eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-8db2195e-f63c-43ed-90f5-07cfb5467cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-4233ab27-b59a-4287-8474-eb110dc40f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-7ae040ee-16d2-4560-85e9-8c736826c84c,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-e50e5831-6c64-4490-98f0-0bbbc4cf7f05,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-676652fd-c04f-4830-b24a-3593da89604d,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-9b7e1a19-6eee-4d7b-ae19-8993f8d23e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658697856-172.17.0.11-1597462884794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-0b7f2640-12f1-4a5e-a6f5-a8834e9b18db,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-0fca2927-1e2b-4781-8a02-f100a22f9eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-8db2195e-f63c-43ed-90f5-07cfb5467cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-4233ab27-b59a-4287-8474-eb110dc40f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-7ae040ee-16d2-4560-85e9-8c736826c84c,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-e50e5831-6c64-4490-98f0-0bbbc4cf7f05,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-676652fd-c04f-4830-b24a-3593da89604d,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-9b7e1a19-6eee-4d7b-ae19-8993f8d23e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186915850-172.17.0.11-1597463024762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-68e968e2-ef28-4df4-a1e0-6f69a6249bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-fb56d70d-dd1c-4517-aa51-298af17c3761,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-91b98804-c40d-4c9a-b1ab-ed94b065cfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-7c433814-2462-49a4-8653-d6842c08a66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-728eadf8-374f-42fc-b3fe-677bc75bb93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-e9afc4f5-a800-47e0-9d69-6eed47bacd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-1ca34a25-ed5c-4e0f-9744-18c1f6f35e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-c7db1df6-8ccf-4d50-bbe6-7eeb541ade7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186915850-172.17.0.11-1597463024762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-68e968e2-ef28-4df4-a1e0-6f69a6249bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-fb56d70d-dd1c-4517-aa51-298af17c3761,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-91b98804-c40d-4c9a-b1ab-ed94b065cfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-7c433814-2462-49a4-8653-d6842c08a66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-728eadf8-374f-42fc-b3fe-677bc75bb93d,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-e9afc4f5-a800-47e0-9d69-6eed47bacd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-1ca34a25-ed5c-4e0f-9744-18c1f6f35e75,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-c7db1df6-8ccf-4d50-bbe6-7eeb541ade7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353933124-172.17.0.11-1597463228989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-d92a3048-20e9-49a9-8e12-389230736019,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-174cbc19-72ad-4c60-9c77-798fa56f0dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-c70a878e-df63-4192-9200-4519ff7dd7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-9bd909a2-8081-4c87-9d45-ce24145fb86c,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-97800a32-270d-47a2-87c6-9f626a645c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-19fd42eb-3203-4070-802a-19b04ff238fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-94221f25-63b4-467f-b549-9a961c5315b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-6423fa1d-f29e-49c3-8e38-cee8b821129d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353933124-172.17.0.11-1597463228989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-d92a3048-20e9-49a9-8e12-389230736019,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-174cbc19-72ad-4c60-9c77-798fa56f0dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-c70a878e-df63-4192-9200-4519ff7dd7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-9bd909a2-8081-4c87-9d45-ce24145fb86c,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-97800a32-270d-47a2-87c6-9f626a645c15,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-19fd42eb-3203-4070-802a-19b04ff238fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-94221f25-63b4-467f-b549-9a961c5315b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-6423fa1d-f29e-49c3-8e38-cee8b821129d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343280936-172.17.0.11-1597463375359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-f0a5d68e-4088-4dc5-87bc-92bb79c8aa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-15fb3024-aa83-45f0-bcaa-70bdf79b57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-3b6dd8c4-aa67-461a-ab44-c00679517950,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-0d7af247-cd4f-4747-8034-99733b4365f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-d3a865b3-d759-4816-95d6-991481b59047,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-3c39d1d2-6735-4d39-bdf6-0813a94b6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-3fd2bb6c-cd65-48d5-8746-e5d89799d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-5256e47b-67f6-4cd4-a92d-133e72e17f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343280936-172.17.0.11-1597463375359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37707,DS-f0a5d68e-4088-4dc5-87bc-92bb79c8aa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-15fb3024-aa83-45f0-bcaa-70bdf79b57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-3b6dd8c4-aa67-461a-ab44-c00679517950,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-0d7af247-cd4f-4747-8034-99733b4365f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-d3a865b3-d759-4816-95d6-991481b59047,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-3c39d1d2-6735-4d39-bdf6-0813a94b6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-3fd2bb6c-cd65-48d5-8746-e5d89799d52a,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-5256e47b-67f6-4cd4-a92d-133e72e17f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204284164-172.17.0.11-1597463644965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37129,DS-ce72eea1-66cc-47ff-b0b9-4febc5827011,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-9d774eb8-5b90-401c-b967-539db9363fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-9da82572-72c8-4e97-ab2d-0a857b61d427,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-f895cb08-ea6e-463d-9eb5-c75a867b525c,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-d9dbc9dc-b466-4749-9010-df8bad7ccb23,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-290eeaed-1c6a-42b9-9294-6dcdb107217a,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-9b73ea5d-1076-411c-9d4e-06738782ae83,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-5560c7c3-f48c-4d36-b5b4-8c998c72b4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204284164-172.17.0.11-1597463644965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37129,DS-ce72eea1-66cc-47ff-b0b9-4febc5827011,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-9d774eb8-5b90-401c-b967-539db9363fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-9da82572-72c8-4e97-ab2d-0a857b61d427,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-f895cb08-ea6e-463d-9eb5-c75a867b525c,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-d9dbc9dc-b466-4749-9010-df8bad7ccb23,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-290eeaed-1c6a-42b9-9294-6dcdb107217a,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-9b73ea5d-1076-411c-9d4e-06738782ae83,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-5560c7c3-f48c-4d36-b5b4-8c998c72b4e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965259421-172.17.0.11-1597463685814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46475,DS-19029c6c-81a1-4890-9663-10d80ca4e567,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-83c528e8-0ef0-47f5-b1bb-40738625b508,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-6c09d47f-c641-4719-8aa5-e20d5be16453,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-5939bebb-0462-443c-bf80-0bebad4b2dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-db893125-ba05-42a7-a3a0-da0fc50a4f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-754f63c0-69ef-4952-a347-0698d36d9187,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-75814cbe-7843-477d-8332-ef61c953da3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-e0b7d84f-cda7-486d-a51b-6d40fb218382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965259421-172.17.0.11-1597463685814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46475,DS-19029c6c-81a1-4890-9663-10d80ca4e567,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-83c528e8-0ef0-47f5-b1bb-40738625b508,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-6c09d47f-c641-4719-8aa5-e20d5be16453,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-5939bebb-0462-443c-bf80-0bebad4b2dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-db893125-ba05-42a7-a3a0-da0fc50a4f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-754f63c0-69ef-4952-a347-0698d36d9187,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-75814cbe-7843-477d-8332-ef61c953da3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-e0b7d84f-cda7-486d-a51b-6d40fb218382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577543380-172.17.0.11-1597464061402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36037,DS-852829dc-4ab7-46e8-aaad-bc7157378bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-05fdb2be-2ced-4358-8a20-7873e136e784,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-5ffdc609-b6f3-4771-9e71-16cb94ef2558,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-2fec65b9-1f2b-4213-b4e8-fa66ee83518a,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-519f46ec-b8d3-4fa7-9f19-392e3c252dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-569a1fa5-6118-403c-92b7-ac5c67f4dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-5f3718e3-a557-4feb-a4f4-256fab52c7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-b093645f-b586-407d-9c81-e4b831d88dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577543380-172.17.0.11-1597464061402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36037,DS-852829dc-4ab7-46e8-aaad-bc7157378bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-05fdb2be-2ced-4358-8a20-7873e136e784,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-5ffdc609-b6f3-4771-9e71-16cb94ef2558,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-2fec65b9-1f2b-4213-b4e8-fa66ee83518a,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-519f46ec-b8d3-4fa7-9f19-392e3c252dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-569a1fa5-6118-403c-92b7-ac5c67f4dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-5f3718e3-a557-4feb-a4f4-256fab52c7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-b093645f-b586-407d-9c81-e4b831d88dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452550529-172.17.0.11-1597464800333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-37c41d48-fa26-4198-997d-2478b32325cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-a78f4847-10a5-41ac-84ac-cad5236e3bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-0046277b-ccda-4dee-8052-905564f5d042,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-a7acd1bf-2918-4abc-a511-0babeb617fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-036e2b22-43d1-470d-b2cb-4153d78b1431,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-7de99ea4-7e82-4948-b96f-a40dd5116e84,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-3603aa8b-0c62-4669-8f7f-a92149f551c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-4f10779f-15f5-4542-928e-e95c93701b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452550529-172.17.0.11-1597464800333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-37c41d48-fa26-4198-997d-2478b32325cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-a78f4847-10a5-41ac-84ac-cad5236e3bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-0046277b-ccda-4dee-8052-905564f5d042,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-a7acd1bf-2918-4abc-a511-0babeb617fca,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-036e2b22-43d1-470d-b2cb-4153d78b1431,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-7de99ea4-7e82-4948-b96f-a40dd5116e84,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-3603aa8b-0c62-4669-8f7f-a92149f551c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-4f10779f-15f5-4542-928e-e95c93701b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68889782-172.17.0.11-1597465092893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38249,DS-f2cc4c3d-e681-4dd8-8eac-1e890b1c063f,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-bc5cd485-bd87-4d3d-b1cd-7218adfa8897,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-b769c923-0f62-46a9-ad35-d83e36d7ed59,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-bca507c1-974c-4abc-9337-55482ba36281,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-1b7b9bc6-ce7f-4bc9-89ee-a85c45b00e71,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-1036c337-90b2-4113-9dd8-35b25b476def,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-23aeaaf0-bc5d-4145-bc47-40ff43e3eeae,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-580dbe86-d66e-44e0-9c83-619625333b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68889782-172.17.0.11-1597465092893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38249,DS-f2cc4c3d-e681-4dd8-8eac-1e890b1c063f,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-bc5cd485-bd87-4d3d-b1cd-7218adfa8897,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-b769c923-0f62-46a9-ad35-d83e36d7ed59,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-bca507c1-974c-4abc-9337-55482ba36281,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-1b7b9bc6-ce7f-4bc9-89ee-a85c45b00e71,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-1036c337-90b2-4113-9dd8-35b25b476def,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-23aeaaf0-bc5d-4145-bc47-40ff43e3eeae,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-580dbe86-d66e-44e0-9c83-619625333b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927497361-172.17.0.11-1597465317386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-045aae0e-7777-4edf-903b-cffa20a3da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-622688e0-047a-41b3-8ecb-9a17a8d35762,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-c5d65e29-1c77-431e-9bdb-c4228d70f91e,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-e49478c0-3057-4e4d-b69b-5cc5ca8fb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-c2e85da1-7d52-4161-9864-727a91e15061,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-98494c82-81e0-4d41-9f3e-b4c9fa9d6ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-f0ecedab-7e35-4536-84cc-b3bc405af9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-a6561d74-74ff-4c50-aa47-d125a123caa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927497361-172.17.0.11-1597465317386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-045aae0e-7777-4edf-903b-cffa20a3da8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-622688e0-047a-41b3-8ecb-9a17a8d35762,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-c5d65e29-1c77-431e-9bdb-c4228d70f91e,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-e49478c0-3057-4e4d-b69b-5cc5ca8fb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-c2e85da1-7d52-4161-9864-727a91e15061,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-98494c82-81e0-4d41-9f3e-b4c9fa9d6ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-f0ecedab-7e35-4536-84cc-b3bc405af9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-a6561d74-74ff-4c50-aa47-d125a123caa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261502975-172.17.0.11-1597465599791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44622,DS-0261d760-32ef-4123-83f0-3ee865d91912,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-107723ba-982d-42bc-99d3-2333fae1050e,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-d551a371-2720-481e-8087-aded649541cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-7863c597-3550-48bd-8e49-8ac44ec22b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-a25e28b1-3b7b-4d57-a227-b122f2604e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-6062f054-9fc2-413d-8243-0a86829ef274,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-5b3ee2f9-6024-445a-ae0f-6aa38f483231,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-8962a49a-7912-4025-b2d9-3ad45d09068a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261502975-172.17.0.11-1597465599791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44622,DS-0261d760-32ef-4123-83f0-3ee865d91912,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-107723ba-982d-42bc-99d3-2333fae1050e,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-d551a371-2720-481e-8087-aded649541cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-7863c597-3550-48bd-8e49-8ac44ec22b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-a25e28b1-3b7b-4d57-a227-b122f2604e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-6062f054-9fc2-413d-8243-0a86829ef274,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-5b3ee2f9-6024-445a-ae0f-6aa38f483231,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-8962a49a-7912-4025-b2d9-3ad45d09068a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699430114-172.17.0.11-1597465708570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35130,DS-02f3e0df-bd2a-4a4c-a935-266b4abea185,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-87dae9b1-d15b-412a-9c22-ed17e62e5a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-96c09689-46fd-45e7-aee4-b6f5df6d8d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-4af7e52a-462c-48df-a2e8-36e2f0be09a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-379ff1a7-2bae-436a-a08c-fbce143fd651,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-4498a4b0-066a-4465-9036-e695738b1fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-6362d1ba-80a1-4468-832f-d2fc2a379436,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-88e645a1-390a-48b2-ae04-478c669da543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699430114-172.17.0.11-1597465708570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35130,DS-02f3e0df-bd2a-4a4c-a935-266b4abea185,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-87dae9b1-d15b-412a-9c22-ed17e62e5a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-96c09689-46fd-45e7-aee4-b6f5df6d8d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-4af7e52a-462c-48df-a2e8-36e2f0be09a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-379ff1a7-2bae-436a-a08c-fbce143fd651,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-4498a4b0-066a-4465-9036-e695738b1fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-6362d1ba-80a1-4468-832f-d2fc2a379436,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-88e645a1-390a-48b2-ae04-478c669da543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441272872-172.17.0.11-1597465888162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-616f85d5-6d3e-416b-89a8-d2ca450d3bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-3cfa1593-b78d-4f27-9ee4-933f3cf3a6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-8f4a72e6-0929-4010-9f86-e9b138ff8315,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-fc357985-654c-4b68-9d5d-bdc278fd1e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-5b7f9e03-44e3-41f8-a4f1-841cb6490359,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-780a390f-1482-43f8-9058-62c37019f7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-13f1d5db-3a42-4429-acbf-8dc4507f93d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-09313503-f5bb-4260-a242-801f1ec0bbe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441272872-172.17.0.11-1597465888162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39108,DS-616f85d5-6d3e-416b-89a8-d2ca450d3bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-3cfa1593-b78d-4f27-9ee4-933f3cf3a6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-8f4a72e6-0929-4010-9f86-e9b138ff8315,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-fc357985-654c-4b68-9d5d-bdc278fd1e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-5b7f9e03-44e3-41f8-a4f1-841cb6490359,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-780a390f-1482-43f8-9058-62c37019f7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-13f1d5db-3a42-4429-acbf-8dc4507f93d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-09313503-f5bb-4260-a242-801f1ec0bbe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633292308-172.17.0.11-1597466160937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42727,DS-9289a258-fd98-47cc-985e-160490983ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-c21709f1-fe49-439b-9846-ada706c9a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-e43855a9-68e6-49d7-92ec-7ef6c3dd60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-87cd7f64-a2bb-4d19-b43f-e143794a5788,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-025a34e8-7a6a-41c6-bdbe-7a5218dd31b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-86b55b06-d876-4531-bf5d-627e3b472848,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-d469d518-ae91-43df-b28f-14583a137de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-3bae9dd1-7d28-4942-84ac-5ac98a9334d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633292308-172.17.0.11-1597466160937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42727,DS-9289a258-fd98-47cc-985e-160490983ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-c21709f1-fe49-439b-9846-ada706c9a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-e43855a9-68e6-49d7-92ec-7ef6c3dd60a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-87cd7f64-a2bb-4d19-b43f-e143794a5788,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-025a34e8-7a6a-41c6-bdbe-7a5218dd31b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-86b55b06-d876-4531-bf5d-627e3b472848,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-d469d518-ae91-43df-b28f-14583a137de7,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-3bae9dd1-7d28-4942-84ac-5ac98a9334d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 99
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507566064-172.17.0.11-1597466190967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-1a09d1f6-0f71-4563-92e5-8cc920508d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-13ee014d-356f-4e89-8b05-b2c7aa79b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-33e48a69-ad7b-41b8-b6dc-06c13bdebbad,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-a14e3d2e-23fa-47d1-ad7f-4b130ee4bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-3bfbe9d7-6b92-4b9e-bf58-ff0ac40fcf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-c5bf48d3-0ed7-442f-bfb9-f49c19428179,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-9243d796-9974-48be-8b47-96918a81f9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-3d414bfa-62f4-41e8-b126-cfbb6a5f4236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507566064-172.17.0.11-1597466190967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-1a09d1f6-0f71-4563-92e5-8cc920508d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-13ee014d-356f-4e89-8b05-b2c7aa79b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-33e48a69-ad7b-41b8-b6dc-06c13bdebbad,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-a14e3d2e-23fa-47d1-ad7f-4b130ee4bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-3bfbe9d7-6b92-4b9e-bf58-ff0ac40fcf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-c5bf48d3-0ed7-442f-bfb9-f49c19428179,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-9243d796-9974-48be-8b47-96918a81f9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-3d414bfa-62f4-41e8-b126-cfbb6a5f4236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5280
