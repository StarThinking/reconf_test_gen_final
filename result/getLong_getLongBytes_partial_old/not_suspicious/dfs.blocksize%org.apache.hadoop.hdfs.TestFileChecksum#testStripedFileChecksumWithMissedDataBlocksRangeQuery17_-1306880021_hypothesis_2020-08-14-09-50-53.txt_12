reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646451586-172.17.0.10-1597400252343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-856f3e41-11bd-4e91-80c6-b29b7380afa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-d7e9f78b-0172-43cc-90c5-229ed140fd43,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-e847c3e6-3069-4640-bc46-b41b2fb7c125,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-ce8e3c06-b4e6-48b4-afdc-cdedb0eb92ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-b6a5d73f-8666-4c48-a3ca-be1d549645cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-e8cb5f92-30cc-401e-97b3-414728eef64d,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-2887c9fb-b7e1-4dd8-9e0a-5c92a330fe04,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-8a00960d-eb3e-4938-bd27-11c859fd9056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646451586-172.17.0.10-1597400252343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-856f3e41-11bd-4e91-80c6-b29b7380afa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-d7e9f78b-0172-43cc-90c5-229ed140fd43,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-e847c3e6-3069-4640-bc46-b41b2fb7c125,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-ce8e3c06-b4e6-48b4-afdc-cdedb0eb92ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-b6a5d73f-8666-4c48-a3ca-be1d549645cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-e8cb5f92-30cc-401e-97b3-414728eef64d,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-2887c9fb-b7e1-4dd8-9e0a-5c92a330fe04,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-8a00960d-eb3e-4938-bd27-11c859fd9056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418131253-172.17.0.10-1597400512526:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42589,DS-e3fb81cb-9dba-431e-a8c5-bd2e45caefa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-ebe23d13-b793-4a03-9143-80f59c3558d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-b24bba9a-22fa-4dc0-8c03-390cdc070513,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-d54ebefe-505c-49b0-9290-0b3bb48ac5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-9da43142-30d6-473d-8a94-e7a2c143e340,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-2b867e37-1cff-45b0-8d8e-f350bc8db35e,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-f44f4733-ff6e-4fd4-8cec-d7398aa4da10,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-47d7bca0-1007-4dd8-995b-a171b15a4d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418131253-172.17.0.10-1597400512526:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42589,DS-e3fb81cb-9dba-431e-a8c5-bd2e45caefa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-ebe23d13-b793-4a03-9143-80f59c3558d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-b24bba9a-22fa-4dc0-8c03-390cdc070513,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-d54ebefe-505c-49b0-9290-0b3bb48ac5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-9da43142-30d6-473d-8a94-e7a2c143e340,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-2b867e37-1cff-45b0-8d8e-f350bc8db35e,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-f44f4733-ff6e-4fd4-8cec-d7398aa4da10,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-47d7bca0-1007-4dd8-995b-a171b15a4d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191395739-172.17.0.10-1597400737694:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-bc17b080-3c56-4320-b653-61873940b4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-98afbe37-13d4-4f44-a4f9-e864527a4447,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-a1f1e929-eea7-4111-828e-baad61908e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-132cc31b-115e-44b3-8a7e-6fb3bd65a735,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-a985e4f0-27bc-4bcb-946d-98070ea36dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-8fcb2521-87e3-43c5-87e9-ac87c2712e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-4ca8f99d-3443-42d0-96b1-fcc999ad9418,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-b10834f5-ef4a-4af9-bf4c-8612cad4342b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191395739-172.17.0.10-1597400737694:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-bc17b080-3c56-4320-b653-61873940b4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-98afbe37-13d4-4f44-a4f9-e864527a4447,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-a1f1e929-eea7-4111-828e-baad61908e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-132cc31b-115e-44b3-8a7e-6fb3bd65a735,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-a985e4f0-27bc-4bcb-946d-98070ea36dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-8fcb2521-87e3-43c5-87e9-ac87c2712e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-4ca8f99d-3443-42d0-96b1-fcc999ad9418,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-b10834f5-ef4a-4af9-bf4c-8612cad4342b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301098300-172.17.0.10-1597401125422:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42369,DS-6e2e627a-ba53-4afc-be3c-7321e92b5918,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-323a581e-b17f-482a-a933-a0b77bf54b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-a8042e58-bc85-4ddf-ba02-b7913b5ade9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-7c8fa4e9-f68f-4944-8d0b-af3f07a27fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-0d7f808c-4627-4b9a-bf45-9354d10ec95f,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-c83a0d3e-1c08-4efc-9f01-41cddc37fcec,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-ed3a77ed-d1a9-42a4-8156-18a74ebe198b,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-f966bb96-eb6e-4523-a316-264c87d04419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301098300-172.17.0.10-1597401125422:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42369,DS-6e2e627a-ba53-4afc-be3c-7321e92b5918,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-323a581e-b17f-482a-a933-a0b77bf54b54,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-a8042e58-bc85-4ddf-ba02-b7913b5ade9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-7c8fa4e9-f68f-4944-8d0b-af3f07a27fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-0d7f808c-4627-4b9a-bf45-9354d10ec95f,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-c83a0d3e-1c08-4efc-9f01-41cddc37fcec,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-ed3a77ed-d1a9-42a4-8156-18a74ebe198b,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-f966bb96-eb6e-4523-a316-264c87d04419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226390217-172.17.0.10-1597401698212:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-c3eeff58-9005-4f79-944c-91412a75f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-45dffa88-fe65-458f-a53f-8bd5dc7e24c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-1350c75e-6644-4e97-9fc3-e544859aac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-6376d486-7c02-4d34-9af3-f27a23ce8b02,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-cf536850-f705-481a-8114-ea0bc9ff5307,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-015995fe-cf9b-4ef5-9e16-913bd12dd211,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-b98c4bcd-dfad-4418-8c59-52bd4121fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-33821579-501a-4123-84fb-4b7d15e27bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226390217-172.17.0.10-1597401698212:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46393,DS-c3eeff58-9005-4f79-944c-91412a75f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-45dffa88-fe65-458f-a53f-8bd5dc7e24c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-1350c75e-6644-4e97-9fc3-e544859aac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-6376d486-7c02-4d34-9af3-f27a23ce8b02,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-cf536850-f705-481a-8114-ea0bc9ff5307,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-015995fe-cf9b-4ef5-9e16-913bd12dd211,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-b98c4bcd-dfad-4418-8c59-52bd4121fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-33821579-501a-4123-84fb-4b7d15e27bb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145907783-172.17.0.10-1597402043061:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-861201a7-1c7a-4e4e-8411-547b146bc44d,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-1d69ed28-8d8a-4d37-8764-947fc27d7a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-1f3927bd-1dc3-4cbf-b03a-40e4fe72653c,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-b98403e1-881b-44e9-8855-8bf4506216e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-3a00887f-c079-4028-b3f1-712c1912961e,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-0ed3a976-b251-4e56-bfb8-f94a025c2c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-c2070a98-eee5-4ef7-85dd-dad20daaf8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-775300c6-5f83-4ea1-830b-351001485ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145907783-172.17.0.10-1597402043061:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-861201a7-1c7a-4e4e-8411-547b146bc44d,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-1d69ed28-8d8a-4d37-8764-947fc27d7a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-1f3927bd-1dc3-4cbf-b03a-40e4fe72653c,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-b98403e1-881b-44e9-8855-8bf4506216e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-3a00887f-c079-4028-b3f1-712c1912961e,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-0ed3a976-b251-4e56-bfb8-f94a025c2c80,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-c2070a98-eee5-4ef7-85dd-dad20daaf8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-775300c6-5f83-4ea1-830b-351001485ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928565076-172.17.0.10-1597402397138:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40784,DS-1cd57f1a-4252-4638-89c3-7342d6ac2b32,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-40d0343d-765f-4a76-86ce-cdf0b143ba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-a7d6cffd-8d91-4083-abc9-13f6e2714d20,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-f789acf7-eaf5-47b3-b0ee-261ce17ec0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-f628f43a-e9e5-4f6b-ac37-120bd4cf666e,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-d9c9a659-0800-4ca0-a72b-2f1b2ab781aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-d8709e00-6091-4e1b-ae5a-ad3c3dee058e,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-5d3e2da8-6a62-41ee-aba5-a8514fe12b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928565076-172.17.0.10-1597402397138:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40784,DS-1cd57f1a-4252-4638-89c3-7342d6ac2b32,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-40d0343d-765f-4a76-86ce-cdf0b143ba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-a7d6cffd-8d91-4083-abc9-13f6e2714d20,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-f789acf7-eaf5-47b3-b0ee-261ce17ec0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-f628f43a-e9e5-4f6b-ac37-120bd4cf666e,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-d9c9a659-0800-4ca0-a72b-2f1b2ab781aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-d8709e00-6091-4e1b-ae5a-ad3c3dee058e,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-5d3e2da8-6a62-41ee-aba5-a8514fe12b91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511388718-172.17.0.10-1597402604785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-14c3968f-e843-477d-8c56-400466473d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-0b1cdfd3-0b72-4f56-abad-d15189126d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-d3d6071f-95d1-497e-bf21-0843339e50db,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-b0fc6510-2a9d-4c34-b652-486376f6d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-96751700-7ca5-4f46-ab39-f424170949d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-064a00be-675c-4eff-a780-2f351e3fbce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-500ed36c-dc15-482a-a763-1efdf947bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-f24a5b3c-6894-4038-aa9a-280f8dc838d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511388718-172.17.0.10-1597402604785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-14c3968f-e843-477d-8c56-400466473d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-0b1cdfd3-0b72-4f56-abad-d15189126d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-d3d6071f-95d1-497e-bf21-0843339e50db,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-b0fc6510-2a9d-4c34-b652-486376f6d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-96751700-7ca5-4f46-ab39-f424170949d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-064a00be-675c-4eff-a780-2f351e3fbce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-500ed36c-dc15-482a-a763-1efdf947bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-f24a5b3c-6894-4038-aa9a-280f8dc838d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673743992-172.17.0.10-1597402681545:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37888,DS-4c4d57af-beea-4b28-956a-1189a272362b,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-2da656f6-db7d-4c98-84c8-e35cad46dbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-e7094f4a-89c1-448c-b4e3-230031ff14a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-2a21df65-435e-426c-a005-24759a404559,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-0db8c51d-fa77-44fe-93cc-e03a38b483ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-950efcb1-4709-469e-8eb5-548047fc3f70,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-3d9787c3-f753-4eba-908e-59535ec17076,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-0c80b840-7a17-4088-812c-aad75505b2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673743992-172.17.0.10-1597402681545:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37888,DS-4c4d57af-beea-4b28-956a-1189a272362b,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-2da656f6-db7d-4c98-84c8-e35cad46dbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-e7094f4a-89c1-448c-b4e3-230031ff14a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-2a21df65-435e-426c-a005-24759a404559,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-0db8c51d-fa77-44fe-93cc-e03a38b483ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-950efcb1-4709-469e-8eb5-548047fc3f70,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-3d9787c3-f753-4eba-908e-59535ec17076,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-0c80b840-7a17-4088-812c-aad75505b2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054645261-172.17.0.10-1597402724670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35917,DS-e7fa1e6b-e619-495c-acbf-de6d3c49e5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-d60b008b-7ec4-4e3c-a84d-be7a850e32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-a691bf4f-debb-4cf5-8aa4-35e356210baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-96516088-23fe-4460-b4ed-ee4dba7c83fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-f7fd7a4c-4824-449e-81b8-67615e35c4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-b9c45f30-bca7-449d-9e46-b14a56848d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-9fd3ce86-dba8-4782-88dc-2e6ba2468148,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-35cf1148-b054-4273-989e-111833945ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054645261-172.17.0.10-1597402724670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35917,DS-e7fa1e6b-e619-495c-acbf-de6d3c49e5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-d60b008b-7ec4-4e3c-a84d-be7a850e32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-a691bf4f-debb-4cf5-8aa4-35e356210baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-96516088-23fe-4460-b4ed-ee4dba7c83fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-f7fd7a4c-4824-449e-81b8-67615e35c4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-b9c45f30-bca7-449d-9e46-b14a56848d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-9fd3ce86-dba8-4782-88dc-2e6ba2468148,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-35cf1148-b054-4273-989e-111833945ecc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119563529-172.17.0.10-1597402760033:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-b61af684-2027-4b27-9ac3-a8c86a58b511,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-11eec348-5283-480d-98ca-e6dc5d3be3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-8907366b-be4e-43f9-aa40-1e848032f539,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-483f935f-e801-4302-856e-e809b6bd9c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-6b54fa21-01f0-4bd8-9e19-fd3c0db99d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-642ee273-ab0f-424b-b5ff-82b56c1031ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-5265a6e1-af88-4a85-b5f4-b78c6fc14ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-854962d0-6a0d-4b93-9985-52e91e18bf17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2119563529-172.17.0.10-1597402760033:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38712,DS-b61af684-2027-4b27-9ac3-a8c86a58b511,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-11eec348-5283-480d-98ca-e6dc5d3be3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-8907366b-be4e-43f9-aa40-1e848032f539,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-483f935f-e801-4302-856e-e809b6bd9c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-6b54fa21-01f0-4bd8-9e19-fd3c0db99d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-642ee273-ab0f-424b-b5ff-82b56c1031ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-5265a6e1-af88-4a85-b5f4-b78c6fc14ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-854962d0-6a0d-4b93-9985-52e91e18bf17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769110710-172.17.0.10-1597402967588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-e597ac42-3da8-497c-946c-9d7bf82bfc12,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-006f323f-d1af-4686-be78-27f56cb693c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-d92dccc5-faa7-4045-bb59-853fbb0b351e,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-20f033d6-a87a-4671-8c51-f35fcc741e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-d8af994b-ee2a-40c8-804d-9eb61b3993bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-cad205e4-07d6-419a-a60e-abb0687df9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-661e415d-0230-47f6-b6e7-aa302e58f688,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-b0777548-4070-43d3-9a12-a1f9600c223b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1769110710-172.17.0.10-1597402967588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-e597ac42-3da8-497c-946c-9d7bf82bfc12,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-006f323f-d1af-4686-be78-27f56cb693c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-d92dccc5-faa7-4045-bb59-853fbb0b351e,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-20f033d6-a87a-4671-8c51-f35fcc741e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-d8af994b-ee2a-40c8-804d-9eb61b3993bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-cad205e4-07d6-419a-a60e-abb0687df9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-661e415d-0230-47f6-b6e7-aa302e58f688,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-b0777548-4070-43d3-9a12-a1f9600c223b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285210763-172.17.0.10-1597403472700:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38553,DS-168eaf98-ffa2-49df-b262-c6b2ba090415,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-e62584c2-3b88-4520-bcaa-8404e7fe6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-7fe9574b-556a-499b-aefb-600ac362a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6b3793e2-c1a8-49f7-a877-ce5f37e1e1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-bcdd882f-3a7c-4524-aa98-5392517f786f,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-12062cff-b4dd-40a7-ad41-740d6bf84ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-57fface3-0c46-41b8-9344-fa1bc63f3dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-3b4f1ef7-5876-454d-b7b5-7da4fecaeb62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285210763-172.17.0.10-1597403472700:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38553,DS-168eaf98-ffa2-49df-b262-c6b2ba090415,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-e62584c2-3b88-4520-bcaa-8404e7fe6aff,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-7fe9574b-556a-499b-aefb-600ac362a2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6b3793e2-c1a8-49f7-a877-ce5f37e1e1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-bcdd882f-3a7c-4524-aa98-5392517f786f,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-12062cff-b4dd-40a7-ad41-740d6bf84ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-57fface3-0c46-41b8-9344-fa1bc63f3dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-3b4f1ef7-5876-454d-b7b5-7da4fecaeb62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108885201-172.17.0.10-1597403849410:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-51b67fd8-b042-4d16-a09c-526724f489d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-a41e4668-2ac2-4edb-895c-baf28be5e75a,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-2928003a-d473-45da-90c3-b25356f9d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-f84313d4-ad61-412c-b24a-8ec02d5b8411,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-eda5107d-71b3-4c71-b59c-b86add8492f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-5f350009-5804-4580-a06b-9c226d17b4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-89883d9c-dc03-4531-af06-183a7f9b7d82,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-c3a0c315-a755-4e10-91b1-8a98a2d4981d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108885201-172.17.0.10-1597403849410:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-51b67fd8-b042-4d16-a09c-526724f489d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-a41e4668-2ac2-4edb-895c-baf28be5e75a,DISK], DatanodeInfoWithStorage[127.0.0.1:34285,DS-2928003a-d473-45da-90c3-b25356f9d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-f84313d4-ad61-412c-b24a-8ec02d5b8411,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-eda5107d-71b3-4c71-b59c-b86add8492f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-5f350009-5804-4580-a06b-9c226d17b4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-89883d9c-dc03-4531-af06-183a7f9b7d82,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-c3a0c315-a755-4e10-91b1-8a98a2d4981d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979939866-172.17.0.10-1597403975789:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32906,DS-d99a8844-5d4b-4a28-bf3b-d7cc2c2c6c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-592def8c-8cc3-437b-985e-f1df878c72e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-94af6654-2c05-433a-8bcf-eeeb92025172,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-14f5030d-9bcd-44d3-b876-3f695a0fbc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-fb700f67-008b-4d35-b3e2-b02ed624b80d,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-7f4d6331-fa24-4880-8015-9dc6a615781c,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-ea10b794-0153-4274-848d-7b9c04eabf72,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-47c173a8-cbbd-4649-9290-814d28b2e34c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979939866-172.17.0.10-1597403975789:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32906,DS-d99a8844-5d4b-4a28-bf3b-d7cc2c2c6c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-592def8c-8cc3-437b-985e-f1df878c72e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-94af6654-2c05-433a-8bcf-eeeb92025172,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-14f5030d-9bcd-44d3-b876-3f695a0fbc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-fb700f67-008b-4d35-b3e2-b02ed624b80d,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-7f4d6331-fa24-4880-8015-9dc6a615781c,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-ea10b794-0153-4274-848d-7b9c04eabf72,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-47c173a8-cbbd-4649-9290-814d28b2e34c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5975
