reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645488119-172.17.0.9-1597536030574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43274,DS-cca85c84-351b-4525-9667-a657590ad32b,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-419a8d25-e5bf-472c-921f-b1370dd774d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-2429ef37-4452-41b5-a31a-8825f961fc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-1548e8c9-5fb3-4bb4-bd35-e8ef0f8fa736,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-cac6bfc8-077f-4828-96ae-ebdaaf9415da,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-da3adabc-dac6-44a3-879d-dbb93f99a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-00892c12-c0ad-4f69-b66e-acf67e5947e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-593023f6-9a50-4395-97ec-a2685adc6523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645488119-172.17.0.9-1597536030574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43274,DS-cca85c84-351b-4525-9667-a657590ad32b,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-419a8d25-e5bf-472c-921f-b1370dd774d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-2429ef37-4452-41b5-a31a-8825f961fc7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-1548e8c9-5fb3-4bb4-bd35-e8ef0f8fa736,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-cac6bfc8-077f-4828-96ae-ebdaaf9415da,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-da3adabc-dac6-44a3-879d-dbb93f99a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-00892c12-c0ad-4f69-b66e-acf67e5947e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-593023f6-9a50-4395-97ec-a2685adc6523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554078009-172.17.0.9-1597536550180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37286,DS-36a3a3c3-46a6-4082-bd43-2725f8b5baab,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-c82360c7-dd29-43d4-ba4b-8d275b6b19f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-dee023f3-0a43-43e0-b27a-6343307c80d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-8279b091-3675-487a-a08f-70566e7f6761,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-a8ca2370-cce8-4ada-8f73-2f7af870f862,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-1ff33eaa-8aa9-42f4-a805-2268ffc15b92,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-cf03e623-31c5-4404-99fe-c2785596be99,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-0fd156bb-d304-4312-985a-e3101d0bd27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554078009-172.17.0.9-1597536550180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37286,DS-36a3a3c3-46a6-4082-bd43-2725f8b5baab,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-c82360c7-dd29-43d4-ba4b-8d275b6b19f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-dee023f3-0a43-43e0-b27a-6343307c80d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-8279b091-3675-487a-a08f-70566e7f6761,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-a8ca2370-cce8-4ada-8f73-2f7af870f862,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-1ff33eaa-8aa9-42f4-a805-2268ffc15b92,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-cf03e623-31c5-4404-99fe-c2785596be99,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-0fd156bb-d304-4312-985a-e3101d0bd27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801061855-172.17.0.9-1597537235129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-98c3985f-f10e-4f9f-9416-3ff0ac722a56,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-76675f1d-c937-42d6-a825-3656a35d2737,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-a25419ac-1af5-4140-b4d2-1b52e175447a,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-a7908065-4e24-4491-a7ba-769cfdc72063,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-868dbb23-7dea-4a5b-98f8-a41708970ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-c4261315-458a-4004-acb4-d8fd50aa5e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-7fb123d1-d3ac-42b4-8bf8-e642974e6879,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-7826600e-e270-4e68-9ae0-848d2fdca55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801061855-172.17.0.9-1597537235129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-98c3985f-f10e-4f9f-9416-3ff0ac722a56,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-76675f1d-c937-42d6-a825-3656a35d2737,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-a25419ac-1af5-4140-b4d2-1b52e175447a,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-a7908065-4e24-4491-a7ba-769cfdc72063,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-868dbb23-7dea-4a5b-98f8-a41708970ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-c4261315-458a-4004-acb4-d8fd50aa5e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-7fb123d1-d3ac-42b4-8bf8-e642974e6879,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-7826600e-e270-4e68-9ae0-848d2fdca55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657868989-172.17.0.9-1597537501400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35473,DS-a9d52bd1-c15e-4a9e-97cd-7396ed059f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-f6ec116d-7452-4c41-8eec-d81cd11b2649,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-1214353f-9351-407a-9d49-82e9224bfa77,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-a8be6f8e-934a-4732-acf8-d78885a547f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-278c6e89-7988-43ca-89c6-68be2b247726,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-0586b63c-8d72-4eda-b253-8a27d81c7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-c3bf810a-56f6-4a87-a23e-8a2cf7d755f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-658adfc0-1228-44fa-8062-3e03482e2130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657868989-172.17.0.9-1597537501400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35473,DS-a9d52bd1-c15e-4a9e-97cd-7396ed059f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-f6ec116d-7452-4c41-8eec-d81cd11b2649,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-1214353f-9351-407a-9d49-82e9224bfa77,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-a8be6f8e-934a-4732-acf8-d78885a547f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-278c6e89-7988-43ca-89c6-68be2b247726,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-0586b63c-8d72-4eda-b253-8a27d81c7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-c3bf810a-56f6-4a87-a23e-8a2cf7d755f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-658adfc0-1228-44fa-8062-3e03482e2130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436880823-172.17.0.9-1597538368550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41789,DS-c7b2a26c-7111-453c-a76b-78b6075382db,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-17ab0c67-1c06-4a97-bb68-2055c72a1561,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-ba17a9f0-42c7-446b-b813-e471d2ea9b05,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-a7809cca-249c-43f9-a6b2-68087916e575,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-a5e753a1-f19c-4af7-a9d8-f616d1839e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-f6d2c3a0-1301-4f80-b52b-91a71009508c,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-5348257a-6ad9-4257-8ccb-28bba3f27710,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-6ed0f45b-3391-44e5-85ce-4e5ccfba5a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436880823-172.17.0.9-1597538368550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41789,DS-c7b2a26c-7111-453c-a76b-78b6075382db,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-17ab0c67-1c06-4a97-bb68-2055c72a1561,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-ba17a9f0-42c7-446b-b813-e471d2ea9b05,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-a7809cca-249c-43f9-a6b2-68087916e575,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-a5e753a1-f19c-4af7-a9d8-f616d1839e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-f6d2c3a0-1301-4f80-b52b-91a71009508c,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-5348257a-6ad9-4257-8ccb-28bba3f27710,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-6ed0f45b-3391-44e5-85ce-4e5ccfba5a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828812847-172.17.0.9-1597538405657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35619,DS-779be0c4-bf1d-4f4c-80fa-138325a315cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-b7d787cc-33be-4cf8-bd99-0acd64d6939d,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-a28d5dd4-38fa-4c62-9371-4bccdbd5ddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-db18ab57-578c-4f46-a05e-0d09ca6e2ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-ea77445f-5cf0-4643-af64-f25e44c7b757,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-0e56a5f9-1a71-4958-b832-700871657c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-efaf454b-5ced-43f9-a0ec-29cc6b6435d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-073f5db6-f67a-4805-8706-4165bcf0b1d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828812847-172.17.0.9-1597538405657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35619,DS-779be0c4-bf1d-4f4c-80fa-138325a315cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-b7d787cc-33be-4cf8-bd99-0acd64d6939d,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-a28d5dd4-38fa-4c62-9371-4bccdbd5ddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-db18ab57-578c-4f46-a05e-0d09ca6e2ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-ea77445f-5cf0-4643-af64-f25e44c7b757,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-0e56a5f9-1a71-4958-b832-700871657c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-efaf454b-5ced-43f9-a0ec-29cc6b6435d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-073f5db6-f67a-4805-8706-4165bcf0b1d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933121957-172.17.0.9-1597538455453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-1804dbaf-1337-4d13-ae16-ca4ff364658b,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-5f3aca49-dfc1-4fa9-a8a3-15968bcdc25d,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-44e9124a-2325-4842-8d97-57d73f7667c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-f9eb2a91-1132-40ac-8cdc-9aa3d0a897ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-79b67395-e03a-48a9-b6ed-ba9fcb7fb4be,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-85ddb834-307b-462c-97c8-37bf16200364,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-2b2ec723-fc44-4a6f-bb07-b09b2e42493f,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-11a2d14f-c0ce-4e94-a1ed-1db3535801c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933121957-172.17.0.9-1597538455453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34710,DS-1804dbaf-1337-4d13-ae16-ca4ff364658b,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-5f3aca49-dfc1-4fa9-a8a3-15968bcdc25d,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-44e9124a-2325-4842-8d97-57d73f7667c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-f9eb2a91-1132-40ac-8cdc-9aa3d0a897ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-79b67395-e03a-48a9-b6ed-ba9fcb7fb4be,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-85ddb834-307b-462c-97c8-37bf16200364,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-2b2ec723-fc44-4a6f-bb07-b09b2e42493f,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-11a2d14f-c0ce-4e94-a1ed-1db3535801c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766572912-172.17.0.9-1597538846065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45575,DS-be0b02f8-866c-44ea-9802-56603b8fe146,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-0c1b2c27-51ee-40a6-9d36-bb47452e6d44,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-b514a56c-cc72-466e-8aa5-d59eef6721f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-54fba500-2822-4099-9b29-6481fcc0407a,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-5aea76c6-c7e8-4604-8c14-1564b4a65ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-55599a41-cb05-4378-a5fd-e496dd61fb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-75e98cb3-ed3f-4280-8ce2-e47c4bf92e32,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-98c87d27-b19d-4694-820f-00462de21d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766572912-172.17.0.9-1597538846065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45575,DS-be0b02f8-866c-44ea-9802-56603b8fe146,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-0c1b2c27-51ee-40a6-9d36-bb47452e6d44,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-b514a56c-cc72-466e-8aa5-d59eef6721f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-54fba500-2822-4099-9b29-6481fcc0407a,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-5aea76c6-c7e8-4604-8c14-1564b4a65ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-55599a41-cb05-4378-a5fd-e496dd61fb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-75e98cb3-ed3f-4280-8ce2-e47c4bf92e32,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-98c87d27-b19d-4694-820f-00462de21d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917620042-172.17.0.9-1597539228222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40181,DS-4ab86d95-1783-4c09-9356-5fcaa242b178,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-c9f2ad45-2a42-42ca-8880-41d88779363a,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-6f304320-b99f-45f0-bd38-1561e4e362b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-776f06d0-d414-4bf0-81aa-2710ee94c3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-e667f080-1735-4992-abfb-64cdfe743303,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-41722657-714e-4c10-93c5-ee0ac6da3222,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-7c49b753-8ea9-4f28-9a14-99b9e4667e11,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-903cbff6-c126-483b-96da-eaa5e4195d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917620042-172.17.0.9-1597539228222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40181,DS-4ab86d95-1783-4c09-9356-5fcaa242b178,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-c9f2ad45-2a42-42ca-8880-41d88779363a,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-6f304320-b99f-45f0-bd38-1561e4e362b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-776f06d0-d414-4bf0-81aa-2710ee94c3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-e667f080-1735-4992-abfb-64cdfe743303,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-41722657-714e-4c10-93c5-ee0ac6da3222,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-7c49b753-8ea9-4f28-9a14-99b9e4667e11,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-903cbff6-c126-483b-96da-eaa5e4195d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411134923-172.17.0.9-1597539612978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39374,DS-45055fc4-0f72-44e5-a08a-6296f946e132,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-812cdefe-d4bf-4509-8f15-e17b53fed0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-197191fd-a2c4-4515-af8b-7d5c55cd2bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-fc3bf549-5fe7-4e8e-87cb-511026e5a779,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-cc0393d5-482f-4d6b-b1ea-23abe0693c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-36622d03-214c-4ea2-903c-cf62bfe94976,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-faf397c9-a5cc-4ada-950e-b061d64917dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-eb6a2f24-1502-45d2-9db1-156c77aec814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411134923-172.17.0.9-1597539612978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39374,DS-45055fc4-0f72-44e5-a08a-6296f946e132,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-812cdefe-d4bf-4509-8f15-e17b53fed0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-197191fd-a2c4-4515-af8b-7d5c55cd2bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-fc3bf549-5fe7-4e8e-87cb-511026e5a779,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-cc0393d5-482f-4d6b-b1ea-23abe0693c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-36622d03-214c-4ea2-903c-cf62bfe94976,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-faf397c9-a5cc-4ada-950e-b061d64917dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-eb6a2f24-1502-45d2-9db1-156c77aec814,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98215005-172.17.0.9-1597540256000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36714,DS-f202248f-1a7a-4ae2-b32c-6d787f3e49f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-945f03b0-59cf-44fe-95cc-a1b79771041a,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-5babed6a-9094-4bc3-8ea1-fe7e3182061d,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-4c3f4b5b-f483-4c22-a752-12ac700a8ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-76f615b9-5eb2-4a6b-9eed-48840a52724f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f6290334-cfb2-4445-916d-9e90223aa4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-62e4be17-259c-4523-8bb3-cf32764975a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-a007d37c-6c5a-4f7a-a88d-dac867079e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98215005-172.17.0.9-1597540256000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36714,DS-f202248f-1a7a-4ae2-b32c-6d787f3e49f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-945f03b0-59cf-44fe-95cc-a1b79771041a,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-5babed6a-9094-4bc3-8ea1-fe7e3182061d,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-4c3f4b5b-f483-4c22-a752-12ac700a8ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-76f615b9-5eb2-4a6b-9eed-48840a52724f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f6290334-cfb2-4445-916d-9e90223aa4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-62e4be17-259c-4523-8bb3-cf32764975a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-a007d37c-6c5a-4f7a-a88d-dac867079e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700048816-172.17.0.9-1597540661803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-cc9f43cd-e94d-40d3-83f4-aabe70391700,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-d384c2ad-5631-48bb-a3c7-166876e7264c,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-66a646e0-7a50-4593-9c54-788dac42d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-7dc98bdb-eeba-4e39-9262-0895d2bffc87,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-e4164b47-ab28-4e90-9e16-0b139e001ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-0f12c228-cedd-45b7-8513-73e625bf97dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-43833c39-5311-4f4a-ae9b-0ba7c630e794,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-46f45978-ebb1-45fc-872d-3f50c23c9572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700048816-172.17.0.9-1597540661803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-cc9f43cd-e94d-40d3-83f4-aabe70391700,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-d384c2ad-5631-48bb-a3c7-166876e7264c,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-66a646e0-7a50-4593-9c54-788dac42d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-7dc98bdb-eeba-4e39-9262-0895d2bffc87,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-e4164b47-ab28-4e90-9e16-0b139e001ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-0f12c228-cedd-45b7-8513-73e625bf97dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-43833c39-5311-4f4a-ae9b-0ba7c630e794,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-46f45978-ebb1-45fc-872d-3f50c23c9572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 20m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717171667-172.17.0.9-1597541709578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43656,DS-a38ef041-1f10-4917-b5d8-df8a4b41c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-96dd6a16-8905-4ae0-a060-3da62f5fc9de,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-8d9865f1-8779-49be-83da-76795bf9e706,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-9f5e2c9b-0383-425e-9884-4ca8d187d494,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-21b9de2c-986b-4b66-9660-a2f21b9383e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-8059ecab-90bf-4fda-bd0c-d14e283e0732,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-78cb68b5-874f-40b2-b677-4d5fe9da0826,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-b3a91fa0-08b1-4646-b7f4-7e42e74bfc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717171667-172.17.0.9-1597541709578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43656,DS-a38ef041-1f10-4917-b5d8-df8a4b41c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-96dd6a16-8905-4ae0-a060-3da62f5fc9de,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-8d9865f1-8779-49be-83da-76795bf9e706,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-9f5e2c9b-0383-425e-9884-4ca8d187d494,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-21b9de2c-986b-4b66-9660-a2f21b9383e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-8059ecab-90bf-4fda-bd0c-d14e283e0732,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-78cb68b5-874f-40b2-b677-4d5fe9da0826,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-b3a91fa0-08b1-4646-b7f4-7e42e74bfc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 7052
