reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935673937-172.17.0.18-1597351479059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45667,DS-8dafdb8e-56de-4707-90f5-607c2d1426e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-b74d6eb0-6cc6-4284-930c-0869126e7114,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-593eb52b-bf73-48b4-9de1-48ec4f91c4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-e770e2a2-edbc-47bd-92ee-bdd17a2277b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-f42513a2-884f-42e2-86d3-f07f2410746c,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5671f2ec-91bb-48e0-ac63-748d90dee4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-4e7f86a8-6d40-4aec-aea5-ed3f6f64ab11,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-4b6ffd00-f3b0-4d40-aa3c-f618f4ff0f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935673937-172.17.0.18-1597351479059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45667,DS-8dafdb8e-56de-4707-90f5-607c2d1426e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-b74d6eb0-6cc6-4284-930c-0869126e7114,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-593eb52b-bf73-48b4-9de1-48ec4f91c4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-e770e2a2-edbc-47bd-92ee-bdd17a2277b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-f42513a2-884f-42e2-86d3-f07f2410746c,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5671f2ec-91bb-48e0-ac63-748d90dee4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-4e7f86a8-6d40-4aec-aea5-ed3f6f64ab11,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-4b6ffd00-f3b0-4d40-aa3c-f618f4ff0f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872386823-172.17.0.18-1597352445070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38351,DS-ff56dc20-b71b-4b5d-8e06-40744e5d1967,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-e02bc80b-3229-4aa0-a89c-08069bd7f87c,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-5dbccba2-143b-4cb9-ac24-cfbddb93696a,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-0db9f78c-d4ac-4e99-b370-e35f8c6b8c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-24b78463-f3a9-4e5f-a0c4-5982f11472b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-be8cf787-fcce-4eca-a316-4dd4ed0f9a41,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-37b582f8-f63c-4940-865d-bae35a4ab380,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-f1b4fd50-0d50-4349-8410-f5e2f79353e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1872386823-172.17.0.18-1597352445070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38351,DS-ff56dc20-b71b-4b5d-8e06-40744e5d1967,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-e02bc80b-3229-4aa0-a89c-08069bd7f87c,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-5dbccba2-143b-4cb9-ac24-cfbddb93696a,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-0db9f78c-d4ac-4e99-b370-e35f8c6b8c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-24b78463-f3a9-4e5f-a0c4-5982f11472b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-be8cf787-fcce-4eca-a316-4dd4ed0f9a41,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-37b582f8-f63c-4940-865d-bae35a4ab380,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-f1b4fd50-0d50-4349-8410-f5e2f79353e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298958340-172.17.0.18-1597352678952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32892,DS-a06b65be-5947-4393-83d4-1a139afeddf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-9bf98845-62f4-4a62-bef4-0f81afd0f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-12d88b26-0ef9-4da9-adff-9c6ca78bfcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-f414f9ed-5c50-47f1-9975-26388281de34,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-2db84bc0-3e48-4917-b624-588c90a7f7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-ac25e404-2cc4-4663-a728-fca0f9d25089,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-a6fc4f8c-138c-4dfc-a0fd-c37374c5fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-9c2ac29e-0b95-4264-9174-c88f50b3a8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298958340-172.17.0.18-1597352678952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32892,DS-a06b65be-5947-4393-83d4-1a139afeddf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-9bf98845-62f4-4a62-bef4-0f81afd0f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-12d88b26-0ef9-4da9-adff-9c6ca78bfcc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-f414f9ed-5c50-47f1-9975-26388281de34,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-2db84bc0-3e48-4917-b624-588c90a7f7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-ac25e404-2cc4-4663-a728-fca0f9d25089,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-a6fc4f8c-138c-4dfc-a0fd-c37374c5fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-9c2ac29e-0b95-4264-9174-c88f50b3a8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125346297-172.17.0.18-1597353399316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38189,DS-04c63951-816c-4c80-89fd-0d65b1a235dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-bcdf829d-115a-4b2b-beeb-a06ae8a87a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-48a0f43e-6c0c-4a4a-b74f-eac071408299,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-6d27aa89-b486-4f26-a35f-ed3067e2adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-34af9768-6db6-41e2-8225-50a3f99fcd02,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-083000fc-2df7-4fba-a34b-8804d4cd5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-7d50ece8-e715-4ff1-b369-f8ee7faec8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-563a7ff3-7e9f-490b-8372-574d712ce5dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125346297-172.17.0.18-1597353399316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38189,DS-04c63951-816c-4c80-89fd-0d65b1a235dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-bcdf829d-115a-4b2b-beeb-a06ae8a87a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-48a0f43e-6c0c-4a4a-b74f-eac071408299,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-6d27aa89-b486-4f26-a35f-ed3067e2adc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-34af9768-6db6-41e2-8225-50a3f99fcd02,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-083000fc-2df7-4fba-a34b-8804d4cd5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-7d50ece8-e715-4ff1-b369-f8ee7faec8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-563a7ff3-7e9f-490b-8372-574d712ce5dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158431570-172.17.0.18-1597353473690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-ff6bf90d-0990-4180-8488-880e20d7e03a,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-8de4ee78-36e6-40a4-83ff-8885382fb6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-1fac11da-cf0a-4650-851a-769c034fcd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-dde6ae40-06c9-4722-99a7-007fb1de6e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-6056afaa-9bb2-4faa-9a1d-c45d2d4a1de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-49c22ba8-792c-4c35-b7f7-80b26033075c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-7d65ff99-8143-4141-be0a-24b9d4d9d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-05ea21be-b6cc-4588-90be-cf31bbb27e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158431570-172.17.0.18-1597353473690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-ff6bf90d-0990-4180-8488-880e20d7e03a,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-8de4ee78-36e6-40a4-83ff-8885382fb6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-1fac11da-cf0a-4650-851a-769c034fcd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-dde6ae40-06c9-4722-99a7-007fb1de6e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-6056afaa-9bb2-4faa-9a1d-c45d2d4a1de4,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-49c22ba8-792c-4c35-b7f7-80b26033075c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-7d65ff99-8143-4141-be0a-24b9d4d9d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-05ea21be-b6cc-4588-90be-cf31bbb27e09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686105226-172.17.0.18-1597353593529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-ac4083c1-5b74-45df-8144-20014b85765a,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-4b3a8b2b-fda5-49a9-bc7b-1ec907b802b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-782f499b-7128-4c1e-8210-e8e519ddb23d,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-8cf12ac8-b6bf-4ebb-a9e5-0c783a09a200,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-01023f63-a0bc-4785-ae71-a2619480ffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-6dec8f83-6ad1-43e9-9e2c-efe556f68720,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-f38b3450-5e12-4a82-99af-b820ec7d4c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-c2f667b7-3c4b-4ef4-91d2-23a9c8e6d9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686105226-172.17.0.18-1597353593529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-ac4083c1-5b74-45df-8144-20014b85765a,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-4b3a8b2b-fda5-49a9-bc7b-1ec907b802b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-782f499b-7128-4c1e-8210-e8e519ddb23d,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-8cf12ac8-b6bf-4ebb-a9e5-0c783a09a200,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-01023f63-a0bc-4785-ae71-a2619480ffeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-6dec8f83-6ad1-43e9-9e2c-efe556f68720,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-f38b3450-5e12-4a82-99af-b820ec7d4c66,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-c2f667b7-3c4b-4ef4-91d2-23a9c8e6d9a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325529510-172.17.0.18-1597353758380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43701,DS-88f840ff-fb08-41fd-b606-0e0fc9cadc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-31ef6e88-6d0a-4944-9d33-d0e2c6f22113,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-23a9cca0-280c-4909-849b-0ebfb6a589f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-71a2273f-4736-442f-944e-66b87b7a3bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-4eac6b2b-7b36-4c7e-8c53-eb2795f888ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-50bc0c78-bb0f-42b2-a8ba-d87977b92c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-0561a656-9554-4841-a097-1245fbc002ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-b0cbe133-f2b6-4e10-b715-abd478ecd245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325529510-172.17.0.18-1597353758380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43701,DS-88f840ff-fb08-41fd-b606-0e0fc9cadc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-31ef6e88-6d0a-4944-9d33-d0e2c6f22113,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-23a9cca0-280c-4909-849b-0ebfb6a589f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-71a2273f-4736-442f-944e-66b87b7a3bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-4eac6b2b-7b36-4c7e-8c53-eb2795f888ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-50bc0c78-bb0f-42b2-a8ba-d87977b92c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-0561a656-9554-4841-a097-1245fbc002ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-b0cbe133-f2b6-4e10-b715-abd478ecd245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373155353-172.17.0.18-1597353880931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-ec4e7aaa-5cc0-49eb-bbf0-6f87b05d8e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-3ed3fb21-e4bc-4625-a9db-b3d42a22189e,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-00d6f954-d809-487c-90f8-0942b835111e,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-2a06a9d0-aefb-4081-8f37-c5ee466f9aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-6c92af2a-bbeb-4b89-8c1e-3f9c48b710e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-74664d2c-9737-471c-b6c5-46c593498fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-08978de8-7aa2-4bb4-b8c5-38af68bfa8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-08f8125b-d5fc-4302-8a37-57f389066629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373155353-172.17.0.18-1597353880931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-ec4e7aaa-5cc0-49eb-bbf0-6f87b05d8e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-3ed3fb21-e4bc-4625-a9db-b3d42a22189e,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-00d6f954-d809-487c-90f8-0942b835111e,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-2a06a9d0-aefb-4081-8f37-c5ee466f9aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-6c92af2a-bbeb-4b89-8c1e-3f9c48b710e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-74664d2c-9737-471c-b6c5-46c593498fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-08978de8-7aa2-4bb4-b8c5-38af68bfa8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-08f8125b-d5fc-4302-8a37-57f389066629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767279343-172.17.0.18-1597354210848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42712,DS-924fc636-67c5-4335-b78d-fefbb8c1f552,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-38a7ae8b-d9f4-4fe2-a1c4-67e8eeeee5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-215f5139-76fe-4b2d-a376-a195f9ac2e53,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-c63a1438-695c-48e0-8d9c-d4c5c3cb16b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-6a676af9-7504-4fc7-9c88-1df27f452af2,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-9b054364-d019-48f3-a5f4-c6bfa138acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-fd884089-538a-4b21-b0e5-3ef610605d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-2cc51fa1-528d-44bb-9760-5b3335e7d553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767279343-172.17.0.18-1597354210848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42712,DS-924fc636-67c5-4335-b78d-fefbb8c1f552,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-38a7ae8b-d9f4-4fe2-a1c4-67e8eeeee5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-215f5139-76fe-4b2d-a376-a195f9ac2e53,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-c63a1438-695c-48e0-8d9c-d4c5c3cb16b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-6a676af9-7504-4fc7-9c88-1df27f452af2,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-9b054364-d019-48f3-a5f4-c6bfa138acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-fd884089-538a-4b21-b0e5-3ef610605d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-2cc51fa1-528d-44bb-9760-5b3335e7d553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286638459-172.17.0.18-1597354957383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-841b8f34-4e7c-485f-b930-d81800c285b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-3563f49a-4d58-453d-bf5b-bae8aa375803,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-b7af5c5f-dc08-40a9-9406-0f2a32a0c107,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-0c342db1-4106-41fb-9fb2-3f097ff3d3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-5cb869bf-5c34-4ae3-b726-951bf5c7a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-6a239a05-8c5c-4c51-8a49-d18539a1d148,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-45aabd38-eed4-4b8c-86d0-aad565d449bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-78586a2d-c279-4c55-acac-9d5acf35a69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286638459-172.17.0.18-1597354957383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-841b8f34-4e7c-485f-b930-d81800c285b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-3563f49a-4d58-453d-bf5b-bae8aa375803,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-b7af5c5f-dc08-40a9-9406-0f2a32a0c107,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-0c342db1-4106-41fb-9fb2-3f097ff3d3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-5cb869bf-5c34-4ae3-b726-951bf5c7a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-6a239a05-8c5c-4c51-8a49-d18539a1d148,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-45aabd38-eed4-4b8c-86d0-aad565d449bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-78586a2d-c279-4c55-acac-9d5acf35a69f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213897143-172.17.0.18-1597355030769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-8e12e319-ee0e-4af3-bc14-ed2cd3ea121f,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-03817cf1-ce74-418c-8ca7-a1297ff09416,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-1532f7a3-22b2-4454-a191-c8db5a4c8d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-151dd48e-7dfa-469a-8590-31d457ad308d,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-af7f4b9a-521d-48ee-bb76-11b2db3caa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-a665177f-d39a-44ea-9bc9-33efeff21767,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-8f0661f3-cfbb-4b49-8d2b-e95b6a6b284e,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-50424084-0909-4172-a3a1-9314ef5476b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213897143-172.17.0.18-1597355030769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-8e12e319-ee0e-4af3-bc14-ed2cd3ea121f,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-03817cf1-ce74-418c-8ca7-a1297ff09416,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-1532f7a3-22b2-4454-a191-c8db5a4c8d51,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-151dd48e-7dfa-469a-8590-31d457ad308d,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-af7f4b9a-521d-48ee-bb76-11b2db3caa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-a665177f-d39a-44ea-9bc9-33efeff21767,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-8f0661f3-cfbb-4b49-8d2b-e95b6a6b284e,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-50424084-0909-4172-a3a1-9314ef5476b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689345775-172.17.0.18-1597355068567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-58fcdb4f-d507-4b26-8fef-58d26c79b7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-d7c5a253-24c7-46c2-bbda-30c9fc7bf5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-7edd18ff-c17e-4ed2-8132-38b48853291f,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-bd1620ef-5bab-4868-bcd6-c171b6484e94,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-0a69c3ff-9985-466c-b607-8c53a26304c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-7d944fa7-416d-4898-86cf-432d9d4bcbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-bee7c522-3308-4c3f-a6bd-164e5b4173ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-b78543a1-c0eb-4f2f-ba16-e05cc1d9e9e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-689345775-172.17.0.18-1597355068567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-58fcdb4f-d507-4b26-8fef-58d26c79b7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-d7c5a253-24c7-46c2-bbda-30c9fc7bf5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-7edd18ff-c17e-4ed2-8132-38b48853291f,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-bd1620ef-5bab-4868-bcd6-c171b6484e94,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-0a69c3ff-9985-466c-b607-8c53a26304c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-7d944fa7-416d-4898-86cf-432d9d4bcbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-bee7c522-3308-4c3f-a6bd-164e5b4173ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-b78543a1-c0eb-4f2f-ba16-e05cc1d9e9e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702562480-172.17.0.18-1597355455412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45984,DS-d2843f88-cbb0-411d-a9a6-afc23fa98810,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-34238027-81ea-46dd-a953-6e9100e9b1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-dc906b37-3792-4509-9366-c97b4809037e,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-fab29e39-eec3-44c7-a571-8d892aee2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-7ef731f0-3b60-41f9-86ad-e2ff0aca69ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-e3cc60f4-144a-4cba-a33b-1f48bf68c195,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-12118f12-6501-41f0-8819-45d55ee661ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-08dd0c3b-688d-4b79-a26a-02381ac791a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702562480-172.17.0.18-1597355455412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45984,DS-d2843f88-cbb0-411d-a9a6-afc23fa98810,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-34238027-81ea-46dd-a953-6e9100e9b1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-dc906b37-3792-4509-9366-c97b4809037e,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-fab29e39-eec3-44c7-a571-8d892aee2a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-7ef731f0-3b60-41f9-86ad-e2ff0aca69ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-e3cc60f4-144a-4cba-a33b-1f48bf68c195,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-12118f12-6501-41f0-8819-45d55ee661ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-08dd0c3b-688d-4b79-a26a-02381ac791a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028486279-172.17.0.18-1597355679270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40391,DS-af7c605d-f357-4e8d-aad7-d9da91ec0225,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-9e5df55c-1b7c-4d7d-ab96-264df5f5a2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-d69757f8-837f-4493-9fc2-c91524d3b8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-d5e34316-0b0a-4ffd-ac52-5821847746a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-71a53071-4309-4ce3-bba7-48a66d32dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-ae3051aa-46dc-487c-a29d-f1f02008617c,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-ce9680a6-e8f3-4553-b456-75b55c69cdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-e5f74fa1-6aa5-4b59-b5fd-2ab266aa707d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028486279-172.17.0.18-1597355679270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40391,DS-af7c605d-f357-4e8d-aad7-d9da91ec0225,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-9e5df55c-1b7c-4d7d-ab96-264df5f5a2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-d69757f8-837f-4493-9fc2-c91524d3b8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-d5e34316-0b0a-4ffd-ac52-5821847746a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-71a53071-4309-4ce3-bba7-48a66d32dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-ae3051aa-46dc-487c-a29d-f1f02008617c,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-ce9680a6-e8f3-4553-b456-75b55c69cdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-e5f74fa1-6aa5-4b59-b5fd-2ab266aa707d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391949848-172.17.0.18-1597355951865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-78bce9a4-a7cb-43a8-9e20-7f7e554c7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-3d6d85f7-77bc-4da5-882e-027f2c9c41e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-1ff2625a-00ca-4a09-af6d-b03382f2879d,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-b7beb13c-412f-4ce1-8769-a6490e4896ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-0a751eb9-a8fa-408a-92c4-768ae0fe8a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-d407219d-e7b3-4388-b684-87ac6d99aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-62d71465-b74c-4749-b1bb-de3d229ac4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-0a65c577-3fe1-4d65-ba42-4c2f98c2746e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391949848-172.17.0.18-1597355951865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-78bce9a4-a7cb-43a8-9e20-7f7e554c7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-3d6d85f7-77bc-4da5-882e-027f2c9c41e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-1ff2625a-00ca-4a09-af6d-b03382f2879d,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-b7beb13c-412f-4ce1-8769-a6490e4896ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-0a751eb9-a8fa-408a-92c4-768ae0fe8a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-d407219d-e7b3-4388-b684-87ac6d99aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-62d71465-b74c-4749-b1bb-de3d229ac4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-0a65c577-3fe1-4d65-ba42-4c2f98c2746e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541613440-172.17.0.18-1597356272499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-179af292-7ad0-4854-8fe8-1973ebfbddfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-72122b15-d341-4f85-8728-2137b13d935c,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-027d8fde-ed82-4265-b599-a0234643ce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-fecee523-df77-4ef1-9f75-cdbadb2afe09,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-eb3c7619-2d06-452e-b438-f5830e5126f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-d8963b95-9f48-486f-b2a1-de5d6161c916,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-510771cf-83ff-45d5-8f99-3d513d436c83,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-63a6ace1-1a85-4ebb-8298-8b197eacafd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541613440-172.17.0.18-1597356272499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46804,DS-179af292-7ad0-4854-8fe8-1973ebfbddfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-72122b15-d341-4f85-8728-2137b13d935c,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-027d8fde-ed82-4265-b599-a0234643ce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-fecee523-df77-4ef1-9f75-cdbadb2afe09,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-eb3c7619-2d06-452e-b438-f5830e5126f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-d8963b95-9f48-486f-b2a1-de5d6161c916,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-510771cf-83ff-45d5-8f99-3d513d436c83,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-63a6ace1-1a85-4ebb-8298-8b197eacafd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806388961-172.17.0.18-1597356313282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-d5a14a0b-af66-4aef-928c-32e86a03de1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-7382a90e-4a35-424a-a612-157a931da0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-06627cd9-377f-4582-9a18-9a7b7a017cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-ee89b0e4-9ac8-4c9a-8f1d-eda254855e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-1f6d4899-dab2-4c5d-ae31-dcbe4c660407,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-05daa62f-815d-4549-9f04-9eb901be5067,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-6578d327-2307-49a8-a9b4-a816e24e3421,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-339521dc-4708-4dc4-9f07-1f556af88b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806388961-172.17.0.18-1597356313282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-d5a14a0b-af66-4aef-928c-32e86a03de1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-7382a90e-4a35-424a-a612-157a931da0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-06627cd9-377f-4582-9a18-9a7b7a017cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-ee89b0e4-9ac8-4c9a-8f1d-eda254855e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-1f6d4899-dab2-4c5d-ae31-dcbe4c660407,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-05daa62f-815d-4549-9f04-9eb901be5067,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-6578d327-2307-49a8-a9b4-a816e24e3421,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-339521dc-4708-4dc4-9f07-1f556af88b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5722
