reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952648099-172.17.0.20-1597419216166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35893,DS-bcff1657-c0e1-4e4f-9878-f33cef7e345e,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-558d03b8-e8a6-44c3-9c56-e42aed30c9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-42970b4b-d4c4-4b51-8e02-8e3fe63a3208,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-1dd7f020-0e59-4431-a29f-3d75a459b1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-6e146bc4-3bdc-40f3-b418-3ec849dd41bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-802eed78-46a2-43bf-9c2c-3e0b14accbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-cd4885a0-aea5-41cf-8a40-3ff82b8a306c,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-d89749f1-33b1-4497-a595-f1d23cf07010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952648099-172.17.0.20-1597419216166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35893,DS-bcff1657-c0e1-4e4f-9878-f33cef7e345e,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-558d03b8-e8a6-44c3-9c56-e42aed30c9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-42970b4b-d4c4-4b51-8e02-8e3fe63a3208,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-1dd7f020-0e59-4431-a29f-3d75a459b1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-6e146bc4-3bdc-40f3-b418-3ec849dd41bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-802eed78-46a2-43bf-9c2c-3e0b14accbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-cd4885a0-aea5-41cf-8a40-3ff82b8a306c,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-d89749f1-33b1-4497-a595-f1d23cf07010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474973010-172.17.0.20-1597420246240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43144,DS-32ae7b9f-125d-4069-99cc-d6220231af7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-51402dc7-425e-4785-b1c1-5ba153166d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-631747b3-a96e-4d91-b79c-57bccda025b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-dd720cf0-b7a1-4498-8cbb-e68686df8c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-3772cfb1-2b16-4b6d-bdb8-4fe0184710a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-60256a2a-45bf-4510-8770-edff97b4481f,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-55217a39-e012-43e6-9852-df2c0fa8065f,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-aa0c72e4-2a11-44f7-9d21-9e67539f13e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474973010-172.17.0.20-1597420246240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43144,DS-32ae7b9f-125d-4069-99cc-d6220231af7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-51402dc7-425e-4785-b1c1-5ba153166d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-631747b3-a96e-4d91-b79c-57bccda025b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-dd720cf0-b7a1-4498-8cbb-e68686df8c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-3772cfb1-2b16-4b6d-bdb8-4fe0184710a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-60256a2a-45bf-4510-8770-edff97b4481f,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-55217a39-e012-43e6-9852-df2c0fa8065f,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-aa0c72e4-2a11-44f7-9d21-9e67539f13e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584136540-172.17.0.20-1597420522299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33744,DS-2f218dd8-a72f-466a-9abc-8f732d2d78e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-55f3f94c-185d-4747-a27e-4d79cc6dc563,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-b55d9476-bb40-4edd-8629-538179e84ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-0d74e2be-9879-4525-9ad1-c0f43eeb0aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-a5f2fb57-6041-441b-a76b-a8a7fe099c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-3d26330b-19cd-4475-a1ba-91b17e5a1962,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-a98397e5-c5aa-40b3-8f0f-85f79219644f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-44a1ccfa-9c2e-4f95-a4d3-c0cd7c13d736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584136540-172.17.0.20-1597420522299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33744,DS-2f218dd8-a72f-466a-9abc-8f732d2d78e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-55f3f94c-185d-4747-a27e-4d79cc6dc563,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-b55d9476-bb40-4edd-8629-538179e84ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-0d74e2be-9879-4525-9ad1-c0f43eeb0aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-a5f2fb57-6041-441b-a76b-a8a7fe099c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-3d26330b-19cd-4475-a1ba-91b17e5a1962,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-a98397e5-c5aa-40b3-8f0f-85f79219644f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-44a1ccfa-9c2e-4f95-a4d3-c0cd7c13d736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652680439-172.17.0.20-1597421407805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-9fc6d1b6-12c5-41d5-84b4-dd35bd72e8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-2e184630-5a29-4432-88f4-e93f12ddd93e,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-3286492b-bc10-4380-aa8b-50d40fa29716,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-bda9956c-e641-4673-9071-7fdf1d242b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-d20a532a-2471-42f1-a8e1-d6cf71968493,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-ee8df120-a1c5-42c4-9c35-a0cb4aa07cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-86e3e3f5-c2fa-4c1b-912e-b2de595b0893,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-2c1c0b30-81dd-45c5-971e-4de19419790f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1652680439-172.17.0.20-1597421407805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34329,DS-9fc6d1b6-12c5-41d5-84b4-dd35bd72e8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-2e184630-5a29-4432-88f4-e93f12ddd93e,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-3286492b-bc10-4380-aa8b-50d40fa29716,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-bda9956c-e641-4673-9071-7fdf1d242b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-d20a532a-2471-42f1-a8e1-d6cf71968493,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-ee8df120-a1c5-42c4-9c35-a0cb4aa07cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-86e3e3f5-c2fa-4c1b-912e-b2de595b0893,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-2c1c0b30-81dd-45c5-971e-4de19419790f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424102739-172.17.0.20-1597421443830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-b173ca2c-077a-4b4a-985c-61f91be185ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-8d136909-f3c8-4642-9acc-3334fe75f763,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-840ec8ab-ebca-453e-8124-c55abbe99090,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-8ab4c6ba-6a95-4417-b002-fce7f9589534,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-c82105d9-7ee5-46a5-8729-36bb2ab5e14f,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-e0a80055-3b7e-43af-81ec-9a6b475ce828,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-715020fa-0aee-4998-83e0-5facdd57c5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-af95203b-8de7-4bd5-9567-14cfe7bd2659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424102739-172.17.0.20-1597421443830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37725,DS-b173ca2c-077a-4b4a-985c-61f91be185ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-8d136909-f3c8-4642-9acc-3334fe75f763,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-840ec8ab-ebca-453e-8124-c55abbe99090,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-8ab4c6ba-6a95-4417-b002-fce7f9589534,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-c82105d9-7ee5-46a5-8729-36bb2ab5e14f,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-e0a80055-3b7e-43af-81ec-9a6b475ce828,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-715020fa-0aee-4998-83e0-5facdd57c5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-af95203b-8de7-4bd5-9567-14cfe7bd2659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836572874-172.17.0.20-1597421877041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-22d9046c-afaf-4a13-8d74-b4f4e6aae71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-0bf55ed9-3faa-42a9-8fcb-66e4ec5b17bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-8eaeb166-3827-4a19-a2b0-b82e3f955eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-ba6dc135-0195-4422-ad55-8a74091f6a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-8bc73664-8db1-42ea-aba8-e3215b9dd9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-3c7c4807-269b-4008-9bbe-1640f9483214,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-9806f1e1-adbd-4225-abfb-089ee62d2475,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-a8d155fc-9919-4ef2-a2f2-30e96c94b439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836572874-172.17.0.20-1597421877041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38982,DS-22d9046c-afaf-4a13-8d74-b4f4e6aae71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-0bf55ed9-3faa-42a9-8fcb-66e4ec5b17bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-8eaeb166-3827-4a19-a2b0-b82e3f955eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-ba6dc135-0195-4422-ad55-8a74091f6a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-8bc73664-8db1-42ea-aba8-e3215b9dd9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-3c7c4807-269b-4008-9bbe-1640f9483214,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-9806f1e1-adbd-4225-abfb-089ee62d2475,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-a8d155fc-9919-4ef2-a2f2-30e96c94b439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463871587-172.17.0.20-1597421913757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45060,DS-09b165f8-4fad-4e8e-a66d-254ed20e0642,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-08573538-9493-459c-ade5-69828a4d2934,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-85983475-741f-4ad4-b1e0-bb9eae96cc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-8815ca94-2dbc-4953-9ff1-cc7a0d69b553,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-7c918abc-bf74-40b5-b0ba-0b48c00caec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-d5914eba-b6e0-4f03-a1bf-b15b0dd95051,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-a45b0bf7-02ba-4e8a-9bc3-8870e407dd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-e470558f-1439-4a3b-8ed2-1d4fa5a09bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463871587-172.17.0.20-1597421913757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45060,DS-09b165f8-4fad-4e8e-a66d-254ed20e0642,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-08573538-9493-459c-ade5-69828a4d2934,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-85983475-741f-4ad4-b1e0-bb9eae96cc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-8815ca94-2dbc-4953-9ff1-cc7a0d69b553,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-7c918abc-bf74-40b5-b0ba-0b48c00caec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-d5914eba-b6e0-4f03-a1bf-b15b0dd95051,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-a45b0bf7-02ba-4e8a-9bc3-8870e407dd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-e470558f-1439-4a3b-8ed2-1d4fa5a09bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496879941-172.17.0.20-1597422541785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-62c0236c-2c39-4047-9164-a1a3751f5c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-718fd08f-4cbd-4e36-96e5-bb68d70ea280,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-cd870cd0-49ad-4882-9bb6-f20160034eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-e3032a23-58b2-448c-85c8-fdd6c349e341,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-de3cdef8-9e14-4a9e-8c0d-2a42e11a185b,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-44b0e20b-09ad-4631-9776-de246dad6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-0b66da77-7fd4-4497-8a11-cb774733e041,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-392c4247-3bd4-4699-a792-857f4bdcfd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496879941-172.17.0.20-1597422541785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-62c0236c-2c39-4047-9164-a1a3751f5c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-718fd08f-4cbd-4e36-96e5-bb68d70ea280,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-cd870cd0-49ad-4882-9bb6-f20160034eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-e3032a23-58b2-448c-85c8-fdd6c349e341,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-de3cdef8-9e14-4a9e-8c0d-2a42e11a185b,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-44b0e20b-09ad-4631-9776-de246dad6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-0b66da77-7fd4-4497-8a11-cb774733e041,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-392c4247-3bd4-4699-a792-857f4bdcfd13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691515357-172.17.0.20-1597422787116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43224,DS-f7aa1002-bbb1-4027-b7ec-4e7e6a11259d,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-30863e71-22d4-43d2-87a8-2be3940265d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-4c85453f-1618-44fa-ab69-01a706d4b5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-63eedb1f-bdc5-4e74-a856-94d1f410e9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-3b421d20-232d-471f-be3d-528fa0b0b375,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-b867da98-99df-460f-9679-2fc0425f00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-5aae99e8-eff6-44e8-bfc3-a85867d1aba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-922345b1-adfb-41c3-a744-415c2f81d453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691515357-172.17.0.20-1597422787116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43224,DS-f7aa1002-bbb1-4027-b7ec-4e7e6a11259d,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-30863e71-22d4-43d2-87a8-2be3940265d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-4c85453f-1618-44fa-ab69-01a706d4b5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-63eedb1f-bdc5-4e74-a856-94d1f410e9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-3b421d20-232d-471f-be3d-528fa0b0b375,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-b867da98-99df-460f-9679-2fc0425f00ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-5aae99e8-eff6-44e8-bfc3-a85867d1aba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-922345b1-adfb-41c3-a744-415c2f81d453,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243429451-172.17.0.20-1597423121197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-45fc82ca-2747-4e73-984f-4e3124b0ccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-ef9c2509-c69e-43b0-aa3d-db242f197fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-b84963dd-4de8-450a-b67d-0275eb743460,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-08083d6d-8e59-4cc9-9c5e-4c5273a0ad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-02461d03-d28a-415d-9783-e9454aa22286,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-96a6b031-2c13-401a-8937-79e9f0f4af15,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-dd45a81d-cddd-4613-a204-914353af58d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-835f1704-e21d-4b04-85a4-49bd18771932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243429451-172.17.0.20-1597423121197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-45fc82ca-2747-4e73-984f-4e3124b0ccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-ef9c2509-c69e-43b0-aa3d-db242f197fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-b84963dd-4de8-450a-b67d-0275eb743460,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-08083d6d-8e59-4cc9-9c5e-4c5273a0ad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-02461d03-d28a-415d-9783-e9454aa22286,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-96a6b031-2c13-401a-8937-79e9f0f4af15,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-dd45a81d-cddd-4613-a204-914353af58d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-835f1704-e21d-4b04-85a4-49bd18771932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671184512-172.17.0.20-1597423257335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44681,DS-17788561-d9b9-4bb5-b46b-838ac1c902e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-7170c4dc-50f5-486d-9993-aee6ee53dccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-5546232a-c81f-402f-a74e-48a0a136949c,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-bcd21e17-4e7c-45ad-ba8b-fda5957e0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-cd733d53-168e-470d-9957-1a5139825759,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-1841df58-808f-4391-ade9-e86a7fac309f,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-da0fe472-3553-4375-abcc-ddaab43ba63f,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-f5088d7e-427c-4085-abe4-5efb7440198f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671184512-172.17.0.20-1597423257335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44681,DS-17788561-d9b9-4bb5-b46b-838ac1c902e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-7170c4dc-50f5-486d-9993-aee6ee53dccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-5546232a-c81f-402f-a74e-48a0a136949c,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-bcd21e17-4e7c-45ad-ba8b-fda5957e0e55,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-cd733d53-168e-470d-9957-1a5139825759,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-1841df58-808f-4391-ade9-e86a7fac309f,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-da0fe472-3553-4375-abcc-ddaab43ba63f,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-f5088d7e-427c-4085-abe4-5efb7440198f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27647481-172.17.0.20-1597423848819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-6c98a65a-aff2-4465-9650-25b611516dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-62ce3ff5-087b-4731-8ef2-1ddedfdac07a,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-702fcc33-fc63-4d71-889e-74147ff30c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-e7cd2653-2498-41f7-bbc7-4b6a1c53818b,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-293da922-ff80-4e90-a244-0cd590525a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-f403e64a-1c46-4596-9b0f-e367d2d52930,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-ff9d39d0-a334-49c9-85e4-96b9185c5938,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-7e9b0c27-d0b4-4286-8374-869438f27eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27647481-172.17.0.20-1597423848819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39899,DS-6c98a65a-aff2-4465-9650-25b611516dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-62ce3ff5-087b-4731-8ef2-1ddedfdac07a,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-702fcc33-fc63-4d71-889e-74147ff30c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-e7cd2653-2498-41f7-bbc7-4b6a1c53818b,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-293da922-ff80-4e90-a244-0cd590525a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-f403e64a-1c46-4596-9b0f-e367d2d52930,DISK], DatanodeInfoWithStorage[127.0.0.1:42395,DS-ff9d39d0-a334-49c9-85e4-96b9185c5938,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-7e9b0c27-d0b4-4286-8374-869438f27eac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90088301-172.17.0.20-1597424258931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42698,DS-a78f512c-08d3-4370-9c8d-c7e8493bf3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-8488b60a-0cf4-4ab8-9e31-e4d61e92ff79,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-6d2680a0-ddf5-4b50-8604-379de411ff65,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-bd93529e-7671-4da0-8c91-0eabb444664f,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-51bfc985-9624-4fe2-869d-20c9bdbe6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-fd69bb0f-d7c8-4eef-b4f8-6eff3300261b,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-4677c434-4615-45b3-a7b1-ec2bb887ea26,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-8465a6c4-3fdd-4c72-b49d-cfdf6e3b6901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90088301-172.17.0.20-1597424258931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42698,DS-a78f512c-08d3-4370-9c8d-c7e8493bf3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-8488b60a-0cf4-4ab8-9e31-e4d61e92ff79,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-6d2680a0-ddf5-4b50-8604-379de411ff65,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-bd93529e-7671-4da0-8c91-0eabb444664f,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-51bfc985-9624-4fe2-869d-20c9bdbe6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-fd69bb0f-d7c8-4eef-b4f8-6eff3300261b,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-4677c434-4615-45b3-a7b1-ec2bb887ea26,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-8465a6c4-3fdd-4c72-b49d-cfdf6e3b6901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901264016-172.17.0.20-1597424332649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42790,DS-12186955-f32a-439f-b223-aa948bde4eed,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-25ba5112-a247-4462-8dfe-e6c1e267f427,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-52641256-e4a7-4262-85a0-afaa0cde1242,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-21017936-cf27-4e82-9605-b9f0a265b932,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-26e2713d-4411-48f3-9169-f0c19cd88df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-0b91f31b-c67e-47a1-bf37-d7f14ad50928,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-5118c7e2-b304-4e0a-a2b4-367f1b8b862a,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-79d91ef4-6214-4679-b69c-f24f60e04e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901264016-172.17.0.20-1597424332649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42790,DS-12186955-f32a-439f-b223-aa948bde4eed,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-25ba5112-a247-4462-8dfe-e6c1e267f427,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-52641256-e4a7-4262-85a0-afaa0cde1242,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-21017936-cf27-4e82-9605-b9f0a265b932,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-26e2713d-4411-48f3-9169-f0c19cd88df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-0b91f31b-c67e-47a1-bf37-d7f14ad50928,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-5118c7e2-b304-4e0a-a2b4-367f1b8b862a,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-79d91ef4-6214-4679-b69c-f24f60e04e71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5291
