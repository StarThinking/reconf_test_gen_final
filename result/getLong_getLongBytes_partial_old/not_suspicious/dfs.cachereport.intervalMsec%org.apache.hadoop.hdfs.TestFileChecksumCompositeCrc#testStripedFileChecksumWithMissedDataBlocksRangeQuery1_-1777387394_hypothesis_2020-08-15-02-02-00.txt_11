reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484452933-172.17.0.12-1597457337289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43319,DS-32085f93-c8b7-4b7c-ac06-62b198c28d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-25cf1128-9363-421f-957c-25f4d7cc0663,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-0b3b4487-af83-41a2-8ced-50b54da16c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-0c57aa14-8bd9-4f09-ac46-b3154bc371db,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-9c6a5834-9c19-457d-be65-ef2cc48cbef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-7b82fc23-5559-4a8a-8297-44fcc6eea5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-9e119dea-8658-414c-812b-c4765cf6dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-7a24c658-406a-4d1a-afe8-e2bd1dedb0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484452933-172.17.0.12-1597457337289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43319,DS-32085f93-c8b7-4b7c-ac06-62b198c28d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-25cf1128-9363-421f-957c-25f4d7cc0663,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-0b3b4487-af83-41a2-8ced-50b54da16c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-0c57aa14-8bd9-4f09-ac46-b3154bc371db,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-9c6a5834-9c19-457d-be65-ef2cc48cbef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-7b82fc23-5559-4a8a-8297-44fcc6eea5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-9e119dea-8658-414c-812b-c4765cf6dcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-7a24c658-406a-4d1a-afe8-e2bd1dedb0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749818591-172.17.0.12-1597457714005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40418,DS-60c6eb16-2102-4c4a-8c4a-1ce2b39a479a,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-5b6bff7e-0943-45b1-8883-be9ae4b6f7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-46e5dc7c-bf1e-4016-a5a9-9bd2ffb9f894,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-263acc21-2db4-424e-95d1-37810aa1efdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-b6a12404-40ec-4c90-9a21-f4fcfb753807,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-c96d30aa-bdbf-442c-bc77-690f2e260b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-b34cc1f6-4c85-4a0b-96f2-6ea5f15e8d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-7ee8db4b-ae6f-4077-99ab-9e64a588251a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749818591-172.17.0.12-1597457714005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40418,DS-60c6eb16-2102-4c4a-8c4a-1ce2b39a479a,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-5b6bff7e-0943-45b1-8883-be9ae4b6f7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-46e5dc7c-bf1e-4016-a5a9-9bd2ffb9f894,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-263acc21-2db4-424e-95d1-37810aa1efdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-b6a12404-40ec-4c90-9a21-f4fcfb753807,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-c96d30aa-bdbf-442c-bc77-690f2e260b99,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-b34cc1f6-4c85-4a0b-96f2-6ea5f15e8d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-7ee8db4b-ae6f-4077-99ab-9e64a588251a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574872557-172.17.0.12-1597457789963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44879,DS-443d224e-e8f8-474b-a8c8-d58115ce13ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-0220d17b-d616-4625-a1d6-dc95c2bddc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-e87a048d-62a0-455e-a791-ad635b73a6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-23c61f92-32ac-44bf-97ae-6f5ea147728d,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-2334d8b5-92e2-487b-a8cf-d01937f93574,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-cc688187-4413-421f-b5e1-33d4cc115e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-48b0d090-0d8f-4331-8082-5a8dc7df0f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-9a682c5a-90dd-49ba-8b27-561477428cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574872557-172.17.0.12-1597457789963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44879,DS-443d224e-e8f8-474b-a8c8-d58115ce13ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-0220d17b-d616-4625-a1d6-dc95c2bddc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-e87a048d-62a0-455e-a791-ad635b73a6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-23c61f92-32ac-44bf-97ae-6f5ea147728d,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-2334d8b5-92e2-487b-a8cf-d01937f93574,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-cc688187-4413-421f-b5e1-33d4cc115e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-48b0d090-0d8f-4331-8082-5a8dc7df0f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-9a682c5a-90dd-49ba-8b27-561477428cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128422325-172.17.0.12-1597457907110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43536,DS-171b81ed-e11d-43e1-869b-eaf10502bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-e2d1245c-91f7-448f-9056-bb11fec45fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-dc596c99-1d82-418d-bb53-ec5998be7e75,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-7fb0c650-4924-4453-ae99-c67486d681ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-73b13c20-5f8f-41df-9ac4-f585fef45606,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-ed56c5d9-3e68-4892-9bb2-59115501b5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-f3bc5797-d859-4314-983c-fa34f7fbf819,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-cde97fd0-e26c-4584-9538-3e21f01b847b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128422325-172.17.0.12-1597457907110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43536,DS-171b81ed-e11d-43e1-869b-eaf10502bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-e2d1245c-91f7-448f-9056-bb11fec45fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-dc596c99-1d82-418d-bb53-ec5998be7e75,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-7fb0c650-4924-4453-ae99-c67486d681ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-73b13c20-5f8f-41df-9ac4-f585fef45606,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-ed56c5d9-3e68-4892-9bb2-59115501b5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-f3bc5797-d859-4314-983c-fa34f7fbf819,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-cde97fd0-e26c-4584-9538-3e21f01b847b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123877475-172.17.0.12-1597458469950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40707,DS-af6bc05f-6fb7-4fae-ada5-8740fc80a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-9912487d-343f-403b-b1b7-21efb0d86a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-da1d8092-5a9a-4076-9e13-115d1d149a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-957077ef-9066-43b6-a80e-0d58951fa50a,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-6ea5b3a7-9331-4444-ba67-6028180b6d67,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-90078885-c6e3-4f1e-a623-307be53f5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-e2a7572e-1176-42f9-af95-0c1aeba10838,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-bf5e2808-c5df-42f7-85f1-b68b59cb483e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123877475-172.17.0.12-1597458469950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40707,DS-af6bc05f-6fb7-4fae-ada5-8740fc80a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-9912487d-343f-403b-b1b7-21efb0d86a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-da1d8092-5a9a-4076-9e13-115d1d149a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-957077ef-9066-43b6-a80e-0d58951fa50a,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-6ea5b3a7-9331-4444-ba67-6028180b6d67,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-90078885-c6e3-4f1e-a623-307be53f5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-e2a7572e-1176-42f9-af95-0c1aeba10838,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-bf5e2808-c5df-42f7-85f1-b68b59cb483e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241810384-172.17.0.12-1597458843119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46800,DS-f2293cf8-0adf-41e3-94b7-338aeb2f62d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-a7bacda2-9aaf-4316-814d-e6ea7092d130,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-3e66e4c3-2189-478c-bc43-58ee9aacc6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-a19261e3-4fe1-4f0b-b13e-5ce8259a5f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-6e900e82-bcd2-44fa-878e-819e53284220,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-627af22e-d8ab-48d2-a8c4-631580266176,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-ab9af9f5-ba04-468d-9918-738ded199b05,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-d55271db-1293-49cd-9a5e-aee2392031c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241810384-172.17.0.12-1597458843119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46800,DS-f2293cf8-0adf-41e3-94b7-338aeb2f62d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-a7bacda2-9aaf-4316-814d-e6ea7092d130,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-3e66e4c3-2189-478c-bc43-58ee9aacc6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-a19261e3-4fe1-4f0b-b13e-5ce8259a5f71,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-6e900e82-bcd2-44fa-878e-819e53284220,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-627af22e-d8ab-48d2-a8c4-631580266176,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-ab9af9f5-ba04-468d-9918-738ded199b05,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-d55271db-1293-49cd-9a5e-aee2392031c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189132197-172.17.0.12-1597459284139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-f5cce245-040c-4050-b9d4-ce49eeb94333,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-fe520a6a-2e8b-4d27-9093-7dfa71ba650a,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-1f9440ad-9f9d-4600-9e24-c00cf072df86,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-8f5439ed-3c9d-490f-a1a6-8017de5350a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-0c96b97d-97f8-473f-95a9-a5bc7d5b46e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-1af53fe9-4e7b-4a2f-8a71-f3dae7391d03,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-d9428343-f221-430d-873c-a13fdf6d6a13,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-4ec2eb33-322f-45e8-b913-17ffd4b73389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189132197-172.17.0.12-1597459284139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-f5cce245-040c-4050-b9d4-ce49eeb94333,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-fe520a6a-2e8b-4d27-9093-7dfa71ba650a,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-1f9440ad-9f9d-4600-9e24-c00cf072df86,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-8f5439ed-3c9d-490f-a1a6-8017de5350a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-0c96b97d-97f8-473f-95a9-a5bc7d5b46e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-1af53fe9-4e7b-4a2f-8a71-f3dae7391d03,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-d9428343-f221-430d-873c-a13fdf6d6a13,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-4ec2eb33-322f-45e8-b913-17ffd4b73389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438639527-172.17.0.12-1597459627476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46325,DS-968472b7-cfb2-4edd-bc55-f6dc121f263e,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-0b059d51-8b31-4e5d-928d-a8dcaf81a765,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-b83a75a7-f6cf-4afd-bc3c-7579001a1842,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-1a0d8995-7dc9-4012-882c-25fd9f69923f,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-e44fd3ae-c9db-4fa6-b59c-f4daaf768abc,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-9564ac44-f318-429e-8554-97a4c7fd6b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-fb45770d-be4b-4321-8c63-68f688baef52,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-29684038-5ec7-4f36-b3c5-6ed816cf3d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438639527-172.17.0.12-1597459627476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46325,DS-968472b7-cfb2-4edd-bc55-f6dc121f263e,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-0b059d51-8b31-4e5d-928d-a8dcaf81a765,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-b83a75a7-f6cf-4afd-bc3c-7579001a1842,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-1a0d8995-7dc9-4012-882c-25fd9f69923f,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-e44fd3ae-c9db-4fa6-b59c-f4daaf768abc,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-9564ac44-f318-429e-8554-97a4c7fd6b86,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-fb45770d-be4b-4321-8c63-68f688baef52,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-29684038-5ec7-4f36-b3c5-6ed816cf3d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808955524-172.17.0.12-1597460598219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46158,DS-73b6e5ba-2613-4e52-89ff-2d81b4fe5ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-9a6c0cef-e378-49dc-acdc-8c6830c757a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-f411a058-8fbd-4ca3-8995-b8b37aba999b,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-4cd37ad2-549e-492b-9146-51b594aca351,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-449f7d8a-cc74-4ced-99af-b9a99b747928,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-263cbb94-6b4a-4c0e-8a9b-7d2d61a7e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-c069df32-d4db-48e4-b157-73e6114a1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-9800b0b3-5f31-4616-965a-e02ce0646360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808955524-172.17.0.12-1597460598219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46158,DS-73b6e5ba-2613-4e52-89ff-2d81b4fe5ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-9a6c0cef-e378-49dc-acdc-8c6830c757a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-f411a058-8fbd-4ca3-8995-b8b37aba999b,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-4cd37ad2-549e-492b-9146-51b594aca351,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-449f7d8a-cc74-4ced-99af-b9a99b747928,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-263cbb94-6b4a-4c0e-8a9b-7d2d61a7e4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-c069df32-d4db-48e4-b157-73e6114a1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-9800b0b3-5f31-4616-965a-e02ce0646360,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879947675-172.17.0.12-1597460760779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37862,DS-861d58bc-fbec-496f-898c-9f064ee0674a,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-f32009b3-7a1b-4510-a04a-02bba31cda5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-4076c310-47ad-4f46-9087-248965d5003c,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-8c017ccf-3fea-412d-94ae-dde42b2e8f44,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-5676795e-e346-42f1-aa11-548e1832ea60,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-862b7d4a-7918-49e5-a1c2-d73cfad1897a,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-4bf9860d-9264-490a-9cf4-97fcb63d04bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-981852b1-c6bc-4590-92d1-ba1b6d62daa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879947675-172.17.0.12-1597460760779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37862,DS-861d58bc-fbec-496f-898c-9f064ee0674a,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-f32009b3-7a1b-4510-a04a-02bba31cda5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-4076c310-47ad-4f46-9087-248965d5003c,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-8c017ccf-3fea-412d-94ae-dde42b2e8f44,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-5676795e-e346-42f1-aa11-548e1832ea60,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-862b7d4a-7918-49e5-a1c2-d73cfad1897a,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-4bf9860d-9264-490a-9cf4-97fcb63d04bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-981852b1-c6bc-4590-92d1-ba1b6d62daa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616698383-172.17.0.12-1597460797083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-35d41e3c-b1c5-4139-a5cd-a2ba8fb87468,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-fe6ed383-a1c3-4856-afd8-6bdd5253040d,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-8488508a-7b4a-4bf2-96b7-8bd1bc2378fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-fd78c353-b623-4f1a-bc1d-c24e41da7b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-f48fc5cb-548a-4871-9f0b-932796d2c30b,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-ef95af96-54d2-4d3e-a01c-e9174f9d45e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-a3e69151-f14a-4be0-a1e2-ce5fda1dcb70,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-2b73da56-8672-4356-9f65-2ad80b43b0fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616698383-172.17.0.12-1597460797083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38936,DS-35d41e3c-b1c5-4139-a5cd-a2ba8fb87468,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-fe6ed383-a1c3-4856-afd8-6bdd5253040d,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-8488508a-7b4a-4bf2-96b7-8bd1bc2378fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-fd78c353-b623-4f1a-bc1d-c24e41da7b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-f48fc5cb-548a-4871-9f0b-932796d2c30b,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-ef95af96-54d2-4d3e-a01c-e9174f9d45e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-a3e69151-f14a-4be0-a1e2-ce5fda1dcb70,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-2b73da56-8672-4356-9f65-2ad80b43b0fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435511797-172.17.0.12-1597461129026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-e43c8112-cc67-4a90-bfbc-3e4ba8605c79,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-15d4af3d-2d4f-40e3-9486-efd449c06716,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-a70e03b8-3e86-45c9-9c98-7f377eff26e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-6c1d0bfd-11ed-479f-b8ba-9ca5ecc3da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-22da951a-e05f-4cfa-93a9-29e069e24f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-f71c3596-52dd-46b5-a294-86c6011c1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-fa0e366f-63f7-470b-9fb0-eec120d476c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-d8bcfaed-9bc3-4b16-8c70-af7c2f2e840b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435511797-172.17.0.12-1597461129026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-e43c8112-cc67-4a90-bfbc-3e4ba8605c79,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-15d4af3d-2d4f-40e3-9486-efd449c06716,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-a70e03b8-3e86-45c9-9c98-7f377eff26e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-6c1d0bfd-11ed-479f-b8ba-9ca5ecc3da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-22da951a-e05f-4cfa-93a9-29e069e24f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-f71c3596-52dd-46b5-a294-86c6011c1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-fa0e366f-63f7-470b-9fb0-eec120d476c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-d8bcfaed-9bc3-4b16-8c70-af7c2f2e840b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337755540-172.17.0.12-1597461259518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46703,DS-79b2870e-f106-45c1-bdf2-c7bef92cc8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-809864ed-320d-4ea4-aec3-d415db9fdb47,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-b83c81de-195a-4295-b9ef-d8a8137896a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-e05bc3b6-e7d0-4137-8213-5f9ff8fcba70,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-eae52a72-204f-462c-b853-f09428383078,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-40e64909-fee7-4e2c-80ac-9c259659dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-d4f8f331-bc71-43bf-9069-f2b3282dea30,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-e079c796-8186-4b8e-97de-ab9b629f6b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337755540-172.17.0.12-1597461259518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46703,DS-79b2870e-f106-45c1-bdf2-c7bef92cc8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-809864ed-320d-4ea4-aec3-d415db9fdb47,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-b83c81de-195a-4295-b9ef-d8a8137896a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-e05bc3b6-e7d0-4137-8213-5f9ff8fcba70,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-eae52a72-204f-462c-b853-f09428383078,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-40e64909-fee7-4e2c-80ac-9c259659dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-d4f8f331-bc71-43bf-9069-f2b3282dea30,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-e079c796-8186-4b8e-97de-ab9b629f6b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393959124-172.17.0.12-1597461979963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38656,DS-25eb1e81-0159-4fc4-97cf-982c6342e008,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-a6b717b0-f404-4a2e-8d05-d422eeb7a251,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-83210853-647d-4d9b-b220-2f29aedd5265,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-c1d50d2b-2029-4d43-9263-7a60d433fe89,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-c3d3a5c0-8084-4168-a018-8a430e2c922c,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-9aa2aba3-fe08-4db0-b2fb-9c4817f16a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-aa85066a-2908-4693-8f03-24ca0dd786fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-ac1ced79-35f3-4ef5-be6e-cc5a6c724b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393959124-172.17.0.12-1597461979963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38656,DS-25eb1e81-0159-4fc4-97cf-982c6342e008,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-a6b717b0-f404-4a2e-8d05-d422eeb7a251,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-83210853-647d-4d9b-b220-2f29aedd5265,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-c1d50d2b-2029-4d43-9263-7a60d433fe89,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-c3d3a5c0-8084-4168-a018-8a430e2c922c,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-9aa2aba3-fe08-4db0-b2fb-9c4817f16a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-aa85066a-2908-4693-8f03-24ca0dd786fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-ac1ced79-35f3-4ef5-be6e-cc5a6c724b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283226872-172.17.0.12-1597462085246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35115,DS-f29a6862-5286-4d38-b9a8-bf88895839bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-7c27491c-e705-4f44-8451-4dedeeb3244f,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-dbca7045-0c4c-4d45-9968-78fddef992d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-2ce83446-3c12-4c23-be69-ad49ba87a168,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-dd8d9752-ed65-44c3-bf9c-f28923d9ef32,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-0b6e9cc8-14e2-45fe-9abe-e1fcf1af6728,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-5d5d111c-b92a-4a46-b625-432fd87a40d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-23d5fc9a-059e-49ec-93c5-1c1dada533e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283226872-172.17.0.12-1597462085246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35115,DS-f29a6862-5286-4d38-b9a8-bf88895839bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-7c27491c-e705-4f44-8451-4dedeeb3244f,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-dbca7045-0c4c-4d45-9968-78fddef992d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-2ce83446-3c12-4c23-be69-ad49ba87a168,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-dd8d9752-ed65-44c3-bf9c-f28923d9ef32,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-0b6e9cc8-14e2-45fe-9abe-e1fcf1af6728,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-5d5d111c-b92a-4a46-b625-432fd87a40d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-23d5fc9a-059e-49ec-93c5-1c1dada533e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279261772-172.17.0.12-1597462340934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-de3dcc19-d5a5-4b53-9841-19556028f657,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-b7d88696-ba38-42e3-b981-6f09ae40c561,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-affda292-eb4a-491b-87bc-1106b3e89957,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-f70fb8bb-2f90-4a00-aed7-d21388c2eeac,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-cc88a255-0a50-4777-90dc-1c0f79cd275f,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-17789c58-ab58-40d2-bca6-8e41e3940892,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-2941231a-ebc8-432f-a72c-2be054803991,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-fa5b97d5-0c4c-4ef2-aa64-cd4964c7b879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279261772-172.17.0.12-1597462340934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46027,DS-de3dcc19-d5a5-4b53-9841-19556028f657,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-b7d88696-ba38-42e3-b981-6f09ae40c561,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-affda292-eb4a-491b-87bc-1106b3e89957,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-f70fb8bb-2f90-4a00-aed7-d21388c2eeac,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-cc88a255-0a50-4777-90dc-1c0f79cd275f,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-17789c58-ab58-40d2-bca6-8e41e3940892,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-2941231a-ebc8-432f-a72c-2be054803991,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-fa5b97d5-0c4c-4ef2-aa64-cd4964c7b879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 10000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401356129-172.17.0.12-1597462499922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39592,DS-aa3d63ef-a670-497b-a1cb-f21b8981ccd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-046aebbc-0042-4586-ac04-b5d3cd919ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-c27f345e-0f9c-42ef-b596-6bc549946aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-1d18398b-7c02-4331-98c8-568b56b33d74,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-4e2f2e97-8ca6-4eca-b7e9-52f5de590a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-81177c44-3371-4f56-96d1-78cdb2ad3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-433ea3fa-8996-48fc-8a34-4708b2e4143a,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-3b7e447f-9063-4a97-a844-07a2b9bd06c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401356129-172.17.0.12-1597462499922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39592,DS-aa3d63ef-a670-497b-a1cb-f21b8981ccd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-046aebbc-0042-4586-ac04-b5d3cd919ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-c27f345e-0f9c-42ef-b596-6bc549946aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-1d18398b-7c02-4331-98c8-568b56b33d74,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-4e2f2e97-8ca6-4eca-b7e9-52f5de590a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-81177c44-3371-4f56-96d1-78cdb2ad3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-433ea3fa-8996-48fc-8a34-4708b2e4143a,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-3b7e447f-9063-4a97-a844-07a2b9bd06c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5668
