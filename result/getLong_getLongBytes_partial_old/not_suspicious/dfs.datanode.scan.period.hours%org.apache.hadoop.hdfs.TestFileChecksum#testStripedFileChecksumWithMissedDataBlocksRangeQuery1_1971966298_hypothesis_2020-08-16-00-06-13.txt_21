reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47705585-172.17.0.11-1597536492487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37045,DS-ece31e8f-e2d0-4b15-95ca-a5c5a8bc04a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-7cc78a5d-1527-4962-8f31-060a84eeaba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-5b1093be-154a-433a-b326-3fb218ffe0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-87ec100a-3cbb-43d9-837b-5e05f3b138c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-74f7fac5-d65d-40fb-818c-68af42ad123f,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-d8b3e349-070f-4553-acc2-e0a5e3ffed57,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-730d65c7-2194-4d0b-aacf-4c93db67129b,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-47405985-4da1-4ee0-a711-dcd4d6725731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47705585-172.17.0.11-1597536492487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37045,DS-ece31e8f-e2d0-4b15-95ca-a5c5a8bc04a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-7cc78a5d-1527-4962-8f31-060a84eeaba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-5b1093be-154a-433a-b326-3fb218ffe0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-87ec100a-3cbb-43d9-837b-5e05f3b138c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-74f7fac5-d65d-40fb-818c-68af42ad123f,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-d8b3e349-070f-4553-acc2-e0a5e3ffed57,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-730d65c7-2194-4d0b-aacf-4c93db67129b,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-47405985-4da1-4ee0-a711-dcd4d6725731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456961583-172.17.0.11-1597536629137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-60fe09f1-c705-4e65-b304-e5b830ed2a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-51319ec8-a3cd-47fa-9ad4-d28b4d901ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-2f4b7f4e-8575-440a-9eb6-015cc2871670,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-bae09e1c-37cc-4341-9174-224c420b545f,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-245a615c-4748-4f7a-8152-ef9ec3e496cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-379ca7df-b5bb-479c-b648-bbfb4b05a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-7d064958-b35e-4061-b388-5d2ec40250a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-abd2e1c6-274a-4420-bf68-7ca71cebd6ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456961583-172.17.0.11-1597536629137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-60fe09f1-c705-4e65-b304-e5b830ed2a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-51319ec8-a3cd-47fa-9ad4-d28b4d901ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-2f4b7f4e-8575-440a-9eb6-015cc2871670,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-bae09e1c-37cc-4341-9174-224c420b545f,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-245a615c-4748-4f7a-8152-ef9ec3e496cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-379ca7df-b5bb-479c-b648-bbfb4b05a9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-7d064958-b35e-4061-b388-5d2ec40250a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-abd2e1c6-274a-4420-bf68-7ca71cebd6ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175963881-172.17.0.11-1597536717385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45176,DS-77485c00-bc93-4ef9-be06-c01dc614357b,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-3031eced-9726-4e4d-9e91-8afe494ed92f,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-541a3cfe-563e-4661-9b90-5984a1559c17,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-d676f44e-74f9-4ee2-ba57-776044dcbfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-4567327c-6ee9-4a9b-916e-3fe060d5946f,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-1780934c-a853-477a-b9eb-6332fa8f768a,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-122daea4-83b9-4c2b-8ec7-fb77078e4633,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-99846b2e-426e-42ad-9b16-1d346fedb85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175963881-172.17.0.11-1597536717385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45176,DS-77485c00-bc93-4ef9-be06-c01dc614357b,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-3031eced-9726-4e4d-9e91-8afe494ed92f,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-541a3cfe-563e-4661-9b90-5984a1559c17,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-d676f44e-74f9-4ee2-ba57-776044dcbfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-4567327c-6ee9-4a9b-916e-3fe060d5946f,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-1780934c-a853-477a-b9eb-6332fa8f768a,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-122daea4-83b9-4c2b-8ec7-fb77078e4633,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-99846b2e-426e-42ad-9b16-1d346fedb85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902369514-172.17.0.11-1597538176900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32781,DS-1168f10a-fdb6-4b85-9bef-1979bd1e45b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-3dace354-3222-4f8d-828e-6877a0960177,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-4d896f2e-1db1-49ff-b95f-822492b46028,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-23693904-833d-4d01-8aa8-65969ddb7ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-65988c0a-7337-4ac5-b59a-7a44e3814f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-cab43471-00ff-487f-b38f-faf5a8f6b8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-c862a43b-e0cc-4c48-b94e-2460ee3a2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-79e6384c-d85e-47d6-bc9c-f10a832f8c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902369514-172.17.0.11-1597538176900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32781,DS-1168f10a-fdb6-4b85-9bef-1979bd1e45b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-3dace354-3222-4f8d-828e-6877a0960177,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-4d896f2e-1db1-49ff-b95f-822492b46028,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-23693904-833d-4d01-8aa8-65969ddb7ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-65988c0a-7337-4ac5-b59a-7a44e3814f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-cab43471-00ff-487f-b38f-faf5a8f6b8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-c862a43b-e0cc-4c48-b94e-2460ee3a2e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-79e6384c-d85e-47d6-bc9c-f10a832f8c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613315827-172.17.0.11-1597538601193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33028,DS-4335204b-fdae-4322-b4e7-41cef9692805,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-01acefdb-760b-4fd6-8e7e-8bfee202fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-1f3f551a-fba5-4ed3-80a9-de4a11d925fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-c02202c2-eb75-40ec-8cd5-5f4fb81f17b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-8a6010b9-98ef-4905-af86-700c30ecdf88,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-1a5418b6-37af-4d75-a97f-6740e01e3b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-7a1d8b1d-c3a3-4ed6-b83f-5cd0db9bfee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-9845f990-567b-4030-810a-cbd7cf7e4e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613315827-172.17.0.11-1597538601193:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33028,DS-4335204b-fdae-4322-b4e7-41cef9692805,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-01acefdb-760b-4fd6-8e7e-8bfee202fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-1f3f551a-fba5-4ed3-80a9-de4a11d925fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-c02202c2-eb75-40ec-8cd5-5f4fb81f17b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-8a6010b9-98ef-4905-af86-700c30ecdf88,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-1a5418b6-37af-4d75-a97f-6740e01e3b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-7a1d8b1d-c3a3-4ed6-b83f-5cd0db9bfee4,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-9845f990-567b-4030-810a-cbd7cf7e4e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574443146-172.17.0.11-1597538740653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46784,DS-5bc0aa64-be6b-4987-a0eb-b8e3208000c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-6f12f1b7-482f-48dd-8f00-63d1bed2259a,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-7e46db8b-1d86-4b61-abe6-64e9dea2f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-ff48859d-2815-4987-a3c1-9e4690a4c080,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-6239bd15-fa9c-4938-a262-027c2220ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-2472a8eb-b939-48bd-8279-b95308b76874,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-526cc9b5-c8b1-49b8-baaa-e7dcea5d9c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-ebab1977-956f-404f-9d00-3ce3a266d846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574443146-172.17.0.11-1597538740653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46784,DS-5bc0aa64-be6b-4987-a0eb-b8e3208000c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-6f12f1b7-482f-48dd-8f00-63d1bed2259a,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-7e46db8b-1d86-4b61-abe6-64e9dea2f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-ff48859d-2815-4987-a3c1-9e4690a4c080,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-6239bd15-fa9c-4938-a262-027c2220ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-2472a8eb-b939-48bd-8279-b95308b76874,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-526cc9b5-c8b1-49b8-baaa-e7dcea5d9c90,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-ebab1977-956f-404f-9d00-3ce3a266d846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879382752-172.17.0.11-1597539101868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35372,DS-61f9be93-6c84-46e3-90dd-44a97c276dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-ee4ae2ad-eda7-47f5-8ed1-b39c6721c200,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-1d1d6549-4d7c-4c08-9f2c-ece9afda46e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-f05ef033-f1fa-40e9-ae85-98374463b86e,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-68c8e0f5-0a12-4aca-954a-5852ad84009e,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-72dd6cca-5862-477b-bcf5-70b7e445614d,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-e0e725e7-b09d-419c-a76b-4c72e13df8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-6003e18b-89af-4caf-acf4-d4c81cc999cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879382752-172.17.0.11-1597539101868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35372,DS-61f9be93-6c84-46e3-90dd-44a97c276dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-ee4ae2ad-eda7-47f5-8ed1-b39c6721c200,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-1d1d6549-4d7c-4c08-9f2c-ece9afda46e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-f05ef033-f1fa-40e9-ae85-98374463b86e,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-68c8e0f5-0a12-4aca-954a-5852ad84009e,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-72dd6cca-5862-477b-bcf5-70b7e445614d,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-e0e725e7-b09d-419c-a76b-4c72e13df8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-6003e18b-89af-4caf-acf4-d4c81cc999cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053152981-172.17.0.11-1597539154780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45958,DS-68ad67fe-b8f3-468d-b2bc-d91b4b025e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-31e10a3d-f72b-4ed4-b102-ebc5f15dc230,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-4be49fca-fb4a-4c40-ab5a-95ca373cafd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-11abf890-4ff6-471e-8c32-24d32b1020e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-c28e1cc5-c379-4b33-a90c-f5c67b344931,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-f12cce76-0f0e-4aca-9fc5-9aaed7ac5927,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-5917a3a3-a964-4fb9-af24-e135deb33c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-2f27ac40-f43b-41b1-8445-57ebed9c5a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053152981-172.17.0.11-1597539154780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45958,DS-68ad67fe-b8f3-468d-b2bc-d91b4b025e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-31e10a3d-f72b-4ed4-b102-ebc5f15dc230,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-4be49fca-fb4a-4c40-ab5a-95ca373cafd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-11abf890-4ff6-471e-8c32-24d32b1020e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-c28e1cc5-c379-4b33-a90c-f5c67b344931,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-f12cce76-0f0e-4aca-9fc5-9aaed7ac5927,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-5917a3a3-a964-4fb9-af24-e135deb33c88,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-2f27ac40-f43b-41b1-8445-57ebed9c5a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618114584-172.17.0.11-1597539678854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-94f933e6-00b4-4eb8-8c04-893b7ae53950,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-554e9fcc-d178-40ee-83d0-35661aa84d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-7d6ce0a5-2ab3-4307-89dc-2399a1cb01dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-67c05ffe-b73f-4622-be98-c701e6fa46e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-97361e29-be97-460b-aafe-c9c09832b856,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-a1cdd20f-b0b7-4a37-8ed1-42a8776103b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-9a600184-0f46-4f03-a251-83f8a93da417,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-2158fc1f-cf08-4a56-8a34-94386e4835d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618114584-172.17.0.11-1597539678854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39950,DS-94f933e6-00b4-4eb8-8c04-893b7ae53950,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-554e9fcc-d178-40ee-83d0-35661aa84d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-7d6ce0a5-2ab3-4307-89dc-2399a1cb01dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-67c05ffe-b73f-4622-be98-c701e6fa46e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-97361e29-be97-460b-aafe-c9c09832b856,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-a1cdd20f-b0b7-4a37-8ed1-42a8776103b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-9a600184-0f46-4f03-a251-83f8a93da417,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-2158fc1f-cf08-4a56-8a34-94386e4835d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320674090-172.17.0.11-1597539960261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38545,DS-aca0f0d2-e548-4fda-a7e0-80bc70ad1647,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-b480f7f4-605f-4d76-bcdb-5584328464e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-81cbe4be-36ba-4d21-b3e7-d9122423c4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-9b568c53-3735-4e49-bdfd-3420a88c63b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-07051400-0e5d-40b4-8f25-f059b138d78f,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-2cca8815-11d9-4a1d-85ae-b0fe2b767722,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-0251e98c-dab5-43e8-b5bd-cbb10fdea91c,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-d1dc0b52-f77e-4e23-8413-3762e7014102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320674090-172.17.0.11-1597539960261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38545,DS-aca0f0d2-e548-4fda-a7e0-80bc70ad1647,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-b480f7f4-605f-4d76-bcdb-5584328464e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-81cbe4be-36ba-4d21-b3e7-d9122423c4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-9b568c53-3735-4e49-bdfd-3420a88c63b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-07051400-0e5d-40b4-8f25-f059b138d78f,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-2cca8815-11d9-4a1d-85ae-b0fe2b767722,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-0251e98c-dab5-43e8-b5bd-cbb10fdea91c,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-d1dc0b52-f77e-4e23-8413-3762e7014102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365769695-172.17.0.11-1597540000389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-06e3060a-9c99-4ea2-b8ff-40eaa6d2de47,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-18278808-cfc8-4a10-b521-432a826f3c41,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-c3a674fb-6a07-4f77-9f95-2bb7db96e51a,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-ade75d41-cc07-43e4-a160-46ea08c76a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-47821865-89f9-40ec-9ccc-a19a3b350d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-9b45134e-9bce-4708-a1cd-47f93f91e486,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-7535dbb9-163c-4495-b240-a16e44bfc312,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-8fdba866-ed80-49e9-975b-2d79ca4105f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365769695-172.17.0.11-1597540000389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-06e3060a-9c99-4ea2-b8ff-40eaa6d2de47,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-18278808-cfc8-4a10-b521-432a826f3c41,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-c3a674fb-6a07-4f77-9f95-2bb7db96e51a,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-ade75d41-cc07-43e4-a160-46ea08c76a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-47821865-89f9-40ec-9ccc-a19a3b350d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-9b45134e-9bce-4708-a1cd-47f93f91e486,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-7535dbb9-163c-4495-b240-a16e44bfc312,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-8fdba866-ed80-49e9-975b-2d79ca4105f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282641693-172.17.0.11-1597540797610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43704,DS-50373096-cf61-4e8e-96be-7b219ac61298,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-044bcb80-05b6-468f-827a-f02612c3c358,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-a059a617-6ce0-478f-ba3a-e953f2dbe308,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-459b956e-b759-4d14-a564-94e05bd4c1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-49d9006a-6f18-422f-8e18-15064b9db022,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-26555ac2-00ba-4400-b0d0-2e4666b097e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-a2f0a761-8eae-47f1-9192-56de3f7d4cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-ba9502b3-0db0-43fc-889e-c0df2da0a16a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282641693-172.17.0.11-1597540797610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43704,DS-50373096-cf61-4e8e-96be-7b219ac61298,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-044bcb80-05b6-468f-827a-f02612c3c358,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-a059a617-6ce0-478f-ba3a-e953f2dbe308,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-459b956e-b759-4d14-a564-94e05bd4c1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-49d9006a-6f18-422f-8e18-15064b9db022,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-26555ac2-00ba-4400-b0d0-2e4666b097e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-a2f0a761-8eae-47f1-9192-56de3f7d4cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-ba9502b3-0db0-43fc-889e-c0df2da0a16a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037824096-172.17.0.11-1597541019417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-fced5f90-95ab-4f34-ac31-1da3aacb0017,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-17d3c6b3-6907-43bc-8527-d5a05a89b4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-ed59e592-08b4-43e5-a404-778edb059916,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-ce940a0e-5388-4c22-a212-c2c41c1989cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-a9d29696-f9cf-4d59-a09f-3d39e27e705c,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-df9cbfd8-0bbe-4c10-8f83-d39f612adabb,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-6a8e0752-f7a7-4704-85ef-6b4f605764d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-8fe9eb32-5332-4448-b1b3-0da91f6cff15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037824096-172.17.0.11-1597541019417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-fced5f90-95ab-4f34-ac31-1da3aacb0017,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-17d3c6b3-6907-43bc-8527-d5a05a89b4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-ed59e592-08b4-43e5-a404-778edb059916,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-ce940a0e-5388-4c22-a212-c2c41c1989cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-a9d29696-f9cf-4d59-a09f-3d39e27e705c,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-df9cbfd8-0bbe-4c10-8f83-d39f612adabb,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-6a8e0752-f7a7-4704-85ef-6b4f605764d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-8fe9eb32-5332-4448-b1b3-0da91f6cff15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211561949-172.17.0.11-1597541552366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40879,DS-4a18e11e-4297-4138-b414-10db4d7b9965,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-3260114d-0d25-45b6-8436-bcb58ffbc41d,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-93c81eb4-a4b2-400e-8eeb-9792a0b8bd27,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-d2e31cb0-d384-482a-a9d6-f620c8424b83,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-b9796886-ef75-4423-a9f9-ae86cfec2dff,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-0225d0fd-00ef-40e0-9408-b37efd8d7454,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-624d845d-3c44-48c6-99f0-3b2bf748d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-3429af94-ba83-4133-bb6b-151606e4301e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211561949-172.17.0.11-1597541552366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40879,DS-4a18e11e-4297-4138-b414-10db4d7b9965,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-3260114d-0d25-45b6-8436-bcb58ffbc41d,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-93c81eb4-a4b2-400e-8eeb-9792a0b8bd27,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-d2e31cb0-d384-482a-a9d6-f620c8424b83,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-b9796886-ef75-4423-a9f9-ae86cfec2dff,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-0225d0fd-00ef-40e0-9408-b37efd8d7454,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-624d845d-3c44-48c6-99f0-3b2bf748d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:32859,DS-3429af94-ba83-4133-bb6b-151606e4301e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349220509-172.17.0.11-1597541766211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-a098babc-f931-4104-8624-413e841e8283,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-eb9eea00-6f2d-4658-82a9-d7a1cf46bd98,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-a800d79f-c425-4bcd-aea1-9988142d9dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-49f212c5-e1eb-4c83-9d3d-0af97dc8fd39,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-fcfba28c-ecfe-46be-b666-5d5825e45a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-a212fb70-fc60-4e48-88a7-2732bbd60936,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-00d5e45d-bd84-477b-8a09-892c5d904266,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-4e55a4ee-a269-457b-9db0-b2c1c8b8a07e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349220509-172.17.0.11-1597541766211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-a098babc-f931-4104-8624-413e841e8283,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-eb9eea00-6f2d-4658-82a9-d7a1cf46bd98,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-a800d79f-c425-4bcd-aea1-9988142d9dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-49f212c5-e1eb-4c83-9d3d-0af97dc8fd39,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-fcfba28c-ecfe-46be-b666-5d5825e45a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-a212fb70-fc60-4e48-88a7-2732bbd60936,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-00d5e45d-bd84-477b-8a09-892c5d904266,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-4e55a4ee-a269-457b-9db0-b2c1c8b8a07e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887906985-172.17.0.11-1597542171294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-e762e088-4bab-4503-8cf3-97d2d6913ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-40ae3939-d6d6-4ae0-906b-a9dc51e59812,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-0d5d2c4f-258c-4ecb-95fe-4ecaa292fab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-41e3da6f-5ab1-4508-ba87-83bf5972e268,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-81f057ca-0043-46f3-8c6f-f857fc6476d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-bcee26ce-0bd5-4f57-bfd5-b0fb6817d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-0859c114-6a93-4cd8-bd89-2af18084d013,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-cea4934a-b1f6-40a1-96f7-9ea66b01157c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887906985-172.17.0.11-1597542171294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-e762e088-4bab-4503-8cf3-97d2d6913ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-40ae3939-d6d6-4ae0-906b-a9dc51e59812,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-0d5d2c4f-258c-4ecb-95fe-4ecaa292fab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-41e3da6f-5ab1-4508-ba87-83bf5972e268,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-81f057ca-0043-46f3-8c6f-f857fc6476d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-bcee26ce-0bd5-4f57-bfd5-b0fb6817d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-0859c114-6a93-4cd8-bd89-2af18084d013,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-cea4934a-b1f6-40a1-96f7-9ea66b01157c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6946
