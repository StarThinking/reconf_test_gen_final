reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896816980-172.17.0.21-1597345034443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42983,DS-efe47c32-6667-4cb7-b302-84706530849c,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-f467caf8-3710-4c5a-9317-0969fbf55851,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-e02bc235-498e-4d8d-b583-05327212064b,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-fa8d0a9e-63cf-409f-8014-75ad8f4f748c,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-f2100c5b-7596-46b5-a0c1-56e80273232e,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-6d4e96e8-cda3-4559-bd2b-db79a05ea39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-26a15e52-d86d-4c57-bda1-9a09247b8ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-3ed2a3b8-8542-4427-9f96-406708ae3c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896816980-172.17.0.21-1597345034443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42983,DS-efe47c32-6667-4cb7-b302-84706530849c,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-f467caf8-3710-4c5a-9317-0969fbf55851,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-e02bc235-498e-4d8d-b583-05327212064b,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-fa8d0a9e-63cf-409f-8014-75ad8f4f748c,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-f2100c5b-7596-46b5-a0c1-56e80273232e,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-6d4e96e8-cda3-4559-bd2b-db79a05ea39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-26a15e52-d86d-4c57-bda1-9a09247b8ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-3ed2a3b8-8542-4427-9f96-406708ae3c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216520588-172.17.0.21-1597346242156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44949,DS-71ed61ba-e5f5-4e13-86b2-710b5bb3e201,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-4177dbcb-b706-42c7-9dcc-6edf84d52295,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-fb6e2b4e-4349-4d94-a7b0-61d0d6d9bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-14e63f79-b1d4-4599-8f0f-bf3571d3cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-eac386db-7ee7-43c4-9c91-0eed840d11ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-34f0a1d0-69a4-4e90-9b56-c227f655cc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-0666858d-8572-4813-be78-d09daf1d7e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-4f9f4fbd-2613-4734-804b-ebfbd5d3a9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216520588-172.17.0.21-1597346242156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44949,DS-71ed61ba-e5f5-4e13-86b2-710b5bb3e201,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-4177dbcb-b706-42c7-9dcc-6edf84d52295,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-fb6e2b4e-4349-4d94-a7b0-61d0d6d9bf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-14e63f79-b1d4-4599-8f0f-bf3571d3cac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-eac386db-7ee7-43c4-9c91-0eed840d11ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-34f0a1d0-69a4-4e90-9b56-c227f655cc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-0666858d-8572-4813-be78-d09daf1d7e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-4f9f4fbd-2613-4734-804b-ebfbd5d3a9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422099703-172.17.0.21-1597346576350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46147,DS-17484e90-726e-4119-8d61-6751b3132963,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-95d6bfc9-dbe2-42a5-aeca-ad737990d093,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-8ad8edd2-6a8a-4769-b9fa-a910ce874e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-753c2b5c-4f8e-4efe-bc1e-b22fbfb2d404,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-8fbd8415-5c98-4388-9e95-027e1cdf9392,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-bfaa1773-9405-4a96-bbe9-08738ba954ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-3a0b48e6-93e4-4a57-a5b6-dda201b2dd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-fc518386-d6f0-4af6-a1e0-547ff5c2f2fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422099703-172.17.0.21-1597346576350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46147,DS-17484e90-726e-4119-8d61-6751b3132963,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-95d6bfc9-dbe2-42a5-aeca-ad737990d093,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-8ad8edd2-6a8a-4769-b9fa-a910ce874e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-753c2b5c-4f8e-4efe-bc1e-b22fbfb2d404,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-8fbd8415-5c98-4388-9e95-027e1cdf9392,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-bfaa1773-9405-4a96-bbe9-08738ba954ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-3a0b48e6-93e4-4a57-a5b6-dda201b2dd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-fc518386-d6f0-4af6-a1e0-547ff5c2f2fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852181389-172.17.0.21-1597346853720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41759,DS-7179efe5-b5f2-48b5-b52b-6876187e9497,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-52f545e7-fc6c-4f57-adc1-782c36a4d3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-22c789bc-b443-4370-aacb-3091994d5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-b20bc928-2fd5-46ce-898c-963b606cebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-5bf220ed-6c83-4acc-930f-d058dbaec696,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-fa65b30b-7ae2-4b69-a170-94b1bee1bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-c392da12-2751-416f-9982-2e4cbdeed697,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-b9e50f0f-7194-4571-96fe-201680d0913d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852181389-172.17.0.21-1597346853720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41759,DS-7179efe5-b5f2-48b5-b52b-6876187e9497,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-52f545e7-fc6c-4f57-adc1-782c36a4d3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-22c789bc-b443-4370-aacb-3091994d5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-b20bc928-2fd5-46ce-898c-963b606cebd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-5bf220ed-6c83-4acc-930f-d058dbaec696,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-fa65b30b-7ae2-4b69-a170-94b1bee1bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-c392da12-2751-416f-9982-2e4cbdeed697,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-b9e50f0f-7194-4571-96fe-201680d0913d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505688617-172.17.0.21-1597347162633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44100,DS-4761d55d-c77d-490c-8453-5ef4855c8cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-e14de34a-2500-4201-bcb0-89940eb2b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-2c7a8d5f-522d-4e96-826f-baf343444f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-fc38660e-cec6-4334-825f-86c1e33fb842,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-6ec73d03-7096-44b6-ac7f-7259879f8be8,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-001418e7-f320-43b1-838a-29689f9fd9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-8adc07b4-34e7-4f51-8733-246ca419c628,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-94860e19-e262-4c35-854b-9e7840f05229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505688617-172.17.0.21-1597347162633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44100,DS-4761d55d-c77d-490c-8453-5ef4855c8cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-e14de34a-2500-4201-bcb0-89940eb2b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-2c7a8d5f-522d-4e96-826f-baf343444f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-fc38660e-cec6-4334-825f-86c1e33fb842,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-6ec73d03-7096-44b6-ac7f-7259879f8be8,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-001418e7-f320-43b1-838a-29689f9fd9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-8adc07b4-34e7-4f51-8733-246ca419c628,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-94860e19-e262-4c35-854b-9e7840f05229,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176360061-172.17.0.21-1597347341331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40846,DS-61854fa1-0a2d-49c8-b752-764f77a07724,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-a9c4f35d-e409-4dba-8798-30788f4a681c,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-2aa512f5-4497-4c5f-a019-b9030a6709bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-ced15d24-4842-4172-8327-3986111c38c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-f96424d0-8884-47be-a39d-9a24ff6ef9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-d9d73b41-45ca-4d7e-9528-e954649578dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-7746f54e-d335-470b-9830-1f9aae43b834,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-c4b0b3ab-b0bf-419b-8207-6ef64fecc714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176360061-172.17.0.21-1597347341331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40846,DS-61854fa1-0a2d-49c8-b752-764f77a07724,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-a9c4f35d-e409-4dba-8798-30788f4a681c,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-2aa512f5-4497-4c5f-a019-b9030a6709bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-ced15d24-4842-4172-8327-3986111c38c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-f96424d0-8884-47be-a39d-9a24ff6ef9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-d9d73b41-45ca-4d7e-9528-e954649578dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-7746f54e-d335-470b-9830-1f9aae43b834,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-c4b0b3ab-b0bf-419b-8207-6ef64fecc714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117970425-172.17.0.21-1597347899225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38333,DS-5d283393-aa37-4ba3-9bca-42e9eed698b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-9ddb7401-6913-4b8b-b671-9bc02f41cbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-490a584f-d391-4e25-886c-ac64243144e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-acb0ce5d-352c-46f3-92a9-c50d8919d2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-6c2b833c-150c-43e2-98e7-785f9a6009fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-203c16a5-904e-4a03-958e-73d993ecf2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-ac03ff09-db3d-4f0f-9b6d-a26212db6d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-792fa6a1-ce89-4cf2-85e5-3b11cabf5ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117970425-172.17.0.21-1597347899225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38333,DS-5d283393-aa37-4ba3-9bca-42e9eed698b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-9ddb7401-6913-4b8b-b671-9bc02f41cbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-490a584f-d391-4e25-886c-ac64243144e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-acb0ce5d-352c-46f3-92a9-c50d8919d2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-6c2b833c-150c-43e2-98e7-785f9a6009fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-203c16a5-904e-4a03-958e-73d993ecf2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-ac03ff09-db3d-4f0f-9b6d-a26212db6d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-792fa6a1-ce89-4cf2-85e5-3b11cabf5ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962216672-172.17.0.21-1597348308098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35669,DS-ad9c2c42-0ab5-4f03-b541-b24ff7f4d501,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-e45236ff-0a42-49d5-9268-325823f12add,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-4e49a37e-23b3-40a7-97f8-96a297822bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-8f657ba4-de61-4381-8b3c-0dd1f06d066e,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-6d70d998-c0f1-4e45-878f-0fffca2fd4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-7fc3bc09-f6c2-4e04-a450-714a6b636f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-b494b485-4262-4ef1-9262-8aa7831af45a,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-713a4291-3e5b-4c0b-b0c7-01ebc67a730a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962216672-172.17.0.21-1597348308098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35669,DS-ad9c2c42-0ab5-4f03-b541-b24ff7f4d501,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-e45236ff-0a42-49d5-9268-325823f12add,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-4e49a37e-23b3-40a7-97f8-96a297822bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-8f657ba4-de61-4381-8b3c-0dd1f06d066e,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-6d70d998-c0f1-4e45-878f-0fffca2fd4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-7fc3bc09-f6c2-4e04-a450-714a6b636f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-b494b485-4262-4ef1-9262-8aa7831af45a,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-713a4291-3e5b-4c0b-b0c7-01ebc67a730a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502984856-172.17.0.21-1597349586488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-4fea3552-57e9-45a7-b23d-a1a4f0460523,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-c3acb2c0-b5cc-498c-983a-ee3535ce087c,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-39e6426d-5942-443d-aeb0-ef86b56e5979,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-5ec6b4ed-ee37-4a0e-aa43-01c29c1cc99c,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-736b3b3b-cd2a-4456-a4a5-ebb6bfab4e41,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-5d7c304f-366b-4c72-bc5a-0499a4f7e120,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-a65b6e96-bff8-455e-b4b9-d50fdb3489d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-d3949b88-cffc-409f-8ab0-e84bcf1e0de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502984856-172.17.0.21-1597349586488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-4fea3552-57e9-45a7-b23d-a1a4f0460523,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-c3acb2c0-b5cc-498c-983a-ee3535ce087c,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-39e6426d-5942-443d-aeb0-ef86b56e5979,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-5ec6b4ed-ee37-4a0e-aa43-01c29c1cc99c,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-736b3b3b-cd2a-4456-a4a5-ebb6bfab4e41,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-5d7c304f-366b-4c72-bc5a-0499a4f7e120,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-a65b6e96-bff8-455e-b4b9-d50fdb3489d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-d3949b88-cffc-409f-8ab0-e84bcf1e0de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322582898-172.17.0.21-1597349807033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-d995ec1b-8b12-4274-808b-1a2aeb7bf966,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-347f8c78-536a-45c5-947a-15c70da63514,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-0b1cf70b-72d7-4c85-ad15-a00a82986aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-54f2e150-a39e-4890-8b9c-a1333d57e2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-ffb9f552-5369-4535-a41c-242eaa5d9fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-bc11e8b0-79ad-4640-bb58-4bde948e53ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-f05450bf-68ab-4429-aebe-2b109c0758a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-ddc160f2-d3a7-43af-8a55-2a0236055ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322582898-172.17.0.21-1597349807033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-d995ec1b-8b12-4274-808b-1a2aeb7bf966,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-347f8c78-536a-45c5-947a-15c70da63514,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-0b1cf70b-72d7-4c85-ad15-a00a82986aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-54f2e150-a39e-4890-8b9c-a1333d57e2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-ffb9f552-5369-4535-a41c-242eaa5d9fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-bc11e8b0-79ad-4640-bb58-4bde948e53ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-f05450bf-68ab-4429-aebe-2b109c0758a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-ddc160f2-d3a7-43af-8a55-2a0236055ac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8661955-172.17.0.21-1597350088930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-61408eca-11a5-4c95-9060-f2ef8b535f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-a180fbb7-73b7-4398-a4ec-0af2edc2fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-85593302-ee45-45c4-998d-ea8d5c8e398b,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-a1a7ae47-e92f-4045-84a7-d06ecd46d6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-5ad3adab-3664-49f1-9edd-084eab96ae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-ce6e007a-7cce-49f6-b938-75aeab29b191,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-e656ceb8-f0bc-4606-b637-562ed9dc435f,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-487101d9-255c-424c-b8dd-35964bc39acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8661955-172.17.0.21-1597350088930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-61408eca-11a5-4c95-9060-f2ef8b535f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-a180fbb7-73b7-4398-a4ec-0af2edc2fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-85593302-ee45-45c4-998d-ea8d5c8e398b,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-a1a7ae47-e92f-4045-84a7-d06ecd46d6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-5ad3adab-3664-49f1-9edd-084eab96ae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-ce6e007a-7cce-49f6-b938-75aeab29b191,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-e656ceb8-f0bc-4606-b637-562ed9dc435f,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-487101d9-255c-424c-b8dd-35964bc39acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222618376-172.17.0.21-1597350352676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42078,DS-fa7f582b-ae09-44f2-867f-52d1442dd325,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-2f0fa565-c45f-4794-b78c-b352cb5973d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-337e49c8-9770-4623-8103-bcf1d0dba41a,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-7effebda-771e-45a1-a8d1-f604d0c9e71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-372a733f-e260-45c9-a401-0c5a53ca7de5,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-87ec2a53-975c-4277-b495-01c1afda771d,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-26d394bc-df6d-4e2b-aaba-6244320cff06,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-216a96f5-48d2-4b66-a9f1-2b9da374bab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222618376-172.17.0.21-1597350352676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42078,DS-fa7f582b-ae09-44f2-867f-52d1442dd325,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-2f0fa565-c45f-4794-b78c-b352cb5973d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-337e49c8-9770-4623-8103-bcf1d0dba41a,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-7effebda-771e-45a1-a8d1-f604d0c9e71f,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-372a733f-e260-45c9-a401-0c5a53ca7de5,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-87ec2a53-975c-4277-b495-01c1afda771d,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-26d394bc-df6d-4e2b-aaba-6244320cff06,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-216a96f5-48d2-4b66-a9f1-2b9da374bab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561686643-172.17.0.21-1597350707827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45408,DS-61a72176-3f65-4b93-a3b1-22fe2da1b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-aeea096a-833a-4a1e-8fc0-0814835d3404,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-25789c6c-5900-4641-acea-31384b219af3,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-70c78aa5-d08d-4bb1-a4ec-a41a0fd702d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-78a53e6a-bfde-478a-b67a-557180783003,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-3952d9ed-9c00-4cad-8b92-c6cd592f170b,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-084e2165-cc40-4a6d-b6b2-dedd83c1a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-ed4f475c-af7e-4d57-a6ac-f5f71fcf9192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561686643-172.17.0.21-1597350707827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45408,DS-61a72176-3f65-4b93-a3b1-22fe2da1b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-aeea096a-833a-4a1e-8fc0-0814835d3404,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-25789c6c-5900-4641-acea-31384b219af3,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-70c78aa5-d08d-4bb1-a4ec-a41a0fd702d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-78a53e6a-bfde-478a-b67a-557180783003,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-3952d9ed-9c00-4cad-8b92-c6cd592f170b,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-084e2165-cc40-4a6d-b6b2-dedd83c1a7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-ed4f475c-af7e-4d57-a6ac-f5f71fcf9192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6814
