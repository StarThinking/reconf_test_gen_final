reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647596299-172.17.0.11-1597590509264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-731d2b6d-f84d-4da2-8385-d8f776dfb555,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-2fb576d7-eb66-4932-91bb-c8ad10bd31be,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-9a6c5145-c90d-46b8-a6fd-08be1d93b9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-d2d34192-2138-4a88-8a84-d06f91c966a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-b5ff8600-731d-4da4-9516-1c0b13c56a59,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-1af415dc-300f-4581-9fd5-71fa69cd5c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-045c9bff-1606-4cb1-81a0-6075b0cd985f,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-98b1621e-2e4b-42b1-9790-2c66decf6da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647596299-172.17.0.11-1597590509264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-731d2b6d-f84d-4da2-8385-d8f776dfb555,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-2fb576d7-eb66-4932-91bb-c8ad10bd31be,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-9a6c5145-c90d-46b8-a6fd-08be1d93b9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-d2d34192-2138-4a88-8a84-d06f91c966a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-b5ff8600-731d-4da4-9516-1c0b13c56a59,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-1af415dc-300f-4581-9fd5-71fa69cd5c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-045c9bff-1606-4cb1-81a0-6075b0cd985f,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-98b1621e-2e4b-42b1-9790-2c66decf6da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453141679-172.17.0.11-1597591017824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-569462df-b675-4e6c-b6d9-1873fd7d1556,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-864f9e3e-a50d-471a-aa4e-f74619f4f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-959ae8b8-8a94-4e2f-8f7b-5b5f97563202,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-9e073b63-b6d9-4a06-b350-3df58139f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-3048f260-4e08-4046-b35d-39028a9cfa29,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-795820a8-54c0-4e54-97bb-d1e59eb118f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-47e5a392-eba0-4e90-a950-2f07c41138c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-aadafe41-fcad-4f86-9aec-a25692f7d8b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453141679-172.17.0.11-1597591017824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-569462df-b675-4e6c-b6d9-1873fd7d1556,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-864f9e3e-a50d-471a-aa4e-f74619f4f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-959ae8b8-8a94-4e2f-8f7b-5b5f97563202,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-9e073b63-b6d9-4a06-b350-3df58139f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-3048f260-4e08-4046-b35d-39028a9cfa29,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-795820a8-54c0-4e54-97bb-d1e59eb118f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-47e5a392-eba0-4e90-a950-2f07c41138c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-aadafe41-fcad-4f86-9aec-a25692f7d8b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9688499-172.17.0.11-1597591253179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-9c638609-a6b8-46a1-af28-5b5340c754a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-afea797f-81b9-4c3f-a110-b3933f0157bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-bfaa0977-6dc8-4784-aafd-d8569023bb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-ee4be9ff-9554-4dc4-9b3e-1705dd7b8a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-4dd7f640-06d5-470f-a9b9-3a8c68faebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-a1f79af9-c65b-458f-91ea-15d6e67bd30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-a66a3259-29e0-4f22-85be-d9c31533080e,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-4a6bc9a3-2a50-4e9d-92f2-8ea9a27e7eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-9688499-172.17.0.11-1597591253179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-9c638609-a6b8-46a1-af28-5b5340c754a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-afea797f-81b9-4c3f-a110-b3933f0157bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-bfaa0977-6dc8-4784-aafd-d8569023bb8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-ee4be9ff-9554-4dc4-9b3e-1705dd7b8a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-4dd7f640-06d5-470f-a9b9-3a8c68faebbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-a1f79af9-c65b-458f-91ea-15d6e67bd30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-a66a3259-29e0-4f22-85be-d9c31533080e,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-4a6bc9a3-2a50-4e9d-92f2-8ea9a27e7eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189895758-172.17.0.11-1597591511870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38699,DS-835354d6-7bea-41cf-89c4-938454b7780d,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-9010999c-8fec-4b1a-a9c9-dd7ba9cac365,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-39a5c36a-0460-492b-bbea-59ae06d4c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-00f2f3bd-6f6b-4b5e-a9c6-528104a378c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-5377280c-f122-4b5d-a3ee-4f22455e57d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-6faf2232-8a07-4d3d-bf30-d5d8213e1cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-5178d70d-b514-4b64-9a6f-dbf899e92cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-47825c04-8f1a-4dcd-a750-6fb9be525161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-189895758-172.17.0.11-1597591511870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38699,DS-835354d6-7bea-41cf-89c4-938454b7780d,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-9010999c-8fec-4b1a-a9c9-dd7ba9cac365,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-39a5c36a-0460-492b-bbea-59ae06d4c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-00f2f3bd-6f6b-4b5e-a9c6-528104a378c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-5377280c-f122-4b5d-a3ee-4f22455e57d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-6faf2232-8a07-4d3d-bf30-d5d8213e1cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-5178d70d-b514-4b64-9a6f-dbf899e92cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-47825c04-8f1a-4dcd-a750-6fb9be525161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056737538-172.17.0.11-1597591665828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-8baf995b-5973-48f0-8e5e-e12eb4826350,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-1948005f-6e9a-4178-a347-cfbac2b153c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-9d777959-d477-441e-8235-b48f597d9299,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-e5030f9b-63b7-417d-b81d-1d4d72b3bfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-2082bbf3-ea37-400b-9863-3f0a6993543a,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-3b1be154-a592-484a-ad81-9150086b64ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-d31d9852-e991-4f56-9a7a-192713fe1a82,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-be4723c4-5393-4348-9eaa-87e27c925b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056737538-172.17.0.11-1597591665828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-8baf995b-5973-48f0-8e5e-e12eb4826350,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-1948005f-6e9a-4178-a347-cfbac2b153c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-9d777959-d477-441e-8235-b48f597d9299,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-e5030f9b-63b7-417d-b81d-1d4d72b3bfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-2082bbf3-ea37-400b-9863-3f0a6993543a,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-3b1be154-a592-484a-ad81-9150086b64ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-d31d9852-e991-4f56-9a7a-192713fe1a82,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-be4723c4-5393-4348-9eaa-87e27c925b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054501460-172.17.0.11-1597593001993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-0e63f1e6-ec96-456b-b1cc-4bda13704ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-cac911aa-f329-4eb3-9b33-68e45ba213ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-ef1c02db-db27-48b1-976e-e1d839dd892d,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-3bce8d1b-7ff7-430a-a96a-e2dc85743211,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-86bb4f13-aa41-45b9-8917-6306640915cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-d318f9be-db06-4ce0-a517-9f0f11a497b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-b77c853c-202b-4be3-9ae7-359fe467a32c,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-a3309f33-b6e7-4341-93dd-c36959c8955e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054501460-172.17.0.11-1597593001993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-0e63f1e6-ec96-456b-b1cc-4bda13704ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-cac911aa-f329-4eb3-9b33-68e45ba213ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-ef1c02db-db27-48b1-976e-e1d839dd892d,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-3bce8d1b-7ff7-430a-a96a-e2dc85743211,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-86bb4f13-aa41-45b9-8917-6306640915cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-d318f9be-db06-4ce0-a517-9f0f11a497b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-b77c853c-202b-4be3-9ae7-359fe467a32c,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-a3309f33-b6e7-4341-93dd-c36959c8955e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742447433-172.17.0.11-1597593254450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-57f1ecfb-e781-448b-bcd6-9020205d22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-8235f96f-d2c5-408e-be5d-f5854c0bc38a,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-5157e8d0-9495-4073-96f4-789eb230f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-e64a59fa-a9a2-4dac-a208-ed0cc871bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-43bf540e-4ee2-4c2c-909e-50d23d8506cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-48547e0d-0ddb-462b-b160-5987f2ea1a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-b60e9b7e-7a79-4bfb-9e82-72650f502fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-51526469-e8a4-4cbd-97d8-cb568bcefbb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742447433-172.17.0.11-1597593254450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40685,DS-57f1ecfb-e781-448b-bcd6-9020205d22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-8235f96f-d2c5-408e-be5d-f5854c0bc38a,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-5157e8d0-9495-4073-96f4-789eb230f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-e64a59fa-a9a2-4dac-a208-ed0cc871bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-43bf540e-4ee2-4c2c-909e-50d23d8506cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-48547e0d-0ddb-462b-b160-5987f2ea1a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-b60e9b7e-7a79-4bfb-9e82-72650f502fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-51526469-e8a4-4cbd-97d8-cb568bcefbb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354723421-172.17.0.11-1597593572178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-4a8cae54-03bb-4487-b387-d5435cd15f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-0e08fd37-6b88-4a84-9b84-817b2f7e3a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-0c38a7c9-4839-4afa-963b-5d6c52bce185,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-7f2e74f2-2196-4625-a4c3-013825d35b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-a6ac9e16-d1e9-4bd0-a384-b1a5795c5cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-ec665dcc-5f6c-4463-a957-80035a049c27,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-3d01568f-bc29-4841-9762-c08ee618798f,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-f2cab340-3d56-4831-bdbd-7c9f169e0b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354723421-172.17.0.11-1597593572178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-4a8cae54-03bb-4487-b387-d5435cd15f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-0e08fd37-6b88-4a84-9b84-817b2f7e3a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-0c38a7c9-4839-4afa-963b-5d6c52bce185,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-7f2e74f2-2196-4625-a4c3-013825d35b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-a6ac9e16-d1e9-4bd0-a384-b1a5795c5cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-ec665dcc-5f6c-4463-a957-80035a049c27,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-3d01568f-bc29-4841-9762-c08ee618798f,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-f2cab340-3d56-4831-bdbd-7c9f169e0b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802587767-172.17.0.11-1597593908667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43011,DS-8b980723-2c76-41c0-b87e-d6b8675f9217,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-7d498e58-d190-45db-afdb-cf1548da0699,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-3706697a-3d84-4e83-b97f-d1d0fec52f21,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-56d2f2c4-84f7-48df-97cf-7f681e8772e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-a1f50f4d-88f5-43a3-b95c-b3babcb0c490,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-a483d945-c3c8-49e0-ade2-45ba2de53d63,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-cc9f6129-311f-444a-8e24-303c3ec8cd31,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-13abf2c4-d15a-49b8-b679-bf77123d4a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802587767-172.17.0.11-1597593908667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43011,DS-8b980723-2c76-41c0-b87e-d6b8675f9217,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-7d498e58-d190-45db-afdb-cf1548da0699,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-3706697a-3d84-4e83-b97f-d1d0fec52f21,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-56d2f2c4-84f7-48df-97cf-7f681e8772e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-a1f50f4d-88f5-43a3-b95c-b3babcb0c490,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-a483d945-c3c8-49e0-ade2-45ba2de53d63,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-cc9f6129-311f-444a-8e24-303c3ec8cd31,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-13abf2c4-d15a-49b8-b679-bf77123d4a92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458758805-172.17.0.11-1597594066638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43891,DS-337d661d-df12-47d6-9177-9914efbedfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-cc770cb6-20e9-415c-9728-9bb39468ba01,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-229d656d-c234-4fcd-97d1-d486e9676ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-3aad6c35-dcaf-490f-83fd-bfe8f5387693,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-ebae68fa-53d3-460d-80a4-82d3470297db,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-47dcbea5-82b9-41aa-a8fd-daa727d31312,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-88e7f191-1195-435e-b379-3c4e19ee430b,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-f519b55a-3a5a-4dc2-9a6d-aa6c7b12e4fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458758805-172.17.0.11-1597594066638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43891,DS-337d661d-df12-47d6-9177-9914efbedfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-cc770cb6-20e9-415c-9728-9bb39468ba01,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-229d656d-c234-4fcd-97d1-d486e9676ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-3aad6c35-dcaf-490f-83fd-bfe8f5387693,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-ebae68fa-53d3-460d-80a4-82d3470297db,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-47dcbea5-82b9-41aa-a8fd-daa727d31312,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-88e7f191-1195-435e-b379-3c4e19ee430b,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-f519b55a-3a5a-4dc2-9a6d-aa6c7b12e4fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752482906-172.17.0.11-1597594112742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-abe9de8f-f94b-4a96-bfec-804b0eafc312,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-19efc920-a1d2-4c47-be53-642f6b353d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-02cc8d45-ba22-4f7a-8db3-d3510fa59085,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-8779ed0e-7c96-44c6-af24-f46e1a387815,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-18da410d-1c5c-4a75-b186-bf8860475b57,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-4b691296-f0ad-4d22-82cb-8b5fd1688b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-4067d4bd-ad74-4240-95d4-57b894b248ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-7173ccb1-6344-4983-85cf-a22b971b67d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752482906-172.17.0.11-1597594112742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-abe9de8f-f94b-4a96-bfec-804b0eafc312,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-19efc920-a1d2-4c47-be53-642f6b353d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-02cc8d45-ba22-4f7a-8db3-d3510fa59085,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-8779ed0e-7c96-44c6-af24-f46e1a387815,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-18da410d-1c5c-4a75-b186-bf8860475b57,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-4b691296-f0ad-4d22-82cb-8b5fd1688b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-4067d4bd-ad74-4240-95d4-57b894b248ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-7173ccb1-6344-4983-85cf-a22b971b67d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206020775-172.17.0.11-1597594282627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43064,DS-983e8be8-9d33-4f2b-bf41-df29b1de36c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-9f94697e-b40f-44f8-8668-9ff060735108,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-bb7c46ee-0f4b-456c-9bf1-c80ad3ff1ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-27cb57b7-2e9b-40a1-abd8-90e77c24892f,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-ecc9591a-287d-485d-80bd-b23a9fd57ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-a48c9150-6c07-4ff4-8087-a06f94b5e9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-7bb1b17c-a353-4c8a-833e-389395a751e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-c36198ca-0130-4e96-b91d-3a63637c3b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206020775-172.17.0.11-1597594282627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43064,DS-983e8be8-9d33-4f2b-bf41-df29b1de36c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-9f94697e-b40f-44f8-8668-9ff060735108,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-bb7c46ee-0f4b-456c-9bf1-c80ad3ff1ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-27cb57b7-2e9b-40a1-abd8-90e77c24892f,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-ecc9591a-287d-485d-80bd-b23a9fd57ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-a48c9150-6c07-4ff4-8087-a06f94b5e9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-7bb1b17c-a353-4c8a-833e-389395a751e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-c36198ca-0130-4e96-b91d-3a63637c3b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912374964-172.17.0.11-1597595063181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-84394bcb-898a-46c6-a0ab-91cc825d352b,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-a4da03bb-32d3-42f7-ae76-5ac1a18dafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-a2650128-7ead-4c26-9140-14b3f1d03590,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-3968d453-419b-4ffc-88ba-0d60c3071226,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-4d77e9e1-3294-4415-9868-869f03d0f8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-c1997038-68c5-437b-a6bb-0432881cacea,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-d1bdf22d-da4d-4d62-b139-b95e142ff613,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-5c6c84ca-aff2-441d-852b-c6407aea54a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912374964-172.17.0.11-1597595063181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-84394bcb-898a-46c6-a0ab-91cc825d352b,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-a4da03bb-32d3-42f7-ae76-5ac1a18dafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-a2650128-7ead-4c26-9140-14b3f1d03590,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-3968d453-419b-4ffc-88ba-0d60c3071226,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-4d77e9e1-3294-4415-9868-869f03d0f8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-c1997038-68c5-437b-a6bb-0432881cacea,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-d1bdf22d-da4d-4d62-b139-b95e142ff613,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-5c6c84ca-aff2-441d-852b-c6407aea54a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30854587-172.17.0.11-1597595196976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-11b7a9ff-d789-41f4-b0d3-f8b11ae4dbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-5e060075-ba45-45c7-8ba1-72682da14e08,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-03668f24-6126-4a6c-8464-3404058f2e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-9b275033-a51b-472d-9cfe-b94d58d71a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-a71812a7-2e26-4baf-9b07-fab35246a73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-2e564596-fa26-4ee2-97e6-a48faec29259,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-65572607-eb57-42c0-9127-a6222121544b,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-da07654b-2518-4a91-ac0f-a08e8ac79e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30854587-172.17.0.11-1597595196976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-11b7a9ff-d789-41f4-b0d3-f8b11ae4dbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-5e060075-ba45-45c7-8ba1-72682da14e08,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-03668f24-6126-4a6c-8464-3404058f2e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-9b275033-a51b-472d-9cfe-b94d58d71a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-a71812a7-2e26-4baf-9b07-fab35246a73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-2e564596-fa26-4ee2-97e6-a48faec29259,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-65572607-eb57-42c0-9127-a6222121544b,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-da07654b-2518-4a91-ac0f-a08e8ac79e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625902152-172.17.0.11-1597596244504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46340,DS-3e95374b-25ae-4e89-842d-070b2a47361c,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-93b04378-dac4-4da3-9c81-2b3be4d7c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-207f9a8f-f54e-42c9-925b-26455fbeb14d,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-befd6eb9-87d7-4ebb-bb54-d66fcfb0dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-b7d23259-3f02-489b-aff2-98a1adf10ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-8053601d-2d3e-4f69-8001-a7dba2e378f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-9449fd82-5321-42ab-9619-6d231160cce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-f2101dd1-d6e3-4826-a347-c6cd009fc5c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625902152-172.17.0.11-1597596244504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46340,DS-3e95374b-25ae-4e89-842d-070b2a47361c,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-93b04378-dac4-4da3-9c81-2b3be4d7c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-207f9a8f-f54e-42c9-925b-26455fbeb14d,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-befd6eb9-87d7-4ebb-bb54-d66fcfb0dfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41100,DS-b7d23259-3f02-489b-aff2-98a1adf10ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-8053601d-2d3e-4f69-8001-a7dba2e378f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-9449fd82-5321-42ab-9619-6d231160cce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-f2101dd1-d6e3-4826-a347-c6cd009fc5c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429496581-172.17.0.11-1597596593552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-3a0e24f4-3132-43bd-b0f6-17d393505048,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-6b8b3248-1bb8-4b19-a0b1-31dd626ad3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-1d0aa474-5589-4c35-809f-5ed60888fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-2e8225cf-4956-4902-b372-7c22f497671c,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-39f4a34e-f2cd-4444-b768-3e7f1ba62b67,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-ec23c7f7-1922-4067-9885-df7645eca275,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-c95e3c42-e07e-469a-a742-8a8a97d58fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-9ed7b327-661d-4fa0-99f3-f26f93304f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-429496581-172.17.0.11-1597596593552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-3a0e24f4-3132-43bd-b0f6-17d393505048,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-6b8b3248-1bb8-4b19-a0b1-31dd626ad3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-1d0aa474-5589-4c35-809f-5ed60888fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-2e8225cf-4956-4902-b372-7c22f497671c,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-39f4a34e-f2cd-4444-b768-3e7f1ba62b67,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-ec23c7f7-1922-4067-9885-df7645eca275,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-c95e3c42-e07e-469a-a742-8a8a97d58fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-9ed7b327-661d-4fa0-99f3-f26f93304f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6632
