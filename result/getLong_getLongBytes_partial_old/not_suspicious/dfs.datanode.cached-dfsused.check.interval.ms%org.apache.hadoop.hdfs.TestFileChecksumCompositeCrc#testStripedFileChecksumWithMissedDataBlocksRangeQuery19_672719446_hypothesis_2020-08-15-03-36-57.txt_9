reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805470746-172.17.0.17-1597462717197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42005,DS-f7bc67cf-3e99-402c-80b9-47b0bb098fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-26ae5621-28f8-4aed-ab4a-868070eaeb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-2ae0f15c-0153-4007-9da2-0cf98bb8c087,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-077507d0-acb3-42f6-b9f7-827230e46af0,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-39211d73-dd30-44da-8bbd-f0767d0b3a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-62488832-8526-41d8-b6dd-ec6e819558df,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-09e839af-448d-443e-9cf9-580a6e5b1239,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-a07d6e96-3d9a-4ce1-9ffa-ccfc61135801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805470746-172.17.0.17-1597462717197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42005,DS-f7bc67cf-3e99-402c-80b9-47b0bb098fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-26ae5621-28f8-4aed-ab4a-868070eaeb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-2ae0f15c-0153-4007-9da2-0cf98bb8c087,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-077507d0-acb3-42f6-b9f7-827230e46af0,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-39211d73-dd30-44da-8bbd-f0767d0b3a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-62488832-8526-41d8-b6dd-ec6e819558df,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-09e839af-448d-443e-9cf9-580a6e5b1239,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-a07d6e96-3d9a-4ce1-9ffa-ccfc61135801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886453686-172.17.0.17-1597462897729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-130a6e2d-eeae-4f20-a15f-9308a91f4fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-875bb76d-abc2-4c83-b852-b5f63ee48086,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-e21bdc20-da5f-488b-bd22-41dfb90f3482,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-b9d500b5-67f7-4f2a-b279-f59e8c1cf221,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-897c6ec9-b376-4883-8098-2d6910cf78e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-f0fc128e-e563-453b-a52c-eb29cf092738,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-daed0b02-fe60-47c8-b9ba-cea9c530fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-e5ee79dc-1d1f-4758-9351-e729dafec3e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-886453686-172.17.0.17-1597462897729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-130a6e2d-eeae-4f20-a15f-9308a91f4fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-875bb76d-abc2-4c83-b852-b5f63ee48086,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-e21bdc20-da5f-488b-bd22-41dfb90f3482,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-b9d500b5-67f7-4f2a-b279-f59e8c1cf221,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-897c6ec9-b376-4883-8098-2d6910cf78e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-f0fc128e-e563-453b-a52c-eb29cf092738,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-daed0b02-fe60-47c8-b9ba-cea9c530fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-e5ee79dc-1d1f-4758-9351-e729dafec3e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334853767-172.17.0.17-1597463133525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-29228ca8-bd7e-47b9-8874-d9664b8a9f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-c9639227-e489-4279-bb35-565ff584ec23,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-745fba2b-629f-40ff-8ea7-bcd739690c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-128edfc1-c9cb-4cb1-b07f-6d9441766438,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-4feeb03e-cd6d-45a9-9edf-4cc65f0dadf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-3197b7d5-0538-4d30-88e5-1fc1b3a220e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-67e56ce6-a07f-4008-9b84-730cb1a79b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-bf66b8aa-4b0a-4ba9-930a-805959eece1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334853767-172.17.0.17-1597463133525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-29228ca8-bd7e-47b9-8874-d9664b8a9f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-c9639227-e489-4279-bb35-565ff584ec23,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-745fba2b-629f-40ff-8ea7-bcd739690c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-128edfc1-c9cb-4cb1-b07f-6d9441766438,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-4feeb03e-cd6d-45a9-9edf-4cc65f0dadf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-3197b7d5-0538-4d30-88e5-1fc1b3a220e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-67e56ce6-a07f-4008-9b84-730cb1a79b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-bf66b8aa-4b0a-4ba9-930a-805959eece1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798939523-172.17.0.17-1597463350880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46876,DS-02d38339-f1a5-47f9-9380-e193943182c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-51653bac-4147-49c7-bd66-31734964e34b,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-4c1e052f-dba9-4bf6-9924-ff33eb2f2657,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-77203315-09cd-4d3f-84e9-292a0be9ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-c33f0a89-2b04-40f8-8cff-5ace9bfd6e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-b013b3d3-2cd9-416b-a328-dd07a9ac67c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-dab00cde-baa5-40fb-a191-2fe432da1823,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-76f50262-d03d-4e0f-815b-4b57422a50ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798939523-172.17.0.17-1597463350880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46876,DS-02d38339-f1a5-47f9-9380-e193943182c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-51653bac-4147-49c7-bd66-31734964e34b,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-4c1e052f-dba9-4bf6-9924-ff33eb2f2657,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-77203315-09cd-4d3f-84e9-292a0be9ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-c33f0a89-2b04-40f8-8cff-5ace9bfd6e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-b013b3d3-2cd9-416b-a328-dd07a9ac67c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-dab00cde-baa5-40fb-a191-2fe432da1823,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-76f50262-d03d-4e0f-815b-4b57422a50ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019725518-172.17.0.17-1597464659945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32793,DS-8cfa5e4f-f7ec-4c04-b0cd-8bc703691d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-89fb4e63-dc3c-4f52-9932-c4165273ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-5dec4256-941e-4b60-aae7-5c8dd9a278c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-d610d802-d9c4-44f6-b179-0f271788dc42,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-fd9297e6-d3e4-4fb6-b691-309304c495b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-47317e00-c6e5-4e7a-958e-c8217e50d4af,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-c282aa52-1dc1-4b41-a57a-ade1cda00a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-bc6a3325-d5b9-4e4d-a8e5-b655cdd97665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019725518-172.17.0.17-1597464659945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32793,DS-8cfa5e4f-f7ec-4c04-b0cd-8bc703691d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-89fb4e63-dc3c-4f52-9932-c4165273ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-5dec4256-941e-4b60-aae7-5c8dd9a278c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-d610d802-d9c4-44f6-b179-0f271788dc42,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-fd9297e6-d3e4-4fb6-b691-309304c495b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-47317e00-c6e5-4e7a-958e-c8217e50d4af,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-c282aa52-1dc1-4b41-a57a-ade1cda00a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-bc6a3325-d5b9-4e4d-a8e5-b655cdd97665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663492320-172.17.0.17-1597464752845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37195,DS-906225e4-1a61-4c9b-9064-ab9a29fba963,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-84873977-6c73-4235-86f3-56b69af1d8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-addfef2b-42a0-432a-8632-2bd7be77978a,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-226f1272-a708-4602-8ed6-12b4540aaca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-9df42df2-93fa-4098-a878-bceea2d89f34,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-ef01e22b-dd3e-427f-9a12-573fdbe30fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-fe434886-16f8-4364-acfc-58e2f6308b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-0e069c98-d868-4677-89ba-1a9ce5df6396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663492320-172.17.0.17-1597464752845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37195,DS-906225e4-1a61-4c9b-9064-ab9a29fba963,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-84873977-6c73-4235-86f3-56b69af1d8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-addfef2b-42a0-432a-8632-2bd7be77978a,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-226f1272-a708-4602-8ed6-12b4540aaca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-9df42df2-93fa-4098-a878-bceea2d89f34,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-ef01e22b-dd3e-427f-9a12-573fdbe30fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-fe434886-16f8-4364-acfc-58e2f6308b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-0e069c98-d868-4677-89ba-1a9ce5df6396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295285159-172.17.0.17-1597465072568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38954,DS-e839f521-79ca-4d77-b953-58b173790496,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-b37b183b-9e52-494e-bf0b-7c4ac7a814c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-4125a054-c344-4b0c-a00e-54e293997b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-aff966eb-84f5-4bef-ac93-26c608ac2481,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-f3f025ac-961c-441b-a825-99a961d43f31,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-966b8b9a-f81a-475c-abbe-bf50a72bf7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-912c91d0-af31-4e9b-9b54-e8c27ecfcd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-e4f81168-2339-45b9-85b6-66cf33e5a876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295285159-172.17.0.17-1597465072568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38954,DS-e839f521-79ca-4d77-b953-58b173790496,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-b37b183b-9e52-494e-bf0b-7c4ac7a814c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-4125a054-c344-4b0c-a00e-54e293997b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-aff966eb-84f5-4bef-ac93-26c608ac2481,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-f3f025ac-961c-441b-a825-99a961d43f31,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-966b8b9a-f81a-475c-abbe-bf50a72bf7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-912c91d0-af31-4e9b-9b54-e8c27ecfcd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-e4f81168-2339-45b9-85b6-66cf33e5a876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762975421-172.17.0.17-1597465166614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36525,DS-2f905c94-4d3d-476e-8d1a-f23edec38026,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-e8fbd028-f852-4fc8-b58c-2171c9aba891,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-ffcc5922-0fd7-4569-bed6-02f01fe64fff,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-8b936cd6-b8ae-42f2-9eb5-fec59795af65,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-9c135c64-db0c-49b4-b4e0-efc0d01178df,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-7c3687f3-951a-4f0d-966a-b2e8c6ad9680,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6167be11-4d40-495c-b088-f341f2bc8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-95eded04-52ab-4f09-8094-4d590cb1cd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762975421-172.17.0.17-1597465166614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36525,DS-2f905c94-4d3d-476e-8d1a-f23edec38026,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-e8fbd028-f852-4fc8-b58c-2171c9aba891,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-ffcc5922-0fd7-4569-bed6-02f01fe64fff,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-8b936cd6-b8ae-42f2-9eb5-fec59795af65,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-9c135c64-db0c-49b4-b4e0-efc0d01178df,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-7c3687f3-951a-4f0d-966a-b2e8c6ad9680,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-6167be11-4d40-495c-b088-f341f2bc8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-95eded04-52ab-4f09-8094-4d590cb1cd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088790183-172.17.0.17-1597465622686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-f65bfd2a-0f0a-4a04-955c-ce2b14497ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-59b742fb-5957-4c44-874e-cf98a45372ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-b405dff9-d0e3-4a16-b0b7-9676c41e3794,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-4a2c70f3-61cd-4490-82aa-ba82d8e9b2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-9a60a93a-4742-45ed-9b3f-f14389fb34cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-aa908e06-f9b2-4d62-b37f-cef185c7ba32,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-201b9f11-75a7-43cb-bcf4-556e8c392209,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-ecf08118-25f2-4118-be6b-289220eb92b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088790183-172.17.0.17-1597465622686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-f65bfd2a-0f0a-4a04-955c-ce2b14497ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-59b742fb-5957-4c44-874e-cf98a45372ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-b405dff9-d0e3-4a16-b0b7-9676c41e3794,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-4a2c70f3-61cd-4490-82aa-ba82d8e9b2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-9a60a93a-4742-45ed-9b3f-f14389fb34cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-aa908e06-f9b2-4d62-b37f-cef185c7ba32,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-201b9f11-75a7-43cb-bcf4-556e8c392209,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-ecf08118-25f2-4118-be6b-289220eb92b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344374433-172.17.0.17-1597466451940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-8e589b0b-ac37-454e-b414-e7acad28af68,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-d6470e71-5bc2-427f-979d-6ce840f5a898,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-beb6c168-d33d-48d1-941b-098c474cc26a,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-7bafb9ec-0a7c-4ae6-9d82-29f15d499aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-ec71c18f-c5f8-4ee0-b97b-73a0afe56f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-67dcea79-b957-46cd-96b4-272631eef9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-ecf3de12-a4ce-4dc1-bd41-c554d2d62dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-da5b3090-7c9e-4603-ac6d-bfc529d499eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344374433-172.17.0.17-1597466451940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-8e589b0b-ac37-454e-b414-e7acad28af68,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-d6470e71-5bc2-427f-979d-6ce840f5a898,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-beb6c168-d33d-48d1-941b-098c474cc26a,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-7bafb9ec-0a7c-4ae6-9d82-29f15d499aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-ec71c18f-c5f8-4ee0-b97b-73a0afe56f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-67dcea79-b957-46cd-96b4-272631eef9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-ecf3de12-a4ce-4dc1-bd41-c554d2d62dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-da5b3090-7c9e-4603-ac6d-bfc529d499eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13928117-172.17.0.17-1597466570420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34999,DS-7c16d503-2a8a-465c-9a0c-2ba3ea37cc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-0fed40ad-5d6a-4642-b85d-8fdeffed8b10,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-4b82b8ec-4dd9-472e-bb28-67c1a2c937b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-e35205d3-59f1-43eb-b994-943d270c7f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-8f050953-be40-4fc4-a1f1-7034b039b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-93f729f2-8a91-4f94-96e1-c6633078edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-66147cad-044b-438e-a614-be1d0a8f2620,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-e97c5bf0-916b-4262-9f7a-d98bf97091d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13928117-172.17.0.17-1597466570420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34999,DS-7c16d503-2a8a-465c-9a0c-2ba3ea37cc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-0fed40ad-5d6a-4642-b85d-8fdeffed8b10,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-4b82b8ec-4dd9-472e-bb28-67c1a2c937b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-e35205d3-59f1-43eb-b994-943d270c7f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-8f050953-be40-4fc4-a1f1-7034b039b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-93f729f2-8a91-4f94-96e1-c6633078edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-66147cad-044b-438e-a614-be1d0a8f2620,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-e97c5bf0-916b-4262-9f7a-d98bf97091d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812863048-172.17.0.17-1597466756202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34181,DS-e94d2386-fdad-4bfd-9b10-f1931c21a383,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-6e9ce2e0-9fe4-441b-a175-b65a288f13fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-f500bf79-00a0-4968-a70a-c74fe847a4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-bc01f01f-ef70-44e3-9ada-8cce788d69bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-0ae52d59-f69e-4ce1-b76a-d66b8722d999,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-d80fd7cb-8acf-44db-b762-9a04e9d8ed84,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-356c8875-1df3-4c1f-bd46-d57c94946bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-860a4c14-4083-476e-8e8c-239a5d705b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812863048-172.17.0.17-1597466756202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34181,DS-e94d2386-fdad-4bfd-9b10-f1931c21a383,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-6e9ce2e0-9fe4-441b-a175-b65a288f13fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-f500bf79-00a0-4968-a70a-c74fe847a4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-bc01f01f-ef70-44e3-9ada-8cce788d69bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-0ae52d59-f69e-4ce1-b76a-d66b8722d999,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-d80fd7cb-8acf-44db-b762-9a04e9d8ed84,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-356c8875-1df3-4c1f-bd46-d57c94946bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-860a4c14-4083-476e-8e8c-239a5d705b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432932838-172.17.0.17-1597466837488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-241094a6-ae93-4a61-8b12-c8d7a244abd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-26b6248a-c385-4dcd-964f-36f48ac66384,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-930ec931-4ce0-4c4b-8edb-c8af098ed56c,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-b5e357cf-bbf9-4d36-b561-02a10176aaba,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-ca126310-c70f-4f3f-8838-6c67e9db98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-5ebbd3e1-0f66-41f6-9c09-90cf94defb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-037faa35-e4b9-4540-8738-bb45a46d0ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-e6836b37-cf31-485b-b571-695becbd9371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432932838-172.17.0.17-1597466837488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32913,DS-241094a6-ae93-4a61-8b12-c8d7a244abd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-26b6248a-c385-4dcd-964f-36f48ac66384,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-930ec931-4ce0-4c4b-8edb-c8af098ed56c,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-b5e357cf-bbf9-4d36-b561-02a10176aaba,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-ca126310-c70f-4f3f-8838-6c67e9db98b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-5ebbd3e1-0f66-41f6-9c09-90cf94defb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-037faa35-e4b9-4540-8738-bb45a46d0ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-e6836b37-cf31-485b-b571-695becbd9371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102262921-172.17.0.17-1597466925766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36550,DS-db95c7d5-fc02-4f0d-96fc-fda530ab8271,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-eea8ee23-307b-4ea6-b752-69d56120134f,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-5ec4a021-abb9-4655-8f3f-70ac93f2e686,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-86fdb5b1-ef03-464a-af92-74e780e46d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-1e726c50-6abd-4a8a-b021-3136ddedc872,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-8ccda745-17ac-4255-8616-164c2c4c01de,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-79a6ab83-4492-40f4-a9f4-c762c5ded2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-5a900c93-30d8-4ce7-a795-1906950775dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102262921-172.17.0.17-1597466925766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36550,DS-db95c7d5-fc02-4f0d-96fc-fda530ab8271,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-eea8ee23-307b-4ea6-b752-69d56120134f,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-5ec4a021-abb9-4655-8f3f-70ac93f2e686,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-86fdb5b1-ef03-464a-af92-74e780e46d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-1e726c50-6abd-4a8a-b021-3136ddedc872,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-8ccda745-17ac-4255-8616-164c2c4c01de,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-79a6ab83-4492-40f4-a9f4-c762c5ded2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-5a900c93-30d8-4ce7-a795-1906950775dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695509999-172.17.0.17-1597467200727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44197,DS-df05c7f6-3261-48ad-85c1-2a30d2f14367,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-0112c2f5-f787-4a45-9491-13bebe249192,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-becf68f1-800f-4fb0-90be-b492bb7d4b47,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-03e9a8ec-def1-4a23-9199-006459e4f72e,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-859c7f6d-f700-40ae-9734-a446d5bc39ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-e6a7f1fa-ebff-4d56-af98-b9d6301c0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-dc70b63c-f502-4aa0-a7f5-905613edc8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-cff02062-289a-4812-8a6d-c6b83864b0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-695509999-172.17.0.17-1597467200727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44197,DS-df05c7f6-3261-48ad-85c1-2a30d2f14367,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-0112c2f5-f787-4a45-9491-13bebe249192,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-becf68f1-800f-4fb0-90be-b492bb7d4b47,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-03e9a8ec-def1-4a23-9199-006459e4f72e,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-859c7f6d-f700-40ae-9734-a446d5bc39ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-e6a7f1fa-ebff-4d56-af98-b9d6301c0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-dc70b63c-f502-4aa0-a7f5-905613edc8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-cff02062-289a-4812-8a6d-c6b83864b0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658855596-172.17.0.17-1597467244074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46501,DS-e1703b42-bcca-4176-8607-e0a435d0fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-e18f7104-e977-4e61-bf70-f9cbd8d24e70,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-130b3ebb-d2c2-4523-a9ce-9d38b6076cda,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-c09c6723-6b6c-4b6a-a5d4-2931e28b78e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-79de8cf2-0e98-498a-9652-e64cd67c1f24,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-7d2d7412-22c6-414f-9040-325c96d3b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-88ab5f08-bd85-4938-ba08-94a360e9d7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-4e527bfc-4269-4074-aa46-318c55858e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658855596-172.17.0.17-1597467244074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46501,DS-e1703b42-bcca-4176-8607-e0a435d0fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-e18f7104-e977-4e61-bf70-f9cbd8d24e70,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-130b3ebb-d2c2-4523-a9ce-9d38b6076cda,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-c09c6723-6b6c-4b6a-a5d4-2931e28b78e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-79de8cf2-0e98-498a-9652-e64cd67c1f24,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-7d2d7412-22c6-414f-9040-325c96d3b68e,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-88ab5f08-bd85-4938-ba08-94a360e9d7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-4e527bfc-4269-4074-aa46-318c55858e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528542032-172.17.0.17-1597467594765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-6f96497a-5c26-44f2-a2a9-d5b2ce30d55c,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-8322589d-0c27-4b00-b91c-2226bad25d41,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-ed27fe6b-44b4-4670-bbe8-a15350a0c8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-3a53a383-4c8d-4a74-8843-4fc7f9eee5de,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-b4c047e7-d61d-4a10-9a0d-db5c4374e582,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-86f2d946-6e25-49f1-aaae-f998973a05b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-c35a06c5-9b3a-402b-b409-a06f020ecb43,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-0a4f6ce5-c4c8-4f8c-b745-62f3548a730b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528542032-172.17.0.17-1597467594765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-6f96497a-5c26-44f2-a2a9-d5b2ce30d55c,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-8322589d-0c27-4b00-b91c-2226bad25d41,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-ed27fe6b-44b4-4670-bbe8-a15350a0c8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-3a53a383-4c8d-4a74-8843-4fc7f9eee5de,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-b4c047e7-d61d-4a10-9a0d-db5c4374e582,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-86f2d946-6e25-49f1-aaae-f998973a05b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-c35a06c5-9b3a-402b-b409-a06f020ecb43,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-0a4f6ce5-c4c8-4f8c-b745-62f3548a730b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733242095-172.17.0.17-1597468420691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44722,DS-9a318917-bd2b-4963-b48c-88194ea7b5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-c2d0015d-7c7e-4019-b208-f709576f9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-3a479190-9cfb-4ee4-badf-d4afa37bad26,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-1028ad0c-c66a-41fa-817e-5460b7b6769b,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-043819b2-7e98-459c-868a-dbfefbe48e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-65210b82-9c18-4b7c-82e9-d30bc63591ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-9735af77-c1ac-43d1-83e9-a432880a86e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-c7660db1-3df8-4248-a4c5-9b8acc2a722d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733242095-172.17.0.17-1597468420691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44722,DS-9a318917-bd2b-4963-b48c-88194ea7b5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-c2d0015d-7c7e-4019-b208-f709576f9dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-3a479190-9cfb-4ee4-badf-d4afa37bad26,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-1028ad0c-c66a-41fa-817e-5460b7b6769b,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-043819b2-7e98-459c-868a-dbfefbe48e39,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-65210b82-9c18-4b7c-82e9-d30bc63591ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-9735af77-c1ac-43d1-83e9-a432880a86e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-c7660db1-3df8-4248-a4c5-9b8acc2a722d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513288500-172.17.0.17-1597469422638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-c101b315-3668-47e0-afc1-82d5e3e14cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-78ad204a-a498-4bc4-a1fe-7a647ff2369b,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-ab1a2254-3b8e-48bd-b1c2-653c602a07c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-a6944518-84f1-4b89-a81c-c709c773848d,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-6ba256de-f33d-4216-bd5b-a5e989b97ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-00fdd308-47bd-4a0d-a916-0fd6ec7bac21,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-31174955-86f1-4bed-b08f-627d8dd36ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-264b0cb5-f4e0-4336-a22f-0d74e713107b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513288500-172.17.0.17-1597469422638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-c101b315-3668-47e0-afc1-82d5e3e14cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-78ad204a-a498-4bc4-a1fe-7a647ff2369b,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-ab1a2254-3b8e-48bd-b1c2-653c602a07c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-a6944518-84f1-4b89-a81c-c709c773848d,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-6ba256de-f33d-4216-bd5b-a5e989b97ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-00fdd308-47bd-4a0d-a916-0fd6ec7bac21,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-31174955-86f1-4bed-b08f-627d8dd36ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-264b0cb5-f4e0-4336-a22f-0d74e713107b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 6833
