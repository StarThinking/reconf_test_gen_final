reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108369510-172.17.0.10-1597417929986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40841,DS-5634dcb5-1dfb-44cb-9b77-23d14402b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-ae6f518c-560a-48f0-975a-57a04fd790d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-9aa728e9-fd82-40d3-928e-e4326297f143,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-922cc012-1a02-4b60-a59d-f9e5420fb01a,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-dcc12e3a-85eb-47b1-8624-82064ee01c03,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-28167c65-e77c-4702-bac8-0756e05c53ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-88ce74cb-099f-445f-baa3-7656d41ed2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-943d97b4-9b94-4121-b528-209ad1c5e069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108369510-172.17.0.10-1597417929986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40841,DS-5634dcb5-1dfb-44cb-9b77-23d14402b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-ae6f518c-560a-48f0-975a-57a04fd790d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-9aa728e9-fd82-40d3-928e-e4326297f143,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-922cc012-1a02-4b60-a59d-f9e5420fb01a,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-dcc12e3a-85eb-47b1-8624-82064ee01c03,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-28167c65-e77c-4702-bac8-0756e05c53ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-88ce74cb-099f-445f-baa3-7656d41ed2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-943d97b4-9b94-4121-b528-209ad1c5e069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359774849-172.17.0.10-1597418173014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45385,DS-9512f928-c855-4678-a24d-fbeff3cc6fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-20ebd78e-d37e-4a05-908e-74ce67b9be8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-7a22a854-447a-4730-9d0d-eba92662ecdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-b8bbeb1a-fc04-4a77-980e-e3a82e84b486,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-4fd87abd-9fca-4970-8cec-367462342c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-b93c038b-2ac0-46f9-9b58-102e654e3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-1be4f6a4-eaee-477c-8f8c-b9b64d1455b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-6fa558ea-ac21-4eef-84d9-b95027ef95e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359774849-172.17.0.10-1597418173014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45385,DS-9512f928-c855-4678-a24d-fbeff3cc6fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-20ebd78e-d37e-4a05-908e-74ce67b9be8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-7a22a854-447a-4730-9d0d-eba92662ecdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-b8bbeb1a-fc04-4a77-980e-e3a82e84b486,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-4fd87abd-9fca-4970-8cec-367462342c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-b93c038b-2ac0-46f9-9b58-102e654e3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-1be4f6a4-eaee-477c-8f8c-b9b64d1455b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-6fa558ea-ac21-4eef-84d9-b95027ef95e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983990854-172.17.0.10-1597418357426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-6188c528-3a37-4d65-8aaa-c5aa50395c40,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-62fe8abd-95d4-4e1a-ae3b-ef2eb999a323,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-9bb457e9-2d4b-439b-bb33-9ec6e4f48c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-4333c5cc-839b-43c6-ba48-07785bd151ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-66fd05c0-05f7-4785-8202-8dcbb3ab4ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-11738c7c-97c9-4cd8-831f-5b9c4ad050e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-d3352553-0131-4f5f-a2de-d46c57eab549,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-24a6e542-597e-4d15-8064-a05c07984bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983990854-172.17.0.10-1597418357426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-6188c528-3a37-4d65-8aaa-c5aa50395c40,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-62fe8abd-95d4-4e1a-ae3b-ef2eb999a323,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-9bb457e9-2d4b-439b-bb33-9ec6e4f48c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-4333c5cc-839b-43c6-ba48-07785bd151ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-66fd05c0-05f7-4785-8202-8dcbb3ab4ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-11738c7c-97c9-4cd8-831f-5b9c4ad050e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-d3352553-0131-4f5f-a2de-d46c57eab549,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-24a6e542-597e-4d15-8064-a05c07984bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188794233-172.17.0.10-1597418788419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34613,DS-5b885528-5634-4a88-a26b-8201b960a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-8aa35488-db82-4699-9e8c-bf52557b8b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-94ae2749-34c5-4265-8b88-a0f895af0344,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-dedcf672-14b4-4388-bea3-6615a8a62b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-d5bf5baf-4823-417d-8644-edc35e16c346,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-3daa4d30-d71c-48d8-a873-11f1886201f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-1235c3ab-9ccb-459c-9e07-2d7dfb087728,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-bc8a1629-39af-4b44-b595-fefe503451ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188794233-172.17.0.10-1597418788419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34613,DS-5b885528-5634-4a88-a26b-8201b960a3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-8aa35488-db82-4699-9e8c-bf52557b8b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-94ae2749-34c5-4265-8b88-a0f895af0344,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-dedcf672-14b4-4388-bea3-6615a8a62b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-d5bf5baf-4823-417d-8644-edc35e16c346,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-3daa4d30-d71c-48d8-a873-11f1886201f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-1235c3ab-9ccb-459c-9e07-2d7dfb087728,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-bc8a1629-39af-4b44-b595-fefe503451ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375985150-172.17.0.10-1597418819792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36431,DS-e9445a29-84cd-49c7-a97a-e27bcf6543b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-22175eaa-1488-4fea-9ccd-f988c6861ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-4a3a4954-4a5d-4ff8-897a-9a521b3a9f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-f2c58d4d-c92a-488f-be2d-acd4820af9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-82bcd06a-fdfa-41a0-bb3e-254c332c05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-ca71cdf7-2238-41b8-808a-ab836f39d677,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-b50fc5b5-190d-498a-acf3-11a4f0177a94,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-935004c9-8dfc-4a36-994c-dcc62a4db9d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375985150-172.17.0.10-1597418819792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36431,DS-e9445a29-84cd-49c7-a97a-e27bcf6543b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-22175eaa-1488-4fea-9ccd-f988c6861ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-4a3a4954-4a5d-4ff8-897a-9a521b3a9f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-f2c58d4d-c92a-488f-be2d-acd4820af9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-82bcd06a-fdfa-41a0-bb3e-254c332c05f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-ca71cdf7-2238-41b8-808a-ab836f39d677,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-b50fc5b5-190d-498a-acf3-11a4f0177a94,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-935004c9-8dfc-4a36-994c-dcc62a4db9d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913080673-172.17.0.10-1597419330903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45074,DS-7e717487-ee5e-4c16-86e6-d1db3a183a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-f727939d-c741-41a1-8a61-12feeb07773f,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-50aa7a15-c5c4-4afc-9a42-3c2952ae2969,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-010ef057-d62e-4f9b-8599-857712ce00ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-76c5e9a8-c0d3-4392-84ac-9bac9661ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-be04de1d-29d7-4098-a7e5-c71295793735,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-b90762ed-19db-4961-ac63-2344d9c7011e,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-b6651874-d095-4615-b526-8e32ac4df253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913080673-172.17.0.10-1597419330903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45074,DS-7e717487-ee5e-4c16-86e6-d1db3a183a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-f727939d-c741-41a1-8a61-12feeb07773f,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-50aa7a15-c5c4-4afc-9a42-3c2952ae2969,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-010ef057-d62e-4f9b-8599-857712ce00ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-76c5e9a8-c0d3-4392-84ac-9bac9661ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-be04de1d-29d7-4098-a7e5-c71295793735,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-b90762ed-19db-4961-ac63-2344d9c7011e,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-b6651874-d095-4615-b526-8e32ac4df253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350083428-172.17.0.10-1597419466122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-a47a1854-3300-434f-8ea6-232e382aca17,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-d4cc127f-f48e-4837-8eb4-48ec3c30a08e,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-00356652-9675-48c2-8a17-cb09fa5dd3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-23abbc35-14c5-441b-b9a4-d28fd21ee58b,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-2a4747b1-f118-4a76-a852-db4efc08c130,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-746279c7-5a6c-475a-8ff0-be45b04bb541,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-155b0630-b64a-4324-bc51-7db0b1cc85c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-c024d9da-facd-4c30-9147-4e88cc6e9261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350083428-172.17.0.10-1597419466122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40447,DS-a47a1854-3300-434f-8ea6-232e382aca17,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-d4cc127f-f48e-4837-8eb4-48ec3c30a08e,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-00356652-9675-48c2-8a17-cb09fa5dd3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-23abbc35-14c5-441b-b9a4-d28fd21ee58b,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-2a4747b1-f118-4a76-a852-db4efc08c130,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-746279c7-5a6c-475a-8ff0-be45b04bb541,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-155b0630-b64a-4324-bc51-7db0b1cc85c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-c024d9da-facd-4c30-9147-4e88cc6e9261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511838524-172.17.0.10-1597420173175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37787,DS-e215f48a-5e70-4075-b235-ca70ec5e26d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-43451cdd-b4f8-4234-b241-6e1714a87e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-786fe510-c8b9-44c5-9688-2bbdec7c588f,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-291055b3-7b57-44c1-b6f8-b28a54d398d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-b6967967-9ddc-441e-915f-4caf16ed3121,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-56e4aee4-f204-4b48-80ba-5d9c8c2b3275,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-ff2f7189-c39c-48af-a38c-8d9deebc1380,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-159e7324-13d7-456e-ad59-6df5e25a4515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511838524-172.17.0.10-1597420173175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37787,DS-e215f48a-5e70-4075-b235-ca70ec5e26d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-43451cdd-b4f8-4234-b241-6e1714a87e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-786fe510-c8b9-44c5-9688-2bbdec7c588f,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-291055b3-7b57-44c1-b6f8-b28a54d398d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-b6967967-9ddc-441e-915f-4caf16ed3121,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-56e4aee4-f204-4b48-80ba-5d9c8c2b3275,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-ff2f7189-c39c-48af-a38c-8d9deebc1380,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-159e7324-13d7-456e-ad59-6df5e25a4515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133941594-172.17.0.10-1597420249787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-8f45e6b8-6538-47bd-a3bd-f84dca6c0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-17ae3ba2-a36d-439c-be1e-63371f39d0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-0e419aaf-f1ce-4875-b6c0-b8c0f174bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-75e2238b-e1d2-4ff6-a2d7-fb8b8eb1e2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-0abd48ce-3821-4cd9-b9e6-81e683489c28,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-f151117c-b924-454d-89ca-2d87e24aab94,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-c5ec1ef3-9939-452d-9a24-4ecaae64e858,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-5a6d858a-649e-47d0-ad0e-525dba58f26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133941594-172.17.0.10-1597420249787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-8f45e6b8-6538-47bd-a3bd-f84dca6c0d54,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-17ae3ba2-a36d-439c-be1e-63371f39d0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-0e419aaf-f1ce-4875-b6c0-b8c0f174bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-75e2238b-e1d2-4ff6-a2d7-fb8b8eb1e2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-0abd48ce-3821-4cd9-b9e6-81e683489c28,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-f151117c-b924-454d-89ca-2d87e24aab94,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-c5ec1ef3-9939-452d-9a24-4ecaae64e858,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-5a6d858a-649e-47d0-ad0e-525dba58f26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386236646-172.17.0.10-1597420536820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-8cd4b617-00de-401e-8757-19e6ae1c5bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-0051a964-5661-4120-b2d9-503a1dc08248,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-72b465df-cb6e-46c9-9cac-b902228c4c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-8bc9a21c-a63d-49fd-9b8d-d4e5274aee1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-e80d2166-8720-4e44-a854-e0a022b4769a,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-1cc4ee36-390b-4d62-a1ec-e658b177a2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-5e825805-a70a-4f49-b595-1d33b5ceade7,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-da472319-9d28-4ffe-998e-a313b28cad49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386236646-172.17.0.10-1597420536820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-8cd4b617-00de-401e-8757-19e6ae1c5bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-0051a964-5661-4120-b2d9-503a1dc08248,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-72b465df-cb6e-46c9-9cac-b902228c4c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-8bc9a21c-a63d-49fd-9b8d-d4e5274aee1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-e80d2166-8720-4e44-a854-e0a022b4769a,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-1cc4ee36-390b-4d62-a1ec-e658b177a2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-5e825805-a70a-4f49-b595-1d33b5ceade7,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-da472319-9d28-4ffe-998e-a313b28cad49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082802448-172.17.0.10-1597420569913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36932,DS-a6acea23-ed32-4347-a382-ce5680e21faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-edfb2ab2-6c5d-48ff-8421-e422d4741866,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-a8591742-e598-4e10-8caa-9cf397e198ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-7bb980ac-1106-4933-878c-ecdf87429520,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-4dbbe4ef-f20d-4c33-aeb7-aaa80d2edec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-bfc30880-ba12-464d-b16c-dc69ff9a6d94,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-01cdc567-ac95-4857-8993-cc9912015e57,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-c4681685-0922-49e2-8b73-a24e8a4daa26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082802448-172.17.0.10-1597420569913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36932,DS-a6acea23-ed32-4347-a382-ce5680e21faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-edfb2ab2-6c5d-48ff-8421-e422d4741866,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-a8591742-e598-4e10-8caa-9cf397e198ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-7bb980ac-1106-4933-878c-ecdf87429520,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-4dbbe4ef-f20d-4c33-aeb7-aaa80d2edec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-bfc30880-ba12-464d-b16c-dc69ff9a6d94,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-01cdc567-ac95-4857-8993-cc9912015e57,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-c4681685-0922-49e2-8b73-a24e8a4daa26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264586188-172.17.0.10-1597420682186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41334,DS-d5d3d6a1-0c0a-4160-8a1f-97c4eead30e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-64c1e415-2d7d-4ceb-8188-af7efadffb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-fa116d7a-6aa7-44f7-beaf-e6914fd6d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-a50509f0-0a5a-4995-8883-1849a6debcff,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-8d5eaf3e-2a0d-435d-9058-c7279bf75d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-e5d077da-5407-4386-a908-c482610f7b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-70ba00b4-aa66-44af-ae37-909fbb3817e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-dcb85923-f5bd-41ae-b73d-0e50f0f615b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264586188-172.17.0.10-1597420682186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41334,DS-d5d3d6a1-0c0a-4160-8a1f-97c4eead30e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-64c1e415-2d7d-4ceb-8188-af7efadffb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-fa116d7a-6aa7-44f7-beaf-e6914fd6d12d,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-a50509f0-0a5a-4995-8883-1849a6debcff,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-8d5eaf3e-2a0d-435d-9058-c7279bf75d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-e5d077da-5407-4386-a908-c482610f7b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-70ba00b4-aa66-44af-ae37-909fbb3817e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-dcb85923-f5bd-41ae-b73d-0e50f0f615b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 3000
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686109316-172.17.0.10-1597421140417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-3004cb21-105f-4ed8-ac18-f0e91a4ae8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-4f1c29f0-66b8-4c5f-9015-6ddfcd258bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-43652570-59ef-49dd-9fdc-6b10d75f3e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-ebff3885-27c5-4353-b035-ea47ee77e464,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-2371c3af-966e-4cdf-822c-f7d6e6907b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-f3b3c9ef-2903-44f3-9518-9445805f024a,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-97b3d226-bf77-4632-b4da-686e64f86202,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-6b7fadcb-8096-45bb-9528-cd48fc7f5c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686109316-172.17.0.10-1597421140417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-3004cb21-105f-4ed8-ac18-f0e91a4ae8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-4f1c29f0-66b8-4c5f-9015-6ddfcd258bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-43652570-59ef-49dd-9fdc-6b10d75f3e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-ebff3885-27c5-4353-b035-ea47ee77e464,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-2371c3af-966e-4cdf-822c-f7d6e6907b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-f3b3c9ef-2903-44f3-9518-9445805f024a,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-97b3d226-bf77-4632-b4da-686e64f86202,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-6b7fadcb-8096-45bb-9528-cd48fc7f5c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5433
