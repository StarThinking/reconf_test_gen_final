reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313157586-172.17.0.15-1597578179884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-affb70ef-aafb-4e24-b2f3-dbe322b805f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-7077c68e-ce0d-47d4-8ecc-5ddedcbb2869,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-48b5d1ab-5b1a-4757-bbf5-0db9f8274d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-86985d68-a1e9-40d4-bd91-1caf645cb32a,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-622aa6ca-18fd-4665-97bd-090b569a0204,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-9c4b38f6-79a2-4c05-b76c-948b62f65ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-c88e17b8-2122-43fa-b77e-eedde7cf06fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-062d1b5a-8867-49c9-8c8e-3640cf08d6bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313157586-172.17.0.15-1597578179884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-affb70ef-aafb-4e24-b2f3-dbe322b805f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-7077c68e-ce0d-47d4-8ecc-5ddedcbb2869,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-48b5d1ab-5b1a-4757-bbf5-0db9f8274d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-86985d68-a1e9-40d4-bd91-1caf645cb32a,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-622aa6ca-18fd-4665-97bd-090b569a0204,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-9c4b38f6-79a2-4c05-b76c-948b62f65ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-c88e17b8-2122-43fa-b77e-eedde7cf06fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-062d1b5a-8867-49c9-8c8e-3640cf08d6bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109942888-172.17.0.15-1597578284096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-5a85b38c-4786-4d1c-9019-3a80587b5abf,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-31656872-6af0-4dc7-a9ad-a92ef7d92185,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-5c0021fc-71ec-4f14-9cdf-f8039626f505,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-0b66878c-23e9-4186-bb46-53bf5c565779,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-387166ef-1770-499c-90df-5cac38149855,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-5b5d44d5-a7fa-4cae-b659-88df50d13e83,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-acb93c0e-8de3-4d92-a1e8-822e5e7623e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-5220dda9-123f-46e3-a24d-df774e3cccee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109942888-172.17.0.15-1597578284096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-5a85b38c-4786-4d1c-9019-3a80587b5abf,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-31656872-6af0-4dc7-a9ad-a92ef7d92185,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-5c0021fc-71ec-4f14-9cdf-f8039626f505,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-0b66878c-23e9-4186-bb46-53bf5c565779,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-387166ef-1770-499c-90df-5cac38149855,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-5b5d44d5-a7fa-4cae-b659-88df50d13e83,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-acb93c0e-8de3-4d92-a1e8-822e5e7623e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-5220dda9-123f-46e3-a24d-df774e3cccee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801897561-172.17.0.15-1597578581560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-e0a31288-dfc9-4a3c-8dcd-9ab826b9f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-8b7b8f90-ecd1-4959-84f2-7bbbcb0c587d,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-010199d0-d3b6-40f6-acd9-786b0abc53fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-6c83e9ba-066a-47a2-aaff-08d8c034afe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-ea7962d0-b8d4-4871-9288-2c79bc58c301,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-00089482-d007-4b1b-afa7-900e6e71d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-49000480-199b-4851-b1eb-2d5bacb3d197,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-b315a561-f8a7-419a-ac79-93010f88791e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1801897561-172.17.0.15-1597578581560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-e0a31288-dfc9-4a3c-8dcd-9ab826b9f47c,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-8b7b8f90-ecd1-4959-84f2-7bbbcb0c587d,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-010199d0-d3b6-40f6-acd9-786b0abc53fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-6c83e9ba-066a-47a2-aaff-08d8c034afe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-ea7962d0-b8d4-4871-9288-2c79bc58c301,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-00089482-d007-4b1b-afa7-900e6e71d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-49000480-199b-4851-b1eb-2d5bacb3d197,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-b315a561-f8a7-419a-ac79-93010f88791e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111975079-172.17.0.15-1597578617282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-32e0e91b-86d7-4306-bd80-05feea31a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-c03db8de-c991-43e2-8eef-a52b2a0f2365,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-291ddd43-7250-4c1e-9c61-1f1c1bc02b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-1d7dc308-5915-46ff-b663-804af8d5f04c,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-d547e42e-d75c-4607-bea0-3e96d00bb6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-55265923-58eb-4f63-8f0b-f1448c9e0658,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-fb296c1d-6943-482c-9de8-8687440cf982,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-8bd442fb-1564-40d6-8fb8-0d8525495135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111975079-172.17.0.15-1597578617282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-32e0e91b-86d7-4306-bd80-05feea31a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-c03db8de-c991-43e2-8eef-a52b2a0f2365,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-291ddd43-7250-4c1e-9c61-1f1c1bc02b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-1d7dc308-5915-46ff-b663-804af8d5f04c,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-d547e42e-d75c-4607-bea0-3e96d00bb6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-55265923-58eb-4f63-8f0b-f1448c9e0658,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-fb296c1d-6943-482c-9de8-8687440cf982,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-8bd442fb-1564-40d6-8fb8-0d8525495135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111786269-172.17.0.15-1597578659297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37432,DS-6fe2c1e4-15e9-4e62-87cf-f331c0752947,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-e02fb48a-42c7-4588-a84b-56accba5365c,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-627ebe5e-6b1a-4924-8db1-3bfeeae0d6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-46cbde8a-7967-4a63-80bf-17bbce6146c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-d920085c-1f19-4265-a639-4f1e2c376a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-256890f0-bcae-491f-909e-95982bf54dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-87a6c077-596f-41a5-acb2-ce3e535d2ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-da2c1431-b523-42cd-b765-abbc386a91a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111786269-172.17.0.15-1597578659297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37432,DS-6fe2c1e4-15e9-4e62-87cf-f331c0752947,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-e02fb48a-42c7-4588-a84b-56accba5365c,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-627ebe5e-6b1a-4924-8db1-3bfeeae0d6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-46cbde8a-7967-4a63-80bf-17bbce6146c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-d920085c-1f19-4265-a639-4f1e2c376a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-256890f0-bcae-491f-909e-95982bf54dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-87a6c077-596f-41a5-acb2-ce3e535d2ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-da2c1431-b523-42cd-b765-abbc386a91a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379742503-172.17.0.15-1597579201931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34594,DS-33956455-789c-46f0-a7cc-5d9eae5af9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-332cab53-ae33-4751-93e1-8039a45f8de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-776e9b19-8f58-4d95-ad2e-377b9bd78a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-b23e0ae3-0309-44f2-9f74-fe728c236663,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-233d3818-3b59-46ca-96bc-548a9e723c24,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-e64787c1-1d0a-4cef-b638-a829c8399404,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-dcf24eea-cc2b-4cb8-9e63-1c97281d39ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-bfe33392-d999-473d-874d-a5965ea82baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379742503-172.17.0.15-1597579201931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34594,DS-33956455-789c-46f0-a7cc-5d9eae5af9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-332cab53-ae33-4751-93e1-8039a45f8de7,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-776e9b19-8f58-4d95-ad2e-377b9bd78a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-b23e0ae3-0309-44f2-9f74-fe728c236663,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-233d3818-3b59-46ca-96bc-548a9e723c24,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-e64787c1-1d0a-4cef-b638-a829c8399404,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-dcf24eea-cc2b-4cb8-9e63-1c97281d39ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-bfe33392-d999-473d-874d-a5965ea82baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103536517-172.17.0.15-1597579244205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-db127cca-2432-49f6-b339-af62fe1883a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-b610283e-635f-4e8d-ae55-d6402b113c92,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-aae81fd8-a00f-4964-9a63-cbff463a190f,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-92244cb5-dc81-4513-84f6-b2c8b3f9b275,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-68d55243-2a45-4e56-a020-817d6bb0b782,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-1a4ccd32-44a2-4b0f-bf83-a572a5188f73,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-4c9147b2-4e88-4c39-81cf-c50619f7a2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-28afec86-fc40-4eb6-9a45-830515ad60cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103536517-172.17.0.15-1597579244205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-db127cca-2432-49f6-b339-af62fe1883a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-b610283e-635f-4e8d-ae55-d6402b113c92,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-aae81fd8-a00f-4964-9a63-cbff463a190f,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-92244cb5-dc81-4513-84f6-b2c8b3f9b275,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-68d55243-2a45-4e56-a020-817d6bb0b782,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-1a4ccd32-44a2-4b0f-bf83-a572a5188f73,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-4c9147b2-4e88-4c39-81cf-c50619f7a2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-28afec86-fc40-4eb6-9a45-830515ad60cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138463395-172.17.0.15-1597579351951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40708,DS-1963a9ce-ff53-4e7f-a824-5524a6be1f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-cdfd4491-06a0-417f-a54e-026ad8229d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-875d4048-26d9-48cc-9332-84f95599afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-1bf6258e-a208-4c8f-b6f5-34a80a174dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-d2d73769-098d-41a3-b88a-edbb732250f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-788b9243-42c1-46c3-8d30-8dc86b7a7a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-fdf4756b-bfaa-45b5-ad88-fe880fddb11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-3c1fc431-ef18-46a9-a105-f1766fbd7e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138463395-172.17.0.15-1597579351951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40708,DS-1963a9ce-ff53-4e7f-a824-5524a6be1f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-cdfd4491-06a0-417f-a54e-026ad8229d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-875d4048-26d9-48cc-9332-84f95599afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-1bf6258e-a208-4c8f-b6f5-34a80a174dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-d2d73769-098d-41a3-b88a-edbb732250f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-788b9243-42c1-46c3-8d30-8dc86b7a7a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-fdf4756b-bfaa-45b5-ad88-fe880fddb11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-3c1fc431-ef18-46a9-a105-f1766fbd7e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15814227-172.17.0.15-1597579564981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-e643d110-0e40-46d2-b30a-7afff30105a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-d6390d91-1ae3-4f59-9745-19af0f830774,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-0f07fb98-ae84-4845-b906-d11b46de94ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-43cf0e05-4507-4af4-b0a2-5480e6cdc75e,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-389da298-928a-4640-9295-4a925753c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-aec48c40-e8dd-4637-85e3-092d7b95f873,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-07192c8e-3d1d-489d-b5f2-29b5692ca9da,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-aaf83874-66e8-4756-b4b9-30e784cc9731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15814227-172.17.0.15-1597579564981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-e643d110-0e40-46d2-b30a-7afff30105a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-d6390d91-1ae3-4f59-9745-19af0f830774,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-0f07fb98-ae84-4845-b906-d11b46de94ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-43cf0e05-4507-4af4-b0a2-5480e6cdc75e,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-389da298-928a-4640-9295-4a925753c1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-aec48c40-e8dd-4637-85e3-092d7b95f873,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-07192c8e-3d1d-489d-b5f2-29b5692ca9da,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-aaf83874-66e8-4756-b4b9-30e784cc9731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259904767-172.17.0.15-1597579581668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40880,DS-ebeb14d4-258e-401d-b42e-9b0758752dda,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-67cedeb9-f45a-4445-a5ad-a33bf3a4691d,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-f0e9e2a9-6c8f-459d-8bbe-25aa40fc167d,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-68c4f165-43f4-4f6a-b198-e7c585e56121,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-7be8ec4a-92ab-49ed-b467-0bc882b06cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-1eb5147a-6b62-462d-8aa4-1443c78967aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-ec65f095-379c-4ea5-8b7b-8eb5fdb2ae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-2759ad65-dc3a-469b-b6d0-dc60facec8d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259904767-172.17.0.15-1597579581668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40880,DS-ebeb14d4-258e-401d-b42e-9b0758752dda,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-67cedeb9-f45a-4445-a5ad-a33bf3a4691d,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-f0e9e2a9-6c8f-459d-8bbe-25aa40fc167d,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-68c4f165-43f4-4f6a-b198-e7c585e56121,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-7be8ec4a-92ab-49ed-b467-0bc882b06cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-1eb5147a-6b62-462d-8aa4-1443c78967aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-ec65f095-379c-4ea5-8b7b-8eb5fdb2ae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-2759ad65-dc3a-469b-b6d0-dc60facec8d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972530465-172.17.0.15-1597579745797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38918,DS-0e519ff7-fef2-4a6e-8222-b43d9a96bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-5dc67cfa-d3f3-44ff-8d65-4c0fd4dc4601,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-f78dc968-f5b2-42c0-9d8b-d356960ae3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-810ac2e6-f800-4733-a86f-0859879206ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-f512138b-9a29-456d-a464-80dfb09e16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-05e35072-b73f-4af0-8941-276fab651037,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-3bc6d7cd-77c3-430d-b1b9-bf4d4aac3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-a53b87ed-4e42-4d2d-9f26-5b75faaab9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972530465-172.17.0.15-1597579745797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38918,DS-0e519ff7-fef2-4a6e-8222-b43d9a96bb32,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-5dc67cfa-d3f3-44ff-8d65-4c0fd4dc4601,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-f78dc968-f5b2-42c0-9d8b-d356960ae3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-810ac2e6-f800-4733-a86f-0859879206ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-f512138b-9a29-456d-a464-80dfb09e16b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-05e35072-b73f-4af0-8941-276fab651037,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-3bc6d7cd-77c3-430d-b1b9-bf4d4aac3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-a53b87ed-4e42-4d2d-9f26-5b75faaab9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702339646-172.17.0.15-1597579925513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39887,DS-e05b4029-e957-4841-9816-d0d6c0450c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-651bc637-f3f2-4eba-b7ea-41ddfe6a975e,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-9b9cec6b-fedb-4a95-b255-892b1324d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-f7ac3100-4495-42c1-b31f-747c3689bd56,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-037ef310-93a6-4938-be71-13c9e280c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-648a63eb-979e-46b2-81ca-a3cf6acde300,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-dbe4696a-424d-4a79-b123-dea6a3959f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-d0ec4ad2-a041-4def-93dd-eeaaed660406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702339646-172.17.0.15-1597579925513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39887,DS-e05b4029-e957-4841-9816-d0d6c0450c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-651bc637-f3f2-4eba-b7ea-41ddfe6a975e,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-9b9cec6b-fedb-4a95-b255-892b1324d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-f7ac3100-4495-42c1-b31f-747c3689bd56,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-037ef310-93a6-4938-be71-13c9e280c73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-648a63eb-979e-46b2-81ca-a3cf6acde300,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-dbe4696a-424d-4a79-b123-dea6a3959f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-d0ec4ad2-a041-4def-93dd-eeaaed660406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187815108-172.17.0.15-1597580154934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36853,DS-08c2c08a-79f3-4a88-8e6c-21c1d7c75b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-0534b30b-aa02-45b7-896d-5e82aba7ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-025ba25b-e89a-4762-8eef-2891aa08fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-aba8c4e1-95d5-480d-ae9a-ba97a6752b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-16c69ea5-4ae7-4548-a913-d6b4d394c296,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-dd9785ef-2a29-47f6-bd97-5bc54505e828,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-814ed891-ab05-4d6c-8c69-8f29b7ee12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-aedb3836-9b94-4fc5-8a6a-05140f99f860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187815108-172.17.0.15-1597580154934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36853,DS-08c2c08a-79f3-4a88-8e6c-21c1d7c75b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-0534b30b-aa02-45b7-896d-5e82aba7ef51,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-025ba25b-e89a-4762-8eef-2891aa08fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-aba8c4e1-95d5-480d-ae9a-ba97a6752b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-16c69ea5-4ae7-4548-a913-d6b4d394c296,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-dd9785ef-2a29-47f6-bd97-5bc54505e828,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-814ed891-ab05-4d6c-8c69-8f29b7ee12e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-aedb3836-9b94-4fc5-8a6a-05140f99f860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764335590-172.17.0.15-1597580187938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-c0ef97d2-e5a4-4ebe-8ae4-0c45a2523cba,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-41b59538-1bc9-4a12-938e-55acbed13917,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-8002877a-e549-4187-939f-ff6da51d9c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-fad6ba8e-382c-46d0-ae06-6108cfbc8099,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-c9d78e81-414a-4c6a-b4bd-c53cc716c184,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-3cd729e2-39c9-407d-bfe3-277f9a1aa0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-d5311420-39b1-4824-9d46-4d5d43435225,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-62d89cb3-10ec-40f4-85c4-36fd45220797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764335590-172.17.0.15-1597580187938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-c0ef97d2-e5a4-4ebe-8ae4-0c45a2523cba,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-41b59538-1bc9-4a12-938e-55acbed13917,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-8002877a-e549-4187-939f-ff6da51d9c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-fad6ba8e-382c-46d0-ae06-6108cfbc8099,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-c9d78e81-414a-4c6a-b4bd-c53cc716c184,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-3cd729e2-39c9-407d-bfe3-277f9a1aa0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-d5311420-39b1-4824-9d46-4d5d43435225,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-62d89cb3-10ec-40f4-85c4-36fd45220797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193833335-172.17.0.15-1597580286788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-1eaada90-ea99-465d-9329-fb3fa1488047,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-1bc65b87-5ec4-4044-b8c4-818ff116f17e,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-21f0d81b-9af0-44ac-886d-2c06cad40b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-b4ce3903-ff10-49d2-b8f3-192e29db4766,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-5a52efe0-08a6-4040-a5e0-5907af088288,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-13b8197e-2292-4eec-b6f5-ae603658ed89,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-815b9d97-f5ea-44d7-afc1-372d273efc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-719d433f-ed4c-4a0e-b014-45ecd8123668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193833335-172.17.0.15-1597580286788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35431,DS-1eaada90-ea99-465d-9329-fb3fa1488047,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-1bc65b87-5ec4-4044-b8c4-818ff116f17e,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-21f0d81b-9af0-44ac-886d-2c06cad40b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-b4ce3903-ff10-49d2-b8f3-192e29db4766,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-5a52efe0-08a6-4040-a5e0-5907af088288,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-13b8197e-2292-4eec-b6f5-ae603658ed89,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-815b9d97-f5ea-44d7-afc1-372d273efc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-719d433f-ed4c-4a0e-b014-45ecd8123668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826031103-172.17.0.15-1597580303492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-5895bb51-0f97-4745-acbe-61945eeb745b,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-3c9c4a96-ab81-4a53-b7a3-c2a6e58a0523,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-9c9e9572-dd62-4991-bbcc-13d356404a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-6d6e63e7-85f7-4a63-aadc-34d530333cda,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-f795c770-ea7f-4a9b-a4f0-7668613e7c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-0fa76a3d-235b-4437-ab0b-84221000579c,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-d6128da2-b7ee-4283-a57a-f476ad765650,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-049a6299-d9e0-40ba-a2ed-1a1d1d19fd64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826031103-172.17.0.15-1597580303492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-5895bb51-0f97-4745-acbe-61945eeb745b,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-3c9c4a96-ab81-4a53-b7a3-c2a6e58a0523,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-9c9e9572-dd62-4991-bbcc-13d356404a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-6d6e63e7-85f7-4a63-aadc-34d530333cda,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-f795c770-ea7f-4a9b-a4f0-7668613e7c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-0fa76a3d-235b-4437-ab0b-84221000579c,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-d6128da2-b7ee-4283-a57a-f476ad765650,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-049a6299-d9e0-40ba-a2ed-1a1d1d19fd64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585137927-172.17.0.15-1597580385782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-35dce2d6-22c9-4314-90ee-f8a0459ef764,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-b8d17e70-862f-4cb2-832f-77310d145e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-14dace6e-2ec9-40ec-a736-1cf117a2d3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-67d07e45-605d-4f04-bde8-21fb2803387e,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-9d159157-d652-4fe5-bea4-12941e6dea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-a61100dc-7893-42d6-8c1b-e8575c2012a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-faf95d68-3194-4962-994f-2f2e23008621,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-1e543c63-f17e-4b4e-87d3-782302e23ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585137927-172.17.0.15-1597580385782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-35dce2d6-22c9-4314-90ee-f8a0459ef764,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-b8d17e70-862f-4cb2-832f-77310d145e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-14dace6e-2ec9-40ec-a736-1cf117a2d3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-67d07e45-605d-4f04-bde8-21fb2803387e,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-9d159157-d652-4fe5-bea4-12941e6dea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-a61100dc-7893-42d6-8c1b-e8575c2012a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-faf95d68-3194-4962-994f-2f2e23008621,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-1e543c63-f17e-4b4e-87d3-782302e23ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845049634-172.17.0.15-1597580730439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-5f4de512-3795-458c-ae61-775dd8786a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-f528d9c4-dd24-46c5-9031-80b853dd8fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-e66bc876-c2a8-4b38-96f0-57de246be11c,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-82504dfe-7a65-420f-a6a4-87b43f35f827,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-d25f7a7e-8737-4e8e-8d8c-d363efccaf95,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-73637ba9-d2d7-4833-bd3c-8ad6b91b113e,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-a9860d75-a4f1-4057-b48b-f8d2e912d184,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-556da92b-b109-4f26-bc96-c5bfb3596b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845049634-172.17.0.15-1597580730439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-5f4de512-3795-458c-ae61-775dd8786a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-f528d9c4-dd24-46c5-9031-80b853dd8fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-e66bc876-c2a8-4b38-96f0-57de246be11c,DISK], DatanodeInfoWithStorage[127.0.0.1:42118,DS-82504dfe-7a65-420f-a6a4-87b43f35f827,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-d25f7a7e-8737-4e8e-8d8c-d363efccaf95,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-73637ba9-d2d7-4833-bd3c-8ad6b91b113e,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-a9860d75-a4f1-4057-b48b-f8d2e912d184,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-556da92b-b109-4f26-bc96-c5bfb3596b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545336840-172.17.0.15-1597580763552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36112,DS-a72ef4bf-ddd3-4523-b019-1c564bbe9913,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-bbed242f-2fc1-4873-8542-2ec4bee1c038,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-e3722e42-43d2-4124-bc13-bb24b21314bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-0a0ac173-f343-461d-9065-a3749bce21a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-c6ba7835-a6f4-4793-a554-b82cf8d204e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-35ae4f52-206e-4bb5-9f71-c9677cda03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-70d1a52b-58fb-45fd-8f2e-8abc4f1b4b89,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-8f2fdddf-111d-4838-b661-c5f657963e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-545336840-172.17.0.15-1597580763552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36112,DS-a72ef4bf-ddd3-4523-b019-1c564bbe9913,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-bbed242f-2fc1-4873-8542-2ec4bee1c038,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-e3722e42-43d2-4124-bc13-bb24b21314bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-0a0ac173-f343-461d-9065-a3749bce21a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-c6ba7835-a6f4-4793-a554-b82cf8d204e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-35ae4f52-206e-4bb5-9f71-c9677cda03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-70d1a52b-58fb-45fd-8f2e-8abc4f1b4b89,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-8f2fdddf-111d-4838-b661-c5f657963e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880630026-172.17.0.15-1597580928161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33927,DS-d95d206f-2252-429a-817e-481dffe5e558,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-3ec42303-0b12-4396-a276-759f2cb37b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-385ac177-1429-4bbc-ae27-20c8ad30bf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-665aeac7-a2ba-4da2-97ff-3009a4d90af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-ddcbd19f-fcf7-4903-adab-0cd9218007be,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-4a4c2545-e81f-403e-96aa-e3abf4bfdf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-34178fef-33ba-4d7f-9fbd-ec0f69f7894b,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-4921a7c2-4afe-4cc1-ac59-94a8ec716935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880630026-172.17.0.15-1597580928161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33927,DS-d95d206f-2252-429a-817e-481dffe5e558,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-3ec42303-0b12-4396-a276-759f2cb37b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-385ac177-1429-4bbc-ae27-20c8ad30bf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-665aeac7-a2ba-4da2-97ff-3009a4d90af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-ddcbd19f-fcf7-4903-adab-0cd9218007be,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-4a4c2545-e81f-403e-96aa-e3abf4bfdf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-34178fef-33ba-4d7f-9fbd-ec0f69f7894b,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-4921a7c2-4afe-4cc1-ac59-94a8ec716935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338782519-172.17.0.15-1597580961347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-70ce733e-99b9-47d4-b434-81107d3cbeab,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-a8da8572-cdf6-45f5-b8b9-b83e223d95ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-8c452fc3-37f5-4b93-82c2-d86162b34ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-c070333b-b65e-4bbc-ba3e-74926b752962,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-146d57d6-251e-45ca-b885-920ccf63bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-5d7a68c7-1a11-4e61-aae9-f57773c6df53,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-b663cce7-4955-4d02-942a-1b41bf2b1b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-5faf81a8-ebc4-4d6c-af8e-a14da6f04580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338782519-172.17.0.15-1597580961347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-70ce733e-99b9-47d4-b434-81107d3cbeab,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-a8da8572-cdf6-45f5-b8b9-b83e223d95ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-8c452fc3-37f5-4b93-82c2-d86162b34ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-c070333b-b65e-4bbc-ba3e-74926b752962,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-146d57d6-251e-45ca-b885-920ccf63bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-5d7a68c7-1a11-4e61-aae9-f57773c6df53,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-b663cce7-4955-4d02-942a-1b41bf2b1b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-5faf81a8-ebc4-4d6c-af8e-a14da6f04580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131622920-172.17.0.15-1597580977851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-b36cc7e0-88b5-4128-bb8d-80b430626fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-058b85e9-76e0-45d9-b7df-63dc8df57af8,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-6ae41ccd-0c7e-438e-ba8d-40820423ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-29eff122-dd28-4ddd-93cf-b25ee3931f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-f4b7205d-f31c-476c-9d6e-5ed081b796f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-154b75d9-7067-425f-8da4-e7a966dbea45,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-32b0b9a0-2ff5-4c1a-a89a-9250fee4040a,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-0dc8a32e-20a6-4f75-aef1-c5a0366d87e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131622920-172.17.0.15-1597580977851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-b36cc7e0-88b5-4128-bb8d-80b430626fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-058b85e9-76e0-45d9-b7df-63dc8df57af8,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-6ae41ccd-0c7e-438e-ba8d-40820423ea1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-29eff122-dd28-4ddd-93cf-b25ee3931f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-f4b7205d-f31c-476c-9d6e-5ed081b796f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-154b75d9-7067-425f-8da4-e7a966dbea45,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-32b0b9a0-2ff5-4c1a-a89a-9250fee4040a,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-0dc8a32e-20a6-4f75-aef1-c5a0366d87e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 5000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051994096-172.17.0.15-1597581059996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45639,DS-a8055464-8758-4d51-b87e-3f8bc30870d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-6d287db1-bb09-4113-9c3d-3e0ffc78b765,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-9999c682-7bc6-4eb1-b701-6f16097262bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-6e56574a-9597-4676-ac19-7b540e2d6c20,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-c5fe8885-541b-42af-9f9b-8919995487c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-b358a000-6431-4d05-85c3-70db0acc139b,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-3a4ff6ac-aeba-410c-8363-aa12688dfea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-cc4ecd59-69c1-484c-a22e-d3794a022346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051994096-172.17.0.15-1597581059996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45639,DS-a8055464-8758-4d51-b87e-3f8bc30870d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-6d287db1-bb09-4113-9c3d-3e0ffc78b765,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-9999c682-7bc6-4eb1-b701-6f16097262bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-6e56574a-9597-4676-ac19-7b540e2d6c20,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-c5fe8885-541b-42af-9f9b-8919995487c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-b358a000-6431-4d05-85c3-70db0acc139b,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-3a4ff6ac-aeba-410c-8363-aa12688dfea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-cc4ecd59-69c1-484c-a22e-d3794a022346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 3168
