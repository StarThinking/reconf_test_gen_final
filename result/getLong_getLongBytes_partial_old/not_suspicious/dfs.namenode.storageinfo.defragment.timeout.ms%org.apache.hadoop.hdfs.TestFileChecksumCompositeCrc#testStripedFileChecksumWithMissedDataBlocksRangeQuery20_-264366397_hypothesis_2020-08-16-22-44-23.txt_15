reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352812904-172.17.0.8-1597617928280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-ba0d3b20-c40a-4ad3-b67d-907d12b09135,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-16c644b5-9d25-4693-aadf-2ee8c586bfed,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-c7a82096-ae21-4621-9b5f-96fc6a7989f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-c7cd39f7-a2aa-4b1f-9e73-524796d59c93,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-9eb30f7e-7c5d-4450-bc89-f2c28c7a488a,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-b745b86f-f8f2-4988-b2f0-4cd5d3ad04c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-059bb295-4301-4ebc-8069-76210edff0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-8be6614b-a0f0-457e-b445-acd6660df0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352812904-172.17.0.8-1597617928280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-ba0d3b20-c40a-4ad3-b67d-907d12b09135,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-16c644b5-9d25-4693-aadf-2ee8c586bfed,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-c7a82096-ae21-4621-9b5f-96fc6a7989f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-c7cd39f7-a2aa-4b1f-9e73-524796d59c93,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-9eb30f7e-7c5d-4450-bc89-f2c28c7a488a,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-b745b86f-f8f2-4988-b2f0-4cd5d3ad04c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-059bb295-4301-4ebc-8069-76210edff0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-8be6614b-a0f0-457e-b445-acd6660df0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515315296-172.17.0.8-1597618182474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33218,DS-248a0ae2-520f-45a9-9514-f8891caa6b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-ef0b1d31-e2f6-41f0-9d94-bf66a2db51a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-2635e51e-1c90-45ac-a37a-6229439e98a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-fed53f23-d886-470f-8081-7550ddd96694,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-36927c4d-6921-4be5-93e2-f4251a2e8526,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-3a710655-7ad3-4247-a1a5-2b6f16d88977,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-0ffb1a06-056b-418d-82ae-de391646662e,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-de753955-4379-44a5-9a75-6319a08dae9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515315296-172.17.0.8-1597618182474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33218,DS-248a0ae2-520f-45a9-9514-f8891caa6b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-ef0b1d31-e2f6-41f0-9d94-bf66a2db51a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-2635e51e-1c90-45ac-a37a-6229439e98a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-fed53f23-d886-470f-8081-7550ddd96694,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-36927c4d-6921-4be5-93e2-f4251a2e8526,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-3a710655-7ad3-4247-a1a5-2b6f16d88977,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-0ffb1a06-056b-418d-82ae-de391646662e,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-de753955-4379-44a5-9a75-6319a08dae9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224544374-172.17.0.8-1597618858479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35373,DS-946357ef-f0ed-44cd-8d11-561bffde4712,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-98401c99-8b60-41af-82bf-5d280c6260b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-c42e2e70-c0e1-4ac0-b387-11e223969856,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-3dda76b7-ad77-4398-8c5c-b17b085f78b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-3aeabe45-7c8b-4c13-8003-3e0c09fa893c,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-b404310c-7d47-413b-982e-538f4c15f570,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-9999a72e-dfc5-4872-a7ca-879c3ecb56f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-23686c17-00a9-48ed-af40-7d033a911089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224544374-172.17.0.8-1597618858479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35373,DS-946357ef-f0ed-44cd-8d11-561bffde4712,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-98401c99-8b60-41af-82bf-5d280c6260b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-c42e2e70-c0e1-4ac0-b387-11e223969856,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-3dda76b7-ad77-4398-8c5c-b17b085f78b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-3aeabe45-7c8b-4c13-8003-3e0c09fa893c,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-b404310c-7d47-413b-982e-538f4c15f570,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-9999a72e-dfc5-4872-a7ca-879c3ecb56f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-23686c17-00a9-48ed-af40-7d033a911089,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66185563-172.17.0.8-1597619120093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35032,DS-bc25798e-f26d-4d13-8d72-8eb9652f1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-ed106fd1-3d47-40dd-87b1-8302eb6b415f,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-3cdf90f6-10db-4f1e-b5e2-512c3ab8d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-e722d28b-dd12-4887-a58d-43e1ae08b3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-13d31a29-491f-4030-9cfa-d8025353868d,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-c94725cf-92bf-40fb-bd59-8c97671f20cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-82aaa7d2-838d-4b7b-af99-6b643d5309d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-6135d007-a9f1-490a-9f5a-8eb0d472f831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66185563-172.17.0.8-1597619120093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35032,DS-bc25798e-f26d-4d13-8d72-8eb9652f1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-ed106fd1-3d47-40dd-87b1-8302eb6b415f,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-3cdf90f6-10db-4f1e-b5e2-512c3ab8d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-e722d28b-dd12-4887-a58d-43e1ae08b3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-13d31a29-491f-4030-9cfa-d8025353868d,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-c94725cf-92bf-40fb-bd59-8c97671f20cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-82aaa7d2-838d-4b7b-af99-6b643d5309d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-6135d007-a9f1-490a-9f5a-8eb0d472f831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753451909-172.17.0.8-1597619334230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-995d8f0a-d3c9-4a25-af30-1078b75b8874,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-5ca09ae5-8176-4372-9874-b9a0e699f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-667daf5a-dbdc-4b54-a09a-d820ee3b2245,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-071c67b2-1134-4751-a765-25861b224d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-150220ce-ea29-45ad-946d-023de567cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-4590cd03-026c-4fc2-9e62-5a99f8645d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-854b6546-b826-4575-a829-e8b5bc69fd13,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-6fc54985-c2e6-4862-a38f-b22c32019edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753451909-172.17.0.8-1597619334230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-995d8f0a-d3c9-4a25-af30-1078b75b8874,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-5ca09ae5-8176-4372-9874-b9a0e699f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-667daf5a-dbdc-4b54-a09a-d820ee3b2245,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-071c67b2-1134-4751-a765-25861b224d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-150220ce-ea29-45ad-946d-023de567cd17,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-4590cd03-026c-4fc2-9e62-5a99f8645d23,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-854b6546-b826-4575-a829-e8b5bc69fd13,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-6fc54985-c2e6-4862-a38f-b22c32019edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557311736-172.17.0.8-1597619469419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-c0ddca07-f5b1-42ba-8ca2-0f91f2ea3d58,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-0d6f09ae-f392-42e9-aff3-0409a66f8dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-d8adbf47-019b-4620-a56e-eec4701c6d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-3bd4bdb5-bd6c-4b7e-9727-5f4ac5f721a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-d7ab2a54-1012-4d87-8ade-6a6cfe9f4b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-9de9d8b1-f3af-476f-b25f-4128dc6a4108,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-423630ad-cd2a-4d84-8285-56bad569c243,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-3fe9a38a-6ccb-4698-a8a6-f994286501aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557311736-172.17.0.8-1597619469419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43003,DS-c0ddca07-f5b1-42ba-8ca2-0f91f2ea3d58,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-0d6f09ae-f392-42e9-aff3-0409a66f8dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-d8adbf47-019b-4620-a56e-eec4701c6d77,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-3bd4bdb5-bd6c-4b7e-9727-5f4ac5f721a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-d7ab2a54-1012-4d87-8ade-6a6cfe9f4b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-9de9d8b1-f3af-476f-b25f-4128dc6a4108,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-423630ad-cd2a-4d84-8285-56bad569c243,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-3fe9a38a-6ccb-4698-a8a6-f994286501aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977898927-172.17.0.8-1597619554489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45101,DS-9099a748-1576-4bc8-874f-c708136a785c,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-ce9bf09a-027e-48ee-a4ff-c341f8b80c35,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-90313803-555e-4106-aeea-1ecddf7f7278,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-2694c82c-e9e9-443e-b04a-fa6dc54756b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-7906b57a-a269-4f43-833a-d4eca662d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-ea7f74e2-4b83-4825-bcda-76c3be69202b,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-4fef4daa-d18e-4d91-aa9a-e260c1702f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-1082b725-1195-433a-9f1a-671896c82ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977898927-172.17.0.8-1597619554489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45101,DS-9099a748-1576-4bc8-874f-c708136a785c,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-ce9bf09a-027e-48ee-a4ff-c341f8b80c35,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-90313803-555e-4106-aeea-1ecddf7f7278,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-2694c82c-e9e9-443e-b04a-fa6dc54756b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-7906b57a-a269-4f43-833a-d4eca662d53c,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-ea7f74e2-4b83-4825-bcda-76c3be69202b,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-4fef4daa-d18e-4d91-aa9a-e260c1702f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-1082b725-1195-433a-9f1a-671896c82ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131097065-172.17.0.8-1597619725862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-3e808eaa-7678-4c56-9ec2-53dd60ac504d,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-c0ef3d9d-5e7f-4c34-b3b0-174ab1ab3435,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-02c6a2cf-bd17-4cdf-9390-12c38ef6b324,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-48c508e3-37e8-484c-88eb-55d2ffdfe8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-8293a205-0a6c-421e-a48e-c9bcd11f915c,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-c0f2c6f1-754e-4e71-9309-93d89edb5559,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-bd7013ee-9164-4170-b158-68d095461199,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-da7f1e0d-6d48-476d-b048-878278801912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131097065-172.17.0.8-1597619725862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-3e808eaa-7678-4c56-9ec2-53dd60ac504d,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-c0ef3d9d-5e7f-4c34-b3b0-174ab1ab3435,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-02c6a2cf-bd17-4cdf-9390-12c38ef6b324,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-48c508e3-37e8-484c-88eb-55d2ffdfe8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-8293a205-0a6c-421e-a48e-c9bcd11f915c,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-c0f2c6f1-754e-4e71-9309-93d89edb5559,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-bd7013ee-9164-4170-b158-68d095461199,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-da7f1e0d-6d48-476d-b048-878278801912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147045350-172.17.0.8-1597619769454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-c03b2fa1-8eec-4b60-8f3e-878df6b2d1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-1b5e462c-4bfb-4c7c-92d9-dab7d03d7ada,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-fde2451a-06f8-480f-9ab4-0514c9db7d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-ef87b22c-4df3-49f0-b480-4dc2e9a7badf,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-312c275c-cceb-429b-8709-98e52c6b2936,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-29415409-77eb-4083-ab00-128d41fe2bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-1c13d024-3106-4940-b7e0-befe12b59403,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-ece5b650-c186-4c7c-9821-3cbbd5e020e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147045350-172.17.0.8-1597619769454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-c03b2fa1-8eec-4b60-8f3e-878df6b2d1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-1b5e462c-4bfb-4c7c-92d9-dab7d03d7ada,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-fde2451a-06f8-480f-9ab4-0514c9db7d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-ef87b22c-4df3-49f0-b480-4dc2e9a7badf,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-312c275c-cceb-429b-8709-98e52c6b2936,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-29415409-77eb-4083-ab00-128d41fe2bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-1c13d024-3106-4940-b7e0-befe12b59403,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-ece5b650-c186-4c7c-9821-3cbbd5e020e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562026497-172.17.0.8-1597619861904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-e2ac62c0-ee07-4694-a852-5925f8983363,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-07e3da9b-0b7f-4af8-8eb7-444fd6731552,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-abdee223-37f8-47d5-8c77-8f088e3ffda8,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-490907c1-5569-4a3f-902d-a494642059b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-a81a5755-fbed-452d-bd4b-b6aa5d5157de,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-43ddaab4-375b-402d-b9cd-9b85a8c38a84,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-2594997f-5bf5-4b6a-9cf3-410fa524296e,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-d3125ccb-6755-4a25-80d6-2d28e1a27ccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562026497-172.17.0.8-1597619861904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-e2ac62c0-ee07-4694-a852-5925f8983363,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-07e3da9b-0b7f-4af8-8eb7-444fd6731552,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-abdee223-37f8-47d5-8c77-8f088e3ffda8,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-490907c1-5569-4a3f-902d-a494642059b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-a81a5755-fbed-452d-bd4b-b6aa5d5157de,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-43ddaab4-375b-402d-b9cd-9b85a8c38a84,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-2594997f-5bf5-4b6a-9cf3-410fa524296e,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-d3125ccb-6755-4a25-80d6-2d28e1a27ccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627595902-172.17.0.8-1597620762029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-5befae8d-9324-4068-a0d5-26e66ac65169,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-33830bed-6451-4da5-a5e8-0cacb7178985,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-79d75821-0893-4342-bdaf-9e68fe3a3bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-c47b28bf-2ac1-477f-8e90-55b4623905fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-1e5749ef-057a-44fd-8601-38f071d06ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-52157ada-9ff1-48e1-a3fb-9ff89d40c347,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-e697e6d9-f986-431b-9f19-044d205e00dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-ed0288c1-86dd-4c92-ac46-bbcc85250faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627595902-172.17.0.8-1597620762029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-5befae8d-9324-4068-a0d5-26e66ac65169,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-33830bed-6451-4da5-a5e8-0cacb7178985,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-79d75821-0893-4342-bdaf-9e68fe3a3bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-c47b28bf-2ac1-477f-8e90-55b4623905fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-1e5749ef-057a-44fd-8601-38f071d06ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-52157ada-9ff1-48e1-a3fb-9ff89d40c347,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-e697e6d9-f986-431b-9f19-044d205e00dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-ed0288c1-86dd-4c92-ac46-bbcc85250faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030349050-172.17.0.8-1597620898410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-4e3c6f89-0cf3-4604-928e-8d684ae35401,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-a5296374-d2e9-4cea-81e0-49137fc220d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-736a044b-09f7-45ff-8464-40509cb75d32,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-ea5529bb-ce31-46f8-a4b3-47f56b7fac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-6363af8b-678c-47b6-9c35-4214b0d563f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-0bf70ea3-b233-44a8-9f3f-b39e8ac57417,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-9019bfbf-000b-491b-8844-1e6fd87582a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-f9a9b1ac-c62e-4f14-b116-7b19b97f6dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030349050-172.17.0.8-1597620898410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41420,DS-4e3c6f89-0cf3-4604-928e-8d684ae35401,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-a5296374-d2e9-4cea-81e0-49137fc220d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-736a044b-09f7-45ff-8464-40509cb75d32,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-ea5529bb-ce31-46f8-a4b3-47f56b7fac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-6363af8b-678c-47b6-9c35-4214b0d563f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-0bf70ea3-b233-44a8-9f3f-b39e8ac57417,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-9019bfbf-000b-491b-8844-1e6fd87582a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-f9a9b1ac-c62e-4f14-b116-7b19b97f6dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590715748-172.17.0.8-1597621121403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41463,DS-0cc58a1c-197a-4e54-97e5-5416ce918562,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-aa36b9d8-c3ba-46b3-a007-01ead36651f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-6a279435-2eb6-4233-a827-2fbd26c8b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-2581ca27-4816-4d6a-95d9-63534c84ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-789ebdcf-59a6-4f4a-a997-9806d8f8958a,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-dd5af648-61b8-401d-9813-c9cf8096f061,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-d7b4486f-6999-4427-a3ff-1e7118580127,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-5338fd1d-f372-44a0-b04e-186a09b9fe43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590715748-172.17.0.8-1597621121403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41463,DS-0cc58a1c-197a-4e54-97e5-5416ce918562,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-aa36b9d8-c3ba-46b3-a007-01ead36651f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-6a279435-2eb6-4233-a827-2fbd26c8b5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-2581ca27-4816-4d6a-95d9-63534c84ccd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-789ebdcf-59a6-4f4a-a997-9806d8f8958a,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-dd5af648-61b8-401d-9813-c9cf8096f061,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-d7b4486f-6999-4427-a3ff-1e7118580127,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-5338fd1d-f372-44a0-b04e-186a09b9fe43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325284721-172.17.0.8-1597621497712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41793,DS-940d4423-57c5-4c4c-9f4e-49c105bd0200,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-5db6ab6a-7394-41e9-9211-a0afebb0d542,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-1b25efe5-574a-4af0-8a49-f3da46901d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-9ad818a2-df9c-4cfa-9c6d-23bf9b94b810,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-739a7d07-0fe3-4525-8be9-88cbbdce3d68,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-e86ad35c-a132-4a29-8cef-6589324c252c,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-043fc829-4d21-4186-9df7-90a91bbbd0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-df5e80d6-b723-47d1-8b9b-b7f543e18e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325284721-172.17.0.8-1597621497712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41793,DS-940d4423-57c5-4c4c-9f4e-49c105bd0200,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-5db6ab6a-7394-41e9-9211-a0afebb0d542,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-1b25efe5-574a-4af0-8a49-f3da46901d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-9ad818a2-df9c-4cfa-9c6d-23bf9b94b810,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-739a7d07-0fe3-4525-8be9-88cbbdce3d68,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-e86ad35c-a132-4a29-8cef-6589324c252c,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-043fc829-4d21-4186-9df7-90a91bbbd0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-df5e80d6-b723-47d1-8b9b-b7f543e18e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495378009-172.17.0.8-1597621728827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46458,DS-c8b8d78e-095b-4767-9371-3522155f7cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-e268ddef-1eb8-4ec5-bf98-46bff50d43e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-2125b8d1-ca9b-41ed-b842-98b862378e96,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-2609d96c-11e1-46f8-b575-9efe0a295e90,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-e9c493e0-2754-4fcc-856a-d86cc74fa254,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-ececcb9c-5195-4c54-a71b-8278c07d93c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-bcb5602f-64b2-452e-9f35-85e3aa7c72df,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-f28fc1be-a76a-4882-9883-87d2e79db270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495378009-172.17.0.8-1597621728827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46458,DS-c8b8d78e-095b-4767-9371-3522155f7cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-e268ddef-1eb8-4ec5-bf98-46bff50d43e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-2125b8d1-ca9b-41ed-b842-98b862378e96,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-2609d96c-11e1-46f8-b575-9efe0a295e90,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-e9c493e0-2754-4fcc-856a-d86cc74fa254,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-ececcb9c-5195-4c54-a71b-8278c07d93c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-bcb5602f-64b2-452e-9f35-85e3aa7c72df,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-f28fc1be-a76a-4882-9883-87d2e79db270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966504399-172.17.0.8-1597621773184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-8ef515f1-caee-4c85-b904-35a3c653f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-100d52ea-e77e-4d7d-814d-ac042d523fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-c7d9bdc6-9f20-4b70-bd2e-f1d1228be564,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-b4d2a0af-8812-4aa8-b4e7-1879f456eb72,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-094a1c02-868b-40ac-bc10-e50d9a11f210,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-a8a4f5ce-9b7f-449e-b166-223d062c52fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-ed316850-6707-4325-8acb-012da7d74ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-0ef83b98-b561-49b2-afa3-07309cdb0999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966504399-172.17.0.8-1597621773184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-8ef515f1-caee-4c85-b904-35a3c653f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-100d52ea-e77e-4d7d-814d-ac042d523fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-c7d9bdc6-9f20-4b70-bd2e-f1d1228be564,DISK], DatanodeInfoWithStorage[127.0.0.1:44446,DS-b4d2a0af-8812-4aa8-b4e7-1879f456eb72,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-094a1c02-868b-40ac-bc10-e50d9a11f210,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-a8a4f5ce-9b7f-449e-b166-223d062c52fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-ed316850-6707-4325-8acb-012da7d74ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-0ef83b98-b561-49b2-afa3-07309cdb0999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1902595315-172.17.0.8-1597621816455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34797,DS-e26ac7df-f02d-4dc1-9022-956b050c254d,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-085bd6de-142a-4590-a7ff-e24cdd7a9380,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-0dfc9c09-a56e-4f76-bc8d-96a17bf32afc,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-54ccea66-ad6b-4e68-a12a-023630416b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-733dff79-fcc5-4374-846c-611de3611bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-a34f1f3c-ba4c-4a4d-8d29-ccef2259e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-117d4eef-ea30-4b94-a446-fac0e0c4b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-0f9346e9-aa9e-4ca2-ae43-2b76f783718c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1902595315-172.17.0.8-1597621816455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34797,DS-e26ac7df-f02d-4dc1-9022-956b050c254d,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-085bd6de-142a-4590-a7ff-e24cdd7a9380,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-0dfc9c09-a56e-4f76-bc8d-96a17bf32afc,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-54ccea66-ad6b-4e68-a12a-023630416b36,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-733dff79-fcc5-4374-846c-611de3611bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-a34f1f3c-ba4c-4a4d-8d29-ccef2259e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-117d4eef-ea30-4b94-a446-fac0e0c4b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-0f9346e9-aa9e-4ca2-ae43-2b76f783718c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103654900-172.17.0.8-1597622787235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-e6f0fec7-7a45-486a-9232-b69dc4c94c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-ff0bf717-59c0-4ef1-893d-626a76b345f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-7432cdfc-a91d-4b46-9615-db9f71952fab,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-917a58cf-ec22-4edc-8f4e-20482d28640d,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-df7609c2-c382-491b-9c4e-be1a4ddeb05f,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-1a4fa971-8269-4f0f-9b08-2dd8be7aa0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-a4f727b1-0185-4dcb-9649-a22907f558d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-7f75dafd-28db-4e32-9e62-bec2a3bb3f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103654900-172.17.0.8-1597622787235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-e6f0fec7-7a45-486a-9232-b69dc4c94c81,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-ff0bf717-59c0-4ef1-893d-626a76b345f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-7432cdfc-a91d-4b46-9615-db9f71952fab,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-917a58cf-ec22-4edc-8f4e-20482d28640d,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-df7609c2-c382-491b-9c4e-be1a4ddeb05f,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-1a4fa971-8269-4f0f-9b08-2dd8be7aa0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-a4f727b1-0185-4dcb-9649-a22907f558d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-7f75dafd-28db-4e32-9e62-bec2a3bb3f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707081704-172.17.0.8-1597623027785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-14728885-5d92-45e9-8414-4e5fa1be4e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-ced5db44-1572-4e08-be0f-ddbc29b6a94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-29f264b1-3f3c-4baa-a1b2-49be8292339d,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-fcd32ed8-702f-4f83-bd05-dc57c952933a,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-ae7cb8a8-900c-4652-afe8-273ebc33587b,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-53d46daf-4429-492b-8bcd-e10e348a7c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-7f52066c-0205-455a-8b1b-8002022ce68f,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-3db1c25e-96dd-490e-8c4a-407e46a57e37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707081704-172.17.0.8-1597623027785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-14728885-5d92-45e9-8414-4e5fa1be4e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-ced5db44-1572-4e08-be0f-ddbc29b6a94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-29f264b1-3f3c-4baa-a1b2-49be8292339d,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-fcd32ed8-702f-4f83-bd05-dc57c952933a,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-ae7cb8a8-900c-4652-afe8-273ebc33587b,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-53d46daf-4429-492b-8bcd-e10e348a7c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-7f52066c-0205-455a-8b1b-8002022ce68f,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-3db1c25e-96dd-490e-8c4a-407e46a57e37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176602354-172.17.0.8-1597623063641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-45af0a9d-f62b-4b5d-bdca-f39f1957b2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-a61de597-123f-430a-9c3a-3bccb6af6512,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-29e11a79-b620-4d13-9599-deb7961816b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-6e740ddc-1a91-44b4-832e-d31ebbc54453,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-04f8ac3c-091d-40dd-9dc3-8761c46d05a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-25bf8790-b6d3-4a76-ba8f-cb308297d30b,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-060b19fb-a59a-4d72-ac45-fab71b141f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-2d081700-17ba-411c-abab-1842ca1ae1d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176602354-172.17.0.8-1597623063641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45211,DS-45af0a9d-f62b-4b5d-bdca-f39f1957b2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-a61de597-123f-430a-9c3a-3bccb6af6512,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-29e11a79-b620-4d13-9599-deb7961816b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-6e740ddc-1a91-44b4-832e-d31ebbc54453,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-04f8ac3c-091d-40dd-9dc3-8761c46d05a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-25bf8790-b6d3-4a76-ba8f-cb308297d30b,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-060b19fb-a59a-4d72-ac45-fab71b141f09,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-2d081700-17ba-411c-abab-1842ca1ae1d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667585598-172.17.0.8-1597623103161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-d460aed0-e89f-4506-a727-c2f062c9b893,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-7dc1bcb4-6195-43c1-8556-59c4ae7bd9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-ad3a7df5-5510-4c15-a510-bd05f06c8826,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-6fe28d3f-ffd2-453d-b9a4-daa4709e6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-64afc068-f9c1-4886-b6b0-abcfdae876fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-4dbcd162-9cfc-41d7-8525-d3063024991f,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-6b68d3e7-a371-4c3e-a307-808f66593a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-99bb8a53-22ba-4d95-b83f-d5b1e001c939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667585598-172.17.0.8-1597623103161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45914,DS-d460aed0-e89f-4506-a727-c2f062c9b893,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-7dc1bcb4-6195-43c1-8556-59c4ae7bd9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-ad3a7df5-5510-4c15-a510-bd05f06c8826,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-6fe28d3f-ffd2-453d-b9a4-daa4709e6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-64afc068-f9c1-4886-b6b0-abcfdae876fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-4dbcd162-9cfc-41d7-8525-d3063024991f,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-6b68d3e7-a371-4c3e-a307-808f66593a51,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-99bb8a53-22ba-4d95-b83f-d5b1e001c939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982307052-172.17.0.8-1597623202812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-74778475-b394-4c65-bbb8-2ab241bf3b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-20b31fab-74cc-467c-9420-801f0ba716b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-78cfb7dc-0384-44ed-a42d-439cc4403b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-d8fce78a-486d-4a26-8a75-2c9b54867195,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-feefce67-18f6-43ad-a00f-f90e188d0000,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-5da425b7-8292-473e-87bd-1578c0ceeff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-0995ab85-e3ca-4a8b-bd28-72f034c35f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-398cb142-58f9-4789-8db8-839c414585e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982307052-172.17.0.8-1597623202812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33641,DS-74778475-b394-4c65-bbb8-2ab241bf3b19,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-20b31fab-74cc-467c-9420-801f0ba716b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-78cfb7dc-0384-44ed-a42d-439cc4403b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-d8fce78a-486d-4a26-8a75-2c9b54867195,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-feefce67-18f6-43ad-a00f-f90e188d0000,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-5da425b7-8292-473e-87bd-1578c0ceeff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-0995ab85-e3ca-4a8b-bd28-72f034c35f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-398cb142-58f9-4789-8db8-839c414585e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911400628-172.17.0.8-1597623710444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-4f494983-252d-4b34-8f9b-ad8d4db75d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-d6bb82a0-b67d-4acd-871a-692ba973189f,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-fb857574-db7d-4059-95f8-0f4789021a07,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-e003e51c-fe69-45d8-a505-ce8e14cc3d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-09774c0a-0be1-4670-a9ed-2cb120951244,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-1b9539d2-8b86-4994-8a63-f44a606d2ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-59c728d1-a359-438b-8e5e-dd07c6a6e442,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-16c10208-3a0f-4470-9bf3-5e60bff47f6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911400628-172.17.0.8-1597623710444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-4f494983-252d-4b34-8f9b-ad8d4db75d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-d6bb82a0-b67d-4acd-871a-692ba973189f,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-fb857574-db7d-4059-95f8-0f4789021a07,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-e003e51c-fe69-45d8-a505-ce8e14cc3d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-09774c0a-0be1-4670-a9ed-2cb120951244,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-1b9539d2-8b86-4994-8a63-f44a606d2ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-59c728d1-a359-438b-8e5e-dd07c6a6e442,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-16c10208-3a0f-4470-9bf3-5e60bff47f6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830613186-172.17.0.8-1597624019626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40908,DS-f054ba5e-b5f7-495d-a2fa-3f35e47389de,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-5ddf86cd-c9a5-4893-9dd9-04425a7cdc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-a9000d48-f5fe-46a1-9271-8d55bb56811b,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-5a511635-48f6-453e-a4dd-eba8733c9810,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-bc66b709-4358-4433-904c-d5d7b69d9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-2755722b-be04-40c8-93db-543b2dbe00bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-9aa2bc53-1238-4dfa-98e5-ac35c856e0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-31f604d9-ae48-4ca5-b307-8cb9fe897339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830613186-172.17.0.8-1597624019626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40908,DS-f054ba5e-b5f7-495d-a2fa-3f35e47389de,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-5ddf86cd-c9a5-4893-9dd9-04425a7cdc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-a9000d48-f5fe-46a1-9271-8d55bb56811b,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-5a511635-48f6-453e-a4dd-eba8733c9810,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-bc66b709-4358-4433-904c-d5d7b69d9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-2755722b-be04-40c8-93db-543b2dbe00bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-9aa2bc53-1238-4dfa-98e5-ac35c856e0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-31f604d9-ae48-4ca5-b307-8cb9fe897339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.timeout.ms
component: hdfs:NameNode
v1: 1024
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49372189-172.17.0.8-1597624380740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-7eb30b02-101c-450a-8acb-69a47358dbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-88125f92-b92a-49de-ac10-14c8dfa4de75,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-7d0663ca-9559-454c-a3c1-c10a6be828e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-95df5b21-fbfa-48dd-ad76-2894d37e5805,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-53c3c9ec-7576-44e3-9504-b05e33b7bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-475991be-d575-4016-8d1f-8195d558bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-ca1155f0-6dfe-4587-8392-9e7de0c97593,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-87232d97-0d53-49fe-97b2-701881fd3b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49372189-172.17.0.8-1597624380740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-7eb30b02-101c-450a-8acb-69a47358dbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-88125f92-b92a-49de-ac10-14c8dfa4de75,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-7d0663ca-9559-454c-a3c1-c10a6be828e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-95df5b21-fbfa-48dd-ad76-2894d37e5805,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-53c3c9ec-7576-44e3-9504-b05e33b7bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-475991be-d575-4016-8d1f-8195d558bff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-ca1155f0-6dfe-4587-8392-9e7de0c97593,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-87232d97-0d53-49fe-97b2-701881fd3b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6828
