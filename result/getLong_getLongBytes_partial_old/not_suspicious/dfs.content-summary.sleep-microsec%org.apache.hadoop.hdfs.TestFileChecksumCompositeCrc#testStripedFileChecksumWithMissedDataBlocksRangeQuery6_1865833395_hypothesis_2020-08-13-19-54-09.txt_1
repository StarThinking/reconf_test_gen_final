reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039974647-172.17.0.8-1597348760117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-9b004b3c-ece2-4910-bbd1-c50a9df2f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-686494e8-c6d8-40a8-aa03-bf4df3dc897d,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-d23f7c9e-f69a-4108-aa09-2308bb26deba,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-9ddc184b-74f3-464c-a731-1a54813ae50d,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-ac48802e-e73f-46ef-9c9f-5c425532506a,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-bf22064d-6508-48a1-8147-4c89860afe43,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-eb08612d-4ddf-44a3-b090-c24a0c7ed362,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-ef0f94ac-e666-4f00-be08-0372aa81d554,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039974647-172.17.0.8-1597348760117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-9b004b3c-ece2-4910-bbd1-c50a9df2f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-686494e8-c6d8-40a8-aa03-bf4df3dc897d,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-d23f7c9e-f69a-4108-aa09-2308bb26deba,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-9ddc184b-74f3-464c-a731-1a54813ae50d,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-ac48802e-e73f-46ef-9c9f-5c425532506a,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-bf22064d-6508-48a1-8147-4c89860afe43,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-eb08612d-4ddf-44a3-b090-c24a0c7ed362,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-ef0f94ac-e666-4f00-be08-0372aa81d554,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760131118-172.17.0.8-1597348964631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-c2e6b259-9614-40b8-9f59-9fc2924e7305,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-64045205-550f-4b16-bf7a-3a036edf6de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-0bcbe73c-5880-4bf4-98fa-37e7c8863d57,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-0a5259a7-6e94-4dc2-b942-4f46a02628b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-1edce069-fa46-4241-a45b-2af639586251,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-c28927de-e7aa-4a7f-901e-c5bd52ca18f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-39b18cfb-3490-43b4-9e77-6cd2d61d77f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-e3785f2f-dae4-4ec3-bd68-0dc1c8c0269a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760131118-172.17.0.8-1597348964631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-c2e6b259-9614-40b8-9f59-9fc2924e7305,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-64045205-550f-4b16-bf7a-3a036edf6de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-0bcbe73c-5880-4bf4-98fa-37e7c8863d57,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-0a5259a7-6e94-4dc2-b942-4f46a02628b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-1edce069-fa46-4241-a45b-2af639586251,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-c28927de-e7aa-4a7f-901e-c5bd52ca18f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-39b18cfb-3490-43b4-9e77-6cd2d61d77f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-e3785f2f-dae4-4ec3-bd68-0dc1c8c0269a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269337131-172.17.0.8-1597349110733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45260,DS-5147f6df-d00f-446f-9364-b80f474a523c,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-4f36a172-aae8-452b-b404-90846b497768,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-fc1d5914-3ff2-4191-bd21-e0454b7b42f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-4bcc7f73-1c7a-41a6-8c47-9a1786a8229c,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-e4c852c4-3153-4a74-bc4a-a51397ae7043,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-37b049cb-6596-4df7-b5e8-5e0b94244fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-f87f78a1-fbc0-4eb5-bb30-bc5c3d776e35,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-d1d1c8c1-3100-4805-965d-b9a4161bee4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269337131-172.17.0.8-1597349110733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45260,DS-5147f6df-d00f-446f-9364-b80f474a523c,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-4f36a172-aae8-452b-b404-90846b497768,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-fc1d5914-3ff2-4191-bd21-e0454b7b42f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-4bcc7f73-1c7a-41a6-8c47-9a1786a8229c,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-e4c852c4-3153-4a74-bc4a-a51397ae7043,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-37b049cb-6596-4df7-b5e8-5e0b94244fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-f87f78a1-fbc0-4eb5-bb30-bc5c3d776e35,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-d1d1c8c1-3100-4805-965d-b9a4161bee4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834937303-172.17.0.8-1597349146390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39154,DS-710a49df-a429-4a0f-9a17-9e88775e90dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-e1343e42-8762-4a23-b0d5-32d7113e1bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-c6fae5a6-ab27-48cf-812d-eaa83a0ebae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-fc6104d8-ec6d-4366-9ff1-d9e086f3f247,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-bf26e82f-f50a-423c-9f45-7581489e07e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-4de82e97-13f4-429b-ba3e-5139628145ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-7f6fb038-157f-4029-9ad5-56342912190e,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-f0d4f616-23d8-4446-ad68-8e6927188094,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834937303-172.17.0.8-1597349146390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39154,DS-710a49df-a429-4a0f-9a17-9e88775e90dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-e1343e42-8762-4a23-b0d5-32d7113e1bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-c6fae5a6-ab27-48cf-812d-eaa83a0ebae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-fc6104d8-ec6d-4366-9ff1-d9e086f3f247,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-bf26e82f-f50a-423c-9f45-7581489e07e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-4de82e97-13f4-429b-ba3e-5139628145ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-7f6fb038-157f-4029-9ad5-56342912190e,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-f0d4f616-23d8-4446-ad68-8e6927188094,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303478402-172.17.0.8-1597349375152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35997,DS-d1aad6ff-96cf-49cf-8c60-34ce5257cead,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-c3ad22e7-380b-4c78-acba-739228f8dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-ba04cd82-03de-4681-b2ef-dbc4173f5522,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-6ad67fd9-609a-4585-8f24-dc256c20bc49,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-a7ac135c-8704-4d79-9c57-c9de28420156,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-eb7f9037-b7e7-4d76-92fd-f363c5f8852c,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-acf31211-49c1-4a43-a6d8-582ee328b475,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-9ce08130-6f99-4958-9357-adc6849e1692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303478402-172.17.0.8-1597349375152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35997,DS-d1aad6ff-96cf-49cf-8c60-34ce5257cead,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-c3ad22e7-380b-4c78-acba-739228f8dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-ba04cd82-03de-4681-b2ef-dbc4173f5522,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-6ad67fd9-609a-4585-8f24-dc256c20bc49,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-a7ac135c-8704-4d79-9c57-c9de28420156,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-eb7f9037-b7e7-4d76-92fd-f363c5f8852c,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-acf31211-49c1-4a43-a6d8-582ee328b475,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-9ce08130-6f99-4958-9357-adc6849e1692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076497271-172.17.0.8-1597349628771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36894,DS-48a89b71-dbe9-4ab1-befe-749562859830,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-892bf5ad-25ee-4f2d-84be-e11b052059ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-b2115a3b-926e-4edb-b13e-29af850fdbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-88c3beaf-210b-4d3b-b722-0b40178d5043,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-a7bde42a-16da-4f53-acd3-77f871ff93b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-34b8511c-f1e3-4fb0-963e-e0a68ecae706,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-5c5bbefe-bf14-4992-af4b-97cc72a10e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-c91be347-884d-4123-8bfe-3b9f2b2ed5da,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076497271-172.17.0.8-1597349628771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36894,DS-48a89b71-dbe9-4ab1-befe-749562859830,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-892bf5ad-25ee-4f2d-84be-e11b052059ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-b2115a3b-926e-4edb-b13e-29af850fdbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-88c3beaf-210b-4d3b-b722-0b40178d5043,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-a7bde42a-16da-4f53-acd3-77f871ff93b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-34b8511c-f1e3-4fb0-963e-e0a68ecae706,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-5c5bbefe-bf14-4992-af4b-97cc72a10e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-c91be347-884d-4123-8bfe-3b9f2b2ed5da,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792441439-172.17.0.8-1597349955579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35910,DS-b2fa451e-7c4e-4972-950c-71761f2318db,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-a6a15389-bee3-404a-9efc-c241b80f9be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-3ba28968-2cc0-4140-a7af-3563c9fe5c77,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-928b07a2-0902-4121-accc-79b44a9e79fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-00385f85-a43f-455c-84d3-bafec9a31d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-7e815614-7ab9-4e9d-9146-3d2f9fa9e506,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-40195ca0-52d9-4366-8115-4a0f9d64a02d,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-4a71d5e5-e90f-4dab-a6dc-602cd8fc8be3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792441439-172.17.0.8-1597349955579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35910,DS-b2fa451e-7c4e-4972-950c-71761f2318db,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-a6a15389-bee3-404a-9efc-c241b80f9be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-3ba28968-2cc0-4140-a7af-3563c9fe5c77,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-928b07a2-0902-4121-accc-79b44a9e79fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-00385f85-a43f-455c-84d3-bafec9a31d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-7e815614-7ab9-4e9d-9146-3d2f9fa9e506,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-40195ca0-52d9-4366-8115-4a0f9d64a02d,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-4a71d5e5-e90f-4dab-a6dc-602cd8fc8be3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682024670-172.17.0.8-1597350002044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35152,DS-7ce92464-791a-4b26-9db5-c82acf4c076c,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-9f52b4af-741e-4afe-a406-8483872e8ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-18f4e0e6-0019-42c6-add1-562262eceb58,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-4556665a-0eda-4431-b14f-5dc8bda47675,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-22902601-e45b-45f4-8e9a-f98507b5ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-6ef091a4-4102-41b5-a4b8-da77733f4041,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-0b8cad6c-6461-4fcf-b8e5-a0930dcf1266,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-3db08a82-82d8-476f-8872-aa30ae2d7667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682024670-172.17.0.8-1597350002044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35152,DS-7ce92464-791a-4b26-9db5-c82acf4c076c,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-9f52b4af-741e-4afe-a406-8483872e8ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-18f4e0e6-0019-42c6-add1-562262eceb58,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-4556665a-0eda-4431-b14f-5dc8bda47675,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-22902601-e45b-45f4-8e9a-f98507b5ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-6ef091a4-4102-41b5-a4b8-da77733f4041,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-0b8cad6c-6461-4fcf-b8e5-a0930dcf1266,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-3db08a82-82d8-476f-8872-aa30ae2d7667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308118953-172.17.0.8-1597350129198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43362,DS-cc05ecc3-fca5-462a-b462-c17d508527ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-aa85e452-5548-4621-9c56-d0ecdbdc9448,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-8c395acd-b42b-49bc-85c3-1d106a697026,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-60e54d36-29c5-426c-a6b6-16c6aa4cb214,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-2963892b-a849-4f2a-b4ff-df77dab35053,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-05c16c0c-70c5-4f4c-996c-3eb8cbe0b23f,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-58472fb5-81aa-44cd-ae3c-79ad861c3663,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-1dc54603-5a5b-4524-a747-b205d8e19ac0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308118953-172.17.0.8-1597350129198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43362,DS-cc05ecc3-fca5-462a-b462-c17d508527ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-aa85e452-5548-4621-9c56-d0ecdbdc9448,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-8c395acd-b42b-49bc-85c3-1d106a697026,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-60e54d36-29c5-426c-a6b6-16c6aa4cb214,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-2963892b-a849-4f2a-b4ff-df77dab35053,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-05c16c0c-70c5-4f4c-996c-3eb8cbe0b23f,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-58472fb5-81aa-44cd-ae3c-79ad861c3663,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-1dc54603-5a5b-4524-a747-b205d8e19ac0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817732752-172.17.0.8-1597350276283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-8601c448-94b5-4e1d-9cda-254fbd7c5e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-ba1597bc-0d2f-4e26-a7da-24874ea46ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-690169a2-493f-4844-b18f-aac46057002b,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-e1ac31e6-0120-468b-8d92-e3cc7a68a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-7adb12c1-6d73-44ab-8426-03a78cec3048,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-4064403f-c0d6-495a-88cb-f1ebdd731c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-6bb7f563-d6ad-4903-ac91-4d74bae2739b,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-ce1398c2-9e54-49d6-9250-775a91d7345d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817732752-172.17.0.8-1597350276283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-8601c448-94b5-4e1d-9cda-254fbd7c5e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-ba1597bc-0d2f-4e26-a7da-24874ea46ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-690169a2-493f-4844-b18f-aac46057002b,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-e1ac31e6-0120-468b-8d92-e3cc7a68a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-7adb12c1-6d73-44ab-8426-03a78cec3048,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-4064403f-c0d6-495a-88cb-f1ebdd731c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-6bb7f563-d6ad-4903-ac91-4d74bae2739b,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-ce1398c2-9e54-49d6-9250-775a91d7345d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182776381-172.17.0.8-1597350310739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33404,DS-eb9f8eb8-4969-4995-aaad-df9ff86cabd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-964aff95-87dc-4b65-9aca-a0ff8ccee99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-b97e9fef-752a-4780-aea2-00197b28f415,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-ea26d65e-6bfd-41a3-8a55-8d6636756383,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-0aa7e1cc-04c0-4a1f-bad0-212853adfc47,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-1fcc58e7-cbbe-4b56-b34e-f0465507b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-fa10efc7-d6e0-4c7f-8d66-22514ec7cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-b50e08a7-e636-453a-ad83-db9c67e9961a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182776381-172.17.0.8-1597350310739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33404,DS-eb9f8eb8-4969-4995-aaad-df9ff86cabd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-964aff95-87dc-4b65-9aca-a0ff8ccee99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-b97e9fef-752a-4780-aea2-00197b28f415,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-ea26d65e-6bfd-41a3-8a55-8d6636756383,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-0aa7e1cc-04c0-4a1f-bad0-212853adfc47,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-1fcc58e7-cbbe-4b56-b34e-f0465507b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-fa10efc7-d6e0-4c7f-8d66-22514ec7cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-b50e08a7-e636-453a-ad83-db9c67e9961a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248128402-172.17.0.8-1597350635976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40777,DS-828c8b20-807d-42f0-9e49-af210d78a723,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-c7d63840-1b4b-464a-b0b6-083b4723babd,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-df88bbcc-9a27-482c-874c-5a42cc557a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-7f7481f3-f43b-478d-8495-764601c07da1,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-d27009d0-a8dd-4b83-b172-7c33772cee67,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-2c9fb240-baf3-410c-9009-d1ff2643da7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-a0f3a5d7-d6a2-47a1-b15f-fbbc0cb717e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-09b2fb14-1fc1-440b-8d88-c1f6a8d548f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248128402-172.17.0.8-1597350635976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40777,DS-828c8b20-807d-42f0-9e49-af210d78a723,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-c7d63840-1b4b-464a-b0b6-083b4723babd,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-df88bbcc-9a27-482c-874c-5a42cc557a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-7f7481f3-f43b-478d-8495-764601c07da1,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-d27009d0-a8dd-4b83-b172-7c33772cee67,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-2c9fb240-baf3-410c-9009-d1ff2643da7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-a0f3a5d7-d6a2-47a1-b15f-fbbc0cb717e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-09b2fb14-1fc1-440b-8d88-c1f6a8d548f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061322932-172.17.0.8-1597350982933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-3ba07989-c327-4925-be4b-8650ae3dea83,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-ce32cc39-5089-4dd6-9985-5a54b44aa199,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-aa86bb26-4b42-4f3d-9c06-335b0cd8a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-ad796e38-27a8-4f11-bd2c-7b0c6a714af0,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-c5abe091-8587-427b-b34e-785bff883ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-a84c4d5e-814f-41c0-b946-39b452c41be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-70aefd37-31d8-4344-8bd9-5401ce4c7302,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-2f3153bd-1d89-42d7-86c5-8734ace0a20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061322932-172.17.0.8-1597350982933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-3ba07989-c327-4925-be4b-8650ae3dea83,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-ce32cc39-5089-4dd6-9985-5a54b44aa199,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-aa86bb26-4b42-4f3d-9c06-335b0cd8a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-ad796e38-27a8-4f11-bd2c-7b0c6a714af0,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-c5abe091-8587-427b-b34e-785bff883ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-a84c4d5e-814f-41c0-b946-39b452c41be7,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-70aefd37-31d8-4344-8bd9-5401ce4c7302,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-2f3153bd-1d89-42d7-86c5-8734ace0a20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519598752-172.17.0.8-1597351027768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42292,DS-45ebc6bf-801c-4af7-9f8a-c31cd4498750,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-ed931884-31ed-4e60-8313-9b60ab241c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-cdaef024-053c-4b51-8392-be0ebc368ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-933f955c-4604-4825-882b-18184b181615,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-4cea641d-c22c-4bea-96dc-924cf4d9f62e,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-37ef7318-6dae-468f-8ce0-979df4e326a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-89da8a9d-3fe1-4f49-b560-8accda571556,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-bd0b6f75-595d-497d-b243-e347e548f4e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519598752-172.17.0.8-1597351027768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42292,DS-45ebc6bf-801c-4af7-9f8a-c31cd4498750,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-ed931884-31ed-4e60-8313-9b60ab241c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-cdaef024-053c-4b51-8392-be0ebc368ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-933f955c-4604-4825-882b-18184b181615,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-4cea641d-c22c-4bea-96dc-924cf4d9f62e,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-37ef7318-6dae-468f-8ce0-979df4e326a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-89da8a9d-3fe1-4f49-b560-8accda571556,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-bd0b6f75-595d-497d-b243-e347e548f4e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087316512-172.17.0.8-1597351179575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41840,DS-79289a07-cdbf-463d-8b86-56c78b1ab796,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-ab1579e9-5369-4351-8e9b-132b7644cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-c95b05e5-31af-459b-852f-832e3835dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-8f981a31-1a27-4ba7-9656-016a2b0b490e,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-e89d54d8-18cc-497c-9e56-d8fd03f5912d,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-e18ee13c-b840-41ab-b4f2-9fc1014271fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-27ad7609-fd7e-4fce-a236-5cdb939b6eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-ccf6ad5c-e472-44e8-b051-a5b494551e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087316512-172.17.0.8-1597351179575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41840,DS-79289a07-cdbf-463d-8b86-56c78b1ab796,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-ab1579e9-5369-4351-8e9b-132b7644cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-c95b05e5-31af-459b-852f-832e3835dfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-8f981a31-1a27-4ba7-9656-016a2b0b490e,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-e89d54d8-18cc-497c-9e56-d8fd03f5912d,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-e18ee13c-b840-41ab-b4f2-9fc1014271fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-27ad7609-fd7e-4fce-a236-5cdb939b6eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-ccf6ad5c-e472-44e8-b051-a5b494551e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507388081-172.17.0.8-1597351216084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-affbbc71-d20a-4a2c-adce-46709e064fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-bb7f5b63-3313-4d1b-8b2c-43a1fc11f841,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-dc439931-f401-4def-ac54-26f915fa08bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-85d63c12-602c-428e-b4d3-f2b621f121dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-29426dd3-82b2-45be-a9fa-2e29d989a876,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-baf96a54-51a8-4a61-9281-02a8a078f459,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-45a13947-dbec-4d6f-bd1c-7d93ad9c79df,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-4c34ed3e-2ab3-4005-9702-84e31ecb5c0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507388081-172.17.0.8-1597351216084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-affbbc71-d20a-4a2c-adce-46709e064fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-bb7f5b63-3313-4d1b-8b2c-43a1fc11f841,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-dc439931-f401-4def-ac54-26f915fa08bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-85d63c12-602c-428e-b4d3-f2b621f121dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-29426dd3-82b2-45be-a9fa-2e29d989a876,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-baf96a54-51a8-4a61-9281-02a8a078f459,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-45a13947-dbec-4d6f-bd1c-7d93ad9c79df,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-4c34ed3e-2ab3-4005-9702-84e31ecb5c0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090095965-172.17.0.8-1597351301959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44271,DS-02644e02-0f73-4839-a8e0-f19a1d2fc8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-83882e45-8f6a-443d-958b-6036ae81b6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-0aa91592-e356-4239-acf7-c904d9ddd3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-1cb6ee70-5cf7-4e51-be88-2daa9fcc7185,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-209112bd-4ce8-41e2-83e3-9e2ab6f867c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-b0f550f8-751e-46d9-852f-3b2734c76e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-eac70ba8-d0e0-4042-87fb-915ece2fb1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-c12d2c26-2501-4d6e-b484-b4dd5ae4302a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090095965-172.17.0.8-1597351301959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44271,DS-02644e02-0f73-4839-a8e0-f19a1d2fc8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-83882e45-8f6a-443d-958b-6036ae81b6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-0aa91592-e356-4239-acf7-c904d9ddd3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-1cb6ee70-5cf7-4e51-be88-2daa9fcc7185,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-209112bd-4ce8-41e2-83e3-9e2ab6f867c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-b0f550f8-751e-46d9-852f-3b2734c76e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-eac70ba8-d0e0-4042-87fb-915ece2fb1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-c12d2c26-2501-4d6e-b484-b4dd5ae4302a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-829632692-172.17.0.8-1597351415572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45416,DS-86342278-7045-4e31-80b1-e16ea7cc661d,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-3ac4836c-b857-483a-ab80-48c075adc8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-79cb6b4f-05c0-4937-a0ac-b9c3d58967c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-341c05e9-3c68-4e6c-931d-6438343a44b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-cac85c84-6742-4634-add1-453743ba5181,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-8b210b8c-c93b-42d6-a573-592563bea4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8f8a0db9-06d9-41aa-ae58-761f4dfa62e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-97051bd8-f81f-459f-acf7-028d3822ebed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-829632692-172.17.0.8-1597351415572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45416,DS-86342278-7045-4e31-80b1-e16ea7cc661d,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-3ac4836c-b857-483a-ab80-48c075adc8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-79cb6b4f-05c0-4937-a0ac-b9c3d58967c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-341c05e9-3c68-4e6c-931d-6438343a44b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-cac85c84-6742-4634-add1-453743ba5181,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-8b210b8c-c93b-42d6-a573-592563bea4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8f8a0db9-06d9-41aa-ae58-761f4dfa62e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-97051bd8-f81f-459f-acf7-028d3822ebed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506164095-172.17.0.8-1597351450392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-3870de43-c831-4aa2-b091-3ce46b1744c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-dc7cd6a1-43ad-45e5-b7ab-d0b8014188de,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-be03b351-bfb7-4190-935e-e83d8a4aa983,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-64753947-ec90-42b0-b0e0-c86213ad3275,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-66adf6e4-c4b5-42df-bc49-84c46b9102dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-63728d6f-fef7-4157-bf84-6ae880376ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-cf0ee3bd-a8ee-494c-8aa3-0d6d0bc27c35,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-a99b856f-6397-424d-bc1c-d6c2b3b7fcc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506164095-172.17.0.8-1597351450392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-3870de43-c831-4aa2-b091-3ce46b1744c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-dc7cd6a1-43ad-45e5-b7ab-d0b8014188de,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-be03b351-bfb7-4190-935e-e83d8a4aa983,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-64753947-ec90-42b0-b0e0-c86213ad3275,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-66adf6e4-c4b5-42df-bc49-84c46b9102dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-63728d6f-fef7-4157-bf84-6ae880376ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-cf0ee3bd-a8ee-494c-8aa3-0d6d0bc27c35,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-a99b856f-6397-424d-bc1c-d6c2b3b7fcc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071051770-172.17.0.8-1597351609235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-46226486-a4ba-4fb1-a8e3-041006ffe1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-b44ee7ed-7d3d-464e-ad13-7da0b7084ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-365ee34a-811c-4879-82b8-f9dbedadb0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-166b0416-d0eb-4eac-ada7-758c31633573,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-4fae8459-b2f3-40d5-b2f6-feced621a72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-8cc8d08d-e89c-47a3-b452-8df176badd96,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-bcfe16af-0e97-455b-8f41-416deecc7e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-2c8acbff-65ff-44dd-9a99-38f2a665a13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1071051770-172.17.0.8-1597351609235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-46226486-a4ba-4fb1-a8e3-041006ffe1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-b44ee7ed-7d3d-464e-ad13-7da0b7084ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-365ee34a-811c-4879-82b8-f9dbedadb0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-166b0416-d0eb-4eac-ada7-758c31633573,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-4fae8459-b2f3-40d5-b2f6-feced621a72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-8cc8d08d-e89c-47a3-b452-8df176badd96,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-bcfe16af-0e97-455b-8f41-416deecc7e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-2c8acbff-65ff-44dd-9a99-38f2a665a13b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598226887-172.17.0.8-1597351646041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-55c68c75-d229-4951-9c0d-cba506f6843f,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-115c38a5-a7c8-4e97-a6d5-3d21da71e2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-ce889620-0431-419a-9553-434a6f2135bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-f9f42817-3b9d-42db-9504-22c919946319,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-b180172c-f3b8-4776-b2b3-51986d25f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-ae3de082-e105-4a0a-9272-8ae81d907318,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-9b446b93-0bb8-44c7-ae29-00663d1346e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-4082f1ea-315d-42de-a6bc-d5b1aa781e04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598226887-172.17.0.8-1597351646041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-55c68c75-d229-4951-9c0d-cba506f6843f,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-115c38a5-a7c8-4e97-a6d5-3d21da71e2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-ce889620-0431-419a-9553-434a6f2135bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-f9f42817-3b9d-42db-9504-22c919946319,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-b180172c-f3b8-4776-b2b3-51986d25f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-ae3de082-e105-4a0a-9272-8ae81d907318,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-9b446b93-0bb8-44c7-ae29-00663d1346e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-4082f1ea-315d-42de-a6bc-d5b1aa781e04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810663781-172.17.0.8-1597351725025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-91bd0c01-c0cc-4909-9366-20d25e82e7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-8be3458b-18e6-4a8b-82cc-ecf36fbe2d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-c794a1e0-0296-44e1-af49-fa774375ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-56b77562-f6ab-49c3-8737-02e160b71fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-b5d874ca-e599-412c-a9ef-35ef4e060038,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-7505b697-c662-440f-a1e4-443c6ea63d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-0f1ee288-1698-4a69-b1e5-e9a98d474aad,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-c4b8e5a2-5b60-4a7d-b0dd-9b4ca24516c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810663781-172.17.0.8-1597351725025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-91bd0c01-c0cc-4909-9366-20d25e82e7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-8be3458b-18e6-4a8b-82cc-ecf36fbe2d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-c794a1e0-0296-44e1-af49-fa774375ed1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-56b77562-f6ab-49c3-8737-02e160b71fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-b5d874ca-e599-412c-a9ef-35ef4e060038,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-7505b697-c662-440f-a1e4-443c6ea63d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-0f1ee288-1698-4a69-b1e5-e9a98d474aad,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-c4b8e5a2-5b60-4a7d-b0dd-9b4ca24516c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902446085-172.17.0.8-1597351954168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37347,DS-f27a6ff2-9fdd-45ad-b5a7-0d25fc9c2807,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-3de880ef-ec3d-4f0c-840d-faf055d39ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-28e067d0-e917-48c8-99ca-9aa014b3b7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-422f31e4-50a0-4d67-852e-3380d8638201,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-e03b5908-d1ad-484d-b02c-f8b089579c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-1821c144-507f-4aaa-9204-e03c4815dc08,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-d075b761-8ba3-4105-9321-3e5e7cc6df33,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-85abc92a-3f48-4786-b585-e08958cd043a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902446085-172.17.0.8-1597351954168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37347,DS-f27a6ff2-9fdd-45ad-b5a7-0d25fc9c2807,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-3de880ef-ec3d-4f0c-840d-faf055d39ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36220,DS-28e067d0-e917-48c8-99ca-9aa014b3b7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-422f31e4-50a0-4d67-852e-3380d8638201,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-e03b5908-d1ad-484d-b02c-f8b089579c15,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-1821c144-507f-4aaa-9204-e03c4815dc08,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-d075b761-8ba3-4105-9321-3e5e7cc6df33,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-85abc92a-3f48-4786-b585-e08958cd043a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895802774-172.17.0.8-1597352109884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43400,DS-1fc01442-d8bc-42aa-9618-3c079284ef79,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-2d187d8c-e300-4755-a953-0ec32e320e36,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-491dfb16-4199-420f-8324-2e64adfa9cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-b47fad04-3d80-45bb-9241-0659e2ab6fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-b7b9efe0-e172-4d6a-ba83-4fc0937b9c22,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-0ac2b1f2-f230-437a-a6ba-6d01c10e3649,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-b874e574-df0a-4390-8b32-7b3deccfc03e,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-61692720-fbdb-4624-b4e2-02e9e05acda2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895802774-172.17.0.8-1597352109884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43400,DS-1fc01442-d8bc-42aa-9618-3c079284ef79,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-2d187d8c-e300-4755-a953-0ec32e320e36,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-491dfb16-4199-420f-8324-2e64adfa9cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-b47fad04-3d80-45bb-9241-0659e2ab6fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-b7b9efe0-e172-4d6a-ba83-4fc0937b9c22,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-0ac2b1f2-f230-437a-a6ba-6d01c10e3649,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-b874e574-df0a-4390-8b32-7b3deccfc03e,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-61692720-fbdb-4624-b4e2-02e9e05acda2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84380392-172.17.0.8-1597353150192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-4eae102f-562f-4486-8f3b-c3673b2e2020,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-ff30dac2-3489-4dbe-9774-b3988d93dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-26c1ed13-230c-4f37-a9c5-d5b68918fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-c2ef67ca-589d-4500-b5af-bc1caff708ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-a479f717-21d6-46c1-9e77-ec34dbe2c358,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-37022958-ccd9-488c-a569-fd61e07a0983,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-849613bd-a276-4833-8db6-1529f6610a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-1c4d2ef2-c87e-4844-9d32-015e2e85246f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84380392-172.17.0.8-1597353150192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-4eae102f-562f-4486-8f3b-c3673b2e2020,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-ff30dac2-3489-4dbe-9774-b3988d93dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-26c1ed13-230c-4f37-a9c5-d5b68918fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-c2ef67ca-589d-4500-b5af-bc1caff708ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-a479f717-21d6-46c1-9e77-ec34dbe2c358,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-37022958-ccd9-488c-a569-fd61e07a0983,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-849613bd-a276-4833-8db6-1529f6610a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-1c4d2ef2-c87e-4844-9d32-015e2e85246f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592496354-172.17.0.8-1597353309114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45031,DS-99e006af-087f-429b-9027-721667a04108,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-4761cb8e-78d6-400e-99d6-abfc87ee9ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-23b03cb8-9dbe-418b-ad35-cffd290d10f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-ec1be041-1611-459c-9aa7-6adad97283a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-eb061f91-1156-4938-9c13-8c0c3cbf073b,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-310d642e-c55c-4175-8beb-045607903488,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-25b35edf-8c1f-4611-a46b-5a82b67cd254,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-8135e67e-d445-4155-9a5f-1cc17c1e49cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592496354-172.17.0.8-1597353309114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45031,DS-99e006af-087f-429b-9027-721667a04108,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-4761cb8e-78d6-400e-99d6-abfc87ee9ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-23b03cb8-9dbe-418b-ad35-cffd290d10f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-ec1be041-1611-459c-9aa7-6adad97283a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-eb061f91-1156-4938-9c13-8c0c3cbf073b,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-310d642e-c55c-4175-8beb-045607903488,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-25b35edf-8c1f-4611-a46b-5a82b67cd254,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-8135e67e-d445-4155-9a5f-1cc17c1e49cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056706484-172.17.0.8-1597353348032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38561,DS-31281826-bffa-43ed-8074-77106da4d613,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-b0b20974-c8c3-4796-8978-36300fc4f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-6f2c7d91-5bd8-41ea-883b-8beeb6fd9b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-b26af96c-5b73-4a10-bc54-a65232188eba,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-bfd01f70-1a80-411b-a827-18738e46db62,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-cd7c91ea-cf08-4702-8d65-850a96cac3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-a40a3fd8-ed87-4c89-b5de-4efb675ad4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-7a28c0f6-e39d-43c4-ac50-dd0a68f25fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056706484-172.17.0.8-1597353348032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38561,DS-31281826-bffa-43ed-8074-77106da4d613,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-b0b20974-c8c3-4796-8978-36300fc4f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-6f2c7d91-5bd8-41ea-883b-8beeb6fd9b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-b26af96c-5b73-4a10-bc54-a65232188eba,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-bfd01f70-1a80-411b-a827-18738e46db62,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-cd7c91ea-cf08-4702-8d65-850a96cac3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-a40a3fd8-ed87-4c89-b5de-4efb675ad4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-7a28c0f6-e39d-43c4-ac50-dd0a68f25fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118679399-172.17.0.8-1597353473812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-6f55a1a6-39c6-4a02-a677-71900178aece,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-b8a36c88-ac23-4e16-a2a2-581462ca43be,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-85f64038-1af7-4286-b571-defa7977dbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-9358280b-dd59-43b1-bbd6-4daf2cecf3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-4e048c6a-6ee6-413a-abd2-b6056679280a,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-9a28da27-ad92-4b0e-af23-bf41892bfd34,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-a04ee35e-5fef-4ddf-a38f-42eaa60988c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-9e083e65-ef12-4fc4-a6a7-902a62d3b41d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118679399-172.17.0.8-1597353473812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-6f55a1a6-39c6-4a02-a677-71900178aece,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-b8a36c88-ac23-4e16-a2a2-581462ca43be,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-85f64038-1af7-4286-b571-defa7977dbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-9358280b-dd59-43b1-bbd6-4daf2cecf3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-4e048c6a-6ee6-413a-abd2-b6056679280a,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-9a28da27-ad92-4b0e-af23-bf41892bfd34,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-a04ee35e-5fef-4ddf-a38f-42eaa60988c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-9e083e65-ef12-4fc4-a6a7-902a62d3b41d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135752014-172.17.0.8-1597353597068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38191,DS-01901c6e-aff5-4d95-9267-65ebaaac602a,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-6bf5e0ec-08d6-435f-adf1-5ec50927cc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-dd71959d-9643-4851-aa1f-6d281be7689c,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-c1fdcf67-f7ec-4bc9-a623-94a38e821616,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-8074034d-ae36-49bd-91e8-70a8cc515489,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-44202224-9b41-4f37-8b0e-e881fc02da94,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-b2ec5d5a-1d25-4950-964a-ffe67e850693,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-f8d13de5-a95b-4c2f-82be-79d7dc8c825b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135752014-172.17.0.8-1597353597068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38191,DS-01901c6e-aff5-4d95-9267-65ebaaac602a,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-6bf5e0ec-08d6-435f-adf1-5ec50927cc34,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-dd71959d-9643-4851-aa1f-6d281be7689c,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-c1fdcf67-f7ec-4bc9-a623-94a38e821616,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-8074034d-ae36-49bd-91e8-70a8cc515489,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-44202224-9b41-4f37-8b0e-e881fc02da94,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-b2ec5d5a-1d25-4950-964a-ffe67e850693,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-f8d13de5-a95b-4c2f-82be-79d7dc8c825b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727478551-172.17.0.8-1597353687059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40184,DS-4298d944-898b-43be-baff-177460b43231,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-bdb72cfa-b37b-4be5-8b05-71f9971cbec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-4a5f35c4-829e-44a2-a3aa-98c107e935e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-c26d79a0-ba5f-4137-96dd-a9c73865acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-0360b161-3a37-42a9-9e7a-4937728d25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-b2da412e-dec5-4a09-b36c-268dcbab203e,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-e01d7b65-a1ff-4c5a-ac9c-d039523166b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-53e08daf-1f7c-4aa6-a882-cda45e2ee59a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727478551-172.17.0.8-1597353687059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40184,DS-4298d944-898b-43be-baff-177460b43231,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-bdb72cfa-b37b-4be5-8b05-71f9971cbec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-4a5f35c4-829e-44a2-a3aa-98c107e935e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-c26d79a0-ba5f-4137-96dd-a9c73865acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-0360b161-3a37-42a9-9e7a-4937728d25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-b2da412e-dec5-4a09-b36c-268dcbab203e,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-e01d7b65-a1ff-4c5a-ac9c-d039523166b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-53e08daf-1f7c-4aa6-a882-cda45e2ee59a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305702727-172.17.0.8-1597353967712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-cb77b3aa-b90b-41f1-b1f8-7d71087e1fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b51467bf-6797-4687-8f56-adf1531dacbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-61ca7090-45ed-4802-9518-ec08a2c6ff64,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-a4b8c93c-f1d2-4ce8-b35b-9fc48b36199a,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-31273c26-651a-4a0e-b000-49fdcfe36e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-1d3b82ee-a474-40d9-8495-922213e5dd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-d24183b2-1082-46f1-90e0-c3b0994ff71b,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-6af9d768-57a8-474a-a4ad-4d72effd4792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305702727-172.17.0.8-1597353967712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42628,DS-cb77b3aa-b90b-41f1-b1f8-7d71087e1fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b51467bf-6797-4687-8f56-adf1531dacbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-61ca7090-45ed-4802-9518-ec08a2c6ff64,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-a4b8c93c-f1d2-4ce8-b35b-9fc48b36199a,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-31273c26-651a-4a0e-b000-49fdcfe36e25,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-1d3b82ee-a474-40d9-8495-922213e5dd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-d24183b2-1082-46f1-90e0-c3b0994ff71b,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-6af9d768-57a8-474a-a4ad-4d72effd4792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022307136-172.17.0.8-1597354197488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-f1a11486-8f61-4103-8109-51810088ceaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-1d3ff43d-f6a1-4553-9367-1fa147500c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-bfd1c8d3-cb2e-4270-b00d-ff6cb919f187,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-9b6362a6-87d9-421a-84ae-f5e40b35d350,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-f9f6e053-11f1-4597-a3f6-efe7cffb46e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-ea70794f-1748-4163-81c6-a994d8bc7ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-beda300f-b2a4-4a11-a78e-b6a762825da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-bc232fc6-bb7c-462d-a874-e4185a004431,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022307136-172.17.0.8-1597354197488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-f1a11486-8f61-4103-8109-51810088ceaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-1d3ff43d-f6a1-4553-9367-1fa147500c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-bfd1c8d3-cb2e-4270-b00d-ff6cb919f187,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-9b6362a6-87d9-421a-84ae-f5e40b35d350,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-f9f6e053-11f1-4597-a3f6-efe7cffb46e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-ea70794f-1748-4163-81c6-a994d8bc7ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-beda300f-b2a4-4a11-a78e-b6a762825da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-bc232fc6-bb7c-462d-a874-e4185a004431,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5808
