reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759654414-172.17.0.11-1597397906774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42718,DS-4643fed7-ae57-4a2b-be4c-86398b73b046,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-646e9472-9f27-410f-b56e-cc40bb776c91,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-8f610bb1-a2a7-4887-9514-8d6a6a4d642a,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-64ccc416-efe3-452a-8c0f-1658c6d96b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-8b24b04b-353f-45dd-8da0-c50ddea0c2da,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-28a72222-4800-4f82-9865-bb764e59f86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-7bbc64fc-8b66-4519-9bd5-89ec39b5f629,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-6dd81410-cccf-4769-82d2-d436f14ace1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759654414-172.17.0.11-1597397906774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42718,DS-4643fed7-ae57-4a2b-be4c-86398b73b046,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-646e9472-9f27-410f-b56e-cc40bb776c91,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-8f610bb1-a2a7-4887-9514-8d6a6a4d642a,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-64ccc416-efe3-452a-8c0f-1658c6d96b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-8b24b04b-353f-45dd-8da0-c50ddea0c2da,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-28a72222-4800-4f82-9865-bb764e59f86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-7bbc64fc-8b66-4519-9bd5-89ec39b5f629,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-6dd81410-cccf-4769-82d2-d436f14ace1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924831607-172.17.0.11-1597398359500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40460,DS-8bf5182f-4186-4807-8a9d-29abde221147,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-9d63622c-793a-4de7-bbaf-94615f96d92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-68486ad0-965a-45bd-bda3-f48b68447a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-f7c38ef2-45ab-45ca-86b6-e93169b513bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-75892e34-1131-4e54-8326-bb7a878e0105,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-01178b62-07df-4fc8-8914-34146778403a,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-6ebf9f08-ac2e-4ed6-807b-5341257b5046,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-4b5edf2d-560e-451b-b20e-5cd0dc318c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924831607-172.17.0.11-1597398359500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40460,DS-8bf5182f-4186-4807-8a9d-29abde221147,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-9d63622c-793a-4de7-bbaf-94615f96d92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-68486ad0-965a-45bd-bda3-f48b68447a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-f7c38ef2-45ab-45ca-86b6-e93169b513bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-75892e34-1131-4e54-8326-bb7a878e0105,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-01178b62-07df-4fc8-8914-34146778403a,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-6ebf9f08-ac2e-4ed6-807b-5341257b5046,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-4b5edf2d-560e-451b-b20e-5cd0dc318c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752323569-172.17.0.11-1597399012934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38573,DS-d0395eac-689a-48b1-bd57-e60cf133b818,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-51aa668d-801b-485c-8ee6-330b653b270c,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-99130849-cfdf-413e-bbbf-8e31717d2f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-00d563a0-ada0-44a8-9dee-8a249f6d98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-7b6dae90-e2d5-4172-a1a8-0c55be3793cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-b43457bc-0eed-461f-85d8-ce12c0f9a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-c561731f-6da8-4d17-921d-a0d68e6506ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-2ec93174-d7ce-4c14-9d03-fc8f646e16b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752323569-172.17.0.11-1597399012934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38573,DS-d0395eac-689a-48b1-bd57-e60cf133b818,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-51aa668d-801b-485c-8ee6-330b653b270c,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-99130849-cfdf-413e-bbbf-8e31717d2f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-00d563a0-ada0-44a8-9dee-8a249f6d98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-7b6dae90-e2d5-4172-a1a8-0c55be3793cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-b43457bc-0eed-461f-85d8-ce12c0f9a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-c561731f-6da8-4d17-921d-a0d68e6506ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-2ec93174-d7ce-4c14-9d03-fc8f646e16b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603869922-172.17.0.11-1597399106555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-349b5ea3-61cc-4cc2-ad53-cef93e233356,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-f7ad9b39-2488-4eee-908b-2c8ccb96e5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-1e124a92-3297-40be-a982-4e9a0aa79db0,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-47f7664b-4114-42f7-8a01-dd17f6d9bc82,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-fbcd9999-ec64-44b6-8753-795af923c829,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-6de20bfd-30ea-4bdc-abc1-3c78afbb1921,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-2b93f12b-bed9-471b-8882-db5ba3fe1220,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-85ddd136-67df-4fde-a04d-a1aa5991a2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603869922-172.17.0.11-1597399106555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-349b5ea3-61cc-4cc2-ad53-cef93e233356,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-f7ad9b39-2488-4eee-908b-2c8ccb96e5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-1e124a92-3297-40be-a982-4e9a0aa79db0,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-47f7664b-4114-42f7-8a01-dd17f6d9bc82,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-fbcd9999-ec64-44b6-8753-795af923c829,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-6de20bfd-30ea-4bdc-abc1-3c78afbb1921,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-2b93f12b-bed9-471b-8882-db5ba3fe1220,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-85ddd136-67df-4fde-a04d-a1aa5991a2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092914124-172.17.0.11-1597399389731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-ec189daf-9385-4bba-a799-12f4882a411e,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-a70080bd-8de3-4f60-b69a-2db3ac2c9cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-d2980bf9-b89b-4a57-b58f-9cef78b922fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-d80fb70d-71ce-4f25-9afe-dcf5e447782a,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-d3efc53b-9d42-4db9-a4f0-fb4ff255d698,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-943f9a19-b4cb-408d-a39c-b39ce06a64cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-e0cb8b21-64a2-4cc5-a10b-26c5559207f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-fbb38455-f5d8-45d3-a84a-c11a021e55a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092914124-172.17.0.11-1597399389731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35299,DS-ec189daf-9385-4bba-a799-12f4882a411e,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-a70080bd-8de3-4f60-b69a-2db3ac2c9cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-d2980bf9-b89b-4a57-b58f-9cef78b922fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-d80fb70d-71ce-4f25-9afe-dcf5e447782a,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-d3efc53b-9d42-4db9-a4f0-fb4ff255d698,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-943f9a19-b4cb-408d-a39c-b39ce06a64cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-e0cb8b21-64a2-4cc5-a10b-26c5559207f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-fbb38455-f5d8-45d3-a84a-c11a021e55a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797751633-172.17.0.11-1597399975021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-20ce6812-eeed-40ed-b677-17e3e5d5634b,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-067cf3f9-25d0-4689-b0bc-96e84ee01b99,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-1ed89165-6b26-4818-add9-3cc3775e5a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-ca6c3fc5-40cc-4887-8988-fbb2e10587d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-90bd2517-1283-4892-b7f9-ae5b6fcbb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-70120f9e-65fe-46fe-bb86-b116def83f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-f54db47a-cfca-4ec8-b71c-ae1300e19e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-00508e18-9848-4e80-b929-819d3ba20755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797751633-172.17.0.11-1597399975021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38057,DS-20ce6812-eeed-40ed-b677-17e3e5d5634b,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-067cf3f9-25d0-4689-b0bc-96e84ee01b99,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-1ed89165-6b26-4818-add9-3cc3775e5a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-ca6c3fc5-40cc-4887-8988-fbb2e10587d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-90bd2517-1283-4892-b7f9-ae5b6fcbb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-70120f9e-65fe-46fe-bb86-b116def83f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-f54db47a-cfca-4ec8-b71c-ae1300e19e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-00508e18-9848-4e80-b929-819d3ba20755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79578184-172.17.0.11-1597400185870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-89c23616-c79e-4c56-a0a1-c8fe1cd3e82b,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-294d900e-d2b4-47bf-a84f-74d1d6fa9415,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-8e678951-5779-4168-b1c3-e7c810fecc95,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-a4dc84e3-bb71-49f1-b74d-8b88ef7c5ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-e3e3638f-5c4d-401f-a395-8f42908aa20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b2d1551a-d81a-4a45-8043-25940be302af,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-cea26c1d-a7f3-4f44-aa35-650f411112e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-fc2d7f93-0fb7-464c-820b-d1b65795db7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79578184-172.17.0.11-1597400185870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-89c23616-c79e-4c56-a0a1-c8fe1cd3e82b,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-294d900e-d2b4-47bf-a84f-74d1d6fa9415,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-8e678951-5779-4168-b1c3-e7c810fecc95,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-a4dc84e3-bb71-49f1-b74d-8b88ef7c5ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-e3e3638f-5c4d-401f-a395-8f42908aa20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-b2d1551a-d81a-4a45-8043-25940be302af,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-cea26c1d-a7f3-4f44-aa35-650f411112e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-fc2d7f93-0fb7-464c-820b-d1b65795db7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481680601-172.17.0.11-1597400318848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-cabd0e90-ec85-4d72-a2da-01689396fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-27c63cb1-c5fb-4201-8879-1538f3862945,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-c77264f1-4385-4bd1-b7bf-be3e100c3080,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-64186e98-d557-4833-8357-dfffd1453f69,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-57a8fa40-9d4b-451c-9108-2c39287cf25d,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-a6bc6e2e-f88d-4122-ae72-0e21e761356d,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-96601156-717f-46e7-a076-89d52fe97ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-ccffdb8a-96bc-455d-82f4-cc6ba18b97ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481680601-172.17.0.11-1597400318848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-cabd0e90-ec85-4d72-a2da-01689396fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-27c63cb1-c5fb-4201-8879-1538f3862945,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-c77264f1-4385-4bd1-b7bf-be3e100c3080,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-64186e98-d557-4833-8357-dfffd1453f69,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-57a8fa40-9d4b-451c-9108-2c39287cf25d,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-a6bc6e2e-f88d-4122-ae72-0e21e761356d,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-96601156-717f-46e7-a076-89d52fe97ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-ccffdb8a-96bc-455d-82f4-cc6ba18b97ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697177340-172.17.0.11-1597400707056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40393,DS-3a769646-2d87-4d98-9b7b-af15cf0c1003,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-67f96e77-68ea-4cee-a51c-6856ab8b4d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-e2c61881-8963-470d-8ea9-d61e1a95230a,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-71c9ef18-5d75-4154-9e33-34166a686008,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-c2387270-f879-4a0b-bdf1-20ad9eeef8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-5e69496b-470d-496d-900c-b1b2cdbf42ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-c05f26ea-0b65-4872-bcef-9088d138aa37,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-2d065846-aff8-4792-b02c-c03178c6523e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697177340-172.17.0.11-1597400707056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40393,DS-3a769646-2d87-4d98-9b7b-af15cf0c1003,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-67f96e77-68ea-4cee-a51c-6856ab8b4d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-e2c61881-8963-470d-8ea9-d61e1a95230a,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-71c9ef18-5d75-4154-9e33-34166a686008,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-c2387270-f879-4a0b-bdf1-20ad9eeef8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-5e69496b-470d-496d-900c-b1b2cdbf42ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-c05f26ea-0b65-4872-bcef-9088d138aa37,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-2d065846-aff8-4792-b02c-c03178c6523e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558467529-172.17.0.11-1597400877137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-6b1c4b58-a9c1-478a-b6c7-3d0abb7ba2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-3f1a7f46-2be2-4905-b0e3-f73e9aadac77,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-93d10bb6-a9be-410a-a198-5a5aebc6d1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-a06c1ac1-a3c0-44b5-8675-d3e7ce4b2c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-ac2105c2-5c3f-4d1e-84e9-cadd63abe369,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-2e751fbe-20d3-466b-8278-ab1fcf715442,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-b5ec3a8d-dd29-4acf-bceb-a03de20656a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-b3fad66d-a4d5-4bbb-9019-9a1437dd1b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558467529-172.17.0.11-1597400877137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-6b1c4b58-a9c1-478a-b6c7-3d0abb7ba2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-3f1a7f46-2be2-4905-b0e3-f73e9aadac77,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-93d10bb6-a9be-410a-a198-5a5aebc6d1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-a06c1ac1-a3c0-44b5-8675-d3e7ce4b2c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-ac2105c2-5c3f-4d1e-84e9-cadd63abe369,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-2e751fbe-20d3-466b-8278-ab1fcf715442,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-b5ec3a8d-dd29-4acf-bceb-a03de20656a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-b3fad66d-a4d5-4bbb-9019-9a1437dd1b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967885387-172.17.0.11-1597401003266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33876,DS-32645a48-0dda-4f41-8e07-ea609ff3952f,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-1ed5039a-c5bb-4853-960c-b39a0f1099ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-4a8ae2dc-a8a4-49b4-97ef-e2b266f82e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-ba20f0fa-10bf-41c5-a73d-cff499503d66,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-2b265190-e0b5-4b72-bdfe-92c3415ee71b,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-b112a276-f66b-4ce4-83ee-94ccf1d42b81,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-dc7af59d-5332-4263-afa3-f86607311cee,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-7a9a6ba7-b088-4ede-93db-d01138677a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967885387-172.17.0.11-1597401003266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33876,DS-32645a48-0dda-4f41-8e07-ea609ff3952f,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-1ed5039a-c5bb-4853-960c-b39a0f1099ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-4a8ae2dc-a8a4-49b4-97ef-e2b266f82e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-ba20f0fa-10bf-41c5-a73d-cff499503d66,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-2b265190-e0b5-4b72-bdfe-92c3415ee71b,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-b112a276-f66b-4ce4-83ee-94ccf1d42b81,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-dc7af59d-5332-4263-afa3-f86607311cee,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-7a9a6ba7-b088-4ede-93db-d01138677a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670680264-172.17.0.11-1597401650747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40500,DS-293b0dad-fc43-4f3c-bd3b-bf2fab5d7608,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-8329e9f0-c7fa-440c-9d5d-a70faab28db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-ff73b071-9c3f-421c-8869-11373f8aa7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-741536cd-f80a-4111-b1ff-b3e269376206,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-de25de4c-1dae-4319-b1aa-5f7d6352fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-2c492f5b-3571-4360-8a16-43e185086863,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-6c01ddf6-096b-4775-84df-4c4ed7da72d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-91e1c3f7-7043-406b-89f0-736c63cfe294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670680264-172.17.0.11-1597401650747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40500,DS-293b0dad-fc43-4f3c-bd3b-bf2fab5d7608,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-8329e9f0-c7fa-440c-9d5d-a70faab28db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-ff73b071-9c3f-421c-8869-11373f8aa7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-741536cd-f80a-4111-b1ff-b3e269376206,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-de25de4c-1dae-4319-b1aa-5f7d6352fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-2c492f5b-3571-4360-8a16-43e185086863,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-6c01ddf6-096b-4775-84df-4c4ed7da72d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-91e1c3f7-7043-406b-89f0-736c63cfe294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703066969-172.17.0.11-1597401882238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-8355e5c9-0e35-4a31-9ddf-756dbc950809,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-e4b72641-f98f-4e94-b490-4241403e0ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-253b05ad-6e1b-499f-9797-899ad5847b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-ad1ea62a-5b18-4741-93b9-25681cd35de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-768f11ee-afd6-45de-aeab-6bd4005a74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-5ef449d8-d5f7-4ce5-a3e6-6d91916bda46,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-40671c85-d749-455d-bc32-ea2945e3844d,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-50d26a45-4c77-4974-a6f3-10b612b20c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703066969-172.17.0.11-1597401882238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-8355e5c9-0e35-4a31-9ddf-756dbc950809,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-e4b72641-f98f-4e94-b490-4241403e0ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-253b05ad-6e1b-499f-9797-899ad5847b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-ad1ea62a-5b18-4741-93b9-25681cd35de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-768f11ee-afd6-45de-aeab-6bd4005a74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-5ef449d8-d5f7-4ce5-a3e6-6d91916bda46,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-40671c85-d749-455d-bc32-ea2945e3844d,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-50d26a45-4c77-4974-a6f3-10b612b20c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132399193-172.17.0.11-1597402271041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-d77129cc-de0f-47d5-936a-232c6db2c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-b95242e5-32d7-44f3-8b2e-d1a6c1106cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-ff4aba37-48fa-4faa-b8d2-597b4c2d9654,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-cd4d1ca2-85c5-434c-91ad-d7b6e9a9e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-423082d6-ab4e-4c46-a401-3faae6ac0c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-a113da9e-0242-4361-baf9-36a784033e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-b7e92ca0-471a-40a4-a730-c89ca6e2e3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-852de4b1-6521-4a62-87f1-b7c19114def3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132399193-172.17.0.11-1597402271041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-d77129cc-de0f-47d5-936a-232c6db2c78a,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-b95242e5-32d7-44f3-8b2e-d1a6c1106cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-ff4aba37-48fa-4faa-b8d2-597b4c2d9654,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-cd4d1ca2-85c5-434c-91ad-d7b6e9a9e2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-423082d6-ab4e-4c46-a401-3faae6ac0c14,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-a113da9e-0242-4361-baf9-36a784033e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-b7e92ca0-471a-40a4-a730-c89ca6e2e3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-852de4b1-6521-4a62-87f1-b7c19114def3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397704094-172.17.0.11-1597402421224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-f2c1b941-35e3-4697-acbe-5286b5fa408e,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-737d54b3-fe21-4ef8-9795-1fb3ad4dd528,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-9b0c0005-e75b-4c91-9923-8b1868059637,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-0b4cca14-5e8b-4f8c-8ff6-8d44504f261e,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-861c14ae-e972-4551-a0da-55cfdf3e9f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-fe78738c-65e7-42d0-9dd3-6c51c5dac728,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-992eaa11-7706-4add-8c58-5135421021b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-787699f2-f8c3-4ec2-bb78-b711288767d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397704094-172.17.0.11-1597402421224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-f2c1b941-35e3-4697-acbe-5286b5fa408e,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-737d54b3-fe21-4ef8-9795-1fb3ad4dd528,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-9b0c0005-e75b-4c91-9923-8b1868059637,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-0b4cca14-5e8b-4f8c-8ff6-8d44504f261e,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-861c14ae-e972-4551-a0da-55cfdf3e9f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-fe78738c-65e7-42d0-9dd3-6c51c5dac728,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-992eaa11-7706-4add-8c58-5135421021b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-787699f2-f8c3-4ec2-bb78-b711288767d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004946117-172.17.0.11-1597402974078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37019,DS-aa6678d0-779a-4371-b06a-0c322a983e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-cf114fe4-fa02-4f5f-ac96-1be70e590757,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-4137eca9-fec4-4278-a0ed-617c1ca2678f,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-d82917a9-6165-447b-b2d8-c709d05ea943,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-99de8424-73df-4c94-aa17-11bd9b74f633,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-d337b68d-c6b1-42e5-acde-fde4d4d6d785,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-5a9fb0b7-cb97-4e92-95a1-c2a4a63e3b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-0f83842c-aec8-433e-adef-3f795ce33c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2004946117-172.17.0.11-1597402974078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37019,DS-aa6678d0-779a-4371-b06a-0c322a983e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-cf114fe4-fa02-4f5f-ac96-1be70e590757,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-4137eca9-fec4-4278-a0ed-617c1ca2678f,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-d82917a9-6165-447b-b2d8-c709d05ea943,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-99de8424-73df-4c94-aa17-11bd9b74f633,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-d337b68d-c6b1-42e5-acde-fde4d4d6d785,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-5a9fb0b7-cb97-4e92-95a1-c2a4a63e3b11,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-0f83842c-aec8-433e-adef-3f795ce33c1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165107080-172.17.0.11-1597403017076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37663,DS-bffc2b38-c5dd-4d22-93b8-b37dfc0752ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-f9e9de1f-05c7-4bd2-b8ee-e432e675cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-4a4cd79e-3de2-4af1-9c4c-572921702180,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-c5324119-19af-440d-a90e-6feefd94371f,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-cf52bc6d-3b64-424d-943f-09926f3510e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-111671bb-d2db-4141-ba6e-1139ea7fb601,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-737d645c-3951-41ec-b405-0db5d80cfcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-ba9e7cd9-85d4-46cb-b289-a09abc5e2ff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165107080-172.17.0.11-1597403017076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37663,DS-bffc2b38-c5dd-4d22-93b8-b37dfc0752ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-f9e9de1f-05c7-4bd2-b8ee-e432e675cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-4a4cd79e-3de2-4af1-9c4c-572921702180,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-c5324119-19af-440d-a90e-6feefd94371f,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-cf52bc6d-3b64-424d-943f-09926f3510e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-111671bb-d2db-4141-ba6e-1139ea7fb601,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-737d645c-3951-41ec-b405-0db5d80cfcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-ba9e7cd9-85d4-46cb-b289-a09abc5e2ff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60140365-172.17.0.11-1597403113042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-0789d172-468b-491b-a8a5-9c6a92a2a001,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-366fb701-f5b0-49ac-a995-49bca3d5d415,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-1459dbb0-efab-4481-abf0-b8af5b957fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-4551a36d-1e9f-48f2-8975-45f5c96653a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-75c0e0d8-53cf-4afb-aeeb-77ac582e6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-69d25536-a8ef-4a3b-9ba3-ce1dc0962727,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-e8982192-86a8-4cd7-8edd-43e043ae5795,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-2b20d753-ef5a-49d8-8f64-f7b0538deb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60140365-172.17.0.11-1597403113042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-0789d172-468b-491b-a8a5-9c6a92a2a001,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-366fb701-f5b0-49ac-a995-49bca3d5d415,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-1459dbb0-efab-4481-abf0-b8af5b957fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-4551a36d-1e9f-48f2-8975-45f5c96653a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-75c0e0d8-53cf-4afb-aeeb-77ac582e6eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41184,DS-69d25536-a8ef-4a3b-9ba3-ce1dc0962727,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-e8982192-86a8-4cd7-8edd-43e043ae5795,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-2b20d753-ef5a-49d8-8f64-f7b0538deb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154274373-172.17.0.11-1597404270415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38649,DS-c6cd4048-77bf-4e77-a655-9fcfbbbec5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-043873de-5bd5-4770-8000-9a1ea8cc74d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-4364cb5f-d145-45cb-a940-375219eabd69,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-dd5f10eb-6d46-41cf-b659-e2cb946a4cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-cd5b7a1a-5a5d-467a-ab27-a1f6eefd9b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-c00f050e-8c1f-491d-9689-e317682dd4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-910ce66f-6b9a-4e88-a2f3-31536bea7781,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-b89fc888-3abf-4b79-b047-558240110895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154274373-172.17.0.11-1597404270415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38649,DS-c6cd4048-77bf-4e77-a655-9fcfbbbec5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-043873de-5bd5-4770-8000-9a1ea8cc74d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-4364cb5f-d145-45cb-a940-375219eabd69,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-dd5f10eb-6d46-41cf-b659-e2cb946a4cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-cd5b7a1a-5a5d-467a-ab27-a1f6eefd9b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-c00f050e-8c1f-491d-9689-e317682dd4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-910ce66f-6b9a-4e88-a2f3-31536bea7781,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-b89fc888-3abf-4b79-b047-558240110895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798236341-172.17.0.11-1597404696407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34482,DS-55308273-6be0-47be-a294-6a2cdc5b194b,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-dcc000b5-42e7-4228-a6b9-09589f9a3374,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-e34284fc-91ea-492e-a332-298eabf4e76b,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-2836dabe-044c-409a-8707-2ffc0630fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-ef240e9b-d588-4eca-bf5d-b70cf3f86c10,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-fedab97b-16bb-47ed-bf34-900a86013796,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-b8b3db56-df06-40bd-b788-745c0da27078,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-ad04a4e6-d839-4b0f-afec-008dbdb5e0f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798236341-172.17.0.11-1597404696407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34482,DS-55308273-6be0-47be-a294-6a2cdc5b194b,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-dcc000b5-42e7-4228-a6b9-09589f9a3374,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-e34284fc-91ea-492e-a332-298eabf4e76b,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-2836dabe-044c-409a-8707-2ffc0630fa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-ef240e9b-d588-4eca-bf5d-b70cf3f86c10,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-fedab97b-16bb-47ed-bf34-900a86013796,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-b8b3db56-df06-40bd-b788-745c0da27078,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-ad04a4e6-d839-4b0f-afec-008dbdb5e0f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 7165
