reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164368500-172.17.0.20-1597484842829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37197,DS-ab0e3c16-54c3-44d4-aef9-f98a6c40b0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-fc035fa2-5cef-4e82-b7d8-effe2b92bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-c1a8acfd-d0c6-4d5b-9b31-b6822bcca797,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-451cc02c-0c69-41b3-9d5e-974bd6664b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-4fa0e360-774c-4483-a08e-acdd03b592a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-824063b9-48df-482d-9950-25c3a12e633f,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-4514bd66-7f6a-4de5-9b53-5f2f4535b903,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-1ab63bca-598c-4c9b-a83f-26773f08bce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164368500-172.17.0.20-1597484842829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37197,DS-ab0e3c16-54c3-44d4-aef9-f98a6c40b0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-fc035fa2-5cef-4e82-b7d8-effe2b92bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-c1a8acfd-d0c6-4d5b-9b31-b6822bcca797,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-451cc02c-0c69-41b3-9d5e-974bd6664b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-4fa0e360-774c-4483-a08e-acdd03b592a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-824063b9-48df-482d-9950-25c3a12e633f,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-4514bd66-7f6a-4de5-9b53-5f2f4535b903,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-1ab63bca-598c-4c9b-a83f-26773f08bce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027260697-172.17.0.20-1597484917417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41875,DS-a85bc2d9-d5a6-47cf-bc25-25891c0d609d,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-77352344-030c-4ef4-9444-1c8d3f83c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-08f5fdb5-404a-4aa7-9b72-d88a89ddbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-51ea796a-52a2-4a1f-9aa0-73582fe9b12e,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-36eae969-dd4e-4295-b9bc-677fb78cb2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-d5a170a0-9b37-4258-989b-097196112427,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-27037e83-92c7-40d9-bdad-afbad012c592,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-8961ba84-0fc5-4ba6-bb93-8164dabea6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027260697-172.17.0.20-1597484917417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41875,DS-a85bc2d9-d5a6-47cf-bc25-25891c0d609d,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-77352344-030c-4ef4-9444-1c8d3f83c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-08f5fdb5-404a-4aa7-9b72-d88a89ddbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-51ea796a-52a2-4a1f-9aa0-73582fe9b12e,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-36eae969-dd4e-4295-b9bc-677fb78cb2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-d5a170a0-9b37-4258-989b-097196112427,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-27037e83-92c7-40d9-bdad-afbad012c592,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-8961ba84-0fc5-4ba6-bb93-8164dabea6a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060153830-172.17.0.20-1597485460914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-15e443cf-3a4a-45de-898a-27dd51888bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-db6bf472-d6f3-459b-8d4d-c50f3ae932e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-51b9d109-d087-4e45-8524-61925754b8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-94929c13-3b4d-43e6-8f50-fc7a5729adf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-09981dd1-9b6f-40f8-9f35-882ddaf82bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-f7ec7a04-41cb-48ac-9fbb-c7267bccfdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-eb9023ba-d56b-471c-b8f6-ebcec558e772,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-8ae5ea8a-4a15-48fa-bcef-d39affbabf7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060153830-172.17.0.20-1597485460914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-15e443cf-3a4a-45de-898a-27dd51888bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-db6bf472-d6f3-459b-8d4d-c50f3ae932e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-51b9d109-d087-4e45-8524-61925754b8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-94929c13-3b4d-43e6-8f50-fc7a5729adf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-09981dd1-9b6f-40f8-9f35-882ddaf82bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-f7ec7a04-41cb-48ac-9fbb-c7267bccfdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-eb9023ba-d56b-471c-b8f6-ebcec558e772,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-8ae5ea8a-4a15-48fa-bcef-d39affbabf7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373224497-172.17.0.20-1597486017781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37889,DS-8ceee9aa-9acf-450e-a41e-1376b39e08a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-85d2a5b9-38b5-43cc-ae63-dc7196cc384a,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-ba399a61-1969-4606-b430-c7673fbc3288,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-e36fe0ae-6351-4ea2-b891-771266064b16,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-caedbbd4-0b15-4a4e-893f-7aeb1fcd23fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-698a0c19-6211-490f-a025-05ce7a529a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-10ab9551-1ee3-422e-979c-f73d7d47010d,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-99795d6c-ae40-4cae-b52d-e2b0987b1e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373224497-172.17.0.20-1597486017781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37889,DS-8ceee9aa-9acf-450e-a41e-1376b39e08a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-85d2a5b9-38b5-43cc-ae63-dc7196cc384a,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-ba399a61-1969-4606-b430-c7673fbc3288,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-e36fe0ae-6351-4ea2-b891-771266064b16,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-caedbbd4-0b15-4a4e-893f-7aeb1fcd23fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-698a0c19-6211-490f-a025-05ce7a529a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-10ab9551-1ee3-422e-979c-f73d7d47010d,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-99795d6c-ae40-4cae-b52d-e2b0987b1e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664258610-172.17.0.20-1597487634509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-00d8d77c-42c9-4fcc-8f64-38f275861da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-b3a533bc-c6c4-4f2b-8197-e5c9db2e8eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-0cfffb98-5fb7-4bcf-8275-c3733905602f,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-0cfb9b8b-350e-4711-acae-9e2e3d2ed8df,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-38dbfdb8-89cb-4225-b9af-b465f096f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-afb5b002-0a87-49c9-bffb-264554b65090,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-808227f2-422a-4be9-b3c0-aaa2065d1a24,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-58914a8e-3566-4b71-9e15-b5eb43c435de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664258610-172.17.0.20-1597487634509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-00d8d77c-42c9-4fcc-8f64-38f275861da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-b3a533bc-c6c4-4f2b-8197-e5c9db2e8eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-0cfffb98-5fb7-4bcf-8275-c3733905602f,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-0cfb9b8b-350e-4711-acae-9e2e3d2ed8df,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-38dbfdb8-89cb-4225-b9af-b465f096f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-afb5b002-0a87-49c9-bffb-264554b65090,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-808227f2-422a-4be9-b3c0-aaa2065d1a24,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-58914a8e-3566-4b71-9e15-b5eb43c435de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277271793-172.17.0.20-1597487667554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-2d5364f1-f967-4d74-95c1-ab9ad2509701,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-eeb14b66-a297-4be8-9676-915c4a86b582,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-e249d407-9e8c-4e11-b9a6-14c05db33ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-4d32ad91-680d-4125-a9f9-54cfb3bbc6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-83448414-9a24-4181-9912-2846b14f387e,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-da403e0f-8b8a-47b0-a04b-1d030c79483c,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-c874bba2-30c4-493e-961e-af55280e6699,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-b9bf1042-6148-4565-ac8e-da80eea7741b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277271793-172.17.0.20-1597487667554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-2d5364f1-f967-4d74-95c1-ab9ad2509701,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-eeb14b66-a297-4be8-9676-915c4a86b582,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-e249d407-9e8c-4e11-b9a6-14c05db33ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-4d32ad91-680d-4125-a9f9-54cfb3bbc6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-83448414-9a24-4181-9912-2846b14f387e,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-da403e0f-8b8a-47b0-a04b-1d030c79483c,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-c874bba2-30c4-493e-961e-af55280e6699,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-b9bf1042-6148-4565-ac8e-da80eea7741b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912501189-172.17.0.20-1597487885396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-9a3e28a5-c1eb-4ab3-9b8e-e6e5a9863171,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-953c890e-898c-47ca-9206-90a1e3f3b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b6dd87ad-460a-43c7-97d4-d1cd3fcbbe36,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-4a1c4dca-69fc-4884-8886-58a2c707a275,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-f96440c0-b3bc-4407-9b96-27907da3c7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-21744e73-0b8c-4359-9830-fbff111b9309,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-f03a0c99-3c70-456d-b9ba-506ab3343cce,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-a115a1ae-5d85-4663-a799-6864ab40768e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912501189-172.17.0.20-1597487885396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-9a3e28a5-c1eb-4ab3-9b8e-e6e5a9863171,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-953c890e-898c-47ca-9206-90a1e3f3b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b6dd87ad-460a-43c7-97d4-d1cd3fcbbe36,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-4a1c4dca-69fc-4884-8886-58a2c707a275,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-f96440c0-b3bc-4407-9b96-27907da3c7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-21744e73-0b8c-4359-9830-fbff111b9309,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-f03a0c99-3c70-456d-b9ba-506ab3343cce,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-a115a1ae-5d85-4663-a799-6864ab40768e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758200054-172.17.0.20-1597488909943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41444,DS-d9fa92cb-132d-4131-b2de-5c25a59fdc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-8d124dc3-139d-4dce-9c35-c19df2426439,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-e692db09-fd6c-4f78-9aa8-61f0e58c1e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-80ed8d15-6ade-444e-be1d-66fcef1a4a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-31764342-fc56-4d31-8341-ef0defe87423,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-ab8eb9e7-3acd-4f19-bf43-0f3e53c97897,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-a7fde4e6-0691-4985-8bdb-2057fdce6274,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-bfe36368-a38e-4858-b70e-edd16b457c2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758200054-172.17.0.20-1597488909943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41444,DS-d9fa92cb-132d-4131-b2de-5c25a59fdc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-8d124dc3-139d-4dce-9c35-c19df2426439,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-e692db09-fd6c-4f78-9aa8-61f0e58c1e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-80ed8d15-6ade-444e-be1d-66fcef1a4a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-31764342-fc56-4d31-8341-ef0defe87423,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-ab8eb9e7-3acd-4f19-bf43-0f3e53c97897,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-a7fde4e6-0691-4985-8bdb-2057fdce6274,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-bfe36368-a38e-4858-b70e-edd16b457c2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053600830-172.17.0.20-1597489713417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43011,DS-de256853-72a0-41dd-b1c7-a56246cf9a85,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-4cbf9524-4eef-43ae-abe7-d7bac7d0a6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-51706aef-6c12-4713-8a87-4c215c9b3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-4d07a805-9f9f-4487-a304-c533cc06fac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-d841af0c-9e11-4b84-8b20-3b883cb33fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-6bd9a06f-98c0-44d1-8dec-027f373f4b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-7f3e18af-dc77-4e54-8953-419c9d603834,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-47c2c108-0748-4d8a-a68d-d5f07b9a496a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053600830-172.17.0.20-1597489713417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43011,DS-de256853-72a0-41dd-b1c7-a56246cf9a85,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-4cbf9524-4eef-43ae-abe7-d7bac7d0a6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-51706aef-6c12-4713-8a87-4c215c9b3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-4d07a805-9f9f-4487-a304-c533cc06fac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-d841af0c-9e11-4b84-8b20-3b883cb33fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-6bd9a06f-98c0-44d1-8dec-027f373f4b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-7f3e18af-dc77-4e54-8953-419c9d603834,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-47c2c108-0748-4d8a-a68d-d5f07b9a496a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505096009-172.17.0.20-1597490278010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-05445e70-3eec-449e-a9b8-08385ec157ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-e2231477-9313-4b1c-a5f7-784129018385,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-f7b7144b-f7c6-4964-bda3-9793158c6889,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-0e942260-47e1-4e1f-a0f9-c96929f6cc97,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-d4500564-e4b3-4022-86b9-60781a52354f,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-9565451c-e03a-492f-879f-9876c0a14d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-20774cec-6a5a-4b68-807e-e365bd4eed99,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-7f0b1a55-eebf-4605-8b73-e4ef68a4847a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505096009-172.17.0.20-1597490278010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-05445e70-3eec-449e-a9b8-08385ec157ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-e2231477-9313-4b1c-a5f7-784129018385,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-f7b7144b-f7c6-4964-bda3-9793158c6889,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-0e942260-47e1-4e1f-a0f9-c96929f6cc97,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-d4500564-e4b3-4022-86b9-60781a52354f,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-9565451c-e03a-492f-879f-9876c0a14d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-20774cec-6a5a-4b68-807e-e365bd4eed99,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-7f0b1a55-eebf-4605-8b73-e4ef68a4847a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5554
