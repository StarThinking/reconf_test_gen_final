reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836359233-172.17.0.8-1597483341321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38004,DS-f67de23e-1ecc-48fc-9f6e-11661afe92d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-1ffd1eef-6745-4200-b88d-c3e76201b2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-586cc787-03af-4ec5-873b-581906ffefea,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-89f9362f-c0ce-4e1b-a2ee-bbad9108e0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-b1ccb90d-b22b-411b-a5f1-f5f10abf5e42,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-49e1fafb-766c-4cf0-93c6-25c863f03f08,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-aec0e353-fbcf-4554-b3d8-37630f14358f,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-275f8f47-bc0a-456c-9041-c50e7e097211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836359233-172.17.0.8-1597483341321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38004,DS-f67de23e-1ecc-48fc-9f6e-11661afe92d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-1ffd1eef-6745-4200-b88d-c3e76201b2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-586cc787-03af-4ec5-873b-581906ffefea,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-89f9362f-c0ce-4e1b-a2ee-bbad9108e0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-b1ccb90d-b22b-411b-a5f1-f5f10abf5e42,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-49e1fafb-766c-4cf0-93c6-25c863f03f08,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-aec0e353-fbcf-4554-b3d8-37630f14358f,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-275f8f47-bc0a-456c-9041-c50e7e097211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252820965-172.17.0.8-1597483648011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36945,DS-6f971b24-f486-4ed8-b335-f884f21e4acd,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-9dba8b4a-34ff-49c5-accb-53a59bdab9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-84a4f2a9-6930-4bea-ab1f-bd244c74fc83,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-7fb805da-db40-4b7a-9e19-0e37c3616627,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-7b725904-3c7c-4d52-8b16-3031604ab250,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-a7a76ff4-55fc-4441-8cf1-8303b2bff783,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-0a1cf369-b314-4ad3-80fe-3f6fd5d25782,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-26573056-d7fb-4a27-a229-55249e4cdde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252820965-172.17.0.8-1597483648011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36945,DS-6f971b24-f486-4ed8-b335-f884f21e4acd,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-9dba8b4a-34ff-49c5-accb-53a59bdab9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-84a4f2a9-6930-4bea-ab1f-bd244c74fc83,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-7fb805da-db40-4b7a-9e19-0e37c3616627,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-7b725904-3c7c-4d52-8b16-3031604ab250,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-a7a76ff4-55fc-4441-8cf1-8303b2bff783,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-0a1cf369-b314-4ad3-80fe-3f6fd5d25782,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-26573056-d7fb-4a27-a229-55249e4cdde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758554452-172.17.0.8-1597483774061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-1e3fd75d-61bc-4774-9dd0-a4918fa424ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-d3aa8299-0b5e-4fd2-a8f5-d8056683e990,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-2dc2c136-6516-446e-b9fa-373658e98466,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-822fc955-6531-45ac-8eb4-4b5a97a3fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-f5ccb057-fc48-48b6-845b-c3edb63966d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-fe861ae4-feb6-4070-b03d-1d9956f04045,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-cb35896e-ad57-4c98-88ad-a72d5f54570b,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-7fd8fd61-7a0b-40b6-ad1d-c7a9dd654418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-758554452-172.17.0.8-1597483774061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45478,DS-1e3fd75d-61bc-4774-9dd0-a4918fa424ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-d3aa8299-0b5e-4fd2-a8f5-d8056683e990,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-2dc2c136-6516-446e-b9fa-373658e98466,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-822fc955-6531-45ac-8eb4-4b5a97a3fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-f5ccb057-fc48-48b6-845b-c3edb63966d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-fe861ae4-feb6-4070-b03d-1d9956f04045,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-cb35896e-ad57-4c98-88ad-a72d5f54570b,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-7fd8fd61-7a0b-40b6-ad1d-c7a9dd654418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854784824-172.17.0.8-1597484078521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42814,DS-b9c21a2f-d174-47be-8eab-9cb12a62d835,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-52312682-0eb9-40a2-95e8-7329b772ce53,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-3903069f-3f69-4f47-8423-68f7ee7490f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-57198ed5-e44f-4662-ab7e-e294b7bf7556,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-e786941d-b1fa-49f5-9454-4ffaa12a8fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-362cbadb-4ff9-47b9-a280-62cdd525b08b,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-b4a54acb-cbac-4960-aaf1-24a46170034f,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-4990bed8-fe48-44b4-b2c0-984700b1cbcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854784824-172.17.0.8-1597484078521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42814,DS-b9c21a2f-d174-47be-8eab-9cb12a62d835,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-52312682-0eb9-40a2-95e8-7329b772ce53,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-3903069f-3f69-4f47-8423-68f7ee7490f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-57198ed5-e44f-4662-ab7e-e294b7bf7556,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-e786941d-b1fa-49f5-9454-4ffaa12a8fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-362cbadb-4ff9-47b9-a280-62cdd525b08b,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-b4a54acb-cbac-4960-aaf1-24a46170034f,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-4990bed8-fe48-44b4-b2c0-984700b1cbcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162047412-172.17.0.8-1597484274528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-ec28caaf-328b-4e36-9c33-d05539ff7758,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-b7e8b3ee-548c-4d82-82d4-aaa4ab328a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-abe5a3a4-fd0b-44c0-852d-3d15d9352886,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-9b7b09bf-7936-4bf5-bccc-4062e6242ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-d668bd9c-906e-4f72-95b4-46ca1e4aee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-374dfd0f-8bee-42d7-bdc8-355827223a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-93391d48-c143-422e-a775-0e6249178cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-2d581412-bbe2-4641-9396-ce8953bccd06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162047412-172.17.0.8-1597484274528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42800,DS-ec28caaf-328b-4e36-9c33-d05539ff7758,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-b7e8b3ee-548c-4d82-82d4-aaa4ab328a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-abe5a3a4-fd0b-44c0-852d-3d15d9352886,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-9b7b09bf-7936-4bf5-bccc-4062e6242ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-d668bd9c-906e-4f72-95b4-46ca1e4aee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-374dfd0f-8bee-42d7-bdc8-355827223a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-93391d48-c143-422e-a775-0e6249178cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-2d581412-bbe2-4641-9396-ce8953bccd06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726958911-172.17.0.8-1597484319614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-2f4d853c-7ac6-474c-8034-02140ee47da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-a575c75a-c84d-4a6d-a191-3aebed13999e,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-2517c7ae-3c0a-4ce3-aff3-546488b3b8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-1d13ef7e-4aaf-4b84-8684-102be6ff3fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-270054d6-c18c-4c1c-86c2-9e24c1c9fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-ccecf152-08db-4253-b80b-5483983ca682,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-ee84437e-8fba-4dd4-b4dd-070565dcdc58,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-dac50f9a-7038-4583-9982-e00042616dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726958911-172.17.0.8-1597484319614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40240,DS-2f4d853c-7ac6-474c-8034-02140ee47da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-a575c75a-c84d-4a6d-a191-3aebed13999e,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-2517c7ae-3c0a-4ce3-aff3-546488b3b8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-1d13ef7e-4aaf-4b84-8684-102be6ff3fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-270054d6-c18c-4c1c-86c2-9e24c1c9fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-ccecf152-08db-4253-b80b-5483983ca682,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-ee84437e-8fba-4dd4-b4dd-070565dcdc58,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-dac50f9a-7038-4583-9982-e00042616dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756132241-172.17.0.8-1597484409051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-fd9d9a55-6346-4506-8757-601f8417359e,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-8d498f3b-aa3f-4fcd-8ef0-8e2c88f4fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-f3d47235-aab1-458d-b1b5-c1e27e6291fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-5aaf62f7-ca21-4372-979f-797337be6b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-6f009f22-49d1-423e-b2c6-dc2f3b1ac12e,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-5ec1aee4-71cb-4dcf-9708-9bf2bda945bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-632bd78c-3f8e-45c7-8e56-b590bc354826,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-742a120d-0ff5-4e35-bb2e-81f709fbb828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756132241-172.17.0.8-1597484409051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43073,DS-fd9d9a55-6346-4506-8757-601f8417359e,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-8d498f3b-aa3f-4fcd-8ef0-8e2c88f4fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-f3d47235-aab1-458d-b1b5-c1e27e6291fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-5aaf62f7-ca21-4372-979f-797337be6b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-6f009f22-49d1-423e-b2c6-dc2f3b1ac12e,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-5ec1aee4-71cb-4dcf-9708-9bf2bda945bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-632bd78c-3f8e-45c7-8e56-b590bc354826,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-742a120d-0ff5-4e35-bb2e-81f709fbb828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031078818-172.17.0.8-1597484525632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39126,DS-160fdde9-823c-4be8-b57c-bb8b919c3d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-a35ccfad-f263-4ae9-ae66-bfbce6af238f,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-fb19fff7-f03e-406b-a57c-f1296d736d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-79641a3b-1b53-42ba-8bdd-3ab4e892a3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-a30a5c73-99a2-42a5-a4dd-2d721e0c96cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-5cee08ba-d338-4fc3-b1a4-0e10e91dbf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-85d32a58-b697-49f7-a900-4e665594751e,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-9810e43f-5328-4b8c-923a-68bb722b5087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031078818-172.17.0.8-1597484525632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39126,DS-160fdde9-823c-4be8-b57c-bb8b919c3d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-a35ccfad-f263-4ae9-ae66-bfbce6af238f,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-fb19fff7-f03e-406b-a57c-f1296d736d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-79641a3b-1b53-42ba-8bdd-3ab4e892a3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-a30a5c73-99a2-42a5-a4dd-2d721e0c96cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-5cee08ba-d338-4fc3-b1a4-0e10e91dbf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-85d32a58-b697-49f7-a900-4e665594751e,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-9810e43f-5328-4b8c-923a-68bb722b5087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186815800-172.17.0.8-1597484824797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-9fb673d0-9b44-4bd4-9d94-d24402bb6b21,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-1d0c2ad0-d122-4b96-b2a3-53b61e945b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-70addfe8-a62e-4eb7-b0b0-3281ffe7eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-a0c045f8-ecd5-472a-ab05-c05ce3f2a230,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-c349663e-da62-4757-86f5-72c3ef7fbbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-c8c39634-95ef-47f8-821c-afe56e4a2ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-2ef14951-9c78-48f5-972e-9656eb421715,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-fb69fabb-218a-4b5d-964a-b35b8c51584c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-186815800-172.17.0.8-1597484824797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-9fb673d0-9b44-4bd4-9d94-d24402bb6b21,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-1d0c2ad0-d122-4b96-b2a3-53b61e945b62,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-70addfe8-a62e-4eb7-b0b0-3281ffe7eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-a0c045f8-ecd5-472a-ab05-c05ce3f2a230,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-c349663e-da62-4757-86f5-72c3ef7fbbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40078,DS-c8c39634-95ef-47f8-821c-afe56e4a2ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-2ef14951-9c78-48f5-972e-9656eb421715,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-fb69fabb-218a-4b5d-964a-b35b8c51584c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854132161-172.17.0.8-1597484901876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-c5d21220-efcb-4221-80d4-9ed3110f9b58,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-302bf350-92ce-4807-9aa8-b4a992801a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-94f81165-fd26-4d7c-ae30-606aeea5591a,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-c35e42b2-a15f-4322-a5d6-949b00107f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-fb96b6cb-04e9-4de5-a9cb-de2d82dec16e,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-050be871-e9b5-4f7d-89ab-fcb31214aca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-428a0877-5ea4-46d9-a6a6-ae9ce7226104,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-21ba401b-9bf1-45ac-aff8-a990b793fba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854132161-172.17.0.8-1597484901876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-c5d21220-efcb-4221-80d4-9ed3110f9b58,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-302bf350-92ce-4807-9aa8-b4a992801a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-94f81165-fd26-4d7c-ae30-606aeea5591a,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-c35e42b2-a15f-4322-a5d6-949b00107f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-fb96b6cb-04e9-4de5-a9cb-de2d82dec16e,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-050be871-e9b5-4f7d-89ab-fcb31214aca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-428a0877-5ea4-46d9-a6a6-ae9ce7226104,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-21ba401b-9bf1-45ac-aff8-a990b793fba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322901329-172.17.0.8-1597485525771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-07ef03f5-f692-415a-8bf7-13ebd122e498,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-d9c52360-6e91-4fda-95a2-351bcda56778,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-d70bccdc-1551-4e67-8c66-5a6255b5f309,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-b230fdf0-35e3-4fd1-bfb6-a6a8503f385f,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-d6ec70f2-ed71-4fba-b83d-a3bef203ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-f0dab355-0ff9-4488-81da-e73b3552b104,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-828940c9-5a81-4923-b6fa-50023a811e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-3a82326e-d4d5-4be7-8cf8-d2a8056a4552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322901329-172.17.0.8-1597485525771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-07ef03f5-f692-415a-8bf7-13ebd122e498,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-d9c52360-6e91-4fda-95a2-351bcda56778,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-d70bccdc-1551-4e67-8c66-5a6255b5f309,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-b230fdf0-35e3-4fd1-bfb6-a6a8503f385f,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-d6ec70f2-ed71-4fba-b83d-a3bef203ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-f0dab355-0ff9-4488-81da-e73b3552b104,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-828940c9-5a81-4923-b6fa-50023a811e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-3a82326e-d4d5-4be7-8cf8-d2a8056a4552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584359880-172.17.0.8-1597485809379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-12f91518-fb3b-49ad-9f32-607c5864e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-d1cea91e-6e02-4f1b-bb11-95762b2aeb36,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-582933ac-ae28-4199-8fd4-7d3b1a14044b,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-416faf02-3f17-4f6e-81e8-8295284a3d56,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-11b57ef1-2ba6-4946-95a7-8c58f4eca18b,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-4cb2d963-0517-45cd-a626-32edc9b641d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-b42710bd-283f-411d-b69d-18213e7b6629,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-6b88d585-c4ea-40fe-bc63-a12b05f43af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584359880-172.17.0.8-1597485809379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-12f91518-fb3b-49ad-9f32-607c5864e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-d1cea91e-6e02-4f1b-bb11-95762b2aeb36,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-582933ac-ae28-4199-8fd4-7d3b1a14044b,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-416faf02-3f17-4f6e-81e8-8295284a3d56,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-11b57ef1-2ba6-4946-95a7-8c58f4eca18b,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-4cb2d963-0517-45cd-a626-32edc9b641d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-b42710bd-283f-411d-b69d-18213e7b6629,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-6b88d585-c4ea-40fe-bc63-a12b05f43af1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190538941-172.17.0.8-1597486205102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-ada496cc-9b16-44ed-8ed2-0ce698efa9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-67f1c198-7b30-471b-aa5e-5c6ee1cb5c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-b7c04837-b957-4eca-a24c-bba66d35003f,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-2d88a4a2-072b-4918-b50a-2bed63310809,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-0b0405a0-80dc-46c0-b324-ccfe0e2ecc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-7ab93883-ff68-40fd-bc2b-a72ce8844914,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-a207d2cd-9451-421c-9a4b-d6b568e787ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-c8c3b6d0-f2eb-4492-9b09-32acacda08cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190538941-172.17.0.8-1597486205102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-ada496cc-9b16-44ed-8ed2-0ce698efa9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-67f1c198-7b30-471b-aa5e-5c6ee1cb5c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-b7c04837-b957-4eca-a24c-bba66d35003f,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-2d88a4a2-072b-4918-b50a-2bed63310809,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-0b0405a0-80dc-46c0-b324-ccfe0e2ecc33,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-7ab93883-ff68-40fd-bc2b-a72ce8844914,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-a207d2cd-9451-421c-9a4b-d6b568e787ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-c8c3b6d0-f2eb-4492-9b09-32acacda08cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264785716-172.17.0.8-1597486247144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-6a843d48-f523-425a-ae96-a9cbbd4453ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-1030c71e-b825-4817-bbac-4bdcfc0c2243,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-906f1705-20b8-4fd8-8106-c8b098b8e345,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-200111ab-e29d-4001-9947-e6493e6b4c01,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-ad824cf9-e9ff-4a07-807f-6dd7471edbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-cefef046-3998-40dc-bee7-986268c21063,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-ab241bd1-162c-42cc-82c0-2ce7424f57c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-3e966428-be11-4b7d-a3f4-bfe70bc5cf1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264785716-172.17.0.8-1597486247144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-6a843d48-f523-425a-ae96-a9cbbd4453ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-1030c71e-b825-4817-bbac-4bdcfc0c2243,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-906f1705-20b8-4fd8-8106-c8b098b8e345,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-200111ab-e29d-4001-9947-e6493e6b4c01,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-ad824cf9-e9ff-4a07-807f-6dd7471edbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-cefef046-3998-40dc-bee7-986268c21063,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-ab241bd1-162c-42cc-82c0-2ce7424f57c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-3e966428-be11-4b7d-a3f4-bfe70bc5cf1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962290763-172.17.0.8-1597486456054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39219,DS-3c11c23e-8c44-44cd-8266-c9af0cf531e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-53c78b8e-e449-48d5-82eb-51fa01366880,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-18df0656-c136-42da-a938-7e4e31042eec,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-7e5a3d04-903c-4216-a91e-df69e3d34a71,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-78d14b52-65cb-4214-86f7-a711669f9b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-21d5b65b-5be8-4e63-aefa-ed8a6f9e2a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-a54d32a5-8ef2-4852-abfa-7584e1e9fd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-8cf7dfb8-535e-47bd-811a-cbf06ca12a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962290763-172.17.0.8-1597486456054:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39219,DS-3c11c23e-8c44-44cd-8266-c9af0cf531e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-53c78b8e-e449-48d5-82eb-51fa01366880,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-18df0656-c136-42da-a938-7e4e31042eec,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-7e5a3d04-903c-4216-a91e-df69e3d34a71,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-78d14b52-65cb-4214-86f7-a711669f9b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-21d5b65b-5be8-4e63-aefa-ed8a6f9e2a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-a54d32a5-8ef2-4852-abfa-7584e1e9fd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-8cf7dfb8-535e-47bd-811a-cbf06ca12a1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188643271-172.17.0.8-1597487136286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-b258d4c2-5e09-41b2-88ff-6c74bf382f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-0ee8ae74-7b41-44de-b681-643c4b350485,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-2305a45e-e604-487b-9213-0a61a50e282c,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-49fe9ca1-4767-429a-9778-8b9e18eb540d,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-2177f0c5-6ab0-4faf-b6e2-01199f09c48d,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-a24de4f8-e14e-43f7-8bc9-21589b7e5aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-085028f0-b2a1-4be9-878f-e371ed8307d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-7f0776ca-7683-44da-9f59-5adc0fcc6eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188643271-172.17.0.8-1597487136286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-b258d4c2-5e09-41b2-88ff-6c74bf382f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-0ee8ae74-7b41-44de-b681-643c4b350485,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-2305a45e-e604-487b-9213-0a61a50e282c,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-49fe9ca1-4767-429a-9778-8b9e18eb540d,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-2177f0c5-6ab0-4faf-b6e2-01199f09c48d,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-a24de4f8-e14e-43f7-8bc9-21589b7e5aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-085028f0-b2a1-4be9-878f-e371ed8307d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-7f0776ca-7683-44da-9f59-5adc0fcc6eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785464236-172.17.0.8-1597487453726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33787,DS-aa702921-49e9-42da-9573-9fa69bb68a41,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-4445999d-46b2-489c-91d0-30c9f93b67b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-fc75dd69-cddf-4de4-928b-33bbeb873105,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-ab7b193f-a816-4834-9595-608bf75a7eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-300d18c2-f3c4-4e5c-9824-cceb9b267aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-a981753a-1302-4699-aa86-cfaeaa035dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-0391d125-8dfb-4afa-8f67-b2dcfee9243b,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-2b406d45-af5a-4de8-a43b-a3a67f61745f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785464236-172.17.0.8-1597487453726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33787,DS-aa702921-49e9-42da-9573-9fa69bb68a41,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-4445999d-46b2-489c-91d0-30c9f93b67b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-fc75dd69-cddf-4de4-928b-33bbeb873105,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-ab7b193f-a816-4834-9595-608bf75a7eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-300d18c2-f3c4-4e5c-9824-cceb9b267aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-a981753a-1302-4699-aa86-cfaeaa035dff,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-0391d125-8dfb-4afa-8f67-b2dcfee9243b,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-2b406d45-af5a-4de8-a43b-a3a67f61745f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416564224-172.17.0.8-1597487566350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-7d742f2e-b72f-4358-b443-9caa74f60acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-7b956498-2870-4654-a1fc-93e4b0009a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-1552b8e5-6c3b-43f6-8e71-2da4f8b144b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-cba44310-85bb-45af-a0db-292d352d18e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-9d3fa33e-d717-4f4c-a06e-81a35568947c,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-7a5080b0-ce25-4e5f-8958-95fbe810cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-87d2758f-e78e-40b2-aca7-3928bb641fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-0f9c84b5-f781-4b6e-be9f-df5385bb1338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416564224-172.17.0.8-1597487566350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-7d742f2e-b72f-4358-b443-9caa74f60acd,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-7b956498-2870-4654-a1fc-93e4b0009a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-1552b8e5-6c3b-43f6-8e71-2da4f8b144b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-cba44310-85bb-45af-a0db-292d352d18e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-9d3fa33e-d717-4f4c-a06e-81a35568947c,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-7a5080b0-ce25-4e5f-8958-95fbe810cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-87d2758f-e78e-40b2-aca7-3928bb641fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-0f9c84b5-f781-4b6e-be9f-df5385bb1338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663440775-172.17.0.8-1597488145090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43381,DS-bc006984-1eae-430f-b859-d12d95d6f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-6bf0e850-970a-4416-86aa-96339568457c,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-73436535-33af-4f6e-bf42-4bebef13d296,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-e2eb44b3-8d5a-4c85-85e1-30211fdcb3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-bd85de0b-709b-4735-947b-5fcfdfe895a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-7b8f03dd-26d6-4ce0-8396-6a52a449a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-c743df60-b730-49cf-aefa-29a99a9bbdee,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-14cc98a9-c4d9-41fe-ae56-1305f7aaeb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663440775-172.17.0.8-1597488145090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43381,DS-bc006984-1eae-430f-b859-d12d95d6f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-6bf0e850-970a-4416-86aa-96339568457c,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-73436535-33af-4f6e-bf42-4bebef13d296,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-e2eb44b3-8d5a-4c85-85e1-30211fdcb3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-bd85de0b-709b-4735-947b-5fcfdfe895a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-7b8f03dd-26d6-4ce0-8396-6a52a449a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-c743df60-b730-49cf-aefa-29a99a9bbdee,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-14cc98a9-c4d9-41fe-ae56-1305f7aaeb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000772566-172.17.0.8-1597488882318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33801,DS-25673668-0d3a-461d-bcbc-1f1835ff2c76,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-6cfce3ec-50ac-423b-9abf-d3e18059c676,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-601dce34-280d-4b31-86ec-c2c07acc7b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-fa91940c-065e-4d34-8ae4-bd0ad4601334,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-47fdbf0c-c89d-44c9-b637-4c26f3d06529,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-b0740125-8972-4ac9-bf62-e04761d7d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-ec44ad89-f152-4cf6-b8f3-a8a574aeefbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-34126f94-ecb2-421f-b3c0-5110d5661829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000772566-172.17.0.8-1597488882318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33801,DS-25673668-0d3a-461d-bcbc-1f1835ff2c76,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-6cfce3ec-50ac-423b-9abf-d3e18059c676,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-601dce34-280d-4b31-86ec-c2c07acc7b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-fa91940c-065e-4d34-8ae4-bd0ad4601334,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-47fdbf0c-c89d-44c9-b637-4c26f3d06529,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-b0740125-8972-4ac9-bf62-e04761d7d8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-ec44ad89-f152-4cf6-b8f3-a8a574aeefbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-34126f94-ecb2-421f-b3c0-5110d5661829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394950415-172.17.0.8-1597488956657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36794,DS-bc97436f-1e03-4ce5-af71-4f9c0ca20e83,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-b2d18ff1-b267-49ce-9028-d7d7e6bbfe44,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-fa006d43-fd99-4798-afe6-82def83b9a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-b5519938-9457-4ae9-b812-a3c2fd17a0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-4cb7b1a6-a936-4c9c-9f70-f9980b30f708,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-36a6e8bd-ccd7-46c1-bc25-0d2c02c91e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-1ce6c23e-a12a-4ecc-8f54-bc4078286c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-3efb411c-01ff-4e21-b577-3420ef1c08f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394950415-172.17.0.8-1597488956657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36794,DS-bc97436f-1e03-4ce5-af71-4f9c0ca20e83,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-b2d18ff1-b267-49ce-9028-d7d7e6bbfe44,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-fa006d43-fd99-4798-afe6-82def83b9a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-b5519938-9457-4ae9-b812-a3c2fd17a0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-4cb7b1a6-a936-4c9c-9f70-f9980b30f708,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-36a6e8bd-ccd7-46c1-bc25-0d2c02c91e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-1ce6c23e-a12a-4ecc-8f54-bc4078286c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-3efb411c-01ff-4e21-b577-3420ef1c08f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6035
