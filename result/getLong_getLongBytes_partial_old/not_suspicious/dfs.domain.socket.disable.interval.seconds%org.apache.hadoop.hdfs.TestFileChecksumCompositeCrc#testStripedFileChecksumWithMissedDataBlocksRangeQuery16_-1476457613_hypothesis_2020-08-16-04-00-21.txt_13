reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110216727-172.17.0.12-1597550434026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42440,DS-96abe0c4-4b03-4356-8966-5f22933d9aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-e3ec464e-5c15-4889-b666-1d3bd6530b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-7027917f-8403-4a44-bc77-da9cbc3dd5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-da0aa79b-1cd6-4992-b26d-c653f5dbe420,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-812a042f-99a9-418f-b436-63d879112132,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-3d515328-6177-4b2d-997a-0aeba3fc3bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-1eb9fd76-b58d-4fc9-9ad5-4ec164b04221,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-41d960ef-03d6-4298-9992-aeba8a89d95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1110216727-172.17.0.12-1597550434026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42440,DS-96abe0c4-4b03-4356-8966-5f22933d9aff,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-e3ec464e-5c15-4889-b666-1d3bd6530b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-7027917f-8403-4a44-bc77-da9cbc3dd5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-da0aa79b-1cd6-4992-b26d-c653f5dbe420,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-812a042f-99a9-418f-b436-63d879112132,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-3d515328-6177-4b2d-997a-0aeba3fc3bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-1eb9fd76-b58d-4fc9-9ad5-4ec164b04221,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-41d960ef-03d6-4298-9992-aeba8a89d95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668076286-172.17.0.12-1597551036964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37180,DS-93f6ced0-7c7e-46c3-865e-5e6df642be5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-41f92bb5-2127-4f79-abd5-db5876cc0982,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-84a688ef-9277-4da6-a3b6-32f93adbe446,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-c8501556-5f5d-4ccf-9757-ba6a8bcf8578,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-dc9bf8af-ac23-4fcb-b655-db0ad674c683,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-938c7d57-1e88-45b8-b6e5-4528cdb5b208,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-78ce89f4-c272-4103-b615-ad8da37beabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-29c381ad-5fa9-4a8b-936a-222cb99b1fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668076286-172.17.0.12-1597551036964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37180,DS-93f6ced0-7c7e-46c3-865e-5e6df642be5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-41f92bb5-2127-4f79-abd5-db5876cc0982,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-84a688ef-9277-4da6-a3b6-32f93adbe446,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-c8501556-5f5d-4ccf-9757-ba6a8bcf8578,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-dc9bf8af-ac23-4fcb-b655-db0ad674c683,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-938c7d57-1e88-45b8-b6e5-4528cdb5b208,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-78ce89f4-c272-4103-b615-ad8da37beabd,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-29c381ad-5fa9-4a8b-936a-222cb99b1fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235729491-172.17.0.12-1597551110032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44355,DS-569f2d8d-2af1-4870-acad-ba2696a80598,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-c1105a85-4c3d-46be-b885-6f2c3df55eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-35a6046b-73bd-48da-b9c1-e6b2f71138f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-cb9bab2f-7f55-499d-b53e-63a8fe4bbf38,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-2ffbe4b6-9609-499a-a894-a7e0c98f9e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-7d6a8420-f9d7-4a4c-9976-31dfac107c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-4c35cfa1-84a0-4ac4-9b79-cc11380bca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-fca50905-36eb-418e-b836-a7a1f6956ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235729491-172.17.0.12-1597551110032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44355,DS-569f2d8d-2af1-4870-acad-ba2696a80598,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-c1105a85-4c3d-46be-b885-6f2c3df55eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-35a6046b-73bd-48da-b9c1-e6b2f71138f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-cb9bab2f-7f55-499d-b53e-63a8fe4bbf38,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-2ffbe4b6-9609-499a-a894-a7e0c98f9e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-7d6a8420-f9d7-4a4c-9976-31dfac107c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-4c35cfa1-84a0-4ac4-9b79-cc11380bca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-fca50905-36eb-418e-b836-a7a1f6956ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093125300-172.17.0.12-1597551192570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42279,DS-90694166-13eb-4d8f-87cd-790e467e988c,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-4419ea1b-4ef1-44df-929f-94f77659dd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-2c458a99-23b9-4384-b83f-31d238767db8,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-976dac31-87ed-4dc3-a006-89fe9d9302fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-ec4f1b10-8f2d-4de8-9ad5-b626d946a18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-bc1c76e9-9b62-4e78-9598-02680375d0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-4759c06a-e726-48fd-b834-bb033212e9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-97bdf522-ad2c-4309-8045-e68cb1e0e35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093125300-172.17.0.12-1597551192570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42279,DS-90694166-13eb-4d8f-87cd-790e467e988c,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-4419ea1b-4ef1-44df-929f-94f77659dd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-2c458a99-23b9-4384-b83f-31d238767db8,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-976dac31-87ed-4dc3-a006-89fe9d9302fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-ec4f1b10-8f2d-4de8-9ad5-b626d946a18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-bc1c76e9-9b62-4e78-9598-02680375d0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-4759c06a-e726-48fd-b834-bb033212e9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-97bdf522-ad2c-4309-8045-e68cb1e0e35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921390266-172.17.0.12-1597551449020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-cd70b162-b41c-4306-bb1f-182c962222ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-30f30d71-2d91-461a-a398-a56ff1ddecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-85b772d5-1c7a-4bdd-848c-8e0b22bda17b,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-140a1cfd-3b0a-4fec-af0f-0cbc12f7c86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-922fd523-9311-4ee4-8d16-1584b801bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8d576db1-9749-4993-b5b4-cab56d4ac7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-58b26430-c3e4-42d4-9f9c-26180d0cbcad,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-5a0d08e7-a24f-43e0-bf89-4a46acceda99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921390266-172.17.0.12-1597551449020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44043,DS-cd70b162-b41c-4306-bb1f-182c962222ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-30f30d71-2d91-461a-a398-a56ff1ddecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-85b772d5-1c7a-4bdd-848c-8e0b22bda17b,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-140a1cfd-3b0a-4fec-af0f-0cbc12f7c86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-922fd523-9311-4ee4-8d16-1584b801bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-8d576db1-9749-4993-b5b4-cab56d4ac7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-58b26430-c3e4-42d4-9f9c-26180d0cbcad,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-5a0d08e7-a24f-43e0-bf89-4a46acceda99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121802510-172.17.0.12-1597551858366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36773,DS-96a94d97-810e-433a-b16e-998faca9e833,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-604727a6-a9de-49aa-b28e-2d890a15a1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-8f71b0b5-358e-40e0-9ed2-392bb33fa025,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-f927d56f-56f5-4e64-abf1-35f390834c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-153d092d-4bb9-411a-af18-a19f3a005fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-7345c1aa-4214-4e8a-b894-d27d76fe814b,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-f71b2d25-d586-4e4a-a634-8cdf6d8e0a07,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-f9c4cdf4-0426-423b-b22e-0038c16d4a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121802510-172.17.0.12-1597551858366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36773,DS-96a94d97-810e-433a-b16e-998faca9e833,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-604727a6-a9de-49aa-b28e-2d890a15a1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-8f71b0b5-358e-40e0-9ed2-392bb33fa025,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-f927d56f-56f5-4e64-abf1-35f390834c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-153d092d-4bb9-411a-af18-a19f3a005fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-7345c1aa-4214-4e8a-b894-d27d76fe814b,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-f71b2d25-d586-4e4a-a634-8cdf6d8e0a07,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-f9c4cdf4-0426-423b-b22e-0038c16d4a8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951745457-172.17.0.12-1597552237012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37116,DS-1f02210e-1e26-42a5-bca5-367203c65d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-93458b0c-910b-40ca-874b-6967b413c376,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-390334f0-7f26-426b-aed7-b204532164f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-20389a63-a79b-4026-8638-4d0166d9cef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-d9d77033-73b0-457b-8b82-58f6eb30b85b,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-49548fae-cecb-4455-ab3d-0e83f452f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-a035454d-80c1-4e75-8a96-8eb69c7d2e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-a9491f7e-bcc9-4483-9fcd-d86ddb0981b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951745457-172.17.0.12-1597552237012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37116,DS-1f02210e-1e26-42a5-bca5-367203c65d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-93458b0c-910b-40ca-874b-6967b413c376,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-390334f0-7f26-426b-aed7-b204532164f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-20389a63-a79b-4026-8638-4d0166d9cef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-d9d77033-73b0-457b-8b82-58f6eb30b85b,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-49548fae-cecb-4455-ab3d-0e83f452f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-a035454d-80c1-4e75-8a96-8eb69c7d2e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-a9491f7e-bcc9-4483-9fcd-d86ddb0981b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638423030-172.17.0.12-1597552514273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-b744b82f-6270-4c7e-92da-5aa7264a3af5,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-996efc38-822f-4f2c-b85c-3d66624f5d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-d554fc5f-ce90-4805-ba4a-b7cd909f329c,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-d9b763d7-1066-4c57-9a1d-bc834a2943a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-698eb361-0dad-42e5-b170-7db83491c044,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c5a5b320-2b05-420f-b3bc-4e69a98a49ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-af2400e4-6885-4008-9d63-42a57cd9fe50,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-b159ef3d-2174-4b66-a781-45860f76bf5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638423030-172.17.0.12-1597552514273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-b744b82f-6270-4c7e-92da-5aa7264a3af5,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-996efc38-822f-4f2c-b85c-3d66624f5d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-d554fc5f-ce90-4805-ba4a-b7cd909f329c,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-d9b763d7-1066-4c57-9a1d-bc834a2943a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-698eb361-0dad-42e5-b170-7db83491c044,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-c5a5b320-2b05-420f-b3bc-4e69a98a49ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-af2400e4-6885-4008-9d63-42a57cd9fe50,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-b159ef3d-2174-4b66-a781-45860f76bf5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505335301-172.17.0.12-1597553004250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44295,DS-5fb59ea1-5a15-43d1-b07f-eb0fd45371c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-b14131dd-83c5-4894-891a-004c68edc97f,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-712eaba7-bb03-4a09-b84a-81bd84f101db,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-c58853fc-b5b3-4539-855a-f99cdb143515,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-bd4ba503-a124-4033-86b9-247ddff9c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-5ad0c0d5-b792-4c83-9cdc-09dca000e582,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-0fdf6a58-d1b9-44ed-b6f7-35c8918812f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-cf578436-839e-4253-b1df-e5d3423c40d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505335301-172.17.0.12-1597553004250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44295,DS-5fb59ea1-5a15-43d1-b07f-eb0fd45371c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-b14131dd-83c5-4894-891a-004c68edc97f,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-712eaba7-bb03-4a09-b84a-81bd84f101db,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-c58853fc-b5b3-4539-855a-f99cdb143515,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-bd4ba503-a124-4033-86b9-247ddff9c74e,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-5ad0c0d5-b792-4c83-9cdc-09dca000e582,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-0fdf6a58-d1b9-44ed-b6f7-35c8918812f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-cf578436-839e-4253-b1df-e5d3423c40d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675631876-172.17.0.12-1597553161033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-a7362a63-8d3c-4a20-a9a7-b680c76abbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-1be3df46-770c-4ade-b588-1750981ab00e,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-087f5f7e-91b0-48ec-80c8-6d8ef1d35c39,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-0e8f9888-8f11-43ed-a1f7-f376f72e1d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-f455cb3b-41ae-4ec2-a488-60e23a9e15a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-9ba995d6-a40c-4ddf-a36f-b9c816f53a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-e73bd3f4-c41a-4e3e-b877-7cb5828ffdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-e91d9df7-d9d6-44be-979a-043b644895cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1675631876-172.17.0.12-1597553161033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39499,DS-a7362a63-8d3c-4a20-a9a7-b680c76abbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-1be3df46-770c-4ade-b588-1750981ab00e,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-087f5f7e-91b0-48ec-80c8-6d8ef1d35c39,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-0e8f9888-8f11-43ed-a1f7-f376f72e1d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-f455cb3b-41ae-4ec2-a488-60e23a9e15a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-9ba995d6-a40c-4ddf-a36f-b9c816f53a09,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-e73bd3f4-c41a-4e3e-b877-7cb5828ffdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-e91d9df7-d9d6-44be-979a-043b644895cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414909650-172.17.0.12-1597553255485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-ec2cd3b1-0adb-4c17-9277-95506c3a041a,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-19e3fbe6-77f7-4ca1-b007-d93274bee166,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-95ed9e75-5ac8-4557-8a2d-eedc27400e75,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-ef846ccf-64c6-40c7-96f4-3256665cda8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-24eee033-968d-47ac-828c-f86d37376876,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-6f3420e8-f4c4-4782-93ce-0faade4cb0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-2da0c88d-d433-46e3-84be-357eedcdb5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-63331612-68d3-478a-8f96-efdc5f234039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414909650-172.17.0.12-1597553255485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-ec2cd3b1-0adb-4c17-9277-95506c3a041a,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-19e3fbe6-77f7-4ca1-b007-d93274bee166,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-95ed9e75-5ac8-4557-8a2d-eedc27400e75,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-ef846ccf-64c6-40c7-96f4-3256665cda8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-24eee033-968d-47ac-828c-f86d37376876,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-6f3420e8-f4c4-4782-93ce-0faade4cb0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-2da0c88d-d433-46e3-84be-357eedcdb5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-63331612-68d3-478a-8f96-efdc5f234039,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644613200-172.17.0.12-1597553482798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45070,DS-6a708ae5-98f8-4a03-ae7a-776ddd688144,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-474cb467-f32f-415d-98a6-76976d7e228c,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-12d64769-9281-439d-92ee-52982aab804b,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-baf15204-2909-4cff-9ef5-1ed2a8f040b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-dd848ee2-40af-48f8-b369-0ed75382824d,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-6f180939-767a-4bc1-856b-c44913bb3cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-9a746de3-4a1f-442b-ad1f-938e0c58c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-f39f2894-5dd5-4fda-b48f-13553748e385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644613200-172.17.0.12-1597553482798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45070,DS-6a708ae5-98f8-4a03-ae7a-776ddd688144,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-474cb467-f32f-415d-98a6-76976d7e228c,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-12d64769-9281-439d-92ee-52982aab804b,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-baf15204-2909-4cff-9ef5-1ed2a8f040b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-dd848ee2-40af-48f8-b369-0ed75382824d,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-6f180939-767a-4bc1-856b-c44913bb3cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-9a746de3-4a1f-442b-ad1f-938e0c58c8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-f39f2894-5dd5-4fda-b48f-13553748e385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730834841-172.17.0.12-1597553514548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-9e42e482-9b80-464f-a75d-757a6d195696,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-539c30d0-9d92-48e5-8344-6ffdd388a288,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-eaf5e3d0-bab9-4266-8d89-07e5a2bfb9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-7f9bd003-2ef0-4f3e-aba1-24ebedf4a813,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-5bff9821-0514-4f0d-b96b-cc1e9dde4eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-c2d049de-5a4d-47c6-a637-95c98b19a976,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-8b4f2fa7-7573-4f34-a1d7-6a7fa52a9e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-6ea6160f-a985-4265-9b4c-b882ce6762a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730834841-172.17.0.12-1597553514548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-9e42e482-9b80-464f-a75d-757a6d195696,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-539c30d0-9d92-48e5-8344-6ffdd388a288,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-eaf5e3d0-bab9-4266-8d89-07e5a2bfb9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-7f9bd003-2ef0-4f3e-aba1-24ebedf4a813,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-5bff9821-0514-4f0d-b96b-cc1e9dde4eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-c2d049de-5a4d-47c6-a637-95c98b19a976,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-8b4f2fa7-7573-4f34-a1d7-6a7fa52a9e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-6ea6160f-a985-4265-9b4c-b882ce6762a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-242130101-172.17.0.12-1597553715863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36081,DS-3cf7bbc0-0bf2-485a-ab72-f9957baa0de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-3a0283f9-43bd-46fd-8cd1-0732b2008182,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-395250f6-5a41-47d3-889f-1996e6bcd8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-1e7538d2-6529-4400-8bc7-33d1a35c428a,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-9a2b45c9-c39f-4d01-bb25-c16d5e86a1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-d8ca7f5e-5244-46ba-abdf-ff5cd2565140,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-67679a79-7495-45a0-be88-ab3203c8f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-4509f1f9-dab6-49aa-935a-a8e502b0b0d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-242130101-172.17.0.12-1597553715863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36081,DS-3cf7bbc0-0bf2-485a-ab72-f9957baa0de9,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-3a0283f9-43bd-46fd-8cd1-0732b2008182,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-395250f6-5a41-47d3-889f-1996e6bcd8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-1e7538d2-6529-4400-8bc7-33d1a35c428a,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-9a2b45c9-c39f-4d01-bb25-c16d5e86a1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-d8ca7f5e-5244-46ba-abdf-ff5cd2565140,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-67679a79-7495-45a0-be88-ab3203c8f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-4509f1f9-dab6-49aa-935a-a8e502b0b0d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142989789-172.17.0.12-1597553747579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43695,DS-f9b5296b-622a-48a0-a980-575f70014ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-941051e2-7f0c-4bfb-812b-4d5faba96f65,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-32230734-6aa3-45f7-a3d3-63f323b63c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-ae766acd-a27f-446b-a83d-f7e2f28e0b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-00b74244-43d4-4bf3-bc7f-62bb650e845d,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-de644b04-9298-421e-ac35-856b7ee573e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-b1e3d17d-f70e-40cd-afe5-9eb4f620ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-19c088c0-3014-4c28-84ce-599f371a5c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142989789-172.17.0.12-1597553747579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43695,DS-f9b5296b-622a-48a0-a980-575f70014ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-941051e2-7f0c-4bfb-812b-4d5faba96f65,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-32230734-6aa3-45f7-a3d3-63f323b63c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-ae766acd-a27f-446b-a83d-f7e2f28e0b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-00b74244-43d4-4bf3-bc7f-62bb650e845d,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-de644b04-9298-421e-ac35-856b7ee573e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-b1e3d17d-f70e-40cd-afe5-9eb4f620ea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-19c088c0-3014-4c28-84ce-599f371a5c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499909964-172.17.0.12-1597553920047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-a29f3966-7479-4c48-94fa-873d092985e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-1d3c5206-6010-4e9b-8096-3591bda8a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-c615b5de-6a16-4370-961d-ae8483bd318a,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-03457e3e-c833-4bc3-8f67-85d44ba79721,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-30336002-1ae1-441c-83d2-8201e292ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-6440ed20-fcb7-41f7-9b29-06a81ec07bde,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-fbb51109-6ad0-41a7-afbb-c48258658df2,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-05c78db4-5d19-4f67-ab80-a53f2574616f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1499909964-172.17.0.12-1597553920047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42659,DS-a29f3966-7479-4c48-94fa-873d092985e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-1d3c5206-6010-4e9b-8096-3591bda8a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-c615b5de-6a16-4370-961d-ae8483bd318a,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-03457e3e-c833-4bc3-8f67-85d44ba79721,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-30336002-1ae1-441c-83d2-8201e292ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-6440ed20-fcb7-41f7-9b29-06a81ec07bde,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-fbb51109-6ad0-41a7-afbb-c48258658df2,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-05c78db4-5d19-4f67-ab80-a53f2574616f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087689431-172.17.0.12-1597554283908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37455,DS-e2f57843-d632-4c98-97c4-44340baf3c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-2637a89a-f777-44ad-ab41-36a50608ad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-2f6a048c-8e0b-41bb-a995-ba2874b4e9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-0c2c2d94-aecd-4a4a-97e4-7cadcc533b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-6f015cf8-9270-4680-b897-fc594e50f4db,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-8fefcf0f-a013-4a71-8455-9cc145cb7411,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-3e138648-3333-4dc2-a289-015f6ff09670,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f126558d-9250-4c6e-a954-47e1eed991a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1087689431-172.17.0.12-1597554283908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37455,DS-e2f57843-d632-4c98-97c4-44340baf3c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-2637a89a-f777-44ad-ab41-36a50608ad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-2f6a048c-8e0b-41bb-a995-ba2874b4e9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-0c2c2d94-aecd-4a4a-97e4-7cadcc533b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-6f015cf8-9270-4680-b897-fc594e50f4db,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-8fefcf0f-a013-4a71-8455-9cc145cb7411,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-3e138648-3333-4dc2-a289-015f6ff09670,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f126558d-9250-4c6e-a954-47e1eed991a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277728335-172.17.0.12-1597554360023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-5e7883f9-5844-4654-a419-4fe27ffeb704,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-d9d4a312-5f22-4c7d-87da-b8e6a9c255a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-3bb81e49-9836-4f60-9120-3602fc99751f,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-3a5246f3-edb4-4824-9ba2-bbfa514365da,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-44f0e294-8790-40f1-991b-46735793c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-336852bc-e2cf-4771-a65b-f3e1858e6166,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-3c0ffa42-23a5-40ec-b4bb-05942037328b,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-7ab462b0-a44e-4e84-9ee2-f7fef4f173f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277728335-172.17.0.12-1597554360023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-5e7883f9-5844-4654-a419-4fe27ffeb704,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-d9d4a312-5f22-4c7d-87da-b8e6a9c255a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-3bb81e49-9836-4f60-9120-3602fc99751f,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-3a5246f3-edb4-4824-9ba2-bbfa514365da,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-44f0e294-8790-40f1-991b-46735793c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-336852bc-e2cf-4771-a65b-f3e1858e6166,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-3c0ffa42-23a5-40ec-b4bb-05942037328b,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-7ab462b0-a44e-4e84-9ee2-f7fef4f173f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102394431-172.17.0.12-1597554756946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-d136d5a4-e637-4ee8-ba9b-a91def93e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-a518c162-ef63-48a3-afc3-a12cdc482417,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-ce7739d4-e8d2-41cb-a24f-9ef54237ad97,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-4aa853cb-db80-42bd-9b5e-1d672ed8b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-08a81536-bcb1-44ed-9f2c-3c6faa3481e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-d48a4b0a-c8d9-44de-bc31-c91e6d4fa43d,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-d564daff-8dbd-48b6-9ee4-f2602d59d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-1257ca80-44cf-4a51-987c-4c1cc9c605c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102394431-172.17.0.12-1597554756946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42162,DS-d136d5a4-e637-4ee8-ba9b-a91def93e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-a518c162-ef63-48a3-afc3-a12cdc482417,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-ce7739d4-e8d2-41cb-a24f-9ef54237ad97,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-4aa853cb-db80-42bd-9b5e-1d672ed8b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44336,DS-08a81536-bcb1-44ed-9f2c-3c6faa3481e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-d48a4b0a-c8d9-44de-bc31-c91e6d4fa43d,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-d564daff-8dbd-48b6-9ee4-f2602d59d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-1257ca80-44cf-4a51-987c-4c1cc9c605c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270630961-172.17.0.12-1597554908603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34647,DS-0e024763-4bde-48f5-b471-80c7ce6330f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-720a1f6b-f32a-4580-818a-ca749401e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-42d49d22-1c53-4d8d-93c6-9e805cc85783,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-a4c444f2-4a12-421a-a11a-6dcd388f5af8,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-3d69c83d-c6c6-45a7-8228-a99bace14b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-23ef50f2-aa52-4c4c-84a4-9981cfde28c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-db77b5a8-2528-4a34-9ccf-7d333fcd7a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-000f8e1f-c72e-4b81-a311-69836cddf31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270630961-172.17.0.12-1597554908603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34647,DS-0e024763-4bde-48f5-b471-80c7ce6330f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-720a1f6b-f32a-4580-818a-ca749401e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-42d49d22-1c53-4d8d-93c6-9e805cc85783,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-a4c444f2-4a12-421a-a11a-6dcd388f5af8,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-3d69c83d-c6c6-45a7-8228-a99bace14b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-23ef50f2-aa52-4c4c-84a4-9981cfde28c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-db77b5a8-2528-4a34-9ccf-7d333fcd7a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-000f8e1f-c72e-4b81-a311-69836cddf31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169707078-172.17.0.12-1597555009665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43148,DS-6ce64ed6-f17e-445b-8a3e-cce5632baaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-cf85e819-80b8-46c4-8c95-124d039e8adf,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-0bd39f32-3169-46b3-bbdf-4de2b4ce92c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-20c88591-186d-4c10-9263-0cc6fa652410,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-6f8ee2f8-48ca-468e-8568-0722851ca870,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-0ac67c79-6ead-482d-9bee-3654c737f755,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-4a61560d-573d-405d-ac64-e5b076126ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-2a6ffba1-bda1-4cc0-b24f-29e03d7f3870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169707078-172.17.0.12-1597555009665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43148,DS-6ce64ed6-f17e-445b-8a3e-cce5632baaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-cf85e819-80b8-46c4-8c95-124d039e8adf,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-0bd39f32-3169-46b3-bbdf-4de2b4ce92c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-20c88591-186d-4c10-9263-0cc6fa652410,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-6f8ee2f8-48ca-468e-8568-0722851ca870,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-0ac67c79-6ead-482d-9bee-3654c737f755,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-4a61560d-573d-405d-ac64-e5b076126ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-2a6ffba1-bda1-4cc0-b24f-29e03d7f3870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 600
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653317876-172.17.0.12-1597555089802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42424,DS-1c203a63-cc39-49be-9294-29c4af1625b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-2b4be05d-f38e-40dd-a536-908b907b65c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-0dad7b45-76fc-4756-ac4d-7eb445128b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-cb1654ff-c54b-4cdf-83c2-b327a2d372f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-a6535530-b50e-4d70-9e4c-65fb4c2cccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-e81323c4-592c-4fe8-b20d-f62116ce49e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-659da11f-72a5-44e9-b400-bf6708c7a8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-07a8b179-6f5d-42bb-8c4b-7e266cbd869d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653317876-172.17.0.12-1597555089802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42424,DS-1c203a63-cc39-49be-9294-29c4af1625b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-2b4be05d-f38e-40dd-a536-908b907b65c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-0dad7b45-76fc-4756-ac4d-7eb445128b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-cb1654ff-c54b-4cdf-83c2-b327a2d372f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-a6535530-b50e-4d70-9e4c-65fb4c2cccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-e81323c4-592c-4fe8-b20d-f62116ce49e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-659da11f-72a5-44e9-b400-bf6708c7a8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-07a8b179-6f5d-42bb-8c4b-7e266cbd869d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5255
