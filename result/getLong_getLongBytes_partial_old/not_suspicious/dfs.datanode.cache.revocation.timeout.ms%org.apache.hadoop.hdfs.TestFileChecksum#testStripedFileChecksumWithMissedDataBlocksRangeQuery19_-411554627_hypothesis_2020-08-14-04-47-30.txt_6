reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-718004018-172.17.0.16-1597380503327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42993,DS-3c37d7cb-515e-4a93-bc65-c447cbac5b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-f0522fdb-e5d4-4fe5-8f09-7dc008bdd29e,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-a3ae1f34-18d4-404c-b62e-8bd63e9e714c,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-b1b40bd1-a986-495d-916b-296df95b5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-8849690e-133b-45b9-a8c0-cee2cbbd04a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-314599cb-2ed7-4f5b-bdd8-6036a61731d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-2b7e6904-8c76-40fb-99e8-8b970878c310,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-e2e210d2-b91c-4ce6-bf55-629d2bc53ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-718004018-172.17.0.16-1597380503327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42993,DS-3c37d7cb-515e-4a93-bc65-c447cbac5b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-f0522fdb-e5d4-4fe5-8f09-7dc008bdd29e,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-a3ae1f34-18d4-404c-b62e-8bd63e9e714c,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-b1b40bd1-a986-495d-916b-296df95b5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-8849690e-133b-45b9-a8c0-cee2cbbd04a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-314599cb-2ed7-4f5b-bdd8-6036a61731d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-2b7e6904-8c76-40fb-99e8-8b970878c310,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-e2e210d2-b91c-4ce6-bf55-629d2bc53ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873859137-172.17.0.16-1597380567452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-f0f34ec7-aa91-4b94-991c-6d8648b7359d,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-8ae22beb-04b2-44ed-b027-48d9088bf99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-0535b36d-bb34-4bf5-ae71-66a98335d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-7a46341e-3f0c-49dc-9ec9-654d4a630d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-185c573d-9f75-45f1-85b2-e5998644e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-0088ba4a-7a88-45ac-9e5e-2b8ec6603c48,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-46c5f80a-df54-4d99-8aa2-5c445b5b4b41,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-e3c9edd2-2d76-4c4f-85e9-1a82b459496a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873859137-172.17.0.16-1597380567452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45944,DS-f0f34ec7-aa91-4b94-991c-6d8648b7359d,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-8ae22beb-04b2-44ed-b027-48d9088bf99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-0535b36d-bb34-4bf5-ae71-66a98335d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-7a46341e-3f0c-49dc-9ec9-654d4a630d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-185c573d-9f75-45f1-85b2-e5998644e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-0088ba4a-7a88-45ac-9e5e-2b8ec6603c48,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-46c5f80a-df54-4d99-8aa2-5c445b5b4b41,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-e3c9edd2-2d76-4c4f-85e9-1a82b459496a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039333206-172.17.0.16-1597381166681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35547,DS-4511eeb6-db14-40fd-a9cd-c194aee5006a,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-31a4bfc5-6fa4-4b31-adb3-ad0b016e2f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-c7d45d7f-2845-453f-9e45-886dbcfaf200,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-ad1983d2-fd9a-4fc9-819a-391d42c5bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-49ac1214-ad0f-4257-97fa-b0bded45cece,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-004cb4b3-6de2-4903-bf7d-f5b9d6fbfa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-4a27a24d-d3ab-4aee-b709-773e2bbea9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-22b89f31-ba3e-41a1-9b62-9da082074979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039333206-172.17.0.16-1597381166681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35547,DS-4511eeb6-db14-40fd-a9cd-c194aee5006a,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-31a4bfc5-6fa4-4b31-adb3-ad0b016e2f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-c7d45d7f-2845-453f-9e45-886dbcfaf200,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-ad1983d2-fd9a-4fc9-819a-391d42c5bac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-49ac1214-ad0f-4257-97fa-b0bded45cece,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-004cb4b3-6de2-4903-bf7d-f5b9d6fbfa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-4a27a24d-d3ab-4aee-b709-773e2bbea9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-22b89f31-ba3e-41a1-9b62-9da082074979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111111702-172.17.0.16-1597381311881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-2e78c030-fc89-4c51-870c-1820f8480329,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-25b260c1-c63f-49ee-a9b7-1ac10fcd367c,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-601aace9-f320-4723-a0ee-98012cd9b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-9b9b1ac2-699b-451e-ba1c-f9a128288696,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-5ca2b743-1922-445a-9023-f995f1bc328e,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-fb9882b3-8730-48d1-8ac1-c0e10c1bf9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-09894245-e131-43ce-b360-cbba6df8cce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-58e416df-2d3b-4f1c-a32b-315093ad3f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111111702-172.17.0.16-1597381311881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37805,DS-2e78c030-fc89-4c51-870c-1820f8480329,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-25b260c1-c63f-49ee-a9b7-1ac10fcd367c,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-601aace9-f320-4723-a0ee-98012cd9b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-9b9b1ac2-699b-451e-ba1c-f9a128288696,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-5ca2b743-1922-445a-9023-f995f1bc328e,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-fb9882b3-8730-48d1-8ac1-c0e10c1bf9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-09894245-e131-43ce-b360-cbba6df8cce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-58e416df-2d3b-4f1c-a32b-315093ad3f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422034176-172.17.0.16-1597381901778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-c4ac7098-c2e5-48f1-be22-415a57f58929,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-df21a7f1-ec31-4e29-9375-cf2e107a846c,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-adb55bc4-b6a9-4145-82c6-8ecd7066a2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-912edd2c-9c72-4b1a-b2bf-299b183d4696,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-86d5f3bf-fc3f-408d-a00b-8bd67323380e,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-d0811a26-5ad5-4f82-b27e-6ec6ba0daa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-372abecc-898f-47bd-bf33-5b70069fd96c,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-c6f7b979-f809-4468-8b5b-9aa05d46f4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422034176-172.17.0.16-1597381901778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43201,DS-c4ac7098-c2e5-48f1-be22-415a57f58929,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-df21a7f1-ec31-4e29-9375-cf2e107a846c,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-adb55bc4-b6a9-4145-82c6-8ecd7066a2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-912edd2c-9c72-4b1a-b2bf-299b183d4696,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-86d5f3bf-fc3f-408d-a00b-8bd67323380e,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-d0811a26-5ad5-4f82-b27e-6ec6ba0daa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-372abecc-898f-47bd-bf33-5b70069fd96c,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-c6f7b979-f809-4468-8b5b-9aa05d46f4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821940537-172.17.0.16-1597382527196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-193952be-ace5-4d62-89b5-28ac69d11340,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-26b45442-b736-42eb-b9e1-7d7d95cb6bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-ff4e82b0-9469-487b-b280-d7cb16afa581,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-cbdf6b69-9757-4b9f-bdbf-b93f57bc3075,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-9fa8b106-4bec-4a1a-ac29-5c89c6969fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-43c43af1-d4ba-42f3-91c3-b6c71e88432f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-8ed70b7b-22c7-4a4c-96fe-f1e988dea238,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-1112da47-a038-4df6-9911-e87cc4bd71f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821940537-172.17.0.16-1597382527196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-193952be-ace5-4d62-89b5-28ac69d11340,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-26b45442-b736-42eb-b9e1-7d7d95cb6bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-ff4e82b0-9469-487b-b280-d7cb16afa581,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-cbdf6b69-9757-4b9f-bdbf-b93f57bc3075,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-9fa8b106-4bec-4a1a-ac29-5c89c6969fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-43c43af1-d4ba-42f3-91c3-b6c71e88432f,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-8ed70b7b-22c7-4a4c-96fe-f1e988dea238,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-1112da47-a038-4df6-9911-e87cc4bd71f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436247950-172.17.0.16-1597383073831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44185,DS-3adfb07c-4bdd-48a7-964a-6036c0bab685,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-8ec1e526-ea44-4467-b521-c0803e5a4609,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-30cbf157-8934-4066-8b02-ec77ea6a924b,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-35f6da1a-02d8-40fd-a7dd-22f91c6d19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-2b7bea67-48af-4695-8f98-f372ba0ca431,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-10a50c7e-a4da-4a46-8a4d-a5c2710445d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-45f3830f-f474-4005-8cb2-974e1c68dbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-277c684b-2221-467e-be43-ed288609ab28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436247950-172.17.0.16-1597383073831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44185,DS-3adfb07c-4bdd-48a7-964a-6036c0bab685,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-8ec1e526-ea44-4467-b521-c0803e5a4609,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-30cbf157-8934-4066-8b02-ec77ea6a924b,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-35f6da1a-02d8-40fd-a7dd-22f91c6d19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-2b7bea67-48af-4695-8f98-f372ba0ca431,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-10a50c7e-a4da-4a46-8a4d-a5c2710445d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-45f3830f-f474-4005-8cb2-974e1c68dbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-277c684b-2221-467e-be43-ed288609ab28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337915744-172.17.0.16-1597383448945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34254,DS-3c6c880c-520b-4d3f-99d0-68d0a94e8466,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-b313e340-18ed-4fda-92ed-0ba0b495ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-1890bdcd-4afe-4fbc-b8c3-3ee3d0609758,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-10bbc4eb-bcc0-45a3-853f-723a2ea879d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-66ed1e96-66a1-404e-adca-93292c631033,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-d54f2f9c-d2b0-45e3-b91f-0bd1eff48e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-f7ee27a8-8169-4b3a-a372-1af19f3d1808,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-c965300c-b84f-4b7b-b711-adeb85b9706e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337915744-172.17.0.16-1597383448945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34254,DS-3c6c880c-520b-4d3f-99d0-68d0a94e8466,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-b313e340-18ed-4fda-92ed-0ba0b495ed0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-1890bdcd-4afe-4fbc-b8c3-3ee3d0609758,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-10bbc4eb-bcc0-45a3-853f-723a2ea879d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-66ed1e96-66a1-404e-adca-93292c631033,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-d54f2f9c-d2b0-45e3-b91f-0bd1eff48e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-f7ee27a8-8169-4b3a-a372-1af19f3d1808,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-c965300c-b84f-4b7b-b711-adeb85b9706e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429200881-172.17.0.16-1597383813289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43121,DS-db47c75b-6815-4315-8042-c9354c4049a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-d84a7500-f849-4c66-958f-c0c0320cabf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-7bbae2da-1dee-4683-8938-9c0acecedfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-b29d64d5-a5bf-482f-9b9b-9e8966d07630,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-249a0f7e-f25a-4c87-91c6-7eb64bd7b0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-f42e0bdd-9723-41d4-b7c0-fa466336f104,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-8f2089be-773c-4af9-acc0-6601723f1868,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-5d36d797-9412-400f-9629-6eec5e8d42ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429200881-172.17.0.16-1597383813289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43121,DS-db47c75b-6815-4315-8042-c9354c4049a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-d84a7500-f849-4c66-958f-c0c0320cabf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-7bbae2da-1dee-4683-8938-9c0acecedfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-b29d64d5-a5bf-482f-9b9b-9e8966d07630,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-249a0f7e-f25a-4c87-91c6-7eb64bd7b0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-f42e0bdd-9723-41d4-b7c0-fa466336f104,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-8f2089be-773c-4af9-acc0-6601723f1868,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-5d36d797-9412-400f-9629-6eec5e8d42ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008714225-172.17.0.16-1597383878538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45808,DS-a4b566f4-fff8-46e9-bd05-03c1d964e4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-912ac4bf-f11c-4a42-a862-b328fa902c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-46f8bd2a-dc2e-4ab5-8bb2-e878a2bd5f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-cf0f2468-d1a3-4670-8ee1-f2feff3b1a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-c7142dc0-cd8d-41f6-84d3-537a20d5a625,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-b04c1098-a36c-451a-bb85-7f5d1f159a59,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-751b6716-e231-4df1-b1e1-95b8d7a2462a,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-0feec25f-2ff7-485b-b853-224fe63ac216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008714225-172.17.0.16-1597383878538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45808,DS-a4b566f4-fff8-46e9-bd05-03c1d964e4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-912ac4bf-f11c-4a42-a862-b328fa902c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-46f8bd2a-dc2e-4ab5-8bb2-e878a2bd5f57,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-cf0f2468-d1a3-4670-8ee1-f2feff3b1a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-c7142dc0-cd8d-41f6-84d3-537a20d5a625,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-b04c1098-a36c-451a-bb85-7f5d1f159a59,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-751b6716-e231-4df1-b1e1-95b8d7a2462a,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-0feec25f-2ff7-485b-b853-224fe63ac216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438067723-172.17.0.16-1597384185803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42734,DS-a9c55831-3d9e-40bd-9f77-040915cde7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-2c6de4b9-b80e-4aac-9748-cd1f61a21328,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-7b6e0ede-6ea9-4e58-867a-e3828c151083,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-73730780-3413-4353-b4ac-3100d79afa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-de062369-4183-4efa-81c7-fec5def61da7,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-815d794d-da7e-4778-a989-5dc2173dcf97,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-e0a1da89-c05c-4512-a725-7c3373b83234,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-0ff7ecaa-b500-41d0-9218-e9f83436be14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438067723-172.17.0.16-1597384185803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42734,DS-a9c55831-3d9e-40bd-9f77-040915cde7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-2c6de4b9-b80e-4aac-9748-cd1f61a21328,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-7b6e0ede-6ea9-4e58-867a-e3828c151083,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-73730780-3413-4353-b4ac-3100d79afa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-de062369-4183-4efa-81c7-fec5def61da7,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-815d794d-da7e-4778-a989-5dc2173dcf97,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-e0a1da89-c05c-4512-a725-7c3373b83234,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-0ff7ecaa-b500-41d0-9218-e9f83436be14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428980032-172.17.0.16-1597384843413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-a0e4785c-83fe-4481-af74-09d08cdfba1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-ec2b2569-dc6c-4c0a-8db3-140873dc7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-cfb619e0-e56c-48c7-ab3c-947aa9a2f9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-277d8bb5-56ff-48ed-861e-153a232c5265,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-b9c592c6-9632-4051-8cea-6b401871397f,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-018803cf-3996-40f5-a832-0b1ffb51a321,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-2c424e66-8148-48df-97b5-be7b96469c51,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-30a434aa-22d8-4c5d-b237-e866a684b455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428980032-172.17.0.16-1597384843413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-a0e4785c-83fe-4481-af74-09d08cdfba1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-ec2b2569-dc6c-4c0a-8db3-140873dc7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-cfb619e0-e56c-48c7-ab3c-947aa9a2f9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-277d8bb5-56ff-48ed-861e-153a232c5265,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-b9c592c6-9632-4051-8cea-6b401871397f,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-018803cf-3996-40f5-a832-0b1ffb51a321,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-2c424e66-8148-48df-97b5-be7b96469c51,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-30a434aa-22d8-4c5d-b237-e866a684b455,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486539238-172.17.0.16-1597385055282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42052,DS-a4cfd7d4-d69e-4b65-91e0-898f6e7e1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-7cd98587-b19a-427b-bdea-6ed0194abe48,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-206ea703-5d54-4cde-bf52-8011f4cb92ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-788eeee5-3b79-4b07-ae95-cdadfa6670b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-d62e2670-a099-4396-8f1f-e8e2c52ba81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-2171c5e0-356d-4513-bf44-af059f835740,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-988fb561-33d7-4abb-8032-ee5bb195f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-989c77b4-6f16-4be9-a121-56b0ab18ba3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486539238-172.17.0.16-1597385055282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42052,DS-a4cfd7d4-d69e-4b65-91e0-898f6e7e1c44,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-7cd98587-b19a-427b-bdea-6ed0194abe48,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-206ea703-5d54-4cde-bf52-8011f4cb92ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-788eeee5-3b79-4b07-ae95-cdadfa6670b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-d62e2670-a099-4396-8f1f-e8e2c52ba81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-2171c5e0-356d-4513-bf44-af059f835740,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-988fb561-33d7-4abb-8032-ee5bb195f1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-989c77b4-6f16-4be9-a121-56b0ab18ba3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535226514-172.17.0.16-1597385353442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-60f1afe5-6696-4ada-82b5-7ddb092a4739,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-1fec4ecb-c64f-4914-8643-b70578b1c093,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-322466a0-5984-446b-9a89-068f3232c0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-1888b032-04d4-4809-850d-9e58b9367903,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-5d525b40-2224-495d-8ada-62d4d6b9bfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-c4eace41-7b98-4bbb-8b6f-36b637bcf0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-5db0fbb8-8498-4ef7-91b4-9a753e0bfb01,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-bcb414e5-0c96-4a2c-9706-895d42342e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535226514-172.17.0.16-1597385353442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-60f1afe5-6696-4ada-82b5-7ddb092a4739,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-1fec4ecb-c64f-4914-8643-b70578b1c093,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-322466a0-5984-446b-9a89-068f3232c0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-1888b032-04d4-4809-850d-9e58b9367903,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-5d525b40-2224-495d-8ada-62d4d6b9bfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-c4eace41-7b98-4bbb-8b6f-36b637bcf0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-5db0fbb8-8498-4ef7-91b4-9a753e0bfb01,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-bcb414e5-0c96-4a2c-9706-895d42342e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972375092-172.17.0.16-1597385551192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-a22c83a7-3dac-4674-9304-e00c3fee815f,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-1a7d3d36-2900-430e-b376-a482e9969376,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-9bafe99b-f9f0-4f4f-bbdd-f7bc63496ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-f174e4ca-b3fb-457c-8f57-3fb2046365bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-79de1516-51c8-4e10-ad35-ddf93d0d07b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-d9cf24ca-9c80-4c7c-9ecf-e2dc9b99194a,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-3a251ea8-1c96-4497-8f6f-0f0d6687b20c,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-b0a7cdb1-52a4-4226-b0b9-9d95f8f53f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972375092-172.17.0.16-1597385551192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-a22c83a7-3dac-4674-9304-e00c3fee815f,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-1a7d3d36-2900-430e-b376-a482e9969376,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-9bafe99b-f9f0-4f4f-bbdd-f7bc63496ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-f174e4ca-b3fb-457c-8f57-3fb2046365bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-79de1516-51c8-4e10-ad35-ddf93d0d07b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-d9cf24ca-9c80-4c7c-9ecf-e2dc9b99194a,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-3a251ea8-1c96-4497-8f6f-0f0d6687b20c,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-b0a7cdb1-52a4-4226-b0b9-9d95f8f53f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5153
