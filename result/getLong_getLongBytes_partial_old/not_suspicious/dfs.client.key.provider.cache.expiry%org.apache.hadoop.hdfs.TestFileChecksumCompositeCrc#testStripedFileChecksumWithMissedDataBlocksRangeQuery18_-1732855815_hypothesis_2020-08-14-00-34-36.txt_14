reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838403080-172.17.0.20-1597365444893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-3bb23048-ba84-4e3b-9e76-95bae802794a,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-453409fe-e013-4b88-be48-4034feefb8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-5406d3fd-ad2c-4c07-ab26-e7a1783ed3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-e079ad14-9718-437a-93af-85c6eedab92b,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-0368c63c-91d1-4391-bb57-4b7c18ad2d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-b920c71b-0329-4c32-96e0-86d7be83fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-2755e13d-2e58-4ba1-9511-bf7ecc5becac,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-17d0de9e-c449-42ef-b997-c3cf99015292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838403080-172.17.0.20-1597365444893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37200,DS-3bb23048-ba84-4e3b-9e76-95bae802794a,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-453409fe-e013-4b88-be48-4034feefb8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-5406d3fd-ad2c-4c07-ab26-e7a1783ed3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-e079ad14-9718-437a-93af-85c6eedab92b,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-0368c63c-91d1-4391-bb57-4b7c18ad2d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-b920c71b-0329-4c32-96e0-86d7be83fd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-2755e13d-2e58-4ba1-9511-bf7ecc5becac,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-17d0de9e-c449-42ef-b997-c3cf99015292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503044494-172.17.0.20-1597365559445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-79157347-eb61-4624-999f-244a1d514294,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-37949885-3af3-4471-953b-1350a24e2f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-d5a825c6-4b48-4cd2-bbac-cc57b8726f68,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-d614fa5f-3bab-4e43-ad7f-0715a2842e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-6f09a1f1-5506-49bc-a984-7e08070e5f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-904ef69c-25a4-40d9-8c4b-f5f5696aba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-0c5785fe-da01-4bf8-bd48-a959037a1bee,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-fdef4fcf-d97f-4d83-856b-62f764f20bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503044494-172.17.0.20-1597365559445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32860,DS-79157347-eb61-4624-999f-244a1d514294,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-37949885-3af3-4471-953b-1350a24e2f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-d5a825c6-4b48-4cd2-bbac-cc57b8726f68,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-d614fa5f-3bab-4e43-ad7f-0715a2842e89,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-6f09a1f1-5506-49bc-a984-7e08070e5f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-904ef69c-25a4-40d9-8c4b-f5f5696aba5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-0c5785fe-da01-4bf8-bd48-a959037a1bee,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-fdef4fcf-d97f-4d83-856b-62f764f20bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204974234-172.17.0.20-1597365587826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-73616f11-e502-4a79-9a76-76aacf137e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-66991639-4288-47f4-9557-81d7ebe66cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-37af6c09-98f9-48ee-8149-872f066e3223,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-60078fe8-a06b-4e85-8765-7cab7e63b7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-f461404b-f9f9-4c40-81d7-40121de255e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-93316e68-58e4-4782-ab42-23af1b8ec1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-9a11d073-9b27-46bd-839a-80f2670bac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-e164f2f2-3ea7-40eb-b173-23e257c17a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204974234-172.17.0.20-1597365587826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-73616f11-e502-4a79-9a76-76aacf137e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-66991639-4288-47f4-9557-81d7ebe66cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-37af6c09-98f9-48ee-8149-872f066e3223,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-60078fe8-a06b-4e85-8765-7cab7e63b7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-f461404b-f9f9-4c40-81d7-40121de255e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-93316e68-58e4-4782-ab42-23af1b8ec1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-9a11d073-9b27-46bd-839a-80f2670bac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-e164f2f2-3ea7-40eb-b173-23e257c17a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776258428-172.17.0.20-1597365818517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-05bc60bc-fcb4-4835-829d-b7abb487cfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-47e8a809-8cbe-43b1-9043-816554e62b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-2d31bf88-0270-4fb0-8a8a-28a6e112694b,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-0085d144-1f1b-46c8-a22e-f166addf4e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-6b39f8c3-8537-4c06-acdd-24a23e59a47a,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-5e10e8dc-1da8-4235-8d47-afc93cd16d34,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-a9ee248a-54ea-4ede-8a90-772c71a4413a,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-6e247d0e-026b-429d-8fcf-59f0971f8b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776258428-172.17.0.20-1597365818517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-05bc60bc-fcb4-4835-829d-b7abb487cfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-47e8a809-8cbe-43b1-9043-816554e62b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-2d31bf88-0270-4fb0-8a8a-28a6e112694b,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-0085d144-1f1b-46c8-a22e-f166addf4e52,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-6b39f8c3-8537-4c06-acdd-24a23e59a47a,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-5e10e8dc-1da8-4235-8d47-afc93cd16d34,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-a9ee248a-54ea-4ede-8a90-772c71a4413a,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-6e247d0e-026b-429d-8fcf-59f0971f8b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113771631-172.17.0.20-1597365934532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-df08e973-9c5d-4b93-bd2b-f5b793047adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-63912958-68c5-49d3-9e31-8b12bfe2a961,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-dcbcf54f-d4a2-4698-b082-74dd0928e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-7a59557e-0b16-4611-945c-788bb5c9c2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-099f1eb4-c9ec-4811-b402-5fa7b70c480d,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-fe483b38-d45f-46ca-85d0-cef35bb62ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-447a0678-45dc-4a76-8ac5-d686f24386e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-7b2a9c45-9f67-492c-ae5c-2176fb35d113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113771631-172.17.0.20-1597365934532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-df08e973-9c5d-4b93-bd2b-f5b793047adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-63912958-68c5-49d3-9e31-8b12bfe2a961,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-dcbcf54f-d4a2-4698-b082-74dd0928e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-7a59557e-0b16-4611-945c-788bb5c9c2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-099f1eb4-c9ec-4811-b402-5fa7b70c480d,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-fe483b38-d45f-46ca-85d0-cef35bb62ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-447a0678-45dc-4a76-8ac5-d686f24386e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-7b2a9c45-9f67-492c-ae5c-2176fb35d113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716054362-172.17.0.20-1597366234347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-afe4567e-4556-47a3-ac19-88ec0be9de3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-89a1a165-964e-44ec-97d9-2ab936515492,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-33f03a56-9f3a-4cc6-a118-82551641ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-0a30667b-a625-4d23-845b-361b0ac4156c,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-9a09f65a-9045-4a35-a482-bafbd9855c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-676b607a-c079-441e-ae87-73bbfbb658d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-de4c7de1-2ed9-4363-8024-bc70e6a2cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-42bfad32-0810-4c63-9a74-e427c6654a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716054362-172.17.0.20-1597366234347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40288,DS-afe4567e-4556-47a3-ac19-88ec0be9de3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-89a1a165-964e-44ec-97d9-2ab936515492,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-33f03a56-9f3a-4cc6-a118-82551641ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-0a30667b-a625-4d23-845b-361b0ac4156c,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-9a09f65a-9045-4a35-a482-bafbd9855c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-676b607a-c079-441e-ae87-73bbfbb658d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-de4c7de1-2ed9-4363-8024-bc70e6a2cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-42bfad32-0810-4c63-9a74-e427c6654a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-725538127-172.17.0.20-1597367125465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36310,DS-501a22a6-4be5-4c0d-8cf0-0db5d00b40b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-26794148-ef79-4290-996f-a27070c12bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-6bb7daf7-6606-4ca3-8a53-a4c0ea16f860,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-cd23c86a-3cf5-4cd6-b714-3c703f3f12c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-704898b6-fdf6-4f45-ad8a-bb9e495bba31,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-9dbad18f-3d86-445e-9af0-331ff0aaeffa,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-ffd30791-24eb-40c6-a046-71dadfd8409a,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-95099fc9-97dd-42fd-b2a1-672ca9670eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-725538127-172.17.0.20-1597367125465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36310,DS-501a22a6-4be5-4c0d-8cf0-0db5d00b40b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-26794148-ef79-4290-996f-a27070c12bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-6bb7daf7-6606-4ca3-8a53-a4c0ea16f860,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-cd23c86a-3cf5-4cd6-b714-3c703f3f12c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-704898b6-fdf6-4f45-ad8a-bb9e495bba31,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-9dbad18f-3d86-445e-9af0-331ff0aaeffa,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-ffd30791-24eb-40c6-a046-71dadfd8409a,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-95099fc9-97dd-42fd-b2a1-672ca9670eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328672198-172.17.0.20-1597367304392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-a9144737-5fc2-47f4-a679-458577243135,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-53cab688-ba44-40d8-8a9d-b277cc83002b,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-1bd5c9b6-eb40-44fe-9083-60c38380b433,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-072bc539-ca18-4f25-b6ea-750025d4c3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-0cada59f-eef2-4dd0-bdf7-ed4c0c9e77cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-d61c8d60-4943-4fa5-8cad-5d88e850d77f,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-a189d18c-cb38-4564-89bf-50271c011304,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-a13c9e98-9a9d-463d-b7e0-f0a41c1b4a62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328672198-172.17.0.20-1597367304392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-a9144737-5fc2-47f4-a679-458577243135,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-53cab688-ba44-40d8-8a9d-b277cc83002b,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-1bd5c9b6-eb40-44fe-9083-60c38380b433,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-072bc539-ca18-4f25-b6ea-750025d4c3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-0cada59f-eef2-4dd0-bdf7-ed4c0c9e77cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-d61c8d60-4943-4fa5-8cad-5d88e850d77f,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-a189d18c-cb38-4564-89bf-50271c011304,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-a13c9e98-9a9d-463d-b7e0-f0a41c1b4a62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136722866-172.17.0.20-1597367506233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-26c9e043-6d69-477c-b360-cccaf2400714,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-e2a8e4e8-d3fe-4244-8999-ab5649acf6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-3be82c47-8e7d-4bfd-ba0a-be73f2e33b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-fd5f3be2-a053-49a6-bd88-8dd09011d368,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-3fd0a57c-c9c8-4516-97ae-8277be225a80,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-3052ca18-e2d6-42a4-9430-2a86f1f264c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-87190e40-9be0-4e5c-88be-11d2af799372,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-4bf41f30-7acb-420c-a65e-fe8993743de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136722866-172.17.0.20-1597367506233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-26c9e043-6d69-477c-b360-cccaf2400714,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-e2a8e4e8-d3fe-4244-8999-ab5649acf6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-3be82c47-8e7d-4bfd-ba0a-be73f2e33b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-fd5f3be2-a053-49a6-bd88-8dd09011d368,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-3fd0a57c-c9c8-4516-97ae-8277be225a80,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-3052ca18-e2d6-42a4-9430-2a86f1f264c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-87190e40-9be0-4e5c-88be-11d2af799372,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-4bf41f30-7acb-420c-a65e-fe8993743de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888880609-172.17.0.20-1597368492698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-b043e2bf-ed97-46ba-aace-025e9eb099ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-d38e2b9e-4c4f-41f1-9a3b-ad563f7872e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-58b51f60-2d4b-4afa-8ee7-805c5ac55321,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-6fae5c86-f98f-4c13-873c-d74d3956f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-562339de-e663-4107-92d1-24e1a59dfd01,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-5260dfef-2511-4d55-a438-16a0671e46de,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-6b13737f-159d-4a94-8fe0-102d6c9aed77,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-2a65c714-12c5-4cbf-88a0-e5cd6daa192f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888880609-172.17.0.20-1597368492698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-b043e2bf-ed97-46ba-aace-025e9eb099ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-d38e2b9e-4c4f-41f1-9a3b-ad563f7872e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-58b51f60-2d4b-4afa-8ee7-805c5ac55321,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-6fae5c86-f98f-4c13-873c-d74d3956f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-562339de-e663-4107-92d1-24e1a59dfd01,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-5260dfef-2511-4d55-a438-16a0671e46de,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-6b13737f-159d-4a94-8fe0-102d6c9aed77,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-2a65c714-12c5-4cbf-88a0-e5cd6daa192f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551113835-172.17.0.20-1597369540673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44990,DS-f0bfe72c-0d67-4a46-a597-64533c86c685,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-16a054c4-5d21-473b-9472-1a1a04728083,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-d179198e-da66-4fe8-b04a-a483a6dd205c,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-1ed456db-d5ce-49f4-b5cf-ee1bfa1e9a88,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-de58c00d-172a-442a-bf36-ec38c9eb77a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-c5e52383-9129-4bc8-8250-8ee23d11fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-88d4246b-49fd-4d45-a13d-803c7f2c877a,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-5612b0b0-c9a0-4bc4-b5d0-0e907d999c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551113835-172.17.0.20-1597369540673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44990,DS-f0bfe72c-0d67-4a46-a597-64533c86c685,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-16a054c4-5d21-473b-9472-1a1a04728083,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-d179198e-da66-4fe8-b04a-a483a6dd205c,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-1ed456db-d5ce-49f4-b5cf-ee1bfa1e9a88,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-de58c00d-172a-442a-bf36-ec38c9eb77a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-c5e52383-9129-4bc8-8250-8ee23d11fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-88d4246b-49fd-4d45-a13d-803c7f2c877a,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-5612b0b0-c9a0-4bc4-b5d0-0e907d999c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100137064-172.17.0.20-1597369872263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-e0333505-b520-4876-894e-408bb5d582eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-bd2df27c-2594-47d8-ad63-ba3fbaa47df8,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-513f6426-a675-4f81-8296-0f1ed5c86a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-2595ea81-7673-4bbe-978e-597b9db1b600,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-b04c1ff6-ffe9-4745-b02f-c2c907ba633b,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-92c4c926-1234-4486-85e5-0f69b4800cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-c2ac115c-8dd8-4f69-b0fa-0b2810fb9f47,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-11be6305-3040-44a2-bbe9-391de7736968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100137064-172.17.0.20-1597369872263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41408,DS-e0333505-b520-4876-894e-408bb5d582eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-bd2df27c-2594-47d8-ad63-ba3fbaa47df8,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-513f6426-a675-4f81-8296-0f1ed5c86a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-2595ea81-7673-4bbe-978e-597b9db1b600,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-b04c1ff6-ffe9-4745-b02f-c2c907ba633b,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-92c4c926-1234-4486-85e5-0f69b4800cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-c2ac115c-8dd8-4f69-b0fa-0b2810fb9f47,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-11be6305-3040-44a2-bbe9-391de7736968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070281962-172.17.0.20-1597370145304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-c3b4fb09-5228-480f-bfab-7525dc27227a,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-88f8350b-27e1-4bd9-8bf0-c62f180a0ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-fdd12b41-8a25-4ea6-8dda-1cdc637289c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-13f3a27a-6ed3-4315-bba2-b5b04be5a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-c542eda8-a8f3-4e22-9df4-9afa4baa8ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-41cc5644-3682-47af-a15b-8dfdbc5bdb88,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-3bda0028-b3ad-49e0-9adc-c830f85fd178,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-6f6317a9-f9bf-4f96-a229-d9c86da745be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070281962-172.17.0.20-1597370145304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42188,DS-c3b4fb09-5228-480f-bfab-7525dc27227a,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-88f8350b-27e1-4bd9-8bf0-c62f180a0ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-fdd12b41-8a25-4ea6-8dda-1cdc637289c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-13f3a27a-6ed3-4315-bba2-b5b04be5a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-c542eda8-a8f3-4e22-9df4-9afa4baa8ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-41cc5644-3682-47af-a15b-8dfdbc5bdb88,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-3bda0028-b3ad-49e0-9adc-c830f85fd178,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-6f6317a9-f9bf-4f96-a229-d9c86da745be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049096671-172.17.0.20-1597370523341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44444,DS-e8df712c-7ca6-4f4f-a71a-1f71e0e6e9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-a24dafe5-309e-4b1e-a831-3806df4a90d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-a3a38c81-6635-46e3-8d26-23a03640bd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-7e90f22c-6594-424e-8555-f2c46596687a,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-e6878fa4-8b18-48bc-9c7b-89b8decb6c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-9b92fce5-89a9-414f-8bb0-73e7dbd045e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-d9ab1920-c5da-4169-93b1-d419b789f046,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-787cb6d1-8020-4a99-b438-a5d398358dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049096671-172.17.0.20-1597370523341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44444,DS-e8df712c-7ca6-4f4f-a71a-1f71e0e6e9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-a24dafe5-309e-4b1e-a831-3806df4a90d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-a3a38c81-6635-46e3-8d26-23a03640bd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-7e90f22c-6594-424e-8555-f2c46596687a,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-e6878fa4-8b18-48bc-9c7b-89b8decb6c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-9b92fce5-89a9-414f-8bb0-73e7dbd045e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-d9ab1920-c5da-4169-93b1-d419b789f046,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-787cb6d1-8020-4a99-b438-a5d398358dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 2000
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2143464180-172.17.0.20-1597370622988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-53f79583-e1e2-41bd-b748-55e8c97dceff,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-eab118af-c935-41f4-b79c-277245fc3139,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-67a59b6f-4aa8-469d-b7b4-1943359da990,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-f0be2603-5d47-491a-a9d5-42ba459a483c,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-a9a5d94f-64a5-48c8-9c52-0c0f144f0bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-ddc2a497-4249-4978-a665-5460e26fb868,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-345f860c-033f-4dee-8204-8f1dd56db466,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-ae40e9ea-ba74-4d55-b9bc-2d15f675939e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2143464180-172.17.0.20-1597370622988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-53f79583-e1e2-41bd-b748-55e8c97dceff,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-eab118af-c935-41f4-b79c-277245fc3139,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-67a59b6f-4aa8-469d-b7b4-1943359da990,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-f0be2603-5d47-491a-a9d5-42ba459a483c,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-a9a5d94f-64a5-48c8-9c52-0c0f144f0bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-ddc2a497-4249-4978-a665-5460e26fb868,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-345f860c-033f-4dee-8204-8f1dd56db466,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-ae40e9ea-ba74-4d55-b9bc-2d15f675939e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5478
