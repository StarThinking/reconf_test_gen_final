reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968698793-172.17.0.16-1597510659789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-2737d7bf-51f3-4133-8899-fd68927e657c,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-3597476f-c3fa-44d0-922c-5cef762207d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-3a84b1d9-51dd-44fe-90e5-6439bffd8cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-b50fe701-be27-4fbe-9db5-f22588ebd06e,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-710110f6-0f3b-4db3-97b3-d5b305950261,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-73fb979e-90a0-4ad7-b430-0c4b354a5cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-667bd1bf-d94e-43dc-bc32-71d69a0e76ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-b42ebaa5-1814-49bb-91e5-af79a25bfcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968698793-172.17.0.16-1597510659789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-2737d7bf-51f3-4133-8899-fd68927e657c,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-3597476f-c3fa-44d0-922c-5cef762207d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-3a84b1d9-51dd-44fe-90e5-6439bffd8cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-b50fe701-be27-4fbe-9db5-f22588ebd06e,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-710110f6-0f3b-4db3-97b3-d5b305950261,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-73fb979e-90a0-4ad7-b430-0c4b354a5cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-667bd1bf-d94e-43dc-bc32-71d69a0e76ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-b42ebaa5-1814-49bb-91e5-af79a25bfcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066824263-172.17.0.16-1597511010369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40966,DS-9f5c5dac-e4cc-440c-a9ed-711555dd58dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-dbf5b093-5dc6-4153-b00b-2ec5edacee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-d52697cd-10de-4dac-bca3-aa6ccbac766c,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-a7d165b5-c426-4241-b04c-b1e61453ce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-1a30f113-a277-4c59-83fc-d72824a47c25,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-d3235f41-fa44-4be3-b1e7-29f210ad78fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-d04a8e26-3594-455d-88bf-7755438d7e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-a4fbf900-e3df-4f51-b335-57a91be81bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066824263-172.17.0.16-1597511010369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40966,DS-9f5c5dac-e4cc-440c-a9ed-711555dd58dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-dbf5b093-5dc6-4153-b00b-2ec5edacee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-d52697cd-10de-4dac-bca3-aa6ccbac766c,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-a7d165b5-c426-4241-b04c-b1e61453ce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-1a30f113-a277-4c59-83fc-d72824a47c25,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-d3235f41-fa44-4be3-b1e7-29f210ad78fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-d04a8e26-3594-455d-88bf-7755438d7e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-a4fbf900-e3df-4f51-b335-57a91be81bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018488263-172.17.0.16-1597511428485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-2285ef66-1f82-470b-94d0-ab9197dd35e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-a596f15f-7804-4c6e-b292-e613f95e785c,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-8e8ed646-b35c-47c7-b4b1-d0d11f1c6cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-82d850c3-4c16-4512-80e9-2d58d94940b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-c392ce89-ebe0-46d7-9df2-9677f00e2cab,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-b9cdfacb-5d32-403a-b527-6094f5da1675,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-b51f9a27-2366-4330-ad1d-dce453e45e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-2c7a26a7-806f-4b97-a031-e4b7b04f1a5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018488263-172.17.0.16-1597511428485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-2285ef66-1f82-470b-94d0-ab9197dd35e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-a596f15f-7804-4c6e-b292-e613f95e785c,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-8e8ed646-b35c-47c7-b4b1-d0d11f1c6cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-82d850c3-4c16-4512-80e9-2d58d94940b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-c392ce89-ebe0-46d7-9df2-9677f00e2cab,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-b9cdfacb-5d32-403a-b527-6094f5da1675,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-b51f9a27-2366-4330-ad1d-dce453e45e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-2c7a26a7-806f-4b97-a031-e4b7b04f1a5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322395061-172.17.0.16-1597512498063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-a77be227-656c-4b03-899e-b598ab3d20a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-7d41e01d-1ece-4dc1-9628-b99cf8c4ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-7d918542-0a9a-43a6-b1b4-a5289f8d0113,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-5c258935-8e36-4c5d-a951-f41fdab1f5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-ab904b80-5c98-4609-b085-6682db640344,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-87e45193-bdb1-4074-b4b7-e57e71548985,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-84f757e5-9d98-4c52-a057-3e3673200edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-527615a6-7c31-44ae-a919-0163fe087935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322395061-172.17.0.16-1597512498063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-a77be227-656c-4b03-899e-b598ab3d20a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-7d41e01d-1ece-4dc1-9628-b99cf8c4ece8,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-7d918542-0a9a-43a6-b1b4-a5289f8d0113,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-5c258935-8e36-4c5d-a951-f41fdab1f5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-ab904b80-5c98-4609-b085-6682db640344,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-87e45193-bdb1-4074-b4b7-e57e71548985,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-84f757e5-9d98-4c52-a057-3e3673200edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-527615a6-7c31-44ae-a919-0163fe087935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907504194-172.17.0.16-1597512704472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40270,DS-fae327a2-7d08-4f7d-a8cc-2790616d522e,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-88a27eb7-08ce-40fc-bb97-592f3410c91a,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-45af1049-2200-4367-91bb-b2a1bcb3d5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-5ebbf48c-9a1d-49ed-887f-f5863c9f1530,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-b84749c8-b26e-46b0-84d5-2d4711084850,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-e974d48b-12b6-4bda-91da-46a618918994,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-42aea95c-9fa4-4cb0-b2c6-ffa7e9edcdef,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-67f84a5b-d7d1-41e9-87c8-8575adcf9375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907504194-172.17.0.16-1597512704472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40270,DS-fae327a2-7d08-4f7d-a8cc-2790616d522e,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-88a27eb7-08ce-40fc-bb97-592f3410c91a,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-45af1049-2200-4367-91bb-b2a1bcb3d5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-5ebbf48c-9a1d-49ed-887f-f5863c9f1530,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-b84749c8-b26e-46b0-84d5-2d4711084850,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-e974d48b-12b6-4bda-91da-46a618918994,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-42aea95c-9fa4-4cb0-b2c6-ffa7e9edcdef,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-67f84a5b-d7d1-41e9-87c8-8575adcf9375,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817362700-172.17.0.16-1597513125070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-3864e769-d472-4ed4-981f-a73ffeb73b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-3c3ed2be-d9ea-45c3-8f75-ff5b27f100a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-4b55bfd0-fbc6-43fa-a21d-cf590db64546,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-15427912-080d-4eb5-a7bd-6a45d6fb5235,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-5c137cbe-a137-4d0a-90f6-fe652f706ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-0f40d773-2e7d-4f43-a348-a7d551cc0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-61c8cf20-8a4e-4700-942a-cb4da5539fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-b7872774-83f8-4e92-b842-885b1f219f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817362700-172.17.0.16-1597513125070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-3864e769-d472-4ed4-981f-a73ffeb73b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-3c3ed2be-d9ea-45c3-8f75-ff5b27f100a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-4b55bfd0-fbc6-43fa-a21d-cf590db64546,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-15427912-080d-4eb5-a7bd-6a45d6fb5235,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-5c137cbe-a137-4d0a-90f6-fe652f706ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-0f40d773-2e7d-4f43-a348-a7d551cc0b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-61c8cf20-8a4e-4700-942a-cb4da5539fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-b7872774-83f8-4e92-b842-885b1f219f3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554683623-172.17.0.16-1597513175945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37474,DS-0f18d813-2c05-44ed-9d8f-b23b980bb254,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-141217df-bc19-41a3-9d29-a59ab91e47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-a11ab9ae-9349-4251-86fe-dc37fb927adc,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-f4515d88-0176-4486-8561-c8f4f1321ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-394186fd-840d-46ac-bff2-a99a58f0e066,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-669b4daa-c40b-4cdd-a295-bdf120b8e0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-4c61cb5f-b4c6-47b4-a6c0-844d6dbefd45,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-a2618a2a-b810-421d-a58e-4ec19c5cc114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-554683623-172.17.0.16-1597513175945:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37474,DS-0f18d813-2c05-44ed-9d8f-b23b980bb254,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-141217df-bc19-41a3-9d29-a59ab91e47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-a11ab9ae-9349-4251-86fe-dc37fb927adc,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-f4515d88-0176-4486-8561-c8f4f1321ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-394186fd-840d-46ac-bff2-a99a58f0e066,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-669b4daa-c40b-4cdd-a295-bdf120b8e0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-4c61cb5f-b4c6-47b4-a6c0-844d6dbefd45,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-a2618a2a-b810-421d-a58e-4ec19c5cc114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042916571-172.17.0.16-1597513262830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46623,DS-ccfeadd4-6662-46fc-8694-8a1bd3ed8de9,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-99ec8585-663e-4fa5-85cb-2feafb9fc5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-7cc4cd2f-80c8-4df4-b2c6-7f2fb193e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-ac7e1a0a-e876-4b94-a74d-a5721472316e,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-4434c08a-0847-4732-8da7-b29708c903b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-49b4633f-7bbf-45d7-9194-901c202a8bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-97aae405-59d7-4e68-b6bb-5bed708ba737,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-881e0b87-fae4-4cd4-bb9d-8ebd6cea1d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042916571-172.17.0.16-1597513262830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46623,DS-ccfeadd4-6662-46fc-8694-8a1bd3ed8de9,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-99ec8585-663e-4fa5-85cb-2feafb9fc5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-7cc4cd2f-80c8-4df4-b2c6-7f2fb193e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-ac7e1a0a-e876-4b94-a74d-a5721472316e,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-4434c08a-0847-4732-8da7-b29708c903b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-49b4633f-7bbf-45d7-9194-901c202a8bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-97aae405-59d7-4e68-b6bb-5bed708ba737,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-881e0b87-fae4-4cd4-bb9d-8ebd6cea1d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672781370-172.17.0.16-1597514120386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40760,DS-dde27675-da6b-4904-839e-42597add85e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-1f28f371-4143-48ee-a5e8-718026ba80e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-babc69df-b123-4fac-ab07-e4df170bdf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-59f3a1ed-3781-4709-8c25-60528128618f,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-209a0f21-5076-4fae-9bc9-2f8934f6dc48,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-72d00494-2cf1-47f1-b688-f864ec86b5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-37c38aac-4b24-4276-8a9f-460e88cf1680,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-c70a5974-0862-4fd1-8c51-1b76908766be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672781370-172.17.0.16-1597514120386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40760,DS-dde27675-da6b-4904-839e-42597add85e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-1f28f371-4143-48ee-a5e8-718026ba80e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-babc69df-b123-4fac-ab07-e4df170bdf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-59f3a1ed-3781-4709-8c25-60528128618f,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-209a0f21-5076-4fae-9bc9-2f8934f6dc48,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-72d00494-2cf1-47f1-b688-f864ec86b5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-37c38aac-4b24-4276-8a9f-460e88cf1680,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-c70a5974-0862-4fd1-8c51-1b76908766be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200833652-172.17.0.16-1597514252957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36584,DS-92ad2176-6ed7-418f-b9ae-2c7cfa24c419,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-c8af5e0c-551a-4ed0-92d7-a5a8d821bdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-75084208-6f5d-4f5f-a460-a0d50ba49095,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f325fdaa-5196-4e4f-9f35-83e136431765,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-66619c9f-b470-46b1-8166-84bf14ebaf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-b5a51d62-02d1-4962-a24a-86ab1a1a6d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-ecb7e512-dd24-47f2-9ae7-ea71018b6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-a4cdedb1-5f46-453b-bd82-34cceb621ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200833652-172.17.0.16-1597514252957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36584,DS-92ad2176-6ed7-418f-b9ae-2c7cfa24c419,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-c8af5e0c-551a-4ed0-92d7-a5a8d821bdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-75084208-6f5d-4f5f-a460-a0d50ba49095,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-f325fdaa-5196-4e4f-9f35-83e136431765,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-66619c9f-b470-46b1-8166-84bf14ebaf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-b5a51d62-02d1-4962-a24a-86ab1a1a6d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-ecb7e512-dd24-47f2-9ae7-ea71018b6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-a4cdedb1-5f46-453b-bd82-34cceb621ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577588137-172.17.0.16-1597514400516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-b827fa86-997a-4f0e-8591-18096e36ccef,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-7466fc41-3866-4859-aa0d-23dc43ad92d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-00c132cf-7ee2-46fc-9af7-9dc7d0eca649,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-01ff98c7-a4c8-42df-a4b8-16b80b771a19,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-a8a062a5-7982-47b3-b778-4bcf34883232,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-378b478a-8eca-4b73-aa7c-9beb6b8fe311,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-e008527e-ebef-4e7d-b34a-8118769b51c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-c0be1c81-aa38-44d9-b09b-4da3fefc3ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577588137-172.17.0.16-1597514400516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37657,DS-b827fa86-997a-4f0e-8591-18096e36ccef,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-7466fc41-3866-4859-aa0d-23dc43ad92d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-00c132cf-7ee2-46fc-9af7-9dc7d0eca649,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-01ff98c7-a4c8-42df-a4b8-16b80b771a19,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-a8a062a5-7982-47b3-b778-4bcf34883232,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-378b478a-8eca-4b73-aa7c-9beb6b8fe311,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-e008527e-ebef-4e7d-b34a-8118769b51c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-c0be1c81-aa38-44d9-b09b-4da3fefc3ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646080283-172.17.0.16-1597515181719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43866,DS-53d82286-93df-47bc-8e11-a61a09428a32,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-f78018c0-fe18-40c7-b0e5-001841bf3079,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-cb3127d6-dfc5-4ee8-b210-be9d8481f394,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-da23a570-fc9b-4531-8133-9cd9fb8ca8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-1193c887-e0f8-48ae-aea4-bb1b0d84e0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-cdaf6fcd-b2c0-4643-b45a-27c50402b572,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-43f65ff6-bcc1-4125-951a-2f7c7bbb1202,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-38a04b5a-d08f-4424-bab9-0f04c3a43f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-646080283-172.17.0.16-1597515181719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43866,DS-53d82286-93df-47bc-8e11-a61a09428a32,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-f78018c0-fe18-40c7-b0e5-001841bf3079,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-cb3127d6-dfc5-4ee8-b210-be9d8481f394,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-da23a570-fc9b-4531-8133-9cd9fb8ca8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-1193c887-e0f8-48ae-aea4-bb1b0d84e0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-cdaf6fcd-b2c0-4643-b45a-27c50402b572,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-43f65ff6-bcc1-4125-951a-2f7c7bbb1202,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-38a04b5a-d08f-4424-bab9-0f04c3a43f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935162853-172.17.0.16-1597515784469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44793,DS-47f70a6a-c43f-47da-af03-6168e5530762,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-9f67758d-df5a-404d-a937-1402dec5a822,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-a359890f-bf98-4ab2-8892-60c5bb27a37d,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-203ec61e-ffb7-4f9f-b503-e1cf5d78a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-670374fa-ec1f-43f7-909c-3770877e64ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-c7b2670a-a969-49d7-a75e-fb98071e9a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-1a53a770-bbf4-48c8-a3e3-3b0056251c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-2afd38b0-f3c5-42e2-aa6f-62cf4f9b4eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935162853-172.17.0.16-1597515784469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44793,DS-47f70a6a-c43f-47da-af03-6168e5530762,DISK], DatanodeInfoWithStorage[127.0.0.1:39767,DS-9f67758d-df5a-404d-a937-1402dec5a822,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-a359890f-bf98-4ab2-8892-60c5bb27a37d,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-203ec61e-ffb7-4f9f-b503-e1cf5d78a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-670374fa-ec1f-43f7-909c-3770877e64ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-c7b2670a-a969-49d7-a75e-fb98071e9a86,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-1a53a770-bbf4-48c8-a3e3-3b0056251c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-2afd38b0-f3c5-42e2-aa6f-62cf4f9b4eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428983360-172.17.0.16-1597516191865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40942,DS-a9137f2d-c6b1-4a7d-912d-8d6d49c336b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-2b2b547a-7129-49bb-85c7-7f40f2ef3cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-7bc68bc4-77d5-43e4-b232-fc3ae1cf0ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-ab1ef9d5-e856-4f57-8bbd-26b2a6f097ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-c573321a-661f-4d79-a000-da09f192d96c,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-b37b5e5b-d71d-42f6-b7ef-fc3e158c9c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-a262bb42-1286-4db5-8900-a668dcf0ac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-65950542-0409-439e-8a22-cadb2d951deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428983360-172.17.0.16-1597516191865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40942,DS-a9137f2d-c6b1-4a7d-912d-8d6d49c336b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-2b2b547a-7129-49bb-85c7-7f40f2ef3cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-7bc68bc4-77d5-43e4-b232-fc3ae1cf0ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-ab1ef9d5-e856-4f57-8bbd-26b2a6f097ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-c573321a-661f-4d79-a000-da09f192d96c,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-b37b5e5b-d71d-42f6-b7ef-fc3e158c9c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-a262bb42-1286-4db5-8900-a668dcf0ac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-65950542-0409-439e-8a22-cadb2d951deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272141265-172.17.0.16-1597516318028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-48a11126-71c3-4f5e-97fc-10393cf34f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-cb0a921a-9552-48d8-bef5-1a59cc523933,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-bdf40cb0-2501-4bbf-8f88-dc276ba471f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-4f764c6a-6375-42b8-9984-b0ef9e1f0093,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-c51845d6-b5a2-40c9-9886-0b9d49ae877a,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-b5d36e49-0296-4afa-bc0d-fa8d2403f63a,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-7c865db2-a353-4280-bd76-7aa39a1e3fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-0c04c81d-aa40-47b3-9b05-fa18a5c642d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272141265-172.17.0.16-1597516318028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-48a11126-71c3-4f5e-97fc-10393cf34f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-cb0a921a-9552-48d8-bef5-1a59cc523933,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-bdf40cb0-2501-4bbf-8f88-dc276ba471f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-4f764c6a-6375-42b8-9984-b0ef9e1f0093,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-c51845d6-b5a2-40c9-9886-0b9d49ae877a,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-b5d36e49-0296-4afa-bc0d-fa8d2403f63a,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-7c865db2-a353-4280-bd76-7aa39a1e3fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-0c04c81d-aa40-47b3-9b05-fa18a5c642d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877412056-172.17.0.16-1597516358695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42366,DS-6fdac1da-37ae-41b1-818b-4565730c649e,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-8972f584-6c6d-46a0-863e-1a4fcb954dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-8af44461-dd47-4f6e-9372-23e9a19e115f,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-e9ba8251-a411-4656-9d6e-9595c4cf13ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-d3b80116-e75b-480a-981b-2afd32af08d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-82e74632-d663-40fe-916a-17622e3db1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-e72524ee-db4c-4946-9070-005f21eed6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-9f693216-442d-4c2c-9944-ffadbcff32b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877412056-172.17.0.16-1597516358695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42366,DS-6fdac1da-37ae-41b1-818b-4565730c649e,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-8972f584-6c6d-46a0-863e-1a4fcb954dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-8af44461-dd47-4f6e-9372-23e9a19e115f,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-e9ba8251-a411-4656-9d6e-9595c4cf13ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-d3b80116-e75b-480a-981b-2afd32af08d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-82e74632-d663-40fe-916a-17622e3db1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-e72524ee-db4c-4946-9070-005f21eed6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-9f693216-442d-4c2c-9944-ffadbcff32b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.expiry.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176881106-172.17.0.16-1597516997861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44769,DS-9e7ee359-7d86-4827-b493-51cdc1755a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-4366e23e-ad11-4223-bf51-12271d97e267,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-8b438122-2ee1-4009-a4ca-26f4b93e06d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-c592afc0-c071-43ff-be33-83c7b5dc8602,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-6f4f7be0-d280-44ba-9744-aa0efc6b251f,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-751a1a05-5349-4df1-9f09-01a2c05a770d,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-0ead403f-dd59-4100-b95d-40df630c2995,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-61c001dd-5b05-4e22-87d8-dbbdeb131fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-176881106-172.17.0.16-1597516997861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44769,DS-9e7ee359-7d86-4827-b493-51cdc1755a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-4366e23e-ad11-4223-bf51-12271d97e267,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-8b438122-2ee1-4009-a4ca-26f4b93e06d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-c592afc0-c071-43ff-be33-83c7b5dc8602,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-6f4f7be0-d280-44ba-9744-aa0efc6b251f,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-751a1a05-5349-4df1-9f09-01a2c05a770d,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-0ead403f-dd59-4100-b95d-40df630c2995,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-61c001dd-5b05-4e22-87d8-dbbdeb131fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6743
