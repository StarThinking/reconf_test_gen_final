reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262071487-172.17.0.5-1597526101129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38384,DS-a2f4fbfb-578d-46e7-bc8f-0972c9cda8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-43b11669-f84c-4a78-8ab1-18fb3bd442cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-ed4ad6fe-19c3-477f-bb95-f72e63e384c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-f55a1ed6-ea6f-4e04-8705-902b7b14d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-e2a6c470-a4ea-4117-b920-41144ddc8072,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-376390a9-f6ef-429d-94eb-38b4adece14f,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-9ff7d5bd-85af-4b6c-a8a6-cf0b60f94a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-afdcf55e-e7cb-4bff-97a3-6caec9ab72d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262071487-172.17.0.5-1597526101129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38384,DS-a2f4fbfb-578d-46e7-bc8f-0972c9cda8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-43b11669-f84c-4a78-8ab1-18fb3bd442cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-ed4ad6fe-19c3-477f-bb95-f72e63e384c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-f55a1ed6-ea6f-4e04-8705-902b7b14d8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-e2a6c470-a4ea-4117-b920-41144ddc8072,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-376390a9-f6ef-429d-94eb-38b4adece14f,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-9ff7d5bd-85af-4b6c-a8a6-cf0b60f94a19,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-afdcf55e-e7cb-4bff-97a3-6caec9ab72d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111834427-172.17.0.5-1597526354391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37134,DS-c9de4613-a5f3-46f6-a4de-97ea16cc374f,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-584cc86b-9b62-440e-9b40-c1b2fb591d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-c9e42810-fe43-4fe2-a153-4aa5e12d6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-2da864c1-096a-4ce0-9e39-aee84ef3a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-b1ab38d1-d1bb-4627-8e59-73ca3b46ddae,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-902754e5-31f5-49da-bdec-932b7f162ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-12b129b1-fcc5-4a1a-9935-b9155c463b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-5f3fab83-ea7e-464e-bd3c-f1495c2ca776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111834427-172.17.0.5-1597526354391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37134,DS-c9de4613-a5f3-46f6-a4de-97ea16cc374f,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-584cc86b-9b62-440e-9b40-c1b2fb591d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-c9e42810-fe43-4fe2-a153-4aa5e12d6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-2da864c1-096a-4ce0-9e39-aee84ef3a4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-b1ab38d1-d1bb-4627-8e59-73ca3b46ddae,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-902754e5-31f5-49da-bdec-932b7f162ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-12b129b1-fcc5-4a1a-9935-b9155c463b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-5f3fab83-ea7e-464e-bd3c-f1495c2ca776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990776747-172.17.0.5-1597526805214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43594,DS-60f280c3-d645-4c9c-92ef-abc958df15bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-647f15de-c665-439b-be4c-0ba8ff715c66,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-6c365fce-b2a9-4c27-935d-e5a531b92f86,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-c1e34131-a0c1-49ce-8e09-eed4bad42d92,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-c5efa473-9ff3-4b1d-9375-f604b9ed9444,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-14b36cf8-f7d7-4770-b666-2aafda281f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-877c19e0-59c4-4ab3-aeb2-f3af76fe13cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-d66a6c9c-07f2-47c7-8c2e-36a89e4c4128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990776747-172.17.0.5-1597526805214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43594,DS-60f280c3-d645-4c9c-92ef-abc958df15bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-647f15de-c665-439b-be4c-0ba8ff715c66,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-6c365fce-b2a9-4c27-935d-e5a531b92f86,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-c1e34131-a0c1-49ce-8e09-eed4bad42d92,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-c5efa473-9ff3-4b1d-9375-f604b9ed9444,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-14b36cf8-f7d7-4770-b666-2aafda281f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-877c19e0-59c4-4ab3-aeb2-f3af76fe13cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-d66a6c9c-07f2-47c7-8c2e-36a89e4c4128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873184752-172.17.0.5-1597526839797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35506,DS-b17ba7b6-3830-41aa-b0c2-9f5586e076ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-58354f04-511f-4288-a311-603439ca703a,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-1e4dbfde-fbc4-479a-b985-eee7695d773e,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-5687e98b-e7a0-47d0-ab35-1c32115fd078,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-546ead92-5a07-464b-ac3c-d3d25158761c,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-015b7661-d5fc-4923-a57f-595b3f496943,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-6036cf3e-28ad-431a-a144-a3acb5bc1da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-ba6daa3b-9670-4b13-8bb2-709ea7fb27ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873184752-172.17.0.5-1597526839797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35506,DS-b17ba7b6-3830-41aa-b0c2-9f5586e076ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-58354f04-511f-4288-a311-603439ca703a,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-1e4dbfde-fbc4-479a-b985-eee7695d773e,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-5687e98b-e7a0-47d0-ab35-1c32115fd078,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-546ead92-5a07-464b-ac3c-d3d25158761c,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-015b7661-d5fc-4923-a57f-595b3f496943,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-6036cf3e-28ad-431a-a144-a3acb5bc1da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-ba6daa3b-9670-4b13-8bb2-709ea7fb27ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504412601-172.17.0.5-1597527090916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-58b466fa-f088-4d46-a5f2-dd0a1e92549e,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-e2d6e2b8-1ff8-46af-870d-5ca6a9a61756,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-8034f2fb-c523-4535-9186-b0f4c79e9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-2cf06dde-73e6-4d49-b7af-ff00c529a510,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-fa98dd2d-6bb7-47e4-a151-b907b7826a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-e9b3c29c-82c0-4f9f-bb92-cd3e56d165d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-057e0001-65a0-4c42-95ec-d20d556b130e,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-86736261-e452-466f-9798-5ae4d6c17c57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504412601-172.17.0.5-1597527090916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-58b466fa-f088-4d46-a5f2-dd0a1e92549e,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-e2d6e2b8-1ff8-46af-870d-5ca6a9a61756,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-8034f2fb-c523-4535-9186-b0f4c79e9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-2cf06dde-73e6-4d49-b7af-ff00c529a510,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-fa98dd2d-6bb7-47e4-a151-b907b7826a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-e9b3c29c-82c0-4f9f-bb92-cd3e56d165d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-057e0001-65a0-4c42-95ec-d20d556b130e,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-86736261-e452-466f-9798-5ae4d6c17c57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769730354-172.17.0.5-1597527132314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-deb276f4-eb5b-4908-8f2e-fbeacb9aa41d,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-92207437-e821-48a4-b2e3-0cfcad2d1e90,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-eb4c8320-a9ea-4747-9503-61744da13400,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-bcba1c21-df2c-4d8c-8902-abc36ebb0459,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-e82e2156-038e-43d5-a3d4-29fd4fceef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-170eb547-0207-4a32-a788-5293b7307d22,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-d1721cd2-66b5-4498-b623-bd21895c1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-57118a43-3a42-4da4-8ebc-e549c28696c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769730354-172.17.0.5-1597527132314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-deb276f4-eb5b-4908-8f2e-fbeacb9aa41d,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-92207437-e821-48a4-b2e3-0cfcad2d1e90,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-eb4c8320-a9ea-4747-9503-61744da13400,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-bcba1c21-df2c-4d8c-8902-abc36ebb0459,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-e82e2156-038e-43d5-a3d4-29fd4fceef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-170eb547-0207-4a32-a788-5293b7307d22,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-d1721cd2-66b5-4498-b623-bd21895c1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-57118a43-3a42-4da4-8ebc-e549c28696c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511940301-172.17.0.5-1597527694613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44605,DS-33593bc0-aa24-490b-9bf2-2194e0ac4bea,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-cf560bf9-882f-4b90-89e7-bdf227c05b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-820488cc-718f-47e6-8f56-400fabac5398,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-8315bc93-237f-484f-8ae0-1a0eb175a126,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-87d67bcc-3d4e-43af-accc-61e800067074,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-c0b1e4e6-5ed4-4f94-a1f3-618e8f044ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-98ead70f-0026-47a4-a4bc-b2a0e4d29f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-8e7f51bb-d7bb-43e9-9f76-65ea1c68b9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1511940301-172.17.0.5-1597527694613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44605,DS-33593bc0-aa24-490b-9bf2-2194e0ac4bea,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-cf560bf9-882f-4b90-89e7-bdf227c05b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-820488cc-718f-47e6-8f56-400fabac5398,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-8315bc93-237f-484f-8ae0-1a0eb175a126,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-87d67bcc-3d4e-43af-accc-61e800067074,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-c0b1e4e6-5ed4-4f94-a1f3-618e8f044ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-98ead70f-0026-47a4-a4bc-b2a0e4d29f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-8e7f51bb-d7bb-43e9-9f76-65ea1c68b9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783290317-172.17.0.5-1597527767433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-b6e08bed-bb7c-4e39-9202-38c26548aa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-27493479-1eff-4823-b67c-75f7879066b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-e4d662d2-ad15-411b-959b-41189e8b8fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-d6013e09-7f80-4f46-881e-7ff367c48901,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-8a5626e6-f130-46b4-be1e-4ef69da3c643,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-cebd8e94-0214-406a-abbc-279d8dfb134c,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-8d0b472d-08d7-4702-bc71-9253bd66d931,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-4f49d4b0-b839-4a70-a5e3-822fd7fecbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783290317-172.17.0.5-1597527767433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-b6e08bed-bb7c-4e39-9202-38c26548aa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-27493479-1eff-4823-b67c-75f7879066b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-e4d662d2-ad15-411b-959b-41189e8b8fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-d6013e09-7f80-4f46-881e-7ff367c48901,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-8a5626e6-f130-46b4-be1e-4ef69da3c643,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-cebd8e94-0214-406a-abbc-279d8dfb134c,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-8d0b472d-08d7-4702-bc71-9253bd66d931,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-4f49d4b0-b839-4a70-a5e3-822fd7fecbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594578206-172.17.0.5-1597527879468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38432,DS-c921e81c-e2fe-4882-a341-b914d1188c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-459f34d9-14c6-495e-9a4c-9590e2013677,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-703e0ec1-9798-4596-bafa-1f39da5b1be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-415a0ea9-501b-4aff-845b-c039ca01cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-d9300ea1-5730-4dd4-a21e-5731aec1d1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-bc4e8cf0-7017-4f89-b449-f6052133b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-642bfe86-aa49-4581-a960-3bb5de097fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-e6f2da33-6b3f-4759-9198-c64079b6a045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594578206-172.17.0.5-1597527879468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38432,DS-c921e81c-e2fe-4882-a341-b914d1188c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-459f34d9-14c6-495e-9a4c-9590e2013677,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-703e0ec1-9798-4596-bafa-1f39da5b1be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-415a0ea9-501b-4aff-845b-c039ca01cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-d9300ea1-5730-4dd4-a21e-5731aec1d1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-bc4e8cf0-7017-4f89-b449-f6052133b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-642bfe86-aa49-4581-a960-3bb5de097fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-e6f2da33-6b3f-4759-9198-c64079b6a045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209036363-172.17.0.5-1597527915432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41772,DS-c33fa2eb-4748-4bf2-8d66-fca73ef2c146,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-c66a1bc6-67b5-4b43-b17c-6934c3f07564,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-52ee62a4-c48f-4370-b211-b85b0be2938b,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-d26f8e04-f00b-4284-a075-80de505031e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-aa4e7a5c-6c81-4ab7-a278-7e6045b8dab3,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-3a42db04-349d-4aa4-bc34-b45ff4f614ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-1054a748-3811-478b-a58a-eaf3cfc5b0af,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-5282e260-fa04-4481-a4ba-5cc72d01e9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209036363-172.17.0.5-1597527915432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41772,DS-c33fa2eb-4748-4bf2-8d66-fca73ef2c146,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-c66a1bc6-67b5-4b43-b17c-6934c3f07564,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-52ee62a4-c48f-4370-b211-b85b0be2938b,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-d26f8e04-f00b-4284-a075-80de505031e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-aa4e7a5c-6c81-4ab7-a278-7e6045b8dab3,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-3a42db04-349d-4aa4-bc34-b45ff4f614ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-1054a748-3811-478b-a58a-eaf3cfc5b0af,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-5282e260-fa04-4481-a4ba-5cc72d01e9bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848319728-172.17.0.5-1597528319059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-9db4e68b-9adf-450f-b36e-7efaf358eae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-7fbb62df-d4df-42fc-a1cc-8383289496ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-67da783d-4f7d-43ec-827d-54789cc38f12,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-e7dcb6be-a69d-46ba-a558-d83fd1a1645d,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-a5ada1ba-8145-4298-a339-8c571b8c2528,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-8cff2173-0fd0-4f5c-9ab5-3dccab77b891,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-adb1e5d1-7e94-423c-8772-cb1d7e9d6b81,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-e147043e-671c-4a72-964d-fbacbd9e646f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848319728-172.17.0.5-1597528319059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-9db4e68b-9adf-450f-b36e-7efaf358eae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-7fbb62df-d4df-42fc-a1cc-8383289496ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-67da783d-4f7d-43ec-827d-54789cc38f12,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-e7dcb6be-a69d-46ba-a558-d83fd1a1645d,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-a5ada1ba-8145-4298-a339-8c571b8c2528,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-8cff2173-0fd0-4f5c-9ab5-3dccab77b891,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-adb1e5d1-7e94-423c-8772-cb1d7e9d6b81,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-e147043e-671c-4a72-964d-fbacbd9e646f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447003340-172.17.0.5-1597528358860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40287,DS-131963d3-17f2-4f5c-8993-fdb7abb4450d,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-6f4ecb18-902a-40ef-9a24-870d8f814732,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-532c96ed-36a1-4a59-a392-68a0522798b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-7a8e7dc6-8c1c-427c-83d5-38ba1154cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-a3ee57c8-bba8-406b-b5ea-dc2227d5cee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-647d2f0d-1de8-44b0-b067-0ed2b7d0568f,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-5fa7fb70-8274-4b9b-80f9-f7753060ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-82668942-12ea-4988-a059-46e57c0ca187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447003340-172.17.0.5-1597528358860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40287,DS-131963d3-17f2-4f5c-8993-fdb7abb4450d,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-6f4ecb18-902a-40ef-9a24-870d8f814732,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-532c96ed-36a1-4a59-a392-68a0522798b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-7a8e7dc6-8c1c-427c-83d5-38ba1154cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-a3ee57c8-bba8-406b-b5ea-dc2227d5cee0,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-647d2f0d-1de8-44b0-b067-0ed2b7d0568f,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-5fa7fb70-8274-4b9b-80f9-f7753060ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-82668942-12ea-4988-a059-46e57c0ca187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855653496-172.17.0.5-1597528473627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-a597f374-d4d4-4486-b6b0-286c1570ff28,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-6413a54f-c8f2-4fa8-a3de-5d66cc603665,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-7f050c6b-4a45-4588-8da2-9552a3fa9d63,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-f9926f22-18f8-42ad-989f-7850e102127b,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-07755267-7efb-4008-983d-b18bf3da309e,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-666c52e1-60d4-4c6a-a6da-491c83fd02e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-bc135d4f-849c-4f23-97bc-975989b378de,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-dd13a4fa-9195-450d-ac4f-f72727b84125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855653496-172.17.0.5-1597528473627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-a597f374-d4d4-4486-b6b0-286c1570ff28,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-6413a54f-c8f2-4fa8-a3de-5d66cc603665,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-7f050c6b-4a45-4588-8da2-9552a3fa9d63,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-f9926f22-18f8-42ad-989f-7850e102127b,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-07755267-7efb-4008-983d-b18bf3da309e,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-666c52e1-60d4-4c6a-a6da-491c83fd02e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-bc135d4f-849c-4f23-97bc-975989b378de,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-dd13a4fa-9195-450d-ac4f-f72727b84125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232349269-172.17.0.5-1597528568119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45925,DS-feac51be-1f17-4d07-89d3-ff2189fef755,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-ac923852-9d8d-4f02-8610-438b9edcde59,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-6029e047-1674-486d-9fe8-e0a9b63a6ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-ce4b140b-1d84-4290-b168-8cfc43efe13e,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-de9c8a1f-8e64-4b81-8085-e813cf992d17,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-2bf87fea-fa7a-40c4-b472-57d0546df237,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-86251699-6d66-4558-92ae-d4e23aa8395a,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-c119edda-ba95-41fb-828d-ff6b45bdf95e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232349269-172.17.0.5-1597528568119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45925,DS-feac51be-1f17-4d07-89d3-ff2189fef755,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-ac923852-9d8d-4f02-8610-438b9edcde59,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-6029e047-1674-486d-9fe8-e0a9b63a6ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-ce4b140b-1d84-4290-b168-8cfc43efe13e,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-de9c8a1f-8e64-4b81-8085-e813cf992d17,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-2bf87fea-fa7a-40c4-b472-57d0546df237,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-86251699-6d66-4558-92ae-d4e23aa8395a,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-c119edda-ba95-41fb-828d-ff6b45bdf95e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833166155-172.17.0.5-1597528924444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-0aed6cf1-56b6-491c-9075-ea2fecbd9008,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-dfc7dc6d-36db-4098-b75c-9a3f41558c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-0efa3350-30a6-4191-81d8-3c732cbc2d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-64c1049b-d3f5-4213-a6ea-b4e7c249b427,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-e7bb2ebd-76b7-45a6-b00c-6e7290857e42,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-3c2b8dd3-b01a-4b81-bc31-449d00a36a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-d213894e-742c-4663-b009-aa03fc37f345,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-28a9ac8c-6f16-441f-8107-2a99912ebeb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833166155-172.17.0.5-1597528924444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40789,DS-0aed6cf1-56b6-491c-9075-ea2fecbd9008,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-dfc7dc6d-36db-4098-b75c-9a3f41558c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-0efa3350-30a6-4191-81d8-3c732cbc2d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-64c1049b-d3f5-4213-a6ea-b4e7c249b427,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-e7bb2ebd-76b7-45a6-b00c-6e7290857e42,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-3c2b8dd3-b01a-4b81-bc31-449d00a36a23,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-d213894e-742c-4663-b009-aa03fc37f345,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-28a9ac8c-6f16-441f-8107-2a99912ebeb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462754451-172.17.0.5-1597529348417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35018,DS-bb06f634-6b3f-4132-9696-f810aba07a06,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-255a66df-0ba1-4675-a5e2-5f3db8b6a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-54ab4a21-5a27-4113-bfa8-e64abd3e90d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-518fbe1e-b8b8-4ec1-adcb-21d8f0982961,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-fd6a1b82-d01a-437f-b674-0b08bd0d8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-f49724cc-e026-48da-b959-3a525e4068fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-8bbc4f0e-3957-4d55-81bd-ced11a0f67b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-0a9d5c44-1a4d-4102-a6e5-6e8b684a21d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462754451-172.17.0.5-1597529348417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35018,DS-bb06f634-6b3f-4132-9696-f810aba07a06,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-255a66df-0ba1-4675-a5e2-5f3db8b6a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-54ab4a21-5a27-4113-bfa8-e64abd3e90d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-518fbe1e-b8b8-4ec1-adcb-21d8f0982961,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-fd6a1b82-d01a-437f-b674-0b08bd0d8d18,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-f49724cc-e026-48da-b959-3a525e4068fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-8bbc4f0e-3957-4d55-81bd-ced11a0f67b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-0a9d5c44-1a4d-4102-a6e5-6e8b684a21d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878816089-172.17.0.5-1597529676911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42672,DS-4ec45929-8eba-4844-9200-597196d8268e,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-263bd0d6-bb37-4001-af44-f9806807b1db,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-fb6277fb-0c4e-49f5-9849-07baba121c83,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-5578b6eb-856a-48b2-808a-016b73316725,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-3e76ff86-280d-4e21-8549-56cf374026d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-220b141f-ffc7-4b5f-bf95-23fe3b553ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-160aa6a1-c7b0-46da-81b8-c0372da9f842,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-85318601-34a3-4d71-96e5-5bc6c2416f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878816089-172.17.0.5-1597529676911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42672,DS-4ec45929-8eba-4844-9200-597196d8268e,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-263bd0d6-bb37-4001-af44-f9806807b1db,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-fb6277fb-0c4e-49f5-9849-07baba121c83,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-5578b6eb-856a-48b2-808a-016b73316725,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-3e76ff86-280d-4e21-8549-56cf374026d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-220b141f-ffc7-4b5f-bf95-23fe3b553ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-160aa6a1-c7b0-46da-81b8-c0372da9f842,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-85318601-34a3-4d71-96e5-5bc6c2416f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416573771-172.17.0.5-1597530106882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41638,DS-58d41e2c-6290-4123-ba05-10ce2e32b508,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-c32aa8c0-e24a-44bc-a09a-532fe8d88214,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-c5c1ddb3-7ae1-4ecd-abe1-ac8ff013f06e,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-a20a1cdd-de7f-4c80-af84-fa5e413121ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-da24c4fe-479f-4224-90f7-0dd09818897c,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-0448b1e6-793b-49e0-90b3-367147438732,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-7c59eee4-7eb3-4841-8b5a-d06d34ee0fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-035157f6-4e5f-4c1d-95f2-3082ea91a21a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416573771-172.17.0.5-1597530106882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41638,DS-58d41e2c-6290-4123-ba05-10ce2e32b508,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-c32aa8c0-e24a-44bc-a09a-532fe8d88214,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-c5c1ddb3-7ae1-4ecd-abe1-ac8ff013f06e,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-a20a1cdd-de7f-4c80-af84-fa5e413121ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-da24c4fe-479f-4224-90f7-0dd09818897c,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-0448b1e6-793b-49e0-90b3-367147438732,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-7c59eee4-7eb3-4841-8b5a-d06d34ee0fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-035157f6-4e5f-4c1d-95f2-3082ea91a21a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335952249-172.17.0.5-1597530141428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38495,DS-bab52567-c637-4b2a-ac1a-bd9c1d7620e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-0fba47f9-e5f2-447e-a704-98e0ea7ba13e,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-375987fd-dae4-49f6-94fa-83bf1f16634d,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-98330623-e9f5-4617-bb86-2f8236556c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-dcf9e700-673e-47ff-a4e2-58b681cf094c,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-18d98c45-0398-47ba-9f72-9cd3ab43038a,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-8cb00b80-8678-4af2-8936-6aa99cc1a853,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-96f95fac-6f29-4519-9d56-62a9129117b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335952249-172.17.0.5-1597530141428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38495,DS-bab52567-c637-4b2a-ac1a-bd9c1d7620e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-0fba47f9-e5f2-447e-a704-98e0ea7ba13e,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-375987fd-dae4-49f6-94fa-83bf1f16634d,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-98330623-e9f5-4617-bb86-2f8236556c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-dcf9e700-673e-47ff-a4e2-58b681cf094c,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-18d98c45-0398-47ba-9f72-9cd3ab43038a,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-8cb00b80-8678-4af2-8936-6aa99cc1a853,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-96f95fac-6f29-4519-9d56-62a9129117b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699488610-172.17.0.5-1597530330552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-bc30485d-0747-402d-95a9-784abb58a1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-f936e9fc-7ede-4522-8ab2-b1cd5fbc4fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-e71cba94-27d7-47b4-b7cf-76b08390628d,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-ae45ca2d-336a-4e98-993f-6351f0830b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-8648c36b-e3f9-4cf9-ae93-f6039578d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-7c6998da-8365-4b05-a56e-9275c65ef0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-cb22215c-ebc9-45a4-bf1d-01ad8d91aab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-04a5c2f5-f01e-4c09-9602-09f6c0f98989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699488610-172.17.0.5-1597530330552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-bc30485d-0747-402d-95a9-784abb58a1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-f936e9fc-7ede-4522-8ab2-b1cd5fbc4fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-e71cba94-27d7-47b4-b7cf-76b08390628d,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-ae45ca2d-336a-4e98-993f-6351f0830b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-8648c36b-e3f9-4cf9-ae93-f6039578d6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-7c6998da-8365-4b05-a56e-9275c65ef0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-cb22215c-ebc9-45a4-bf1d-01ad8d91aab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-04a5c2f5-f01e-4c09-9602-09f6c0f98989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693359894-172.17.0.5-1597530364930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40762,DS-2977eb36-5aee-4f80-bafa-4c2e8d66194c,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-e4963227-e1bf-4c36-a03a-00ba00c617fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-421e7db8-84e1-4ed5-8986-b84fedd7874c,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-1b3d0101-d65c-4e7a-85d9-6496b1e00a78,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-bedad18e-d7bf-42e8-8a62-dd9bda532d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-aab2e99e-2937-4d2c-a3b6-d2307d9c9efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-1c803860-0392-4212-aba3-0090832bce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-213f6229-771e-4583-8e79-c788cfa0531a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693359894-172.17.0.5-1597530364930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40762,DS-2977eb36-5aee-4f80-bafa-4c2e8d66194c,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-e4963227-e1bf-4c36-a03a-00ba00c617fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-421e7db8-84e1-4ed5-8986-b84fedd7874c,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-1b3d0101-d65c-4e7a-85d9-6496b1e00a78,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-bedad18e-d7bf-42e8-8a62-dd9bda532d83,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-aab2e99e-2937-4d2c-a3b6-d2307d9c9efa,DISK], DatanodeInfoWithStorage[127.0.0.1:35163,DS-1c803860-0392-4212-aba3-0090832bce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-213f6229-771e-4583-8e79-c788cfa0531a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112185953-172.17.0.5-1597530682830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34406,DS-fa36a74f-2f06-4cfa-bd0c-a5182b59d267,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-12940eda-8a56-4c90-bf1c-4789277b3618,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-793d2a30-3877-42d7-9206-38352bfa003e,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-85714d8d-f234-4f3b-92fa-c9121c67f060,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-e8678e81-8c9b-444f-8a10-6e336260a314,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a5f3a34e-a95c-4135-88d3-fddead24c792,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-10636327-9a78-4ff4-b5ae-b160062d9cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-309fef12-6967-4783-b169-1d0b7a8bd7b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112185953-172.17.0.5-1597530682830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34406,DS-fa36a74f-2f06-4cfa-bd0c-a5182b59d267,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-12940eda-8a56-4c90-bf1c-4789277b3618,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-793d2a30-3877-42d7-9206-38352bfa003e,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-85714d8d-f234-4f3b-92fa-c9121c67f060,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-e8678e81-8c9b-444f-8a10-6e336260a314,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a5f3a34e-a95c-4135-88d3-fddead24c792,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-10636327-9a78-4ff4-b5ae-b160062d9cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-309fef12-6967-4783-b169-1d0b7a8bd7b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003431334-172.17.0.5-1597530719930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-3ac8f43b-e7d7-451f-b32e-56f64e132338,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-12104bc2-b670-48f2-85b3-05345cb0c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-74468926-ada5-4526-bdf1-c02f336e2312,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-39ae05ea-570e-40b8-9b29-e8c4913bb90d,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-54ac2d54-3e1a-403f-8744-5eef311c473e,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-8c4ab387-5fb6-4e5a-847e-00da1af66b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-d19014b1-f407-4541-8a3b-1564d724f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-0abcf33b-2af0-4afe-bcc7-06719a5ecb08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003431334-172.17.0.5-1597530719930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-3ac8f43b-e7d7-451f-b32e-56f64e132338,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-12104bc2-b670-48f2-85b3-05345cb0c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-74468926-ada5-4526-bdf1-c02f336e2312,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-39ae05ea-570e-40b8-9b29-e8c4913bb90d,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-54ac2d54-3e1a-403f-8744-5eef311c473e,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-8c4ab387-5fb6-4e5a-847e-00da1af66b63,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-d19014b1-f407-4541-8a3b-1564d724f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-0abcf33b-2af0-4afe-bcc7-06719a5ecb08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5335
