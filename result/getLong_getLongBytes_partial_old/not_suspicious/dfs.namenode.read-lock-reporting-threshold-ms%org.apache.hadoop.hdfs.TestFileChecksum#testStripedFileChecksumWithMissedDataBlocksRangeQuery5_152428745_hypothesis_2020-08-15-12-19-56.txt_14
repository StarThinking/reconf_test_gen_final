reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823726472-172.17.0.17-1597495029652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33321,DS-23181532-79af-4365-9166-2891936e9bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-bc257d70-8dac-488a-a811-589ebe9cb6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-4a22ada5-fc54-4bf0-8194-b23bef1597cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-205a9d76-0113-4b27-9b1f-ded9a8719a22,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-1e78a0e5-4aeb-441a-a667-27fff6887143,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-bb3721aa-14af-43f2-b4ff-3ff6557fb054,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-3c2f3dae-d6bd-4f4b-b72a-259aa8d58fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-04dd25e5-334f-4a67-bb2d-22ad807339a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823726472-172.17.0.17-1597495029652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33321,DS-23181532-79af-4365-9166-2891936e9bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-bc257d70-8dac-488a-a811-589ebe9cb6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-4a22ada5-fc54-4bf0-8194-b23bef1597cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-205a9d76-0113-4b27-9b1f-ded9a8719a22,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-1e78a0e5-4aeb-441a-a667-27fff6887143,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-bb3721aa-14af-43f2-b4ff-3ff6557fb054,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-3c2f3dae-d6bd-4f4b-b72a-259aa8d58fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-04dd25e5-334f-4a67-bb2d-22ad807339a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555436246-172.17.0.17-1597495525590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-28a5d7c2-36f0-44b7-9b96-61e8758a5c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-b3c12c25-2562-44a9-9c86-97022ee48593,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-e34be783-1955-45be-84bc-58cadcbf0fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-e05b28a4-5b62-42ca-a450-05d1d0c66378,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-b7c2d517-7279-45db-aa0f-94d81a70682a,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-e042b82c-93a6-4085-ac3e-8a1778e64370,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-a0e661a2-ed04-4251-a951-47f970048c77,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-7da33fde-b92d-427e-90c8-81ed2caf1044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555436246-172.17.0.17-1597495525590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46429,DS-28a5d7c2-36f0-44b7-9b96-61e8758a5c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-b3c12c25-2562-44a9-9c86-97022ee48593,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-e34be783-1955-45be-84bc-58cadcbf0fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-e05b28a4-5b62-42ca-a450-05d1d0c66378,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-b7c2d517-7279-45db-aa0f-94d81a70682a,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-e042b82c-93a6-4085-ac3e-8a1778e64370,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-a0e661a2-ed04-4251-a951-47f970048c77,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-7da33fde-b92d-427e-90c8-81ed2caf1044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997963033-172.17.0.17-1597495604696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44164,DS-b2adbc9e-79a0-4101-a826-ec1723f5117d,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-36480c6c-3f7c-40a8-a54a-7af18245fc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-08e13d0f-f18f-4c04-9daa-6d049dff7abe,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-30ad130c-f3f7-4731-a80e-73ec59d72ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-43115f68-66bb-4ca2-ad25-bac9edfd69c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-8e8bc177-a346-476d-8463-8de173f2936e,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-8168b2d7-38e0-4a97-8877-bb415b249a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-f3ff54bd-5ed4-4b64-8a10-9e2633f437cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997963033-172.17.0.17-1597495604696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44164,DS-b2adbc9e-79a0-4101-a826-ec1723f5117d,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-36480c6c-3f7c-40a8-a54a-7af18245fc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-08e13d0f-f18f-4c04-9daa-6d049dff7abe,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-30ad130c-f3f7-4731-a80e-73ec59d72ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-43115f68-66bb-4ca2-ad25-bac9edfd69c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-8e8bc177-a346-476d-8463-8de173f2936e,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-8168b2d7-38e0-4a97-8877-bb415b249a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-f3ff54bd-5ed4-4b64-8a10-9e2633f437cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367250216-172.17.0.17-1597495644335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46698,DS-7a9eae89-7342-4441-bb5a-97abef532ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-79c47456-ac83-4920-9bba-1e3c9e3983b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-16f32940-ccc5-436a-ba92-c0e27db65ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-21a736dc-52a2-418c-8c08-96c1e92c3dec,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-adeecc3d-2c72-4998-b6d4-aaaefd885023,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-0fc101ac-a949-47b1-8299-9de919b8998d,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-c9ea7c3d-e076-4670-a8de-59a9adfb5bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-c69747c4-6d61-4b87-8817-3d4cd1251adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367250216-172.17.0.17-1597495644335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46698,DS-7a9eae89-7342-4441-bb5a-97abef532ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-79c47456-ac83-4920-9bba-1e3c9e3983b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-16f32940-ccc5-436a-ba92-c0e27db65ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-21a736dc-52a2-418c-8c08-96c1e92c3dec,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-adeecc3d-2c72-4998-b6d4-aaaefd885023,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-0fc101ac-a949-47b1-8299-9de919b8998d,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-c9ea7c3d-e076-4670-a8de-59a9adfb5bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-c69747c4-6d61-4b87-8817-3d4cd1251adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260229496-172.17.0.17-1597496299546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42317,DS-0404da54-1eb9-43f8-ac50-b96fb6841b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-7ae360d3-3a3d-46f8-9f82-375e62a84706,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-3781b9b5-7b45-4583-ae35-4765cf97d8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-6817c0f0-5c12-4416-871e-5a070b0e234c,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-6793de5a-a4b8-4ed3-9d35-cf4810dedfab,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-e6de2587-3889-4342-b962-73b2ff3318dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-c5962ab3-a70a-4315-b724-8fe77a12ac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-6965c62a-d722-4a83-a166-ab6a3d3a9c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260229496-172.17.0.17-1597496299546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42317,DS-0404da54-1eb9-43f8-ac50-b96fb6841b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-7ae360d3-3a3d-46f8-9f82-375e62a84706,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-3781b9b5-7b45-4583-ae35-4765cf97d8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-6817c0f0-5c12-4416-871e-5a070b0e234c,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-6793de5a-a4b8-4ed3-9d35-cf4810dedfab,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-e6de2587-3889-4342-b962-73b2ff3318dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-c5962ab3-a70a-4315-b724-8fe77a12ac9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-6965c62a-d722-4a83-a166-ab6a3d3a9c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597157515-172.17.0.17-1597496504239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35831,DS-c0cbad1c-f041-4f4c-b727-31e0b28908b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-df74d0a9-786d-4963-99d1-ed85d6347797,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-ceb18125-7213-450c-b064-fae3cc29fa52,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-0e2216f7-dbb5-4b1a-879a-c444ad51a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-636933a2-8991-4759-a7a5-f693300c8e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-41d3d41c-f53d-4708-9d84-2f8e0bfd8679,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-114b9b50-d562-4f44-9f18-61dd87a0b2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-77be95d4-d90b-45f1-a1c7-dbbb466060cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597157515-172.17.0.17-1597496504239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35831,DS-c0cbad1c-f041-4f4c-b727-31e0b28908b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-df74d0a9-786d-4963-99d1-ed85d6347797,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-ceb18125-7213-450c-b064-fae3cc29fa52,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-0e2216f7-dbb5-4b1a-879a-c444ad51a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-636933a2-8991-4759-a7a5-f693300c8e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-41d3d41c-f53d-4708-9d84-2f8e0bfd8679,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-114b9b50-d562-4f44-9f18-61dd87a0b2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-77be95d4-d90b-45f1-a1c7-dbbb466060cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929209331-172.17.0.17-1597496867909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36993,DS-382d600d-063f-4923-9619-f0dc0588c7af,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-8cb38756-f0ed-49bd-868b-5ed23b74570e,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-275d7823-9782-4773-a21c-bcd20e9a0938,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-bc1755fd-3ff8-4a98-bccb-97b5e82b15c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-9083cda3-2650-4719-a10d-86c59b382e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-0b534e60-d64e-4506-8a80-65bf467681c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-d5d6f5c9-5fab-4044-842e-cd0cafd26768,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-34809f60-6d59-4aaf-aa25-bfa5d7c442dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929209331-172.17.0.17-1597496867909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36993,DS-382d600d-063f-4923-9619-f0dc0588c7af,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-8cb38756-f0ed-49bd-868b-5ed23b74570e,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-275d7823-9782-4773-a21c-bcd20e9a0938,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-bc1755fd-3ff8-4a98-bccb-97b5e82b15c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-9083cda3-2650-4719-a10d-86c59b382e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-0b534e60-d64e-4506-8a80-65bf467681c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-d5d6f5c9-5fab-4044-842e-cd0cafd26768,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-34809f60-6d59-4aaf-aa25-bfa5d7c442dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929288795-172.17.0.17-1597497441677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41581,DS-a7bd9f5d-268d-4fde-b1f0-176295043a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-2f3b79c1-4ecb-444a-a5f2-00725eaaac70,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-32747c5c-38a0-434b-a1d4-5a1e28084371,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-95a7d38f-10cd-4856-96ff-9c6f3c4ab2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-b829d5cb-c45a-410e-ab3d-4de62b6b528a,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-15543ec5-dc6e-476b-bb8a-27e961dc5edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-e78a763c-cbc5-46ec-aa64-1629072ece09,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-25bc59dd-ff00-481d-8dc1-2ea82e2dc5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929288795-172.17.0.17-1597497441677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41581,DS-a7bd9f5d-268d-4fde-b1f0-176295043a29,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-2f3b79c1-4ecb-444a-a5f2-00725eaaac70,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-32747c5c-38a0-434b-a1d4-5a1e28084371,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-95a7d38f-10cd-4856-96ff-9c6f3c4ab2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-b829d5cb-c45a-410e-ab3d-4de62b6b528a,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-15543ec5-dc6e-476b-bb8a-27e961dc5edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-e78a763c-cbc5-46ec-aa64-1629072ece09,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-25bc59dd-ff00-481d-8dc1-2ea82e2dc5b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135653557-172.17.0.17-1597497540038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-b73991b3-f800-4623-99aa-45be1a5f6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-8a38a52a-7596-4741-9ddc-749125351ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-cc9c555e-1177-4040-a9bc-01cbd7ff9077,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-4eefb640-d5a8-4943-8b70-4f68c3cc5ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-971aa64e-a5fd-48bf-95d2-794aec213288,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-584a9883-1b94-4c4a-9bd3-28a232b36c27,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-ddee3903-adf2-473f-9f07-405bc58c47b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-50832009-750e-44d8-acd9-cd32070bdb5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135653557-172.17.0.17-1597497540038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-b73991b3-f800-4623-99aa-45be1a5f6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-8a38a52a-7596-4741-9ddc-749125351ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-cc9c555e-1177-4040-a9bc-01cbd7ff9077,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-4eefb640-d5a8-4943-8b70-4f68c3cc5ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-971aa64e-a5fd-48bf-95d2-794aec213288,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-584a9883-1b94-4c4a-9bd3-28a232b36c27,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-ddee3903-adf2-473f-9f07-405bc58c47b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-50832009-750e-44d8-acd9-cd32070bdb5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553651883-172.17.0.17-1597497743537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46071,DS-5e6a07b1-4848-4bf3-8b32-dd2d3c069ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-3b983b43-88b2-404d-9d43-dd93dcdc795a,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-a0d8081f-a0e4-4749-a49e-a1e86e7dea69,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-49336b72-b40e-4dbc-a709-e7c02acb854c,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-4cf0aab5-d274-40f9-b3d1-3554a49b21be,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-8990e053-59e8-4e40-a4fd-1cad49b7aa53,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-277edca7-4e9e-4249-a555-97f8f41baa22,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-9634f348-297b-4b4a-a61d-a1ba4d3c63fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553651883-172.17.0.17-1597497743537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46071,DS-5e6a07b1-4848-4bf3-8b32-dd2d3c069ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-3b983b43-88b2-404d-9d43-dd93dcdc795a,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-a0d8081f-a0e4-4749-a49e-a1e86e7dea69,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-49336b72-b40e-4dbc-a709-e7c02acb854c,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-4cf0aab5-d274-40f9-b3d1-3554a49b21be,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-8990e053-59e8-4e40-a4fd-1cad49b7aa53,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-277edca7-4e9e-4249-a555-97f8f41baa22,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-9634f348-297b-4b4a-a61d-a1ba4d3c63fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319405609-172.17.0.17-1597497855434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-f0cb689f-c00a-4102-837a-3d1a46dea0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-6f91ca3d-be49-4c29-8646-9d21247e7b75,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-d25cbb56-8e9e-4e5d-a1b3-712ffd9f0372,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-3e96903f-c70b-4690-9bfc-b46e78cc2da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-03b0f878-72b7-4429-9a5c-b9f89f152225,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-2b9c4fd4-5e39-489a-9688-29896d9428e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-8d6891db-099f-4770-b457-b4b93cb727fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-d9b2a13b-55ac-4f99-93d4-a25be4145343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319405609-172.17.0.17-1597497855434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-f0cb689f-c00a-4102-837a-3d1a46dea0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-6f91ca3d-be49-4c29-8646-9d21247e7b75,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-d25cbb56-8e9e-4e5d-a1b3-712ffd9f0372,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-3e96903f-c70b-4690-9bfc-b46e78cc2da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-03b0f878-72b7-4429-9a5c-b9f89f152225,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-2b9c4fd4-5e39-489a-9688-29896d9428e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-8d6891db-099f-4770-b457-b4b93cb727fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-d9b2a13b-55ac-4f99-93d4-a25be4145343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289711135-172.17.0.17-1597497995980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-c31af5b5-353d-4094-8bcf-1d6c6b7f21b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-c1ce0dc9-0c9d-4cd1-a407-4d08d3654772,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-cb6ff15a-ec9c-4cbb-9b22-7a5e0b00d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-2db5e4f8-608b-4c59-b4e2-d93a426c6ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-1d7cb96c-60aa-4295-8ef1-7b0e4a05a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-293ed7bc-603f-40f2-83f1-ec46681fe66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-9ba80f30-e3c0-43d0-8560-7a0747510f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-d9a825b4-641d-4b8f-9c28-0234d4a707c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289711135-172.17.0.17-1597497995980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-c31af5b5-353d-4094-8bcf-1d6c6b7f21b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-c1ce0dc9-0c9d-4cd1-a407-4d08d3654772,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-cb6ff15a-ec9c-4cbb-9b22-7a5e0b00d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-2db5e4f8-608b-4c59-b4e2-d93a426c6ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-1d7cb96c-60aa-4295-8ef1-7b0e4a05a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-293ed7bc-603f-40f2-83f1-ec46681fe66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-9ba80f30-e3c0-43d0-8560-7a0747510f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-d9a825b4-641d-4b8f-9c28-0234d4a707c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23543570-172.17.0.17-1597498030070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-795f4eb1-54fc-422a-b8cd-e620c3d3f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-bb0b3c71-fb65-4d36-a904-133c16099000,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-61f540b7-0fc2-4762-8e87-b514ec6a58dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-a7d09ffd-2337-413b-8bfa-32dc406fefd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-d5911256-e221-4a8a-a965-986c723af334,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-db8a20af-9e09-48a0-8d24-fefb7aa928a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-17b08a4c-4f54-4fa1-911c-82ba584f3b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-6ed9c26a-5e13-4cb7-863f-ef0cb058aa88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23543570-172.17.0.17-1597498030070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-795f4eb1-54fc-422a-b8cd-e620c3d3f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-bb0b3c71-fb65-4d36-a904-133c16099000,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-61f540b7-0fc2-4762-8e87-b514ec6a58dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-a7d09ffd-2337-413b-8bfa-32dc406fefd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-d5911256-e221-4a8a-a965-986c723af334,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-db8a20af-9e09-48a0-8d24-fefb7aa928a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-17b08a4c-4f54-4fa1-911c-82ba584f3b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-6ed9c26a-5e13-4cb7-863f-ef0cb058aa88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024789101-172.17.0.17-1597498070507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-45989c1c-24d8-4e9d-b86a-b635ace3cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-a75012f0-1269-41c2-ab7e-5fe65c13c124,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8e712e8a-5130-4018-879a-eb02cf0a9327,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-72b0783f-1993-41ed-b6fa-ca48dee60cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-e18794ee-ff13-41b3-9516-bd326bc3b415,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-89a1eef3-1b38-490a-9f44-b632255a0d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-1f705c4a-66f8-469d-841c-ecfd28022a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-b46f90b7-1d30-47b3-94da-9ecbefac525d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024789101-172.17.0.17-1597498070507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34824,DS-45989c1c-24d8-4e9d-b86a-b635ace3cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-a75012f0-1269-41c2-ab7e-5fe65c13c124,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-8e712e8a-5130-4018-879a-eb02cf0a9327,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-72b0783f-1993-41ed-b6fa-ca48dee60cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-e18794ee-ff13-41b3-9516-bd326bc3b415,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-89a1eef3-1b38-490a-9f44-b632255a0d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-1f705c4a-66f8-469d-841c-ecfd28022a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-b46f90b7-1d30-47b3-94da-9ecbefac525d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679603553-172.17.0.17-1597498661461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-e8eab8f3-5029-43c7-b7ef-417c4af2e032,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-7b19dc8e-97a5-480a-a198-ca07198e2153,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c6d9b676-84e7-414e-acfa-4471461f90f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-79480406-8a3f-401b-b82d-4ae1d246969a,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-c8d4493a-2fad-4e06-b594-ae72900de6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-c0e870fb-df1a-4544-8b81-4f2b3c0b1c18,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-786bee99-986b-4ee9-b45d-783b35c21928,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-0659b5e8-9a57-4f13-9aab-f7545a3c951b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679603553-172.17.0.17-1597498661461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-e8eab8f3-5029-43c7-b7ef-417c4af2e032,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-7b19dc8e-97a5-480a-a198-ca07198e2153,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-c6d9b676-84e7-414e-acfa-4471461f90f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-79480406-8a3f-401b-b82d-4ae1d246969a,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-c8d4493a-2fad-4e06-b594-ae72900de6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-c0e870fb-df1a-4544-8b81-4f2b3c0b1c18,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-786bee99-986b-4ee9-b45d-783b35c21928,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-0659b5e8-9a57-4f13-9aab-f7545a3c951b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722289135-172.17.0.17-1597498821865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40579,DS-2ce5915d-9843-4060-953f-e6cecc4782ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-90e1c42a-43de-4495-a17e-d6706623bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-f8871fcc-c817-4840-bb9f-dcffb7df9866,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-60df9c79-c13f-4aba-9bc3-bbfc6697b442,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-4a6b2786-d577-4ce0-b333-a0477425600e,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-a0056a30-7a46-4268-9210-1aa55c7656d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-57f197f6-e365-4ccf-9d01-4b4272c4e716,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-181b5b7d-6151-4645-a705-69f65f6bf59d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722289135-172.17.0.17-1597498821865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40579,DS-2ce5915d-9843-4060-953f-e6cecc4782ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-90e1c42a-43de-4495-a17e-d6706623bfe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-f8871fcc-c817-4840-bb9f-dcffb7df9866,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-60df9c79-c13f-4aba-9bc3-bbfc6697b442,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-4a6b2786-d577-4ce0-b333-a0477425600e,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-a0056a30-7a46-4268-9210-1aa55c7656d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-57f197f6-e365-4ccf-9d01-4b4272c4e716,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-181b5b7d-6151-4645-a705-69f65f6bf59d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5552
