reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498025270-172.17.0.4-1597562005726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33666,DS-369fe819-1efa-428f-aac8-23a8b14ae668,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-2fab358b-f538-419d-9c81-350adde1b657,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-3306fd39-3b4a-429a-b5ff-c73e1fbf4933,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-8f7d0953-cfb4-412e-84b9-d5fe966d752e,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-2d2b667d-db7e-4818-b892-7dabf989cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-5f342eab-dd0e-4c0c-9c08-78f31c9ad856,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-f12f63c7-10e9-4f9b-b27c-56333982ba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-a3dcb492-27dc-4ef2-82ea-baedb827f6bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498025270-172.17.0.4-1597562005726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33666,DS-369fe819-1efa-428f-aac8-23a8b14ae668,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-2fab358b-f538-419d-9c81-350adde1b657,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-3306fd39-3b4a-429a-b5ff-c73e1fbf4933,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-8f7d0953-cfb4-412e-84b9-d5fe966d752e,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-2d2b667d-db7e-4818-b892-7dabf989cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-5f342eab-dd0e-4c0c-9c08-78f31c9ad856,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-f12f63c7-10e9-4f9b-b27c-56333982ba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-a3dcb492-27dc-4ef2-82ea-baedb827f6bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289829956-172.17.0.4-1597562379694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32941,DS-a427d9b1-411c-4ae4-bb79-c2e79c276f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-6565e938-0d07-4d10-bb68-6bb16390c460,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-486635a9-6cc0-49d4-ac70-8a4bc6ef7aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-d6248dfd-b8be-4962-a8bd-f5d9f31fe6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-3aa47eec-7716-4a7b-871b-aeadbf896ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-e7f914f1-ed4b-44b5-859f-6f9036b08a65,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-6be74920-87d6-4770-84c8-b3febfdb78ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-242b7d67-7ad8-429d-bd73-342b00597f1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289829956-172.17.0.4-1597562379694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32941,DS-a427d9b1-411c-4ae4-bb79-c2e79c276f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-6565e938-0d07-4d10-bb68-6bb16390c460,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-486635a9-6cc0-49d4-ac70-8a4bc6ef7aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-d6248dfd-b8be-4962-a8bd-f5d9f31fe6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-3aa47eec-7716-4a7b-871b-aeadbf896ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-e7f914f1-ed4b-44b5-859f-6f9036b08a65,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-6be74920-87d6-4770-84c8-b3febfdb78ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-242b7d67-7ad8-429d-bd73-342b00597f1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338948328-172.17.0.4-1597562567383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40290,DS-47561dd3-9ad3-414d-a3a5-8cf49ed6d3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-31dbafb5-b293-453f-acf4-e3174a2a4d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-8f7b822e-99bc-415e-b756-330ec07f9e82,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-424bc337-478d-4ca0-a384-96beb140beab,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-8bfb44aa-6309-4f8a-ac9d-7f15a1fa8701,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-a798ea37-04a8-42e8-a211-ca87adfbce4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-2dd215f5-9c2b-4310-8a55-ffa294197aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-8f18c1e7-35c8-47c6-b339-f965938cfc85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338948328-172.17.0.4-1597562567383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40290,DS-47561dd3-9ad3-414d-a3a5-8cf49ed6d3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-31dbafb5-b293-453f-acf4-e3174a2a4d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-8f7b822e-99bc-415e-b756-330ec07f9e82,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-424bc337-478d-4ca0-a384-96beb140beab,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-8bfb44aa-6309-4f8a-ac9d-7f15a1fa8701,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-a798ea37-04a8-42e8-a211-ca87adfbce4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-2dd215f5-9c2b-4310-8a55-ffa294197aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-8f18c1e7-35c8-47c6-b339-f965938cfc85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562009806-172.17.0.4-1597562918790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-8424851f-e904-4ee3-96bd-eeb82b225612,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-080def28-365c-4643-99d8-5515ae542274,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-9213ebd4-9e31-40a1-b9bd-5bee7067ef32,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-f9db010a-3f78-44f4-b285-d46d594d3c92,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-f70f3f7b-dbee-493d-b499-38cf86813119,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-f41b6879-787e-4e60-8406-944c3a345b52,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-9b6cf051-5bf1-4726-b1f0-a87df508730b,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-af330015-59b7-46c1-b0cb-dfe68c1347be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562009806-172.17.0.4-1597562918790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-8424851f-e904-4ee3-96bd-eeb82b225612,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-080def28-365c-4643-99d8-5515ae542274,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-9213ebd4-9e31-40a1-b9bd-5bee7067ef32,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-f9db010a-3f78-44f4-b285-d46d594d3c92,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-f70f3f7b-dbee-493d-b499-38cf86813119,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-f41b6879-787e-4e60-8406-944c3a345b52,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-9b6cf051-5bf1-4726-b1f0-a87df508730b,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-af330015-59b7-46c1-b0cb-dfe68c1347be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210167976-172.17.0.4-1597563039092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44221,DS-d27e1b31-720c-4bc3-9ea6-87fbdb4f01ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-2101cf63-c42c-481c-84ea-651a166777d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-3b394bcb-c40e-43f7-836c-14ac9f50eb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-3aff000f-d954-4f2d-8ab4-e5a73f857704,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-73be96fe-1852-4ecf-a346-0d2e2aea8438,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-4f7d429a-a1de-4fc1-8469-f2dc37e69355,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-a84f274e-20e2-45be-8ad8-4dc387e67096,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-5f8c14f1-7318-4b7f-b12f-53b1760b9114,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210167976-172.17.0.4-1597563039092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44221,DS-d27e1b31-720c-4bc3-9ea6-87fbdb4f01ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-2101cf63-c42c-481c-84ea-651a166777d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-3b394bcb-c40e-43f7-836c-14ac9f50eb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-3aff000f-d954-4f2d-8ab4-e5a73f857704,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-73be96fe-1852-4ecf-a346-0d2e2aea8438,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-4f7d429a-a1de-4fc1-8469-f2dc37e69355,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-a84f274e-20e2-45be-8ad8-4dc387e67096,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-5f8c14f1-7318-4b7f-b12f-53b1760b9114,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81569982-172.17.0.4-1597563291104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-4d997362-d63a-47ab-aa32-1af4eb49688d,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-51c15434-0621-4ced-853b-9f3987582ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-577142dd-47ef-4b8d-8dc0-2adbd92d8aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-e5bbfdec-2f34-47a8-aa86-bf6b683dd476,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-d8a6df73-ea98-47ba-9edc-28556dcb4009,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-c6bfeb57-bd5b-442f-9834-f87f410f7534,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-34f25883-0c5f-40c3-854b-2a8bf00e0858,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-e08533ba-5fcf-4a75-9059-d06c6da405c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81569982-172.17.0.4-1597563291104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38336,DS-4d997362-d63a-47ab-aa32-1af4eb49688d,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-51c15434-0621-4ced-853b-9f3987582ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-577142dd-47ef-4b8d-8dc0-2adbd92d8aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-e5bbfdec-2f34-47a8-aa86-bf6b683dd476,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-d8a6df73-ea98-47ba-9edc-28556dcb4009,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-c6bfeb57-bd5b-442f-9834-f87f410f7534,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-34f25883-0c5f-40c3-854b-2a8bf00e0858,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-e08533ba-5fcf-4a75-9059-d06c6da405c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286318908-172.17.0.4-1597563426305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46690,DS-71c5c038-d221-445d-af5a-0a27251fbc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-28d6cbeb-beee-4542-aba6-8607ff173ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-bc9ccbd8-a692-42f9-a174-cacc48a15e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-c7a0c8b0-be70-4bc0-bc90-6a5a5d8ed335,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c6a01f72-ac97-4572-930c-73bcb99d0ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-065c8492-269f-4f0d-98e4-80052866cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-6d796fc2-5437-49ba-bb8f-1636fe47fbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-32c75d48-3c33-4474-b4b6-69aae10bfd57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286318908-172.17.0.4-1597563426305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46690,DS-71c5c038-d221-445d-af5a-0a27251fbc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-28d6cbeb-beee-4542-aba6-8607ff173ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-bc9ccbd8-a692-42f9-a174-cacc48a15e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-c7a0c8b0-be70-4bc0-bc90-6a5a5d8ed335,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c6a01f72-ac97-4572-930c-73bcb99d0ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-065c8492-269f-4f0d-98e4-80052866cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-6d796fc2-5437-49ba-bb8f-1636fe47fbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-32c75d48-3c33-4474-b4b6-69aae10bfd57,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265016421-172.17.0.4-1597563508509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37220,DS-5cd0e2d5-1e94-42da-8253-ac735460aca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-d9faa63f-d72c-4521-8556-39e795cecb72,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-5170bc82-9ba3-4dca-a2d5-78b68c20b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-fb278ab3-371e-46ff-ae8f-92a406db2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-bd294ad0-1826-43af-9f9e-81e331ee4185,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-05ae1e68-dcb1-46a3-89d6-6bbdb0478caa,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-fc8da49f-45ff-4dcd-b6d1-11a72ace3bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-5c4ba4aa-5166-4598-b976-34b97e137fb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265016421-172.17.0.4-1597563508509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37220,DS-5cd0e2d5-1e94-42da-8253-ac735460aca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-d9faa63f-d72c-4521-8556-39e795cecb72,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-5170bc82-9ba3-4dca-a2d5-78b68c20b2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-fb278ab3-371e-46ff-ae8f-92a406db2dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-bd294ad0-1826-43af-9f9e-81e331ee4185,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-05ae1e68-dcb1-46a3-89d6-6bbdb0478caa,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-fc8da49f-45ff-4dcd-b6d1-11a72ace3bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-5c4ba4aa-5166-4598-b976-34b97e137fb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481030098-172.17.0.4-1597563545089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34966,DS-1d377c93-4687-4e5c-8912-f2b1465aba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-3d0c393f-54bf-43ef-bf7e-80f29398c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-10a848a9-f0fe-44d9-8922-da0c4beab2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-5a9f80bd-ed2a-4db8-81e7-56cd90b3357b,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-380ec953-91e9-420b-a46c-ad9c0045a843,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-c5109c29-665e-4b82-9bca-cdf41ccf8bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-1cfda82d-b60b-46a6-926d-fd8df25859ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-2a114d0c-55d1-4f88-b8e0-2ae51e068503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481030098-172.17.0.4-1597563545089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34966,DS-1d377c93-4687-4e5c-8912-f2b1465aba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-3d0c393f-54bf-43ef-bf7e-80f29398c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-10a848a9-f0fe-44d9-8922-da0c4beab2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-5a9f80bd-ed2a-4db8-81e7-56cd90b3357b,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-380ec953-91e9-420b-a46c-ad9c0045a843,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-c5109c29-665e-4b82-9bca-cdf41ccf8bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-1cfda82d-b60b-46a6-926d-fd8df25859ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-2a114d0c-55d1-4f88-b8e0-2ae51e068503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076137314-172.17.0.4-1597563925590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42913,DS-37e49981-56ee-4570-9aee-f2ddfab0fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-af75bdea-2b09-4c29-9e57-5d5434f0e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-73137b90-629d-4d8a-b712-e30c58170830,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-e801fd87-d1fd-4d4a-9e37-abcaa890e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-f22a996f-c6ed-4eec-8d4f-16a94ddce2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-e6657d58-840b-4c6e-ad68-304a0195ea08,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-7d531b6f-553d-4c19-a798-fc593153a535,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-5a819a34-6bba-4441-8168-adcb12e97caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076137314-172.17.0.4-1597563925590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42913,DS-37e49981-56ee-4570-9aee-f2ddfab0fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-af75bdea-2b09-4c29-9e57-5d5434f0e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-73137b90-629d-4d8a-b712-e30c58170830,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-e801fd87-d1fd-4d4a-9e37-abcaa890e88b,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-f22a996f-c6ed-4eec-8d4f-16a94ddce2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-e6657d58-840b-4c6e-ad68-304a0195ea08,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-7d531b6f-553d-4c19-a798-fc593153a535,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-5a819a34-6bba-4441-8168-adcb12e97caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967943585-172.17.0.4-1597564009558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-b043c10a-6e2b-4b2b-835a-c4cb6df859c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-469c0c38-d57b-4413-8c2e-d2a10dce5018,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-99d5218a-1c12-417c-9a46-8b5a2f67724d,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-2ff2f63e-d949-4194-878d-bfa1dddbe932,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-c74d2e3c-2c7f-452d-ab9e-76c50016cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-d0f4ab2d-9080-4a69-85ce-22836ec393b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-50bb5219-3a08-45c1-9dec-b85e69dbeabf,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-e22a49d6-e46d-4e48-966d-92377673fde6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967943585-172.17.0.4-1597564009558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-b043c10a-6e2b-4b2b-835a-c4cb6df859c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-469c0c38-d57b-4413-8c2e-d2a10dce5018,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-99d5218a-1c12-417c-9a46-8b5a2f67724d,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-2ff2f63e-d949-4194-878d-bfa1dddbe932,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-c74d2e3c-2c7f-452d-ab9e-76c50016cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-d0f4ab2d-9080-4a69-85ce-22836ec393b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-50bb5219-3a08-45c1-9dec-b85e69dbeabf,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-e22a49d6-e46d-4e48-966d-92377673fde6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281736512-172.17.0.4-1597564050958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-2f68ffb0-3e6a-4fbd-ab03-3d9b610b7602,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-9fb24b7c-5c65-4b46-ac75-44d118cb1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-e983c53a-28f2-4d78-8520-c02300ce1862,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-7b3b5dba-8fbb-4989-993f-ca5448d59eee,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-5c61254c-ce9b-4a75-a324-3ae6fa97ee28,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-0b04d6ad-83f2-4ea0-9b8e-519649cc4c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-38f04403-51ac-40d1-8acc-28a0aaaf70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-eccd074e-2072-4f19-bde2-0b7f5ab548b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281736512-172.17.0.4-1597564050958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-2f68ffb0-3e6a-4fbd-ab03-3d9b610b7602,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-9fb24b7c-5c65-4b46-ac75-44d118cb1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-e983c53a-28f2-4d78-8520-c02300ce1862,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-7b3b5dba-8fbb-4989-993f-ca5448d59eee,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-5c61254c-ce9b-4a75-a324-3ae6fa97ee28,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-0b04d6ad-83f2-4ea0-9b8e-519649cc4c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-38f04403-51ac-40d1-8acc-28a0aaaf70e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-eccd074e-2072-4f19-bde2-0b7f5ab548b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465116389-172.17.0.4-1597564309478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34901,DS-04514b42-73af-48f1-8ba8-c17e754fa51d,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-dfbb2714-669d-4afa-b5ef-bc27b0e58487,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-3b930355-e166-4565-ad74-c9dbe0d15eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-4d7c7974-db5c-4169-baec-bf2edb1bc639,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-a642020d-94f7-4956-8aa9-90f3b2d21bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-b0fd4c7d-f5b2-46a1-a7f7-3397676e73dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-0ac20c76-5391-4876-b8fd-7b9ad7815b70,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-9fabfe32-f3fb-43fa-ada8-5d0c13ccc3ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465116389-172.17.0.4-1597564309478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34901,DS-04514b42-73af-48f1-8ba8-c17e754fa51d,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-dfbb2714-669d-4afa-b5ef-bc27b0e58487,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-3b930355-e166-4565-ad74-c9dbe0d15eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-4d7c7974-db5c-4169-baec-bf2edb1bc639,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-a642020d-94f7-4956-8aa9-90f3b2d21bed,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-b0fd4c7d-f5b2-46a1-a7f7-3397676e73dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-0ac20c76-5391-4876-b8fd-7b9ad7815b70,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-9fabfe32-f3fb-43fa-ada8-5d0c13ccc3ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307887573-172.17.0.4-1597564530699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38471,DS-fd844cbb-02a5-4703-bbba-54648324f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-df3bc1b2-9609-4f97-aa18-97bd214a84d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-d9229e34-4668-4878-8963-989281b2b265,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-4bce5bdd-2bf0-4838-868d-f0caa2838414,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-c652d395-f43b-4fff-bb6b-7baa5ea23aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-92575378-a050-4729-8ce8-a64bc0d4049c,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-116cf018-9a0a-4b74-981b-75e37854885c,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-c03e441b-b3ae-41e1-9951-94fd22c195f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307887573-172.17.0.4-1597564530699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38471,DS-fd844cbb-02a5-4703-bbba-54648324f2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-df3bc1b2-9609-4f97-aa18-97bd214a84d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-d9229e34-4668-4878-8963-989281b2b265,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-4bce5bdd-2bf0-4838-868d-f0caa2838414,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-c652d395-f43b-4fff-bb6b-7baa5ea23aec,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-92575378-a050-4729-8ce8-a64bc0d4049c,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-116cf018-9a0a-4b74-981b-75e37854885c,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-c03e441b-b3ae-41e1-9951-94fd22c195f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474912141-172.17.0.4-1597565430782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44804,DS-90e0fc04-67be-402a-8501-9c8cb19cafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-19285c4c-bb95-4dc4-9547-e7d69582ec09,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-46517724-a9de-4e71-b709-6cac1792b62e,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-4e3dfe47-d69b-4d93-b1d6-721c141b6d75,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-5d0afa5d-f128-40f8-b9f4-9c1a1ae4ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-75811c87-5ba1-42f7-9a9c-b6e25cb046e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-ab2d322f-0c37-40e9-bb20-68fcb8c82bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-293595fd-a8e4-4e47-aac1-909d7ff31574,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474912141-172.17.0.4-1597565430782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44804,DS-90e0fc04-67be-402a-8501-9c8cb19cafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-19285c4c-bb95-4dc4-9547-e7d69582ec09,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-46517724-a9de-4e71-b709-6cac1792b62e,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-4e3dfe47-d69b-4d93-b1d6-721c141b6d75,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-5d0afa5d-f128-40f8-b9f4-9c1a1ae4ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-75811c87-5ba1-42f7-9a9c-b6e25cb046e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-ab2d322f-0c37-40e9-bb20-68fcb8c82bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-293595fd-a8e4-4e47-aac1-909d7ff31574,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899422366-172.17.0.4-1597565717923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-2a147298-fa30-443f-b286-410b79f74ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-ded775c3-b7ba-4fb0-b518-ea4f9466156f,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-cd7b7498-915f-46cf-80fc-7b24b3b5d712,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-e5a1c75d-bd05-4989-831d-5e72b8bafd99,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-f04b89b3-f310-47ab-8cfe-7c2d27962d23,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-ae76edf3-5274-42e9-acfb-79985c31068f,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-0efaf0b6-2ce8-4776-9ed0-b80743dea336,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-28023ca9-277f-42b6-aa87-88b3a71f2a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899422366-172.17.0.4-1597565717923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-2a147298-fa30-443f-b286-410b79f74ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-ded775c3-b7ba-4fb0-b518-ea4f9466156f,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-cd7b7498-915f-46cf-80fc-7b24b3b5d712,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-e5a1c75d-bd05-4989-831d-5e72b8bafd99,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-f04b89b3-f310-47ab-8cfe-7c2d27962d23,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-ae76edf3-5274-42e9-acfb-79985c31068f,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-0efaf0b6-2ce8-4776-9ed0-b80743dea336,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-28023ca9-277f-42b6-aa87-88b3a71f2a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557111879-172.17.0.4-1597565758034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38703,DS-7569cf16-4dbd-4ead-a8f6-54948b2c775b,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-9f3cdca6-f019-4a94-bc31-61f929004d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-b2afecaf-a070-4271-99ac-9365703f6369,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-36beec89-3bb2-40e6-bbc1-f30c0d23c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-8247c74d-50c9-44ba-b1a0-5d01d7c03648,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-9e62492d-0de6-428d-87ab-06304fd40c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-134a1b62-a301-45e9-8f5a-14c8e338ead2,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-fd5c3eeb-b0cb-475d-9bf9-0fe058718bdc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557111879-172.17.0.4-1597565758034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38703,DS-7569cf16-4dbd-4ead-a8f6-54948b2c775b,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-9f3cdca6-f019-4a94-bc31-61f929004d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-b2afecaf-a070-4271-99ac-9365703f6369,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-36beec89-3bb2-40e6-bbc1-f30c0d23c31e,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-8247c74d-50c9-44ba-b1a0-5d01d7c03648,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-9e62492d-0de6-428d-87ab-06304fd40c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-134a1b62-a301-45e9-8f5a-14c8e338ead2,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-fd5c3eeb-b0cb-475d-9bf9-0fe058718bdc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165572579-172.17.0.4-1597566083149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-bab32690-ff81-4df7-a3f9-efb17fe757e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-5e376e69-b506-4ca6-9c2e-eb2b165e5b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-ce92d467-07f0-455f-9fb1-9b7e784bff78,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-f7abf436-5d5f-42f5-91e5-457b29b1014a,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-5f7ec134-7a3e-4fe2-aea2-6ce5a2dba709,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-973f4872-6857-4296-9682-86b9190ef462,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-b28ff612-7a9a-427e-aa22-e97c5f89126f,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-cdf3361a-8930-4651-96dd-313a257b9904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165572579-172.17.0.4-1597566083149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42765,DS-bab32690-ff81-4df7-a3f9-efb17fe757e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-5e376e69-b506-4ca6-9c2e-eb2b165e5b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-ce92d467-07f0-455f-9fb1-9b7e784bff78,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-f7abf436-5d5f-42f5-91e5-457b29b1014a,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-5f7ec134-7a3e-4fe2-aea2-6ce5a2dba709,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-973f4872-6857-4296-9682-86b9190ef462,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-b28ff612-7a9a-427e-aa22-e97c5f89126f,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-cdf3361a-8930-4651-96dd-313a257b9904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549571699-172.17.0.4-1597566126070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-b158c36d-28fd-4437-913f-871396c9616f,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-c2b9c7a1-605b-4ded-b578-d45dccbbad30,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-b22f059c-f3a0-4cea-a160-c9e858f6e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-80ce7244-76c1-43b6-9421-8ca325866fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-993b5ff0-d435-4f10-85ec-e984b1547578,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-4958a68e-aa05-4072-b430-8bf7c2378e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-2ffb2669-4aee-45be-bbd1-5b5cd9152c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-3ac51402-bd04-494f-a2db-602dae59c760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549571699-172.17.0.4-1597566126070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-b158c36d-28fd-4437-913f-871396c9616f,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-c2b9c7a1-605b-4ded-b578-d45dccbbad30,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-b22f059c-f3a0-4cea-a160-c9e858f6e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-80ce7244-76c1-43b6-9421-8ca325866fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-993b5ff0-d435-4f10-85ec-e984b1547578,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-4958a68e-aa05-4072-b430-8bf7c2378e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-2ffb2669-4aee-45be-bbd1-5b5cd9152c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-3ac51402-bd04-494f-a2db-602dae59c760,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648647706-172.17.0.4-1597566234847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-d50426d1-77b5-4299-82c7-4248a7fd4f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-4a3e6c42-2394-4d13-ba54-4f208462ee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-e5253caf-db94-4553-af9b-508aa69bc7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-a3e3dd22-7b84-488e-a8d0-a82bff188266,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-a45c6606-af7c-432b-912a-6f093b4e223e,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-762d0dd6-8b0f-45ba-80ba-3aab5341d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-99313cca-d622-432c-a0da-afa87b31e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-d4ffd9b6-dda8-4169-a0d1-722b7e7ca36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648647706-172.17.0.4-1597566234847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-d50426d1-77b5-4299-82c7-4248a7fd4f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-4a3e6c42-2394-4d13-ba54-4f208462ee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-e5253caf-db94-4553-af9b-508aa69bc7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-a3e3dd22-7b84-488e-a8d0-a82bff188266,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-a45c6606-af7c-432b-912a-6f093b4e223e,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-762d0dd6-8b0f-45ba-80ba-3aab5341d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-99313cca-d622-432c-a0da-afa87b31e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-d4ffd9b6-dda8-4169-a0d1-722b7e7ca36b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967180630-172.17.0.4-1597566362365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41830,DS-5a9768d3-3a41-44a2-9a38-70cc13393f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-02d5dc16-0342-48fe-a84b-e1fa1ae463aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-f0f167e9-24a2-409a-af1e-cc61bbb6aaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-39539412-527e-4ad4-8d8c-b9b77001e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-9e595657-af34-46eb-8a7d-deca4857d986,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-c8ab8766-07a2-4b54-841c-77c1f25bef6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-73dfc3f8-0506-4557-b95d-14ddeb2b6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-ea9e0c44-fe53-4571-acd4-22f3a3ab8d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967180630-172.17.0.4-1597566362365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41830,DS-5a9768d3-3a41-44a2-9a38-70cc13393f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-02d5dc16-0342-48fe-a84b-e1fa1ae463aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-f0f167e9-24a2-409a-af1e-cc61bbb6aaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-39539412-527e-4ad4-8d8c-b9b77001e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-9e595657-af34-46eb-8a7d-deca4857d986,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-c8ab8766-07a2-4b54-841c-77c1f25bef6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-73dfc3f8-0506-4557-b95d-14ddeb2b6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-ea9e0c44-fe53-4571-acd4-22f3a3ab8d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892562504-172.17.0.4-1597566678079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-44cf0f97-c2b3-4461-a6cd-b89648b1e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-78ba39e3-dc3d-4547-9762-71924fef5eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-af1be3fd-599a-45cd-83bc-023c59a6354e,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-80b772d9-74c8-4a7b-ad2c-9b9cbef60c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-5566581c-b37e-48da-8b63-ac914c340af1,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-3ad9d762-b26d-4845-8472-ddfaa8c6e096,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-7f157827-704c-4600-b78e-2c187ed118a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-49cb0335-9e26-4e88-86e0-3fef06a99757,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892562504-172.17.0.4-1597566678079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-44cf0f97-c2b3-4461-a6cd-b89648b1e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-78ba39e3-dc3d-4547-9762-71924fef5eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-af1be3fd-599a-45cd-83bc-023c59a6354e,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-80b772d9-74c8-4a7b-ad2c-9b9cbef60c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-5566581c-b37e-48da-8b63-ac914c340af1,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-3ad9d762-b26d-4845-8472-ddfaa8c6e096,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-7f157827-704c-4600-b78e-2c187ed118a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-49cb0335-9e26-4e88-86e0-3fef06a99757,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900511040-172.17.0.4-1597566715495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42493,DS-7d9b7b27-8577-4cea-bdb3-7204a63850f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-36a55ac6-57b8-4e77-a023-3a116cd6596e,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-2b260b14-7b53-4d16-b850-0483ff07f398,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-69c1f1e7-2d03-498f-aea8-e95bcdde8040,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-11d7d917-ba32-4fa0-be7b-469ad2612ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-248e67ff-5b88-49ad-8a22-2f1fb3b39d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-cee12bdb-f383-4e5e-83dc-cbde4bcd730e,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-410dd028-c691-4a18-85c8-9c99abc4fd05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900511040-172.17.0.4-1597566715495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42493,DS-7d9b7b27-8577-4cea-bdb3-7204a63850f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-36a55ac6-57b8-4e77-a023-3a116cd6596e,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-2b260b14-7b53-4d16-b850-0483ff07f398,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-69c1f1e7-2d03-498f-aea8-e95bcdde8040,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-11d7d917-ba32-4fa0-be7b-469ad2612ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-248e67ff-5b88-49ad-8a22-2f1fb3b39d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-cee12bdb-f383-4e5e-83dc-cbde4bcd730e,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-410dd028-c691-4a18-85c8-9c99abc4fd05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576322766-172.17.0.4-1597567015859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-764d1c5e-0875-45e2-afe6-56e926dbf227,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-ab807f51-1cd3-4a78-a98f-61b0f0830e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-1daef1c0-d677-4c4c-8052-8f2769425a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-8ba25c12-da1d-4ae0-82e5-3e4888cc1ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-fb24c61b-c53a-4aaa-8b8a-5885e3219af1,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-82558d87-df40-494a-8c90-f21ad851e3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-79d693fe-e600-42f9-9539-490cccd54b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-746b3188-8e4a-45d4-8ee7-4fd920a3ccb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576322766-172.17.0.4-1597567015859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43877,DS-764d1c5e-0875-45e2-afe6-56e926dbf227,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-ab807f51-1cd3-4a78-a98f-61b0f0830e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-1daef1c0-d677-4c4c-8052-8f2769425a19,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-8ba25c12-da1d-4ae0-82e5-3e4888cc1ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-fb24c61b-c53a-4aaa-8b8a-5885e3219af1,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-82558d87-df40-494a-8c90-f21ad851e3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-79d693fe-e600-42f9-9539-490cccd54b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-746b3188-8e4a-45d4-8ee7-4fd920a3ccb2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626185986-172.17.0.4-1597567059952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-80a38327-5bb0-4bec-a16d-d9cf596f6568,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-8635809d-f5d4-45d7-91b7-f560ad888f92,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-a04a922d-cfe1-4ed9-8bcf-1e7a3c7b5b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-060d272d-f76d-4064-80ae-8e3b056f4cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-0d80fc00-b483-4c88-af9c-fba89805fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d227cb55-fdb6-4008-96a5-9f2bea6c99ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-b4c32cc1-acf8-44bf-a7ad-63362bc3c664,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-3c8cff4e-8cc1-4c62-8696-14d6f5789609,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626185986-172.17.0.4-1597567059952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-80a38327-5bb0-4bec-a16d-d9cf596f6568,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-8635809d-f5d4-45d7-91b7-f560ad888f92,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-a04a922d-cfe1-4ed9-8bcf-1e7a3c7b5b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-060d272d-f76d-4064-80ae-8e3b056f4cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-0d80fc00-b483-4c88-af9c-fba89805fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d227cb55-fdb6-4008-96a5-9f2bea6c99ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-b4c32cc1-acf8-44bf-a7ad-63362bc3c664,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-3c8cff4e-8cc1-4c62-8696-14d6f5789609,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935249114-172.17.0.4-1597567167029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44294,DS-e4ad5dbb-1cf3-406d-abac-b899046b3e06,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-fdcf740a-d634-4639-baab-09ebff064285,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-36275029-1c08-4094-9dc7-db461441a4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-730b0a39-2d3d-46b8-b924-b201a7f129fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-67f524da-af6f-457a-ae9c-5b55ce253e76,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-dcfdc55c-cbc0-4759-9899-bcc094dfb516,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-f204a085-e287-4ae9-958f-f9280d02e68e,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-5e5e47de-20b0-493f-98d1-117576034d19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935249114-172.17.0.4-1597567167029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44294,DS-e4ad5dbb-1cf3-406d-abac-b899046b3e06,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-fdcf740a-d634-4639-baab-09ebff064285,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-36275029-1c08-4094-9dc7-db461441a4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-730b0a39-2d3d-46b8-b924-b201a7f129fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-67f524da-af6f-457a-ae9c-5b55ce253e76,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-dcfdc55c-cbc0-4759-9899-bcc094dfb516,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-f204a085-e287-4ae9-958f-f9280d02e68e,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-5e5e47de-20b0-493f-98d1-117576034d19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343325082-172.17.0.4-1597567206497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38068,DS-0909c289-ac64-464d-ba2d-80dd700754aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-bbcac773-a001-455a-805a-cf9c54f8a527,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-b5a7145f-f18a-453c-bf86-28600f88614b,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-b4f0c64d-e7aa-4f36-abb7-815b745572e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-9fa16302-cea2-441b-bee7-db112d1a86fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-b88be188-3a58-4e3d-bedd-29a5b2467a54,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-5a4184d0-c841-4624-a676-edba66a74d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-f5288cbb-3482-49e9-ad6a-3e61bfa7ed23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343325082-172.17.0.4-1597567206497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38068,DS-0909c289-ac64-464d-ba2d-80dd700754aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-bbcac773-a001-455a-805a-cf9c54f8a527,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-b5a7145f-f18a-453c-bf86-28600f88614b,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-b4f0c64d-e7aa-4f36-abb7-815b745572e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-9fa16302-cea2-441b-bee7-db112d1a86fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-b88be188-3a58-4e3d-bedd-29a5b2467a54,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-5a4184d0-c841-4624-a676-edba66a74d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-f5288cbb-3482-49e9-ad6a-3e61bfa7ed23,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820973781-172.17.0.4-1597567438510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-a8a85add-ab76-457c-a8c5-e8118889478d,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-0639b496-2886-4617-80fa-199784b999d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-65065486-675a-486b-b505-048632ef2289,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-14137e09-9ecc-4578-8807-073c1276267a,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-682183a7-10ac-44f3-bb3a-b07bf3614ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-2c8bd106-a524-495c-a66a-fae7fb15f53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-58c22516-94d8-452d-8106-4501a76dc98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-4bb6e9fe-8a9f-4d95-a160-6fef892d6a83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820973781-172.17.0.4-1597567438510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-a8a85add-ab76-457c-a8c5-e8118889478d,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-0639b496-2886-4617-80fa-199784b999d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-65065486-675a-486b-b505-048632ef2289,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-14137e09-9ecc-4578-8807-073c1276267a,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-682183a7-10ac-44f3-bb3a-b07bf3614ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-2c8bd106-a524-495c-a66a-fae7fb15f53c,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-58c22516-94d8-452d-8106-4501a76dc98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-4bb6e9fe-8a9f-4d95-a160-6fef892d6a83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24323633-172.17.0.4-1597567694170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37132,DS-2e7f5fbf-5552-43a6-873f-dad8b63dca51,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-2c017baa-f047-47ec-b849-0820cf6d7291,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-c2d55f14-6134-48ce-97c1-4b1973328264,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-3320470c-1a9e-460d-a2ad-9e6d1853c13f,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-0c98e9fa-af84-49b5-9251-de03322c7342,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-3dc81954-3df0-4501-ad58-3bb99748b412,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-e2f8dc64-e8ec-400e-aca2-40eaf019d486,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-9a779a10-b906-44ee-8171-0ad1b7d40cd7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24323633-172.17.0.4-1597567694170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37132,DS-2e7f5fbf-5552-43a6-873f-dad8b63dca51,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-2c017baa-f047-47ec-b849-0820cf6d7291,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-c2d55f14-6134-48ce-97c1-4b1973328264,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-3320470c-1a9e-460d-a2ad-9e6d1853c13f,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-0c98e9fa-af84-49b5-9251-de03322c7342,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-3dc81954-3df0-4501-ad58-3bb99748b412,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-e2f8dc64-e8ec-400e-aca2-40eaf019d486,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-9a779a10-b906-44ee-8171-0ad1b7d40cd7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5802
