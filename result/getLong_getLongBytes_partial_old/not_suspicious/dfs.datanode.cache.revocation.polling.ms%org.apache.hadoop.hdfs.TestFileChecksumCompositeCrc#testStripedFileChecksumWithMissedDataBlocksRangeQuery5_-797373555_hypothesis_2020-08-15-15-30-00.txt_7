reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209840244-172.17.0.4-1597506333188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43414,DS-b5afe3b9-b68e-430b-833f-9faf2e88d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-edea4e7b-23cc-485d-ba64-848ae1ba9d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-639a7c33-9e3c-4011-b3d4-c96db85c256f,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-8ff8a64f-06cc-4443-864c-b7da7968fcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-8c0778e9-488f-471c-8732-3f36773e0b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-1175e6b6-187a-4705-9493-c34864035ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d772c8a6-cb36-460d-952f-99f2f54332fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-383ac624-e91e-4b57-b333-28d2b1343b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209840244-172.17.0.4-1597506333188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43414,DS-b5afe3b9-b68e-430b-833f-9faf2e88d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-edea4e7b-23cc-485d-ba64-848ae1ba9d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-639a7c33-9e3c-4011-b3d4-c96db85c256f,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-8ff8a64f-06cc-4443-864c-b7da7968fcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-8c0778e9-488f-471c-8732-3f36773e0b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-1175e6b6-187a-4705-9493-c34864035ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d772c8a6-cb36-460d-952f-99f2f54332fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-383ac624-e91e-4b57-b333-28d2b1343b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388287825-172.17.0.4-1597506875926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-578c98f8-405a-41c9-bfc9-e66757c55b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-5f28f313-09e5-4871-a5a7-126597bf2770,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-cbcb5800-e550-4a56-8211-6067bca96308,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-da6ee8ca-a8c1-46e1-94c7-6c2d374d954b,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-a839fc67-3023-48c7-8dba-a12f794d9015,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-da6beff0-990e-4e2e-a4ab-93335ea8d6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-42cf31a4-7981-4d3a-98be-e602184bf47d,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-ad3cba6e-b6d3-480d-b40a-3a1a0540576f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388287825-172.17.0.4-1597506875926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-578c98f8-405a-41c9-bfc9-e66757c55b74,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-5f28f313-09e5-4871-a5a7-126597bf2770,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-cbcb5800-e550-4a56-8211-6067bca96308,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-da6ee8ca-a8c1-46e1-94c7-6c2d374d954b,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-a839fc67-3023-48c7-8dba-a12f794d9015,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-da6beff0-990e-4e2e-a4ab-93335ea8d6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-42cf31a4-7981-4d3a-98be-e602184bf47d,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-ad3cba6e-b6d3-480d-b40a-3a1a0540576f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113072851-172.17.0.4-1597506921222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-4e5415a1-21a2-4cb0-a593-f766b0a3637e,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-97d45f37-bbf3-4657-b6fe-c40bc395fd22,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-a640e0dc-8106-4200-a689-4ce941e2f70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-0bf8a779-0b14-498a-ab1c-de4360d81463,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-5d8c6c75-d3d1-4c02-b7b7-86311102122b,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-ca1212a1-916a-4c15-ad8d-b1581acda032,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-f0843b3a-342b-47ac-b051-4b5d68acd95a,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-7fc7978b-945c-42cc-9ea5-0fe272289917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113072851-172.17.0.4-1597506921222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40377,DS-4e5415a1-21a2-4cb0-a593-f766b0a3637e,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-97d45f37-bbf3-4657-b6fe-c40bc395fd22,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-a640e0dc-8106-4200-a689-4ce941e2f70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-0bf8a779-0b14-498a-ab1c-de4360d81463,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-5d8c6c75-d3d1-4c02-b7b7-86311102122b,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-ca1212a1-916a-4c15-ad8d-b1581acda032,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-f0843b3a-342b-47ac-b051-4b5d68acd95a,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-7fc7978b-945c-42cc-9ea5-0fe272289917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51680400-172.17.0.4-1597507241047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43855,DS-21755e6e-9835-4d77-ab06-139f31c1a197,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-0bf863f5-f8be-4ed6-bd7d-52cf8d911831,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-32e1d67e-76e4-45c8-9a7f-34755a553b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-83770313-a3e8-4afa-9286-07f91810bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-2a7b4877-e3e7-4d0e-a107-78d8ce889d88,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-6dfbc837-e586-491f-9190-c9dce5749835,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-b6d0dcee-f5be-4c42-8c7f-c5300ba1b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-9b87114f-3c4b-4e49-831b-8b662591480a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51680400-172.17.0.4-1597507241047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43855,DS-21755e6e-9835-4d77-ab06-139f31c1a197,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-0bf863f5-f8be-4ed6-bd7d-52cf8d911831,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-32e1d67e-76e4-45c8-9a7f-34755a553b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-83770313-a3e8-4afa-9286-07f91810bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-2a7b4877-e3e7-4d0e-a107-78d8ce889d88,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-6dfbc837-e586-491f-9190-c9dce5749835,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-b6d0dcee-f5be-4c42-8c7f-c5300ba1b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46513,DS-9b87114f-3c4b-4e49-831b-8b662591480a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461725407-172.17.0.4-1597507426081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-e0340b84-0b3c-409f-8e73-23b3cf10782e,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-be65aaec-fa82-44ff-8537-3829f24678dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-626fe33f-4b56-47f6-ae7a-42fd0d589b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-52c71404-74cb-46e7-8f2c-29151b0e7fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-fce356de-3d69-47e0-bd3b-b212b001d825,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-6f664375-9229-43fb-8e44-afa92c872876,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-d727db20-d1c3-4a4e-9f95-9c3166f0d8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-4e8c565b-1d44-42eb-9ec2-234ae9a7094e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461725407-172.17.0.4-1597507426081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-e0340b84-0b3c-409f-8e73-23b3cf10782e,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-be65aaec-fa82-44ff-8537-3829f24678dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-626fe33f-4b56-47f6-ae7a-42fd0d589b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-52c71404-74cb-46e7-8f2c-29151b0e7fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-fce356de-3d69-47e0-bd3b-b212b001d825,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-6f664375-9229-43fb-8e44-afa92c872876,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-d727db20-d1c3-4a4e-9f95-9c3166f0d8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-4e8c565b-1d44-42eb-9ec2-234ae9a7094e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292287514-172.17.0.4-1597507606035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-a444b253-10ec-45f6-8255-c8cb328c5772,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-b1687f5b-57d5-4293-8d5a-6d55494e6ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-7fd731b9-1e88-49ce-9d51-7eef7692103a,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-a3b56950-dea4-4eaf-89fb-37621849ffc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-43e8ea50-a394-4981-9ce3-4b744bb798be,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-4d4b5a6c-0be5-4d2e-84bc-ca068c9c0388,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-23a8ad69-77a5-4d9a-a8c7-362ade17956d,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-2f5c74e2-a893-43c4-be84-6a421d6a4cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292287514-172.17.0.4-1597507606035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-a444b253-10ec-45f6-8255-c8cb328c5772,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-b1687f5b-57d5-4293-8d5a-6d55494e6ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-7fd731b9-1e88-49ce-9d51-7eef7692103a,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-a3b56950-dea4-4eaf-89fb-37621849ffc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-43e8ea50-a394-4981-9ce3-4b744bb798be,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-4d4b5a6c-0be5-4d2e-84bc-ca068c9c0388,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-23a8ad69-77a5-4d9a-a8c7-362ade17956d,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-2f5c74e2-a893-43c4-be84-6a421d6a4cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317298042-172.17.0.4-1597507642502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-b79c3dd8-f444-4709-b08a-44de777e5089,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-de4043b9-4434-4aa8-936a-5c595a53af13,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-cc40b662-0d27-4392-90c0-2fef8a5a44d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-323321bf-33a6-464d-b55f-8e639a60e8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-02fd9e03-8fc8-45a1-afbb-634662fd496b,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-9a1e46da-9194-4201-b5d1-a9f76504d6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-e95e3478-eaf7-414c-aaa6-4f278641515b,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-cf5fdc04-4c48-46ff-aa5a-d091420ebc43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317298042-172.17.0.4-1597507642502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46366,DS-b79c3dd8-f444-4709-b08a-44de777e5089,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-de4043b9-4434-4aa8-936a-5c595a53af13,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-cc40b662-0d27-4392-90c0-2fef8a5a44d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-323321bf-33a6-464d-b55f-8e639a60e8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-02fd9e03-8fc8-45a1-afbb-634662fd496b,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-9a1e46da-9194-4201-b5d1-a9f76504d6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-e95e3478-eaf7-414c-aaa6-4f278641515b,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-cf5fdc04-4c48-46ff-aa5a-d091420ebc43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173916724-172.17.0.4-1597507692289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42708,DS-fda569f3-7f6f-4c6d-9c91-681106869816,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-55fa16d7-d8d6-4864-ac0d-1a6548d785de,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-e55bdfc7-cf46-4be5-a0a3-8db4ce3ed9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-c4fb6c28-d2a8-4ec9-9518-5b194bcc0dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-a689dd58-1410-481f-9bc6-3f958efaa2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-31109425-2f62-4a73-ab2c-aadf571905cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-f4d9611f-d2ef-4ef4-a1eb-7e49fab45de9,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-1cb5a223-5950-40c0-bc14-0657a7705f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173916724-172.17.0.4-1597507692289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42708,DS-fda569f3-7f6f-4c6d-9c91-681106869816,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-55fa16d7-d8d6-4864-ac0d-1a6548d785de,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-e55bdfc7-cf46-4be5-a0a3-8db4ce3ed9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-c4fb6c28-d2a8-4ec9-9518-5b194bcc0dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-a689dd58-1410-481f-9bc6-3f958efaa2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-31109425-2f62-4a73-ab2c-aadf571905cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-f4d9611f-d2ef-4ef4-a1eb-7e49fab45de9,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-1cb5a223-5950-40c0-bc14-0657a7705f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348414402-172.17.0.4-1597508701168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36261,DS-fb859d60-9c16-4875-ba65-c9ce526fd726,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-00a3274c-8645-450a-bd22-de4db69ea7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a8cb9117-ec61-4d7c-b768-c35ea8169ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-f4c4ab2c-a86a-49cb-bfe9-5c0c62dec155,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-4dceb67c-f654-41e7-833b-5667e803a137,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-54354c9d-8f1e-46d9-9782-2f72c7aa9b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-6b39ceba-5631-436c-8f00-7ac0adfb08a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-24ce2db9-a69c-4cd3-9218-99f9f3b54330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348414402-172.17.0.4-1597508701168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36261,DS-fb859d60-9c16-4875-ba65-c9ce526fd726,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-00a3274c-8645-450a-bd22-de4db69ea7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a8cb9117-ec61-4d7c-b768-c35ea8169ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-f4c4ab2c-a86a-49cb-bfe9-5c0c62dec155,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-4dceb67c-f654-41e7-833b-5667e803a137,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-54354c9d-8f1e-46d9-9782-2f72c7aa9b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-6b39ceba-5631-436c-8f00-7ac0adfb08a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-24ce2db9-a69c-4cd3-9218-99f9f3b54330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777863209-172.17.0.4-1597508916559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41211,DS-0494698d-0c2d-4d90-a1f2-a58cdb2a0ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-708b8fc1-69cd-4db4-b801-8f5ea01d115d,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-8ffe08b2-fad0-468b-a3dd-b3b4d57808f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-d6904443-0388-4b14-8bda-bdbec120ef05,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-779874ae-628c-4761-b152-2e72fdae702f,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-686da9e2-11a2-48eb-a8a7-ff2050a109a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-e27e6dcf-95ce-49eb-bd64-5ec5cdbc2326,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-988f3006-988f-4513-8773-193cf4545ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777863209-172.17.0.4-1597508916559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41211,DS-0494698d-0c2d-4d90-a1f2-a58cdb2a0ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-708b8fc1-69cd-4db4-b801-8f5ea01d115d,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-8ffe08b2-fad0-468b-a3dd-b3b4d57808f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-d6904443-0388-4b14-8bda-bdbec120ef05,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-779874ae-628c-4761-b152-2e72fdae702f,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-686da9e2-11a2-48eb-a8a7-ff2050a109a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-e27e6dcf-95ce-49eb-bd64-5ec5cdbc2326,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-988f3006-988f-4513-8773-193cf4545ab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526834033-172.17.0.4-1597509476246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-a8fba5fd-ccc6-4894-a837-82a1af9bf4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-8142659c-c998-4a44-b99d-1731933e40f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-2df6d581-aefa-44e2-a12e-506c54420564,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-520b56e0-b86c-437b-b898-af56e751ee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-4748ae78-3f84-409c-9d49-b9c9abfe73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-29e244fd-59a1-43f0-b9df-f90d8e68dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-c1774cb1-1adb-47f0-85fa-9d08136bbdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-2f9c22ec-16d6-411c-9e2a-dbf293c6b63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526834033-172.17.0.4-1597509476246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39816,DS-a8fba5fd-ccc6-4894-a837-82a1af9bf4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-8142659c-c998-4a44-b99d-1731933e40f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-2df6d581-aefa-44e2-a12e-506c54420564,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-520b56e0-b86c-437b-b898-af56e751ee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-4748ae78-3f84-409c-9d49-b9c9abfe73d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-29e244fd-59a1-43f0-b9df-f90d8e68dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-c1774cb1-1adb-47f0-85fa-9d08136bbdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-2f9c22ec-16d6-411c-9e2a-dbf293c6b63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823986006-172.17.0.4-1597510165367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38393,DS-9f67939e-7cfc-4b12-8204-50a101a3f800,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-5a4430b4-1933-4d6b-920b-ef9be77cd38f,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-b7e7eee1-9f2f-423c-adf0-cf55ac07d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-16e84f74-07f0-4919-aab2-2bf9fdb7e809,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-406d0297-5436-4f20-a72f-aefb903bfe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-4981d82e-892c-4bd2-bd95-bc845712fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-48b8a49f-701e-4f3b-bfe1-a09ce74e5137,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-3778ac66-916c-4947-bfdc-3704069cb217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823986006-172.17.0.4-1597510165367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38393,DS-9f67939e-7cfc-4b12-8204-50a101a3f800,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-5a4430b4-1933-4d6b-920b-ef9be77cd38f,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-b7e7eee1-9f2f-423c-adf0-cf55ac07d30a,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-16e84f74-07f0-4919-aab2-2bf9fdb7e809,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-406d0297-5436-4f20-a72f-aefb903bfe2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-4981d82e-892c-4bd2-bd95-bc845712fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-48b8a49f-701e-4f3b-bfe1-a09ce74e5137,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-3778ac66-916c-4947-bfdc-3704069cb217,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662985162-172.17.0.4-1597510311253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34598,DS-261b8769-2a78-4d89-b120-dd2764c78fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-729cc9c5-f612-4a61-b016-1b0a36f43abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-256755cf-2e96-436d-ade9-92a1adb91b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-128a4f01-27c4-448d-ad07-36998146f0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-54fc4ad7-3e96-4bd1-889b-38110c0b2b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-12616c82-b37a-48b0-8fb9-e8bcbf781edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-4c014f06-e4c5-4040-a654-246c7e44edef,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-00ec80c6-70e4-42d5-b7f3-65a58d7dd7db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662985162-172.17.0.4-1597510311253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34598,DS-261b8769-2a78-4d89-b120-dd2764c78fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-729cc9c5-f612-4a61-b016-1b0a36f43abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-256755cf-2e96-436d-ade9-92a1adb91b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-128a4f01-27c4-448d-ad07-36998146f0da,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-54fc4ad7-3e96-4bd1-889b-38110c0b2b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-12616c82-b37a-48b0-8fb9-e8bcbf781edb,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-4c014f06-e4c5-4040-a654-246c7e44edef,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-00ec80c6-70e4-42d5-b7f3-65a58d7dd7db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496310320-172.17.0.4-1597510478083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43334,DS-d2383150-4b0a-4445-ae38-18795bd318c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-976558e8-cf07-41f2-a965-104d8316d20f,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-fe0af106-9ab6-4381-8434-79338936a703,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-ab932970-009e-4a1a-a3d8-9bd972ff5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-54b27553-c483-48ca-8f13-66053fb29b10,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-730bbe31-9bc4-431c-931a-49225a658d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-0f71738b-cbdc-40cc-988d-f874adf2acbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-23e24694-390e-4c02-85a4-35c78e6904f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496310320-172.17.0.4-1597510478083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43334,DS-d2383150-4b0a-4445-ae38-18795bd318c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-976558e8-cf07-41f2-a965-104d8316d20f,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-fe0af106-9ab6-4381-8434-79338936a703,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-ab932970-009e-4a1a-a3d8-9bd972ff5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-54b27553-c483-48ca-8f13-66053fb29b10,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-730bbe31-9bc4-431c-931a-49225a658d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-0f71738b-cbdc-40cc-988d-f874adf2acbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-23e24694-390e-4c02-85a4-35c78e6904f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596343847-172.17.0.4-1597510568038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44028,DS-4f6ddd8a-6768-420b-93c2-13c4554b7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-a67b5239-bf13-4ae5-a6bf-f5ab41d21720,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-19cf8034-47f7-4a4d-9e2b-c1874f520c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-c1e2aaea-29bd-47a8-a184-94db56961048,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-41b012c1-7117-4794-b992-c6bf05a72655,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-233337cc-4e59-4aa6-b376-94cfc99dbf00,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-af731360-5bd2-4caf-8619-7ba9066a7305,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-324d8b8b-e2c2-481a-b2b0-d19ec08ddcf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596343847-172.17.0.4-1597510568038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44028,DS-4f6ddd8a-6768-420b-93c2-13c4554b7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-a67b5239-bf13-4ae5-a6bf-f5ab41d21720,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-19cf8034-47f7-4a4d-9e2b-c1874f520c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-c1e2aaea-29bd-47a8-a184-94db56961048,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-41b012c1-7117-4794-b992-c6bf05a72655,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-233337cc-4e59-4aa6-b376-94cfc99dbf00,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-af731360-5bd2-4caf-8619-7ba9066a7305,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-324d8b8b-e2c2-481a-b2b0-d19ec08ddcf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545040654-172.17.0.4-1597511002889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-7c05397c-8803-48d8-8263-6fb83efe83e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-4bf3a66d-1ba7-4486-96b2-6782512b4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-a53e2301-c35e-4dfd-afe5-24689a05fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-d64ce9be-5522-4e99-b5cd-3239bd90e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-e4415b13-20df-4759-a180-27efe1945c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-e643d72a-496c-4b7a-ba5c-48f1741fc518,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-a0f87aba-8121-48ee-b32e-88028826bf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-7db63f98-44f6-483a-8200-e1bd378c9189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545040654-172.17.0.4-1597511002889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39735,DS-7c05397c-8803-48d8-8263-6fb83efe83e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-4bf3a66d-1ba7-4486-96b2-6782512b4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-a53e2301-c35e-4dfd-afe5-24689a05fbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-d64ce9be-5522-4e99-b5cd-3239bd90e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-e4415b13-20df-4759-a180-27efe1945c90,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-e643d72a-496c-4b7a-ba5c-48f1741fc518,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-a0f87aba-8121-48ee-b32e-88028826bf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-7db63f98-44f6-483a-8200-e1bd378c9189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777067160-172.17.0.4-1597511497077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38190,DS-bfb46336-df17-4c14-81f8-b10712c5d0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-e2ff97ca-b07f-43ab-9be3-841020e1375b,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-118c1817-b07e-419d-b247-8f84a0510270,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-18006d37-6857-4470-ba23-3ab85c1dd397,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-18c45e88-8e4d-40d0-aeeb-83be79578344,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-7e1caf60-119c-4fcd-aa8a-4d10b94908ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-82873c49-2e1f-4716-be60-e4853af5cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-63c21d61-a7bd-4ab3-86d1-0c4c85d41547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777067160-172.17.0.4-1597511497077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38190,DS-bfb46336-df17-4c14-81f8-b10712c5d0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-e2ff97ca-b07f-43ab-9be3-841020e1375b,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-118c1817-b07e-419d-b247-8f84a0510270,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-18006d37-6857-4470-ba23-3ab85c1dd397,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-18c45e88-8e4d-40d0-aeeb-83be79578344,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-7e1caf60-119c-4fcd-aa8a-4d10b94908ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-82873c49-2e1f-4716-be60-e4853af5cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-63c21d61-a7bd-4ab3-86d1-0c4c85d41547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189512463-172.17.0.4-1597511693383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-d891cf5b-69e5-4404-9c83-6ac20a64224b,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-ea4fab74-3b20-4072-b27b-2b696ba9f9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-e2590dc9-5a15-4e3d-9944-338cff483937,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-0dcbbafb-37bc-4d91-9d5a-98d9a58fb75b,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-4d0f83da-55df-4f1d-867b-3fd47d142219,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-2b071e0f-0943-4f64-a4b6-50713012a857,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-3e6bf2b2-28d3-4e84-a5f9-fa5cd28819bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-f4fbd773-5ab2-4e96-8f6c-7a107667206b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189512463-172.17.0.4-1597511693383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-d891cf5b-69e5-4404-9c83-6ac20a64224b,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-ea4fab74-3b20-4072-b27b-2b696ba9f9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-e2590dc9-5a15-4e3d-9944-338cff483937,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-0dcbbafb-37bc-4d91-9d5a-98d9a58fb75b,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-4d0f83da-55df-4f1d-867b-3fd47d142219,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-2b071e0f-0943-4f64-a4b6-50713012a857,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-3e6bf2b2-28d3-4e84-a5f9-fa5cd28819bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-f4fbd773-5ab2-4e96-8f6c-7a107667206b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599389489-172.17.0.4-1597512275571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-0f856958-5f02-4416-8236-ee40116f7637,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-590b9b38-f05f-4669-a2f0-e84c7954837b,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-e838bad1-a128-4e55-945c-6ee0b09f18e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-ae6c394c-0129-499b-8826-b81e2594b2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-2538d2c4-8807-4c1b-8e01-a6a4bd600ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-05c93582-b798-4e81-97b4-90de7b308a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-a861aaf4-5aa8-4d2d-aa18-a0b255dfbe70,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-6cd2418f-9c52-4ed0-9501-a1c2819be61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599389489-172.17.0.4-1597512275571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-0f856958-5f02-4416-8236-ee40116f7637,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-590b9b38-f05f-4669-a2f0-e84c7954837b,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-e838bad1-a128-4e55-945c-6ee0b09f18e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-ae6c394c-0129-499b-8826-b81e2594b2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-2538d2c4-8807-4c1b-8e01-a6a4bd600ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-05c93582-b798-4e81-97b4-90de7b308a15,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-a861aaf4-5aa8-4d2d-aa18-a0b255dfbe70,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-6cd2418f-9c52-4ed0-9501-a1c2819be61a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6903
